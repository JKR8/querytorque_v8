You are an expert database performance analyst. Your job is to deeply analyze a slow SQL query, identify the root cause of its performance problems, and propose specific structural changes.

You follow a rigorous methodology: understand the structure, profile the costs, identify the mechanism (not just the symptom), propose changes with correctness reasoning, and learn from past failures.

## Query: query_1
## Dialect: duckdb

```sql
WITH customer_total_return AS (
  SELECT
    sr_customer_sk AS ctr_customer_sk,
    sr_store_sk AS ctr_store_sk,
    SUM(sr_return_amt) AS ctr_total_return
  FROM store_returns, date_dim
  WHERE
    sr_returned_date_sk = d_date_sk AND d_year = 2000
  GROUP BY
    sr_customer_sk,
    sr_store_sk
)
SELECT
  c_customer_id
FROM customer_total_return AS ctr1, store, customer
WHERE
  ctr1.ctr_total_return > (
    SELECT
      AVG(ctr_total_return) * 1.2
    FROM customer_total_return AS ctr2
    WHERE
      ctr1.ctr_store_sk = ctr2.ctr_store_sk
  )
  AND s_store_sk = ctr1.ctr_store_sk
  AND s_state = 'TN'
  AND ctr1.ctr_customer_sk = c_customer_sk
ORDER BY
  c_customer_id
LIMIT 100
```

## Query Structure (DAG)

- **customer_total_return** (cte, depth 0, **50%** cost) [GROUP_BY]
   tables: store_returns, date_dim
  operators: HASH_GROUP_BY, SEQ_SCAN[store_returns], SEQ_SCAN[date_dim]
  sql: `SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(sr_return_amt) AS ctr_total_return FROM store_returns, date_dim WHERE sr_returned_date_sk = d_date_sk AND d_year = 2000 GROUP...`
- **main_query** (main, depth 1, **50%** cost) [GROUP_BY, CORRELATED] ← reads [customer_total_return, customer_total_return]
   tables: customer_total_return, store, customer, customer_total_return
  operators: HASH_GROUP_BY, HASH_JOIN, SEQ_SCAN[customer_total_return], SEQ_SCAN[store], SEQ_SCAN[customer]
  sql: `SELECT c_customer_id FROM customer_total_return AS ctr1, store, customer WHERE ctr1.ctr_total_return > (SELECT AVG(ctr_total_return) * 1.2 FROM customer_total_return AS ctr2 WHERE ctr1.ctr_store_sk = ...`

## Known Effective Patterns (from benchmark history)

- **date_cte_isolate**: 12 wins, 1.34x avg. 

## Known Regressions (DO NOT repeat these)

- **OR_TO_UNION_GUARD_Q90**: 0.59x. Doubles the fact table scan

## Reference Examples

**FAISS selected (by structural similarity):** decorrelate, materialize_cte, union_cte_split

**All available gold examples:**

- **decorrelate** (2.92xx) — Convert correlated subquery to JOIN
- **date_cte_isolate** (4.00xx) — Pre-filter date_dim into CTE
- **early_filter** (4.00xx) — Push filters into CTEs
- **pushdown** (2.11xx) — Push predicates into subqueries

## Your Task

Analyze this query following these steps IN ORDER:

### 1. STRUCTURAL BREAKDOWN
For each CTE/subquery/block, explain in 1-2 sentences:
- What it computes (in plain language)
- What tables it reads and approximately how many rows
- What it outputs (cardinality estimate)

### 2. BOTTLENECK IDENTIFICATION
Using the DAG costs above, identify the dominant cost center.
Don't just name it — explain the MECHANISM:
- Is it a full table scan that could be filtered?
- Is it a sort for a window function that could be deferred?
- Is it a hash join on a large build side that could be pre-filtered?
- Is it scanning the same table multiple times when once would suffice?

### 3. PROPOSED OPTIMIZATION
Propose 1-3 specific structural changes. For EACH one:
- **What**: Exactly what to change (e.g., 'merge CTEs X and Y into one scan')
- **Why**: The performance mechanism (e.g., 'eliminates a 28M-row rescan of store_sales')
- **Risk**: What semantic constraint could break (e.g., 'the HAVING filter must be preserved')
- **Estimated impact**: minor / moderate / significant

### 5. RECOMMENDED STRATEGY
Synthesize everything into a single recommended optimization approach.
Be specific enough that another engineer could implement it from your description.

### 6. EXAMPLE SELECTION
FAISS selected these examples: decorrelate, materialize_cte, union_cte_split
Review the FAISS picks against the available examples above.
If you think different examples would be more relevant for this query,
list your preferred examples. Otherwise confirm the FAISS picks are good.

```
EXAMPLES: example_id_1, example_id_2, example_id_3
```

Use exact IDs from the available examples list above.
