You are analyzing 5 failed optimization attempts to design a refined approach that reaches 2.0x speedup.

Your job: understand WHY each attempt fell short, identify unexplored optimization angles, and synthesize a NEW strategy that combines the best insights while avoiding repeated mistakes.

## Query: query_3
## Target: 2.0x speedup
## Dialect: duckdb

```sql
-- start query 3 in stream 0 using template query3.tpl
select dt.d_year 
       ,item.i_brand_id brand_id 
       ,item.i_brand brand
       ,sum(ss_sales_price) sum_agg
 from  date_dim dt 
      ,store_sales
      ,item
 where dt.d_date_sk = store_sales.ss_sold_date_sk
   and store_sales.ss_item_sk = item.i_item_sk
   and item.i_manufact_id = 816
   and dt.d_moy=11
 group by dt.d_year
      ,item.i_brand
      ,item.i_brand_id
 order by dt.d_year
         ,sum_agg desc
         ,brand_id
 LIMIT 100;

-- end query 3 in stream 0 using template query3.tpl
```

## Previous Attempts

### Worker 1: conservative_early_filtering
- **Status**: pass (0.94x)
- **Transforms**: none
- **Examples used**: early_filter, pushdown, date_cte_isolate
- **Strategy hint**: Apply aggressive predicate pushdown by pre‑filtering dimension tables in CTEs before joining, minimizing fact‑table rows early.

```sql
WITH filtered_date AS (
    SELECT d_date_sk, d_year
    FROM date_dim
    WHERE d_moy = 11
), filtered_item AS (
    SELECT i_item_sk, i_brand_id, i_brand
    FROM item
    WHERE i_manufact_id = 816
)
SELECT
    fd.d_year,
    fi.i_brand_id AS brand_id,
    fi.i_brand AS brand,
    SUM(ss.ss_sales_price) AS sum_agg
FROM store_sales ss
JOIN filtered_date fd ON ss.ss_sold_date_sk = fd.d_date_sk
JOIN filtered_item fi ON ss.ss_item_sk = fi.i_item_sk
GROUP BY
    fd.d_year,
    fi.i_brand,
    fi.i_brand_id
ORDER BY
    fd.d_year,
    sum_agg DESC,
    brand_id
LIMIT 100
```

### Worker 2: moderate_dimension_isolation
- **Status**: pass (0.98x)
- **Transforms**: none
- **Examples used**: dimension_cte_isolate, multi_dimension_prefetch, multi_date_range_cte
- **Strategy hint**: Isolate each filtered dimension (date_dim, item) into separate CTEs, then join with the fact table, enabling better predicate pushdown and join ordering.

```sql
WITH filtered_dates AS (
    SELECT d_date_sk, d_year
    FROM date_dim
    WHERE d_moy = 11
),
filtered_items AS (
    SELECT i_item_sk, i_brand_id, i_brand
    FROM item
    WHERE i_manufact_id = 816
)
SELECT
    dt.d_year,
    item.i_brand_id AS brand_id,
    item.i_brand AS brand,
    SUM(ss_sales_price) AS sum_agg
FROM store_sales
JOIN filtered_dates AS dt ON store_sales.ss_sold_date_sk = dt.d_date_sk
JOIN filtered_items AS item ON store_sales.ss_item_sk = item.i_item_sk
GROUP BY
    dt.d_year,
    item.i_brand,
    item.i_brand_id
ORDER BY
    dt.d_year,
    sum_agg DESC,
    brand_id
LIMIT 100
```

### Worker 3: aggressive_cte_restructuring
- **Status**: pass (1.04x)
- **Transforms**: none
- **Examples used**: prefetch_fact_join, shared_dimension_multi_channel, single_pass_aggregation
- **Strategy hint**: Restructure into a multi‑step CTE pipeline: pre‑filter dimensions, pre‑join with facts, then aggregate in a single pass, sharing filtered dimensions across channels.

```sql
WITH filtered_dates AS (
  SELECT d_date_sk, d_year
  FROM date_dim
  WHERE d_moy = 11
),
filtered_items AS (
  SELECT i_item_sk, i_brand_id, i_brand
  FROM item
  WHERE i_manufact_id = 816
),
joined_sales AS (
  SELECT
    dt.d_year,
    it.i_brand_id,
    it.i_brand,
    ss.ss_sales_price
  FROM store_sales ss
  JOIN filtered_dates dt ON ss.ss_sold_date_sk = dt.d_date_sk
  JOIN filtered_items it ON ss.ss_item_sk = it.i_item_sk
)
SELECT
  d_year,
  i_brand_id AS brand_id,
  i_brand AS brand,
  SUM(ss_sales_price) AS sum_agg
FROM joined_sales
GROUP BY
  d_year,
  i_brand,
  i_brand_id
-- ... (truncated)
```

### Worker 4: novel_structural_transform
- **Status**: pass (0.97x)
- **Transforms**: none
- **Examples used**: or_to_union, intersect_to_exists, decorrelate
- **Strategy hint**: Apply structural transformations such as splitting OR conditions into UNION ALL, converting INTERSECT to EXISTS, and decorrelating subqueries to unlock alternative join plans.

```sql
WITH filtered_dates AS (
  SELECT d_date_sk, d_year
  FROM date_dim
  WHERE d_moy = 11
),
filtered_items AS (
  SELECT i_item_sk, i_brand_id, i_brand
  FROM item
  WHERE i_manufact_id = 816
)
SELECT
  fd.d_year,
  fi.i_brand_id AS brand_id,
  fi.i_brand AS brand,
  SUM(ss.ss_sales_price) AS sum_agg
FROM store_sales ss
JOIN filtered_dates fd ON ss.ss_sold_date_sk = fd.d_date_sk
JOIN filtered_items fi ON ss.ss_item_sk = fi.i_item_sk
GROUP BY
  fd.d_year,
  fi.i_brand,
  fi.i_brand_id
ORDER BY
  fd.d_year,
  sum_agg DESC,
  brand_id
LIMIT 100
```

### Worker 5: refined_snipe
- **Status**: pass (1.04x)
- **Transforms**: none
- **Examples used**: 
- **Strategy hint**: Snipe from iter 1

```sql
WITH filtered_dates AS (
  SELECT d_date_sk, d_year
  FROM date_dim
  WHERE d_moy = 11
),
filtered_items AS (
  SELECT i_item_sk, i_brand_id, i_brand
  FROM item
  WHERE i_manufact_id = 816
)
SELECT
  dt.d_year,
  fi.i_brand_id AS brand_id,
  fi.i_brand AS brand,
  SUM(ss.ss_sales_price) AS sum_agg
FROM store_sales ss
JOIN filtered_dates dt ON ss.ss_sold_date_sk = dt.d_date_sk
JOIN filtered_items fi ON ss.ss_item_sk = fi.i_item_sk
GROUP BY
  dt.d_year,
  fi.i_brand,
  fi.i_brand_id
ORDER BY
  dt.d_year,
  sum_agg DESC,
  brand_id
LIMIT 100
```

## DAG Structure & Bottlenecks

| Node | Role | Cost % |
|------|------|-------:|
| main_query |  | 0.0% |

## Available Examples (Full Catalog)

- **composite_decorrelate_union** (2.42xx) — Decorrelate multiple correlated EXISTS subqueries into pre-materialized DISTINCT
- **date_cte_isolate** (4.00xx) — Extract date filtering into a separate CTE to enable predicate pushdown and redu
- **decorrelate** (2.92xx) — Convert correlated subquery to separate CTE with GROUP BY, then JOIN
- **deferred_window_aggregation** (1.36xx) — When multiple CTEs each perform GROUP BY + WINDOW (cumulative sum), then are joi
- **dimension_cte_isolate** (1.93xx) — Pre-filter ALL dimension tables into CTEs before joining with fact table, not ju
- **early_filter** (4.00xx) — Filter dimension tables FIRST, then join to fact tables to reduce expensive join
- **intersect_to_exists** (1.83xx) — Convert INTERSECT subquery pattern to multiple EXISTS clauses for better join pl
- **materialize_cte** (1.37xx) — Extract repeated subquery patterns into a CTE to avoid recomputation
- **multi_date_range_cte** (2.35xx) — When query uses multiple date_dim aliases with different filters (d1, d2, d3), c
- **multi_dimension_prefetch** (2.71xx) — Pre-filter multiple dimension tables (date + store) into separate CTEs before jo
- **or_to_union** (3.17xx) — Split OR conditions on different columns into UNION ALL branches for better inde
- **prefetch_fact_join** (3.77xx) — Pre-filter dimension table into CTE, then pre-join with fact table in second CTE
- **pushdown** (2.11xx) — Push filters from outer query into CTEs/subqueries to reduce intermediate result
- **shared_dimension_multi_channel** (1.30xx) — Extract shared dimension filters (date, item, promotion) into CTEs when multiple
- **single_pass_aggregation** (4.47xx) — Consolidate multiple subqueries scanning the same table into a single CTE with c
- **union_cte_split** (1.36xx) — Split a generic UNION ALL CTE into specialized CTEs when the main query filters 

## Your Task

Analyze the failed attempts and design a refined approach:

1. **Failure Analysis**: Why did all attempts fall short? Be specific about mechanisms.
2. **Common Patterns**: What did multiple workers try unsuccessfully?
3. **Unexplored Space**: What optimization angles were missed entirely?
4. **Refined Strategy**: Synthesize a NEW approach combining best insights.

### Output Format (follow EXACTLY)

```
FAILURE_ANALYSIS:
<Why all workers fell short — be specific about mechanisms>

UNEXPLORED_OPPORTUNITIES:
<What optimization approaches haven't been tried>

REFINED_STRATEGY:
<Concrete optimization approach for next attempt>

EXAMPLES: <ex1>, <ex2>, <ex3>
HINT: <specific guidance for the refined attempt>
```