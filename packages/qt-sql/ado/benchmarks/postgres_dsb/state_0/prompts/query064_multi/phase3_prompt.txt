You are a SQL query rewrite engine.

Your goal: rewrite the complete SQL query to maximize execution speed
while preserving exact semantic equivalence (same rows, same columns,
same ordering).

You will receive the full query, its DAG structure showing how CTEs and
subqueries connect, cost analysis per node, and suggested rewrite patterns.
You may restructure the query freely: create new CTEs, merge existing ones,
push filters across node boundaries, or decompose subqueries.

## Query: query064_multi

```sql
WITH cs_ui AS (
  SELECT
    cs_item_sk,
    SUM(cs_ext_list_price) AS sale,
    SUM(cr_refunded_cash + cr_reversed_charge + cr_store_credit) AS refund
  FROM catalog_sales, catalog_returns
  WHERE
    cs_item_sk = cr_item_sk
    AND cs_order_number = cr_order_number
    AND cs_wholesale_cost BETWEEN 34 AND 54
  GROUP BY
    cs_item_sk
  HAVING
    SUM(cs_ext_list_price) > 2 * SUM(cr_refunded_cash + cr_reversed_charge + cr_store_credit)
), cross_sales AS (
  SELECT
    i_product_name AS product_name,
    i_item_sk AS item_sk,
    s_store_name AS store_name,
    s_zip AS store_zip,
    ad1.ca_street_number AS b_street_number,
    ad1.ca_street_name AS b_street_name,
    ad1.ca_city AS b_city,
    ad1.ca_zip AS b_zip,
    ad2.ca_street_number AS c_street_number,
    ad2.ca_street_name AS c_street_name,
    ad2.ca_city AS c_city,
    ad2.ca_zip AS c_zip,
    d1.d_year AS syear,
    d2.d_year AS fsyear,
    d3.d_year AS s2year,
    COUNT(*) AS cnt,
    SUM(ss_wholesale_cost) AS s1,
    SUM(ss_list_price) AS s2,
    SUM(ss_coupon_amt) AS s3
  FROM store_sales, store_returns, cs_ui, date_dim AS d1, date_dim AS d2, date_dim AS d3, store, customer, customer_demographics AS cd1, customer_demographics AS cd2, promotion, household_demographics AS hd1, household_demographics AS hd2, customer_address AS ad1, customer_address AS ad2, income_band AS ib1, income_band AS ib2, item
  WHERE
    ss_store_sk = s_store_sk
    AND ss_sold_date_sk = d1.d_date_sk
    AND ss_customer_sk = c_customer_sk
    AND ss_cdemo_sk = cd1.cd_demo_sk
    AND ss_hdemo_sk = hd1.hd_demo_sk
    AND ss_addr_sk = ad1.ca_address_sk
    AND ss_item_sk = i_item_sk
    AND ss_item_sk = sr_item_sk
    AND ss_ticket_number = sr_ticket_number
    AND ss_item_sk = cs_ui.cs_item_sk
    AND c_current_cdemo_sk = cd2.cd_demo_sk
    AND c_current_hdemo_sk = hd2.hd_demo_sk
    AND c_current_addr_sk = ad2.ca_address_sk
    AND c_first_sales_date_sk = d2.d_date_sk
    AND c_first_shipto_date_sk = d3.d_date_sk
    AND ss_promo_sk = p_promo_sk
    AND hd1.hd_income_band_sk = ib1.ib_income_band_sk
    AND hd2.hd_income_band_sk = ib2.ib_income_band_sk
    AND cd1.cd_marital_status <> cd2.cd_marital_status
    AND i_current_price BETWEEN 20 AND 20 + 10
    AND p_channel_email = 'Y'
    AND p_channel_tv = 'N'
    AND p_channel_radio = 'Y'
    AND ad2.ca_state IN ('LA', 'TX', 'VA')
    AND ss_wholesale_cost BETWEEN 34 AND 54
    AND cd1.cd_marital_status IN ('M', 'M', 'U')
    AND cd1.cd_education_status IN ('Unknown', 'College', 'College')
    AND cd2.cd_marital_status IN ('M', 'M', 'U')
    AND cd2.cd_education_status IN ('Unknown', 'College', 'College')
  GROUP BY
    i_product_name,
    i_item_sk,
    s_store_name,
    s_zip,
    ad1.ca_street_number,
    ad1.ca_street_name,
    ad1.ca_city,
    ad1.ca_zip,
    ad2.ca_street_number,
    ad2.ca_street_name,
    ad2.ca_city,
    ad2.ca_zip,
    d1.d_year,
    d2.d_year,
    d3.d_year
)
SELECT
  cs1.product_name,
  cs1.store_name,
  cs1.store_zip,
  cs1.b_street_number,
  cs1.b_street_name,
  cs1.b_city,
  cs1.b_zip,
  cs1.c_street_number,
  cs1.c_street_name,
  cs1.c_city,
  cs1.c_zip,
  cs1.syear,
  cs1.cnt,
  cs1.s1 AS s11,
  cs1.s2 AS s21,
  cs1.s3 AS s31,
  cs2.s1 AS s12,
  cs2.s2 AS s22,
  cs2.s3 AS s32,
  cs2.syear,
  cs2.cnt
FROM cross_sales AS cs1, cross_sales AS cs2
WHERE
  cs1.item_sk = cs2.item_sk
  AND cs1.syear = 1998
  AND cs2.syear = 1998 + 1
  AND cs2.cnt <= cs1.cnt
  AND cs1.store_name = cs2.store_name
  AND cs1.store_zip = cs2.store_zip
ORDER BY
  cs1.product_name,
  cs1.store_name,
  cs2.cnt,
  cs1.s1,
  cs2.s1
```

## DAG Topology

```sql
-- DAG TOPOLOGY
-- Depth 0:
--   cs_ui (cte, 33% cost) [GROUP_BY]
--     outputs: [cs_item_sk, sale, refund]
-- Depth 1:
--   cross_sales (cte, 33% cost) [GROUP_BY] ← reads [cs_ui]
--     outputs: [product_name, item_sk, store_name, store_zip, b_street_number, b_street_name, b_city, b_zip, ...]
-- Depth 2:
--   main_query (main, 33% cost) [GROUP_BY] ← reads [cross_sales, cross_sales]
--     outputs: [product_name, store_name, store_zip, b_street_number, b_street_name, b_city, b_zip, c_street_number, ...]
-- Edges:
--   cs_ui → cross_sales
--   cross_sales → main_query
--   cross_sales → main_query
```

## Performance Profile

**cs_ui**: 33% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, SEQ_SCAN[catalog_sales], SEQ_SCAN[catalog_returns]
**cross_sales**: 33% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, HASH_JOIN, SEQ_SCAN[store_sales], SEQ_SCAN[store_returns], SEQ_SCAN[cs_ui]
**main_query**: 33% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, HASH_JOIN, SEQ_SCAN[cross_sales], SEQ_SCAN[cross_sales]

## Suggested Rewrite Strategy

Phase 2 analysis identified these optimization opportunities:

- **cs_ui** → apply **pushdown**
  Heuristic: 33.3% cost, flags=['GROUP_BY']
- **cross_sales** → apply **date_cte_isolate**
  Heuristic: 33.3% cost, flags=['GROUP_BY']

Nodes not flagged (low cost or no opportunity):
- main_query: No matching pattern for flags=['GROUP_BY']

## Reference Example: date_cte_isolate

### BEFORE (slow)
```sql
[main_query]:
SELECT a.ca_state state, count(*) cnt
FROM customer_address a, customer c, store_sales s, date_dim d, item i
WHERE a.ca_address_sk = c.c_current_addr_sk
  AND c.c_customer_sk = s.ss_customer_sk
  AND s.ss_sold_date_sk = d.d_date_sk
  AND s.ss_item_sk = i.i_item_sk
  AND d.d_month_seq = (SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1)
  AND i.i_current_price > 1.2 * (SELECT avg(j.i_current_price) FROM item j WHERE j.i_category = i.i_category)
GROUP BY a.ca_state HAVING count(*) >= 10
ORDER BY cnt, a.ca_state LIMIT 100
```

**Key insight:** Extract date month_seq subquery into CTE. Extract category average into separate CTE with GROUP BY. Join instead of correlated subquery. This allows each CTE to be scanned once.

### AFTER (fast)
[target_month]:
```sql
SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1
```
[category_avg_price]:
```sql
SELECT i_category, AVG(i_current_price) * 1.2 AS avg_threshold FROM item GROUP BY i_category
```
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim JOIN target_month ON d_month_seq = target_month.d_month_seq
```
[filtered_sales]:
```sql
SELECT ss_customer_sk, ss_item_sk FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk
```
[main_query]:
```sql
SELECT a.ca_state AS state, COUNT(*) AS cnt FROM customer_address a JOIN customer c ON a.ca_address_sk = c.c_current_addr_sk JOIN filtered_sales s ON c.c_customer_sk = s.ss_customer_sk JOIN item i ON s.ss_item_sk = i.i_item_sk JOIN category_avg_price cap ON i.i_category = cap.i_category WHERE i.i_current_price > cap.avg_threshold GROUP BY a.ca_state HAVING COUNT(*) >= 10 ORDER BY cnt, a.ca_state LIMIT 100
```

### When NOT to use this pattern
Do not use when the optimizer already pushes date predicates effectively (e.g., simple equality filters on date columns in self-joins). Do not decompose an already-efficient existing CTE into sub-CTEs — this adds materialization overhead without reducing scans. Caused 0.49x regression on Q31 (DuckDB already optimized the date pushdown) and 0.71x on Q1 (decomposed a well-structured CTE into slower pieces).

## Constraints

### CRITICAL — Correctness Guards (top of sandwich)

**SEMANTIC_EQUIVALENCE**
The rewritten query MUST return exactly the same rows, columns, and
ordering as the original. This is the prime directive.

**LITERAL_PRESERVATION**
Keep all literal values (dates, strings, numbers) exactly as they appear in
the original SQL. Do not round, truncate, or reformat them.

### HIGH — Performance and Style Rules (middle of sandwich)

**NO_UNFILTERED_DIM_CTE**
When creating a new CTE that scans a dimension table, include at least one
filter predicate. Never materialize an entire dimension without a WHERE clause.

**OR_TO_UNION_LIMIT**
When converting OR predicates to UNION ALL, limit to 4 branches maximum.
Beyond 4, the UNION overhead exceeds the OR scan cost for most planners.

**EXPLICIT_JOINS**
Convert comma-separated implicit joins to explicit JOIN ... ON syntax.
This gives the optimizer better join-order freedom.

### CRITICAL — Correctness Guards (bottom of sandwich)

**KEEP_EXISTS_AS_EXISTS**
Preserve EXISTS/NOT EXISTS subqueries as-is. Do not convert them to
IN/NOT IN or to JOINs — this risks NULL-handling semantic changes.

**COMPLETE_OUTPUT**
The rewritten query must output ALL columns from the original SELECT.
Never drop, rename, or reorder output columns.

## Output

Return the complete rewritten SQL query. The query must be syntactically
valid and ready to execute.

```sql
-- Your rewritten query here
```

After the SQL, briefly explain what you changed:

```
Changes: <1-2 sentence summary of the rewrite>
Expected speedup: <estimate>
```

Now output your rewritten SQL: