You are a SQL query rewrite engine.

Your goal: rewrite the complete SQL query to maximize execution speed
while preserving exact semantic equivalence (same rows, same columns,
same ordering).

You will receive the full query, its DAG structure showing how CTEs and
subqueries connect, cost analysis per node, and suggested rewrite patterns.
You may restructure the query freely: create new CTEs, merge existing ones,
push filters across node boundaries, or decompose subqueries.

## Query: query023_multi

```sql
WITH frequent_ss_items AS (
  SELECT
    SUBSTRING(i_item_desc FROM 1 FOR 30) AS itemdesc,
    i_item_sk AS item_sk,
    d_date AS solddate,
    COUNT(*) AS cnt
  FROM store_sales, date_dim, item
  WHERE
    ss_sold_date_sk = d_date_sk
    AND ss_item_sk = i_item_sk
    AND d_year = 1998
    AND i_manager_id BETWEEN 81 AND 100
    AND i_category IN ('Home', 'Jewelry', 'Music')
  GROUP BY
    SUBSTRING(i_item_desc FROM 1 FOR 30),
    i_item_sk,
    d_date
  HAVING
    COUNT(*) > 4
), max_store_sales AS (
  SELECT
    MAX(csales) AS tpcds_cmax
  FROM (
    SELECT
      c_customer_sk,
      SUM(ss_quantity * ss_sales_price) AS csales
    FROM store_sales, customer, date_dim
    WHERE
      ss_customer_sk = c_customer_sk
      AND ss_sold_date_sk = d_date_sk
      AND d_year = 1998
      AND ss_wholesale_cost BETWEEN 26 AND 36
    GROUP BY
      c_customer_sk
  ) AS tmp1
), best_ss_customer AS (
  SELECT
    c_customer_sk,
    SUM(ss_quantity * ss_sales_price) AS ssales
  FROM store_sales, customer
  WHERE
    ss_customer_sk = c_customer_sk AND c_birth_year BETWEEN 1927 AND 1933
  GROUP BY
    c_customer_sk
  HAVING
    SUM(ss_quantity * ss_sales_price) > (
      95 / 100.0
    ) * (
      SELECT
        *
      FROM max_store_sales
    )
)
SELECT
  SUM(sales)
FROM (
  SELECT
    cs_quantity * cs_list_price AS sales
  FROM catalog_sales, date_dim
  WHERE
    d_year = 1998
    AND d_moy = 3
    AND cs_sold_date_sk = d_date_sk
    AND cs_item_sk IN (
      SELECT
        item_sk
      FROM frequent_ss_items
    )
    AND cs_bill_customer_sk IN (
      SELECT
        c_customer_sk
      FROM best_ss_customer
    )
    AND cs_wholesale_cost BETWEEN 26 AND 36
  UNION ALL
  SELECT
    ws_quantity * ws_list_price AS sales
  FROM web_sales, date_dim
  WHERE
    d_year = 1998
    AND d_moy = 3
    AND ws_sold_date_sk = d_date_sk
    AND ws_item_sk IN (
      SELECT
        item_sk
      FROM frequent_ss_items
    )
    AND ws_bill_customer_sk IN (
      SELECT
        c_customer_sk
      FROM best_ss_customer
    )
    AND ws_wholesale_cost BETWEEN 26 AND 36
) AS tmp2
LIMIT 100
```

## DAG Topology

```sql
-- DAG TOPOLOGY
-- Depth 0:
--   frequent_ss_items (cte, 25% cost) [GROUP_BY]
--     outputs: [itemdesc, item_sk, solddate, cnt]
--   max_store_sales (cte, 25% cost) [GROUP_BY]
--     outputs: [tpcds_cmax]
-- Depth 1:
--   best_ss_customer (cte, 25% cost) [GROUP_BY] ← reads [max_store_sales]
--     outputs: [c_customer_sk, ssales]
-- Depth 2:
--   main_query (main, 25% cost) [GROUP_BY] ← reads [best_ss_customer, best_ss_customer, frequent_ss_items, frequent_ss_items]
--     outputs: [SUM(sales)]
-- Edges:
--   max_store_sales → best_ss_customer
--   best_ss_customer → main_query
--   best_ss_customer → main_query
--   frequent_ss_items → main_query
--   frequent_ss_items → main_query
```

## Performance Profile

**frequent_ss_items**: 25% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, SEQ_SCAN[store_sales], SEQ_SCAN[date_dim], SEQ_SCAN[item]
**max_store_sales**: 25% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, SEQ_SCAN[store_sales], SEQ_SCAN[customer], SEQ_SCAN[date_dim]
**best_ss_customer**: 25% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, HASH_JOIN, SEQ_SCAN[store_sales], SEQ_SCAN[customer], SEQ_SCAN[max_store_sales]
**main_query**: 25% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, HASH_JOIN, SEQ_SCAN[catalog_sales], SEQ_SCAN[date_dim], SEQ_SCAN[web_sales]

## Suggested Rewrite Strategy

Phase 2 analysis identified these optimization opportunities:

- **frequent_ss_items** → apply **pushdown**
  Heuristic: 25.0% cost, flags=['GROUP_BY']
- **max_store_sales** → apply **pushdown**
  Heuristic: 25.0% cost, flags=['GROUP_BY']
- **best_ss_customer** → apply **early_filter**
  Heuristic: 25.0% cost, flags=['GROUP_BY']
- **main_query** → apply **date_cte_isolate**
  Heuristic: 25.0% cost, flags=['GROUP_BY']

## Reference Example: early_filter

### BEFORE (slow)
```sql
[main_query]:
SELECT ss_customer_sk, SUM(act_sales) AS sumsales
FROM (SELECT ss.ss_customer_sk, CASE WHEN sr.sr_return_quantity IS NOT NULL
        THEN (ss.ss_quantity - sr.sr_return_quantity) * ss.ss_sales_price
        ELSE ss.ss_quantity * ss.ss_sales_price END AS act_sales
      FROM store_sales ss LEFT JOIN store_returns sr ON ss.ss_item_sk = sr.sr_item_sk
      JOIN reason r ON sr.sr_reason_sk = r.r_reason_sk
      WHERE r.r_reason_desc = 'duplicate purchase') t
GROUP BY ss_customer_sk ORDER BY sumsales, ss_customer_sk LIMIT 100
```

**Key insight:** Filter dimension table (reason) FIRST, then join to fact. Reduces returns to only 'duplicate purchase' before expensive store_sales join.

### AFTER (fast)
[filtered_reason]:
```sql
SELECT r_reason_sk FROM reason WHERE r_reason_desc = 'duplicate purchase'
```
[filtered_returns]:
```sql
SELECT sr_item_sk, sr_ticket_number, sr_return_quantity FROM store_returns JOIN filtered_reason ON sr_reason_sk = r_reason_sk
```
[main_query]:
```sql
SELECT ss_customer_sk, SUM(act_sales) AS sumsales FROM (SELECT ss.ss_customer_sk, CASE WHEN NOT fr.sr_return_quantity IS NULL THEN (ss.ss_quantity - fr.sr_return_quantity) * ss.ss_sales_price ELSE (ss.ss_quantity * ss.ss_sales_price) END AS act_sales FROM store_sales ss JOIN filtered_returns fr ON (fr.sr_item_sk = ss.ss_item_sk AND fr.sr_ticket_number = ss.ss_ticket_number)) AS t GROUP BY ss_customer_sk ORDER BY sumsales, ss_customer_sk LIMIT 100
```

## Constraints

### CRITICAL — Correctness Guards (top of sandwich)

**SEMANTIC_EQUIVALENCE**
The rewritten query MUST return exactly the same rows, columns, and
ordering as the original. This is the prime directive.

**LITERAL_PRESERVATION**
Keep all literal values (dates, strings, numbers) exactly as they appear in
the original SQL. Do not round, truncate, or reformat them.

### HIGH — Performance and Style Rules (middle of sandwich)

**NO_UNFILTERED_DIM_CTE**
When creating a new CTE that scans a dimension table, include at least one
filter predicate. Never materialize an entire dimension without a WHERE clause.

**OR_TO_UNION_LIMIT**
When converting OR predicates to UNION ALL, limit to 4 branches maximum.
Beyond 4, the UNION overhead exceeds the OR scan cost for most planners.

**EXPLICIT_JOINS**
Convert comma-separated implicit joins to explicit JOIN ... ON syntax.
This gives the optimizer better join-order freedom.

### CRITICAL — Correctness Guards (bottom of sandwich)

**KEEP_EXISTS_AS_EXISTS**
Preserve EXISTS/NOT EXISTS subqueries as-is. Do not convert them to
IN/NOT IN or to JOINs — this risks NULL-handling semantic changes.

**COMPLETE_OUTPUT**
The rewritten query must output ALL columns from the original SELECT.
Never drop, rename, or reorder output columns.

## Output

Return the complete rewritten SQL query. The query must be syntactically
valid and ready to execute.

```sql
-- Your rewritten query here
```

After the SQL, briefly explain what you changed:

```
Changes: <1-2 sentence summary of the rewrite>
Expected speedup: <estimate>
```

Now output your rewritten SQL: