You are a SQL query rewrite engine.

Your goal: rewrite the complete SQL query to maximize execution speed
while preserving exact semantic equivalence (same rows, same columns,
same ordering).

You will receive the full query, its DAG structure showing how CTEs and
subqueries connect, cost analysis per node, and suggested rewrite patterns.
You may restructure the query freely: create new CTEs, merge existing ones,
push filters across node boundaries, or decompose subqueries.

## Query: query075_multi

```sql
WITH all_sales AS (
  SELECT
    d_year,
    i_brand_id,
    i_class_id,
    i_category_id,
    i_manufact_id,
    SUM(sales_cnt) AS sales_cnt,
    SUM(sales_amt) AS sales_amt
  FROM (
    SELECT
      d_year,
      i_brand_id,
      i_class_id,
      i_category_id,
      i_manufact_id,
      cs_quantity - COALESCE(cr_return_quantity, 0) AS sales_cnt,
      cs_ext_sales_price - COALESCE(cr_return_amount, 0.0) AS sales_amt
    FROM catalog_sales
    JOIN item
      ON i_item_sk = cs_item_sk
    JOIN date_dim
      ON d_date_sk = cs_sold_date_sk
    LEFT JOIN catalog_returns
      ON (
        cs_order_number = cr_order_number AND cs_item_sk = cr_item_sk
      )
    WHERE
      i_category = 'Music'
      AND cs_sales_price / cs_list_price BETWEEN 33 * 0.01 AND 53 * 0.01
      AND cr_reason_sk IN (17, 48, 50, 56, 68)
    UNION
    SELECT
      d_year,
      i_brand_id,
      i_class_id,
      i_category_id,
      i_manufact_id,
      ss_quantity - COALESCE(sr_return_quantity, 0) AS sales_cnt,
      ss_ext_sales_price - COALESCE(sr_return_amt, 0.0) AS sales_amt
    FROM store_sales
    JOIN item
      ON i_item_sk = ss_item_sk
    JOIN date_dim
      ON d_date_sk = ss_sold_date_sk
    LEFT JOIN store_returns
      ON (
        ss_ticket_number = sr_ticket_number AND ss_item_sk = sr_item_sk
      )
    WHERE
      i_category = 'Music'
      AND ss_sales_price / ss_list_price BETWEEN 33 * 0.01 AND 53 * 0.01
      AND sr_reason_sk IN (17, 48, 50, 56, 68)
    UNION
    SELECT
      d_year,
      i_brand_id,
      i_class_id,
      i_category_id,
      i_manufact_id,
      ws_quantity - COALESCE(wr_return_quantity, 0) AS sales_cnt,
      ws_ext_sales_price - COALESCE(wr_return_amt, 0.0) AS sales_amt
    FROM web_sales
    JOIN item
      ON i_item_sk = ws_item_sk
    JOIN date_dim
      ON d_date_sk = ws_sold_date_sk
    LEFT JOIN web_returns
      ON (
        ws_order_number = wr_order_number AND ws_item_sk = wr_item_sk
      )
    WHERE
      i_category = 'Music'
      AND ws_sales_price / ws_list_price BETWEEN 33 * 0.01 AND 53 * 0.01
      AND wr_reason_sk IN (17, 48, 50, 56, 68)
  ) AS sales_detail
  GROUP BY
    d_year,
    i_brand_id,
    i_class_id,
    i_category_id,
    i_manufact_id
)
SELECT
  prev_yr.d_year AS prev_year,
  curr_yr.d_year AS year,
  curr_yr.i_brand_id,
  curr_yr.i_class_id,
  curr_yr.i_category_id,
  curr_yr.i_manufact_id,
  prev_yr.sales_cnt AS prev_yr_cnt,
  curr_yr.sales_cnt AS curr_yr_cnt,
  curr_yr.sales_cnt - prev_yr.sales_cnt AS sales_cnt_diff,
  curr_yr.sales_amt - prev_yr.sales_amt AS sales_amt_diff
FROM all_sales AS curr_yr, all_sales AS prev_yr
WHERE
  curr_yr.i_brand_id = prev_yr.i_brand_id
  AND curr_yr.i_class_id = prev_yr.i_class_id
  AND curr_yr.i_category_id = prev_yr.i_category_id
  AND curr_yr.i_manufact_id = prev_yr.i_manufact_id
  AND curr_yr.d_year = 2002
  AND prev_yr.d_year = 2002 - 1
  AND prev_yr.sales_cnt > 0
  AND CAST(curr_yr.sales_cnt AS DECIMAL(17, 2)) / CAST(prev_yr.sales_cnt AS DECIMAL(17, 2)) < 0.9
ORDER BY
  sales_cnt_diff,
  sales_amt_diff
LIMIT 100
```

## DAG Topology

```sql
-- DAG TOPOLOGY
-- Depth 0:
--   all_sales (cte, 50% cost) [GROUP_BY, UNION_ALL]
--     outputs: [d_year, i_brand_id, i_class_id, i_category_id, i_manufact_id, sales_cnt, sales_amt]
-- Depth 1:
--   main_query (main, 50% cost) [GROUP_BY] ← reads [all_sales, all_sales]
--     outputs: [prev_year, year, i_brand_id, i_class_id, i_category_id, i_manufact_id, prev_yr_cnt, curr_yr_cnt, ...]
-- Edges:
--   all_sales → main_query
--   all_sales → main_query
```

## Performance Profile

**all_sales**: 50% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, SEQ_SCAN[web_sales], SEQ_SCAN[item], SEQ_SCAN[date_dim]
**main_query**: 50% of total cost, ~1,000 rows
  operators: HASH_GROUP_BY, HASH_JOIN, SEQ_SCAN[all_sales], SEQ_SCAN[all_sales]

## Suggested Rewrite Strategy

Phase 2 analysis identified these optimization opportunities:

- **all_sales** → apply **union_cte_split**
  Heuristic: 50.0% cost, flags=['GROUP_BY', 'UNION_ALL']

Nodes not flagged (low cost or no opportunity):
- main_query: No matching pattern for flags=['GROUP_BY']

## Reference Examples

### 1. pg_self_join_decomposition (3.93x)

**BEFORE (slow):**
```sql
select s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand
from store, item,
  (select ss_store_sk, avg(revenue) as ave
   from (select ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
         from store_sales, date_dim
         where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1224
           and ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48
         group by ss_store_sk, ss_item_sk) sa
   group by ss_store_sk) sb,
  (select ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
   from store_sales, date_dim
   where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1224
     and ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48
   group by ss_store_sk, ss_item_sk) sc
where sb.ss_store_sk = sc.ss_store_sk
  and sc.revenue <= 0.1 * sb.ave
  and s_store_sk = sc.ss_store_sk
  and i_item_sk = sc.ss_item_sk
  and i_manager_id BETWEEN 32 AND 36
  and s_state in ('TN','TX','VA')
order by s_store_name, i_item_desc
limit 100
```

**Key insight:** The original scans store_sales+date_dim TWICE with identical predicates (sa/sc subqueries). On PostgreSQL, CTE materialization computes the fact table aggregation ONCE and reuses it for both per-item revenue and per-store averages. Combined with dimension pre-filtering (store, item), this eliminates the dominant I/O cost.

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

### 2. pg_materialized_dimension_fact_prefilter (2.68x)

**BEFORE (slow):**
```sql
select i_item_desc, w_warehouse_name, d1.d_week_seq,
  sum(case when p_promo_sk is null then 1 else 0 end) no_promo,
  sum(case when p_promo_sk is not null then 1 else 0 end) promo,
  count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity
  and d3.d_date > d1.d_date + interval '3 day'
  and hd_buy_potential = '501-1000'
  and d1.d_year = 1998
  and cd_marital_status = 'M'
  and cd_dep_count between 9 and 11
  and i_category IN ('Home', 'Men', 'Music')
  and cs_wholesale_cost BETWEEN 34 AND 54
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
limit 100
```

**Key insight:** When a query has expensive non-equi joins (inv_quantity < cs_quantity, d_week_seq correlation across 3 date_dim instances), reducing BOTH dimension AND fact table sizes before the join dramatically shrinks the search space. MATERIALIZED CTEs on PG12+ force early execution. The fact table CTE (cs_wholesale_cost BETWEEN x AND y) removes ~70% of catalog_sales rows before hitting the inventory join. Combined with tiny dimension CTEs (date: ~365 rows from 73K, item: 3 categories, cd/hd: single-value filters), the optimizer gets much smaller inputs for the expensive joins.

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk, d_date, d_week_seq FROM date_dim WHERE d_year = 1998
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc FROM item WHERE i_category IN ('Home', 'Men', 'Music')
```
[filtered_cd]:
```sql
SELECT cd_demo_sk FROM customer_demographics WHERE cd_marital_status = 'M' AND cd_dep_count BETWEEN 9 AND 11
```
[filtered_hd]:
```sql
SELECT hd_demo_sk FROM household_demographics WHERE hd_buy_potential = '501-1000'
```
[cs_filtered]:
```sql
SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk, cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost, cs_order_number FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 34 AND 54
```
[main_query]:
```sql
SELECT i.i_item_desc, w.w_warehouse_name, d1.d_week_seq, SUM(CASE WHEN p.p_promo_sk IS NULL THEN 1 ELSE 0 END) AS no_promo, SUM(CASE WHEN p.p_promo_sk IS NOT NULL THEN 1 ELSE 0 END) AS promo, COUNT(*) AS total_cnt FROM cs_filtered cs JOIN inventory inv ON cs.cs_item_sk = inv.inv_item_sk JOIN warehouse w ON w.w_warehouse_sk = inv.inv_warehouse_sk JOIN filtered_item i ON i.i_item_sk = cs.cs_item_sk JOIN filtered_cd cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk JOIN filtered_hd hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk JOIN filtered_date d1 ON cs.cs_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON inv.inv_date_sk = d2.d_date_sk JOIN date_dim d3 ON cs.cs_ship_date_sk = d3.d_date_sk LEFT OUTER JOIN promotion p ON cs.cs_promo_sk = p.p_promo_sk LEFT OUTER JOIN catalog_returns cr ON cr.cr_item_sk = cs.cs_item_sk AND cr.cr_order_number = cs.cs_order_number WHERE d1.d_week_seq = d2.d_week_seq AND inv.inv_quantity_on_hand < cs.cs_quantity AND d3.d_date > d1.d_date + INTERVAL '3 day' GROUP BY i.i_item_desc, w.w_warehouse_name, d1.d_week_seq ORDER BY total_cnt DESC, i.i_item_desc, w.w_warehouse_name, d1.d_week_seq LIMIT 100
```

### 3. GROUPING_SETS_INSTEAD_OF_UNION (unknown)

**BEFORE (slow):**
```sql
SELECT region, NULL as product, SUM(sales) FROM sales GROUP BY region
      UNION ALL
      SELECT NULL, product, SUM(sales) FROM sales GROUP BY product
      UNION ALL
      SELECT NULL, NULL, SUM(sales) FROM sales;
```

**Key insight:** Reports requiring multiple aggregation levels (subtotals, grand totals).

## Constraints

### CRITICAL — Correctness Guards (top of sandwich)

**SEMANTIC_EQUIVALENCE**
The rewritten query MUST return exactly the same rows, columns, and
ordering as the original. This is the prime directive.

**LITERAL_PRESERVATION**
Keep all literal values (dates, strings, numbers) exactly as they appear in
the original SQL. Do not round, truncate, or reformat them.

### HIGH — Performance and Style Rules (middle of sandwich)

**NO_UNFILTERED_DIM_CTE**
When creating a new CTE that scans a dimension table, include at least one
filter predicate. Never materialize an entire dimension without a WHERE clause.

**OR_TO_UNION_LIMIT**
When converting OR predicates to UNION ALL, limit to 4 branches maximum.
Beyond 4, the UNION overhead exceeds the OR scan cost for most planners.

**EXPLICIT_JOINS**
Convert comma-separated implicit joins to explicit JOIN ... ON syntax.
This gives the optimizer better join-order freedom.

### CRITICAL — Correctness Guards (bottom of sandwich)

**KEEP_EXISTS_AS_EXISTS**
Preserve EXISTS/NOT EXISTS subqueries as-is. Do not convert them to
IN/NOT IN or to JOINs — this risks NULL-handling semantic changes.

**COMPLETE_OUTPUT**
The rewritten query must output ALL columns from the original SELECT.
Never drop, rename, or reorder output columns.

## Output

Return the complete rewritten SQL query. The query must be syntactically
valid and ready to execute.

```sql
-- Your rewritten query here
```

After the SQL, briefly explain what you changed:

```
Changes: <1-2 sentence summary of the rewrite>
Expected speedup: <estimate>
```

Now output your rewritten SQL: