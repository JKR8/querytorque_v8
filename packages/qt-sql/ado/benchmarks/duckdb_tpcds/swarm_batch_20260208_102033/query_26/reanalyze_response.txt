FAILURE_ANALYSIS:
All attempts failed because they only addressed dimension table filtering without tackling the core bottleneck: scanning and joining the massive catalog_sales fact table (likely the dominant cost). The CTE-based pre-filtering approaches (used by all workers) are redundant because DuckDB's optimizer already pushes filters through joins effectively. Worker 4's UNION transformation on promotion actually hurt performance (0.51x) by doubling work and preventing join elimination opportunities. The strategies missed that: 1) catalog_sales dominates runtime, 2) dimension filters are selective enough for early reduction, 3) no one exploited partitioning/sorting of catalog_sales, and 4) all attempts kept the same 5-way join structure without considering alternative join orders or Bloom filters.

UNEXPLORED_OPPORTUNITIES:
1. **Bloom filter acceleration**: Use semi-joins to create Bloom filters from selective dimensions (customer_demographics, date_dim) to pre-filter catalog_sales before full joins.
2. **Join order restructuring**: Place the most selective dimension (likely customer_demographics with triple equality) as the first join to drastically reduce fact table rows early.
3. **Aggregation pushdown**: Aggregate catalog_sales metrics at the fact level before joining with item, reducing data volume for the final join.
4. **Exploit physical layout**: If catalog_sales is partitioned/clustered by date or item, restructure joins to leverage partition pruning.
5. **Avoid redundant dimension materialization**: Filter dimensions directly in joins without CTEs to let DuckDB's optimizer choose optimal join order.

REFINED_STRATEGY:
Combine Bloom filter pre-filtering with early aggregation on fact table, restructure joins to prioritize most selective dimensions first, and exploit known data distributions. Instead of materializing filtered dimensions in CTEs (which forces materialization), use them to create semi-join filters that prune catalog_sales early. Then aggregate at the item level before the final dimension joins.

EXAMPLES: prefetch_fact_join, single_pass_aggregation, pushdown
HINT: First, create a filtered catalog_sales using EXISTS subqueries with the selective dimensions (customer_demographics and date_dim) to prune most rows early. Then aggregate metrics at item_sk level. Finally, join with remaining dimensions (item, promotion) and apply their filters. This transforms the 5-way join into a staged reduction pipeline.