{
  "query_id": "query_9",
  "worker_id": 1,
  "run_name": "swarm_batch_20260208_102033",
  "timestamp": "2026-02-08T13:34:28.127124",
  "query_intent": "",
  "query_fingerprint": "",
  "examples_used": [
    "pushdown",
    "single_pass_aggregation",
    "materialize_cte"
  ],
  "strategy": "conservative_single_pass",
  "status": "REGRESSION",
  "speedup": 0.4244512598812492,
  "transforms_applied": [
    "pushdown",
    "single_pass_aggregation",
    "materialize_cte"
  ],
  "error_category": null,
  "error_messages": [],
  "what_worked": null,
  "why_it_worked": null,
  "what_failed": "Regression (0.42x): Consolidated five independent store_sales scans into a single CTE using conditional aggregates, then computed final CASE logic on the pre-aggregated results. This reduces table scans from 10 (5 counts + 5 averages) to just 1.",
  "why_it_failed": "All attempts fell short because they failed to address the fundamental bottleneck: DuckDB's columnar execution engine struggles with computing 15 different conditional aggregates (5 counts + 10 averages) in a single scan when they involve overlapping CASE conditions. The original query's independent subqueries allow DuckDB to apply specialized optimizations for each quantity range (potentially using zonemaps/min-max filtering), while the consolidated approaches force evaluation of all conditions",
  "principle": null,
  "reviewed": true
}