You are analyzing 5 failed optimization attempts to design a refined approach that reaches 2.0x speedup.

Your job: understand WHY each attempt fell short, identify unexplored optimization angles, and synthesize a NEW strategy that combines the best insights while avoiding repeated mistakes.

## Query: query_92
## Target: 2.0x speedup
## Dialect: duckdb

```sql
-- start query 92 in stream 0 using template query92.tpl
select 
   sum(ws_ext_discount_amt)  as "Excess Discount Amount" 
from 
    web_sales 
   ,item 
   ,date_dim
where
i_manufact_id = 320
and i_item_sk = ws_item_sk 
and d_date between '2002-02-26' and 
        (cast('2002-02-26' as date) + INTERVAL 90 DAY)
and d_date_sk = ws_sold_date_sk 
and ws_ext_discount_amt  
     > ( 
         SELECT 
            1.3 * avg(ws_ext_discount_amt) 
         FROM 
            web_sales 
           ,date_dim
         WHERE 
              ws_item_sk = i_item_sk 
          and d_date between '2002-02-26' and
                             (cast('2002-02-26' as date) + INTERVAL 90 DAY)
          and d_date_sk = ws_sold_date_sk 
      ) 
order by sum(ws_ext_discount_amt)
 LIMIT 100;

-- end query 92 in stream 0 using template query92.tpl
```

## Previous Attempts

### Worker 1: conservative_early_pushdown
- **Status**: pass (0.94x)
- **Transforms**: none
- **Examples used**: early_filter, pushdown, materialize_cte
- **Strategy hint**: Filter dimension tables first, push date predicates into subqueries, and materialize the repeated correlated subquery logic into a CTE to avoid redundant computation.

```sql
WITH filtered_items AS (
    SELECT i_item_sk
    FROM item
    WHERE i_manufact_id = 320
),
date_range AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_date BETWEEN '2002-02-26' AND (
        CAST('2002-02-26' AS DATE) + INTERVAL '90' DAY
    )
),
item_avg_discount AS (
    SELECT
        ws_item_sk,
        1.3 * AVG(ws_ext_discount_amt) AS avg_disc
    FROM web_sales
    INNER JOIN date_range ON ws_sold_date_sk = d_date_sk
    WHERE ws_item_sk IN (SELECT i_item_sk FROM filtered_items)
    GROUP BY ws_item_sk
)
SELECT
    SUM(ws_ext_discount_amt) AS "Excess Discount Amount"
FROM web_sales
INNER JOIN filtered_items ON ws_item_sk = i_item_sk
INNER JOIN date_range ON ws_sold_date_sk = d_date_sk
INNER JOIN item_avg_discount ON web_sales.ws_item_sk = item_avg_discount.ws_item_sk
WHERE ws_ext_discount_amt > avg_disc
ORDER BY SUM(ws_ext_discount_amt)
LIMIT 100;
```

### Worker 2: moderate_dimension_isolation
- **Status**: pass (0.91x)
- **Transforms**: none
- **Examples used**: date_cte_isolate, dimension_cte_isolate, decorrelate
- **Strategy hint**: Create separate CTEs for pre-filtered date and item dimensions, then decorrelate the subquery by precomputing per-item averages for the date range before joining.

```sql
WITH filtered_dates AS (
  SELECT d_date_sk
  FROM date_dim
  WHERE d_date BETWEEN '2002-02-26' AND (
    CAST('2002-02-26' AS DATE) + INTERVAL '90' DAY
  )
),
filtered_items AS (
  SELECT i_item_sk
  FROM item
  WHERE i_manufact_id = 320
),
item_avg_discount AS (
  SELECT 
    ws_item_sk,
    1.3 * AVG(ws_ext_discount_amt) AS avg_threshold
  FROM web_sales
  JOIN filtered_dates ON ws_sold_date_sk = d_date_sk
  GROUP BY ws_item_sk
)
SELECT
  SUM(ws.ws_ext_discount_amt) AS "Excess Discount Amount"
FROM web_sales ws
JOIN filtered_items fi ON ws.ws_item_sk = fi.i_item_sk
JOIN filtered_dates fd ON ws.ws_sold_date_sk = fd.d_date_sk
JOIN item_avg_discount iad ON ws.ws_item_sk = iad.ws_item_sk
WHERE ws.ws_ext_discount_amt > iad.avg_threshold
ORDER BY SUM(ws.ws_ext_discount_amt)
LIMIT 100
```

### Worker 3: aggressive_prefetch_restructure
- **Status**: pass (0.87x)
- **Transforms**: none
- **Examples used**: multi_date_range_cte, prefetch_fact_join, shared_dimension_multi_channel
- **Strategy hint**: Precompute the date range as a CTE, prefetch filtered fact-dimension joins, and restructure using shared dimension CTEs to streamline the multi-step filtering and aggregation.

```sql
WITH date_range AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_date BETWEEN '2002-02-26' AND (
        CAST('2002-02-26' AS DATE) + INTERVAL '90' DAY
    )
),
filtered_items AS (
    SELECT i_item_sk
    FROM item
    WHERE i_manufact_id = 320
),
web_sales_filtered AS (
    SELECT ws.ws_ext_discount_amt, ws.ws_item_sk, ws.ws_sold_date_sk
    FROM web_sales ws
    JOIN date_range d ON ws.ws_sold_date_sk = d.d_date_sk
    JOIN filtered_items i ON ws.ws_item_sk = i.i_item_sk
),
item_avg_discount AS (
    SELECT ws.ws_item_sk, 1.3 * AVG(ws.ws_ext_discount_amt) AS threshold
    FROM web_sales ws
    JOIN date_range d ON ws.ws_sold_date_sk = d.d_date_sk
    GROUP BY ws.ws_item_sk
)
SELECT
    SUM(ws.ws_ext_discount_amt) AS "Excess Discount Amount"
FROM web_sales_filtered ws
JOIN item_avg_discount a ON ws.ws_item_sk = a.ws_item_sk
WHERE ws.ws_ext_discount_amt > a.threshold
ORDER BY SUM(ws.ws_ext_discount_amt)
-- ... (truncated)
```

### Worker 4: novel_structural_transform
- **Status**: pass (0.81x)
- **Transforms**: none
- **Examples used**: single_pass_aggregation, composite_decorrelate_union, or_to_union
- **Strategy hint**: Consolidate the main query and subquery into a single-pass aggregation, transform correlation via union-based decorrelation, and explore splitting any implicit OR conditions for optimal indexing.

```sql
WITH filtered_dates AS (
  SELECT d_date_sk
  FROM date_dim
  WHERE d_date BETWEEN '2002-02-26' AND (CAST('2002-02-26' AS DATE) + INTERVAL '90' DAY)
),
item_avg_discount AS (
  SELECT 
    ws_item_sk,
    AVG(ws_ext_discount_amt) * 1.3 AS threshold
  FROM web_sales
  JOIN filtered_dates ON d_date_sk = ws_sold_date_sk
  GROUP BY ws_item_sk
)
SELECT
  SUM(ws_ext_discount_amt) AS "Excess Discount Amount"
FROM web_sales
JOIN item ON i_item_sk = ws_item_sk
JOIN filtered_dates ON d_date_sk = ws_sold_date_sk
JOIN item_avg_discount ON web_sales.ws_item_sk = item_avg_discount.ws_item_sk
WHERE
  i_manufact_id = 320
  AND ws_ext_discount_amt > item_avg_discount.threshold
ORDER BY
  SUM(ws_ext_discount_amt)
LIMIT 100
```

### Worker 5: refined_snipe
- **Status**: error (0.00x)
- **Error**: Binder Error: Ambiguous reference to column name "ws_item_sk" (use: "web_sales.ws_item_sk" or "iad.ws_item_sk")
- **Transforms**: none
- **Examples used**: 
- **Strategy hint**: Snipe from iter 1

```sql
WITH filtered_dates AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_date BETWEEN '2002-02-26' AND (
        CAST('2002-02-26' AS DATE) + INTERVAL '90' DAY
    )
),
item_avg_discount AS (
    SELECT 
        ws_item_sk,
        1.3 * AVG(ws_ext_discount_amt) AS avg_discount
    FROM web_sales
    JOIN filtered_dates ON d_date_sk = ws_sold_date_sk
    GROUP BY ws_item_sk
)
SELECT
    SUM(ws_ext_discount_amt) AS "Excess Discount Amount"
FROM web_sales
JOIN item ON i_item_sk = ws_item_sk
JOIN filtered_dates ON d_date_sk = ws_sold_date_sk
JOIN item_avg_discount iad ON ws_item_sk = iad.ws_item_sk
WHERE i_manufact_id = 320
  AND ws_ext_discount_amt > iad.avg_discount
ORDER BY SUM(ws_ext_discount_amt)
LIMIT 100
```

## DAG Structure & Bottlenecks

| Node | Role | Cost % |
|------|------|-------:|
| main_query |  | 0.0% |

## Available Examples (Full Catalog)

- **composite_decorrelate_union** (2.42xx) — Decorrelate multiple correlated EXISTS subqueries into pre-materialized DISTINCT
- **date_cte_isolate** (4.00xx) — Extract date filtering into a separate CTE to enable predicate pushdown and redu
- **decorrelate** (2.92xx) — Convert correlated subquery to separate CTE with GROUP BY, then JOIN
- **deferred_window_aggregation** (1.36xx) — When multiple CTEs each perform GROUP BY + WINDOW (cumulative sum), then are joi
- **dimension_cte_isolate** (1.93xx) — Pre-filter ALL dimension tables into CTEs before joining with fact table, not ju
- **early_filter** (4.00xx) — Filter dimension tables FIRST, then join to fact tables to reduce expensive join
- **intersect_to_exists** (1.83xx) — Convert INTERSECT subquery pattern to multiple EXISTS clauses for better join pl
- **materialize_cte** (1.37xx) — Extract repeated subquery patterns into a CTE to avoid recomputation
- **multi_date_range_cte** (2.35xx) — When query uses multiple date_dim aliases with different filters (d1, d2, d3), c
- **multi_dimension_prefetch** (2.71xx) — Pre-filter multiple dimension tables (date + store) into separate CTEs before jo
- **or_to_union** (3.17xx) — Split OR conditions on different columns into UNION ALL branches for better inde
- **prefetch_fact_join** (3.77xx) — Pre-filter dimension table into CTE, then pre-join with fact table in second CTE
- **pushdown** (2.11xx) — Push filters from outer query into CTEs/subqueries to reduce intermediate result
- **shared_dimension_multi_channel** (1.30xx) — Extract shared dimension filters (date, item, promotion) into CTEs when multiple
- **single_pass_aggregation** (4.47xx) — Consolidate multiple subqueries scanning the same table into a single CTE with c
- **union_cte_split** (1.36xx) — Split a generic UNION ALL CTE into specialized CTEs when the main query filters 

## Your Task

Analyze the failed attempts and design a refined approach:

1. **Failure Analysis**: Why did all attempts fall short? Be specific about mechanisms.
2. **Common Patterns**: What did multiple workers try unsuccessfully?
3. **Unexplored Space**: What optimization angles were missed entirely?
4. **Refined Strategy**: Synthesize a NEW approach combining best insights.

### Output Format (follow EXACTLY)

```
FAILURE_ANALYSIS:
<Why all workers fell short — be specific about mechanisms>

UNEXPLORED_OPPORTUNITIES:
<What optimization approaches haven't been tried>

REFINED_STRATEGY:
<Concrete optimization approach for next attempt>

EXAMPLES: <ex1>, <ex2>, <ex3>
HINT: <specific guidance for the refined attempt>
```