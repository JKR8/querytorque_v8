Query: query072_agg
Retrieval method: dsb_mapping
Examples: ['AGGREGATE_PUSH_BELOW_JOIN', 'STAR_SCHEMA_DIMENSION_FILTER_FIRST', 'DSB_NON_EQUI_JOIN_WINDOW']
================================================================================

## Example: Aggregate Push Below Join (AGGREGATE_PUSH_BELOW_JOIN)
Verified speedup: unknown

### Input:
[main_query]:
SELECT c.region, SUM(o.amount)
      FROM customers c
      JOIN orders o ON c.id = o.customer_id
      GROUP BY c.region;


**Key insight:** Join followed by aggregation where one side contributes only to
      aggregate, not to grouping.

---

## Example: Star Schema Dimension Filter First (STAR_SCHEMA_DIMENSION_FILTER_FIRST)
Verified speedup: unknown

### Input:
[main_query]:
-- May scan fact table first
      SELECT f.*, d1.name, d2.category
      FROM fact_sales f
      JOIN dim_date d1 ON f.date_id = d1.id
      JOIN dim_product d2 ON f.product_id = d2.id
      WHERE d1.year = 2025
        AND d2.category = 'Electronics';


**Key insight:** Star schema queries with selective dimension filters where optimizer
      scans fact table first instead of filtering dimensions.

---

## Example: Dsb Non Equi Join Window (DSB_NON_EQUI_JOIN_WINDOW)
Verified speedup: unknown

### Input:
[main_query]:
-- Purchase, return, repurchase pattern
      SELECT * FROM web_returns wr
      JOIN web_sales ws ON wr.wr_item_sk = ws.ws_item_sk
      JOIN store_sales ss ON ws.ws_item_sk = ss.ss_item_sk
      WHERE wr.wr_returned_date_sk < ss.ss_sold_date_sk
        AND ws.ws_sold_date_sk < wr.wr_returned_date_sk;


**Key insight:** DSB Query 101, 102 patterns with range/temporal constraints.

---

## CONSTRAINTS (Learned from Benchmark Failures)

The following constraints are MANDATORY based on observed failures:

### LITERAL_PRESERVATION [CRITICAL]
CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

### OR_TO_UNION_LIMIT [HIGH]
CAUTION with OR→UNION: Only split OR conditions into UNION ALL when there are ≤3 simple branches AND they have different access patterns. If you have nested ORs (e.g., 3 conditions × 3 values = 9 combinations), DO NOT expand them - keep the original OR structure. DuckDB handles OR predicates efficiently. Over-splitting causes multiple scans of fact tables and severe regressions (0.23x-0.41x observed). When in doubt, preserve the original OR structure.


---

You are an autonomous Query Rewrite Engine. Your goal is to maximize execution speed while strictly preserving semantic invariants.

Output atomic rewrite sets in JSON.

RULES:
- Primary Goal: Maximize execution speed while strictly preserving semantic invariants.
- Allowed Transforms: Use the provided list. If a standard SQL optimization applies that is not listed, label it "semantic_rewrite".
- Atomic Sets: Group dependent changes (e.g., creating a CTE and joining it) into a single rewrite_set.
- Contracts: Output columns, grain, and total result rows must remain invariant.
- Naming: Use descriptive CTE names (e.g., `filtered_returns` vs `cte1`).
- Column Aliasing: Permitted only for aggregations or disambiguation.

ALLOWED TRANSFORMS: pushdown, decorrelate, or_to_union, early_filter, date_cte_isolate, materialize_cte, flatten_subquery, reorder_join, multi_push_predicate, inline_cte, remove_redundant, semantic_rewrite

OUTPUT FORMAT:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "transform_name",
      "nodes": {
        "node_id": "new SQL..."
      },
      "invariants_kept": ["list of preserved semantics"],
      "expected_speedup": "2x",
      "risk": "low"
    }
  ],
  "explanation": "what was changed and why"
}
```

## Target Nodes
  [main_query]

## Subgraph Slice
[main_query] type=main
```sql

select  i_item_desc
      ,w_warehouse_name
      ,d1.d_week_seq
      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo
      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo
      ,count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity
  and d3.d_date > d1.d_date + interval '3 day'
  and hd_buy_potential = '501-1000'
  and d1.d_year = 1998
  and cd_marital_status = 'M'
  and cd_dep_count between 9 and 11
  and i_category IN ('Home', 'Men', 'Music')
  and cs_wholesale_cost BETWEEN 34 AND 54
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
limit 100;



```

## Node Contracts
[main_query]:
  output_columns: (not parsed)
  required_predicates: (not parsed)

Now output your rewrite_sets:

## Execution Plan
```
(execution plan would go here)
```
