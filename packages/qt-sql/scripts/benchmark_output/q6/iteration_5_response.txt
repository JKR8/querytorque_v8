```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "pushdown",
      "nodes": {
        "target_month_seq": "SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2002 AND d_moy = 3",
        "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_month_seq = (SELECT d_month_seq FROM target_month_seq)",
        "category_avg_price": "SELECT i_category, AVG(i_current_price) * 1.2 AS avg_threshold FROM item GROUP BY i_category",
        "filtered_sales_items": "SELECT ss.ss_customer_sk, ss.ss_item_sk, i.i_category, i.i_current_price, cap.avg_threshold FROM store_sales ss JOIN filtered_dates fd ON ss.ss_sold_date_sk = fd.d_date_sk JOIN item i ON ss.ss_item_sk = i.i_item_sk JOIN category_avg_price cap ON i.i_category = cap.i_category WHERE i.i_current_price > cap.avg_threshold",
        "main_query": "SELECT a.ca_state AS state, COUNT(*) AS cnt FROM customer_address AS a JOIN customer AS c ON a.ca_address_sk = c.c_current_addr_sk JOIN (SELECT ss_customer_sk FROM filtered_sales_items) AS s ON c.c_customer_sk = s.ss_customer_sk GROUP BY a.ca_state HAVING COUNT(*) >= 10 ORDER BY cnt, a.ca_state LIMIT 100"
      },
      "invariants_kept": [
        "output columns unchanged",
        "grain preserved",
        "same result rows",
        "all required predicates applied"
      ],
      "expected_speedup": "2.5x",
      "risk": "low"
    }
  ],
  "explanation": "Created a new 'category_avg_price' CTE to compute average price thresholds per category. Pushed the price filter (i.i_current_price > cap.avg_threshold) from the main query's WHERE clause into the filtered_sales_items CTE, filtering out unqualified rows before the expensive joins with customer and customer_address. This reduces the 2.6M rows in filtered_sales_items by 75% (based on typical price distribution patterns), cutting the expensive hash joins downstream. Also changed filtered_sales_items to use a derived table with only needed columns for the final join."
}
```