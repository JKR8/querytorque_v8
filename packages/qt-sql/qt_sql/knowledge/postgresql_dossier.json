{
  "schema_version": "3.0",
  "engine": "postgresql",
  "version_tested": "14.3+",
  "profile_type": "engine_dossier",
  "briefing_note": "This is field intelligence gathered from 53 DSB queries at SF5-SF10. PostgreSQL is a fundamentally different optimizer than DuckDB \u2014 it has bitmap index scans, JIT compilation, and aggressive CTE materialization. Techniques that work on DuckDB often regress here. Use this to guide your analysis but apply your own judgment \u2014 every query is different. Add to this knowledge if you observe something new.",
  "strengths": [
    {
      "id": "BITMAP_OR_SCAN",
      "summary": "Multi-branch OR conditions on indexed columns are handled via BitmapOr \u2014 a single fact table scan with bitmap combination. Extremely efficient.",
      "field_note": "NEVER split OR conditions into UNION ALL branches on PostgreSQL. BitmapOr is categorically faster. We saw 0.21x on Q085 and 0.26x on Q091 \u2014 each UNION branch forced a full 7-table join + fact scan that BitmapOr avoids. The only conceivable case for OR-to-UNION on PG is when branches reference completely different tables, and even then it's risky.",
      "guard_rail": {
        "id": "PG_OR_TO_UNION_BLOCK",
        "severity": "CRITICAL",
        "instruction": "POSTGRESQL RULE: NEVER use OR\u2192UNION on PostgreSQL. PostgreSQL handles OR conditions efficiently via BitmapOr index scans in a single pass. Converting OR to UNION ALL forces multiple scans of fact tables and causes catastrophic regressions (0.21x-0.26x observed on DSB benchmark). Keep the original OR structure.",
        "evidence": "DSB Q085_agg 0.21x \u2014 3x scans of web_sales + web_returns fact tables. Original did 1 scan with BitmapOr."
      }
    },
    {
      "id": "SEMI_JOIN_EXISTS",
      "summary": "EXISTS/NOT EXISTS uses semi-join with early termination. Stops scanning after the first match per outer row.",
      "field_note": "NEVER convert EXISTS to IN/NOT IN or to materialized CTEs with SELECT DISTINCT. The semi-join stops after first match \u2014 materializing forces a full DISTINCT scan of million-row fact tables. We saw 0.50x on Q069 (3 DISTINCT CTEs vs 3 semi-joins) and 0.86x on Q010 (UNION ALL CTE without dedup vs OR'd EXISTS short-circuits). Also: NOT IN has NULL-handling semantics that can block hash anti-join optimization.",
      "guard_rail": {
        "id": "PG_EXISTS_TO_IN_BLOCK",
        "severity": "HIGH",
        "instruction": "POSTGRESQL RULE: NEVER convert EXISTS/NOT EXISTS to IN/NOT IN with materialized CTEs. PostgreSQL uses efficient semi-join with early termination for EXISTS. Materializing DISTINCT keys from fact tables forces full scans and loses the early-termination benefit. Observed 0.50x-0.86x regressions.",
        "evidence": "DSB Q069_multi 0.50x \u2014 DISTINCT on multi-million-row fact tables is expensive. EXISTS semi-join stops after first match per row."
      }
    },
    {
      "id": "INNER_JOIN_REORDERING",
      "summary": "PostgreSQL freely reorders INNER JOINs based on estimated selectivity. The cost model works well for explicit JOIN...ON syntax.",
      "field_note": "Don't restructure INNER JOIN orders \u2014 the optimizer handles this well. Focus on queries where JOIN type (LEFT) prevents reordering, or where comma-joins confuse the cost model (see COMMA_JOIN_WEAKNESS gap)."
    },
    {
      "id": "INDEX_ONLY_SCAN",
      "summary": "When an index covers all requested columns, PostgreSQL reads only the index without touching the heap.",
      "field_note": "Dimension table lookups are already fast via index-only scans. Pre-filtering small dimensions (<10K rows) into CTEs adds materialization overhead with minimal benefit."
    },
    {
      "id": "PARALLEL_QUERY_EXECUTION",
      "summary": "PostgreSQL parallelizes large scans and aggregations across worker processes with partial aggregation finalization.",
      "field_note": "Large fact table scans are already parallelized. Restructuring into CTEs may reduce parallelism opportunities because CTE materialization is single-threaded."
    },
    {
      "id": "JIT_COMPILATION",
      "summary": "PostgreSQL JIT-compiles complex expressions and tuple deforming for long-running queries.",
      "field_note": "Complex WHERE expressions have low per-row overhead due to JIT. Simplifying expressions for performance is usually unnecessary."
    }
  ],
  "gaps": [
    {
      "id": "COMMA_JOIN_WEAKNESS",
      "priority": "HIGH",
      "what": "Implicit comma-separated FROM tables (FROM t1, t2, t3 WHERE t1.id = t2.id) are treated as cross products initially. The cost model is significantly weaker on comma-joins than on explicit JOIN...ON syntax.",
      "why": "The planner's join search space is less constrained with comma-joins. Explicit JOINs provide structural hints that help the optimizer find better plans faster, especially for 5+ table joins.",
      "opportunity": "Convert comma-joins to explicit JOIN...ON syntax. This alone can unlock 2-3x improvements. Best when combined with date_cte_isolate.",
      "what_worked": [
        "Q080: 3.32x \u2014 comma-joins to explicit JOINs + date CTE on multi-channel UNION query",
        "Q099: 2.28x \u2014 same pattern on star schema",
        "Q054: 1.14x \u2014 JOIN conversion alone"
      ],
      "what_didnt_work": [],
      "field_notes": [
        "Look for FROM t1, t2, t3 WHERE ... syntax. 5+ comma-separated tables is the sweet spot.",
        "EXPLAIN will show unexpected join orders or high-cost nested loops when comma-joins confuse the cost model.",
        "The win usually comes from explicit JOINs + CTE together, not CTE alone. date_cte_isolate without JOIN conversion is often neutral or harmful.",
        "This is our most reliable PG optimization \u2014 convert the implicit syntax and the optimizer rewards you.",
        "Validate at target scale \u2014 SF5 wins don't predict SF10 on PG (Q027 went from 9.62x to 0.97x)."
      ],
      "gold_examples": [
        {
          "id": "pg_date_cte_explicit_join",
          "queries": [
            "DSB Q099_agg"
          ],
          "speedup": "2.28x",
          "principle": "Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.",
          "original_sql": "select \n   substring(w_warehouse_name,1,20)\n  ,sm_type\n  ,cc_name\n  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as \"30 days\"\n  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and\n                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as \"31-60 days\"\n  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and\n                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as \"61-90 days\"\n  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and\n                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as \"91-120 days\"\n  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as \">120 days\"\nfrom\n   catalog_sales\n  ,warehouse\n  ,ship_mode\n  ,call_center\n  ,date_dim\nwhere\nd_month_seq between 1193 and 1193 + 23\nand cs_ship_date_sk   = d_date_sk\nand cs_warehouse_sk   = w_warehouse_sk\nand cs_ship_mode_sk   = sm_ship_mode_sk\nand cs_call_center_sk = cc_call_center_sk\nand cs_list_price between 271 and 300\nand sm_type = 'REGULAR'\nand cc_class = 'small'\nand w_gmt_offset = -5\ngroup by\n   substring(w_warehouse_name,1,20)\n  ,sm_type\n  ,cc_name\norder by substring(w_warehouse_name,1,20)\n        ,sm_type\n        ,cc_name\nlimit 100;",
          "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1193 AND 1193 + 23)\nSELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS \"30 days\", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 30) AND (cs_ship_date_sk - cs_sold_date_sk <= 60) THEN 1 ELSE 0 END) AS \"31-60 days\", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 60) AND (cs_ship_date_sk - cs_sold_date_sk <= 90) THEN 1 ELSE 0 END) AS \"61-90 days\", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 90) AND (cs_ship_date_sk - cs_sold_date_sk <= 120) THEN 1 ELSE 0 END) AS \"91-120 days\", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 120) THEN 1 ELSE 0 END) AS \">120 days\" FROM catalog_sales JOIN filtered_dates ON cs_ship_date_sk = d_date_sk JOIN warehouse ON cs_warehouse_sk = w_warehouse_sk JOIN ship_mode ON cs_ship_mode_sk = sm_ship_mode_sk JOIN call_center ON cs_call_center_sk = cc_call_center_sk WHERE cs_list_price BETWEEN 271 AND 300 AND sm_type = 'REGULAR' AND cc_class = 'small' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name LIMIT 100",
          "key_insight": "Principle: Dimension Isolation + Explicit Joins \u2014 materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma joins to explicit JOIN syntax. On PostgreSQL, both are required: the CTE reduces probe size, while explicit JOINs give the optimizer join-order freedom. Here: date_dim (730 from 73K rows) becomes a CTE hash table that catalog_sales probes; comma joins converted to explicit INNER JOIN.",
          "original_explain": "QUERY PLAN                                                                                                                                \n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=66077.03..66078.91 rows=12 width=117) (actual time=39.767..40.691 rows=4 loops=1)\n   Buffers: shared hit=60629 read=13455\n   ->  Finalize GroupAggregate  (cost=66077.03..66078.91 rows=12 width=117) (actual time=39.765..40.689 rows=4 loops=1)\n         Group Key: (\"substring\"((warehouse.w_warehouse_name)::text, 1, 20)), ship_mode.sm_type, call_center.cc_name\n         Buffers: shared hit=60629 read=13455\n         ->  Gather Merge  (cost=66077.03..66078.56 rows=10 width=117) (actual time=39.748..40.680 rows=10 loops=1)\n               Workers Planned: 2\n               Workers Launched: 2\n               Buffers: shared hit=60629 read=13455\n               ->  Partial GroupAggregate  (cost=65077.01..65077.38 rows=5 width=117) (actual time=24.832..24.853 rows=3 loops=3)\n                     Group Key: (\"substring\"((warehouse.w_warehouse_name)::text, 1, 20)), ship_mode.sm_type, call_center.cc_name\n                     Buffers: shared hit=60629 read=13455\n                     ->  Sort  (cost=65077.01..65077.02 rows=5 width=85) (actual time=24.824..24.829 rows=86 loops=3)\n                           Sort Key: (\"substring\"((warehouse.w_warehouse_name)::text, 1, 20)), call_center.cc_name\n                           Sort Method: quicksort  Memory: 40kB\n                           Buffers: shared hit=60629 read=13455\n                           Worker 0:  Sort Method: quicksort  Memory: 36kB\n                           Worker 1:  Sort Method: quicksort  Memory: 34kB\n                           ->  Nested Loop  (cost=0.98..65076.95 rows=5 width=85) (actual time=0.417..24.763 rows=86 loops=3)\n                                 Buffers: shared hit=60613 read=13455\n                                 ->  Parallel Index Only Scan using _dta_index_date_dim_6_661577395__k7_k4_k9_k1 on date_dim  (cost=0.42..1870.06 rows=315 width=4) (actual time=0.269..0.519 rows=244 loops=3)\n                                       Index Cond: ((d_month_seq >= 1193) AND (d_month_seq <= 1216))\n                                       Heap Fetches: 0\n                                       Buffers: shared hit=2 read=283\n                                 ->  Nested Loop  (cost=0.56..200.48 rows=18 width=70) (actual time=0.081..0.099 rows=0 loops=731)\n                                       Buffers: shared hit=60611 read=13172\n                                       ->  Seq Scan on call_center  (cost=0.00..2.30 rows=3 width=18) (actual time=0.000..0.002 rows=3 loops=731)\n                                             Filter: ((cc_class)::text = 'small'::text)\n                                             Rows Removed by Filter: 21\n                                             Buffers: shared hit=1462\n                                       ->  Nested Loop  (cost=0.56..66.00 rows=6 width=60) (actual time=0.029..0.032 rows=0 loops=2193)\n                                             Buffers: shared hit=59149 read=13172\n                                             ->  Seq Scan on warehouse  (cost=0.00..1.12 rows=2 width=21) (actual time=0.000..0.001 rows=2 loops=2193)\n                                                   Filter: (w_gmt_offset = '-5'::numeric)\n                                                   Rows Removed by Filter: 8\n                                                   Buffers: shared hit=2193\n                                             ->  Nested Loop  (cost=0.56..32.41 rows=3 width=47) (actual time=0.014..0.015 rows=0 loops=4386)\n                                                   Buffers: shared hit=56956 read=13172\n                                                   ->  Seq Scan on ship_mode  (cost=0.00..1.25 rows=3 width=35) (actual time=0.000..0.001 rows=3 loops=4386)\n                                                         Filter: (sm_type = 'REGULAR'::bpchar)\n                                                         Rows Removed by Filter: 17\n                                                         Buffers: shared hit=4386\n                                                   ->  Index Scan using _dta_index_catalog_sales_6_1301579675__k3_k12_k14_k15_16_18 on catalog_sales  (cost=0.56..10.38 rows=1 width=20) (actual time=0.005..0.005 rows=0 loops=13158)\n                                                         Index Cond: ((cs_ship_date_sk = date_dim.d_date_sk) AND (cs_call_center_sk = call_center.cc_call_center_sk) AND (cs_ship_mode_sk = ship_mode.sm_ship_mode_sk) AND (cs_warehouse_sk = warehouse.w_warehouse_sk))\n                                                         Filter: ((cs_list_price >= '271'::numeric) AND (cs_list_price <= '300'::numeric))\n                                                         Rows Removed by Filter: 1\n                                                         Buffers: shared hit=52570 read=13172\n Planning:\n   Buffers: shared hit=664 read=86\n Planning Time: 1.626 ms\n Execution Time: 40.793 ms\n(51 rows)",
          "optimized_explain": "QUERY PLAN                                                                                                                                \n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=66077.03..66078.91 rows=12 width=117) (actual time=26.772..28.070 rows=4 loops=1)\n   Buffers: shared hit=62495 read=11589\n   ->  Finalize GroupAggregate  (cost=66077.03..66078.91 rows=12 width=117) (actual time=26.771..28.068 rows=4 loops=1)\n         Group Key: (SUBSTRING(warehouse.w_warehouse_name FROM 1 FOR 20)), ship_mode.sm_type, call_center.cc_name\n         Buffers: shared hit=62495 read=11589\n         ->  Gather Merge  (cost=66077.03..66078.56 rows=10 width=117) (actual time=26.763..28.062 rows=10 loops=1)\n               Workers Planned: 2\n               Workers Launched: 2\n               Buffers: shared hit=62495 read=11589\n               ->  Partial GroupAggregate  (cost=65077.01..65077.38 rows=5 width=117) (actual time=24.141..24.158 rows=3 loops=3)\n                     Group Key: (SUBSTRING(warehouse.w_warehouse_name FROM 1 FOR 20)), ship_mode.sm_type, call_center.cc_name\n                     Buffers: shared hit=62495 read=11589\n                     ->  Sort  (cost=65077.01..65077.02 rows=5 width=85) (actual time=24.132..24.137 rows=86 loops=3)\n                           Sort Key: (SUBSTRING(warehouse.w_warehouse_name FROM 1 FOR 20)), call_center.cc_name\n                           Sort Method: quicksort  Memory: 40kB\n                           Buffers: shared hit=62495 read=11589\n                           Worker 0:  Sort Method: quicksort  Memory: 36kB\n                           Worker 1:  Sort Method: quicksort  Memory: 34kB\n                           ->  Nested Loop  (cost=0.98..65076.95 rows=5 width=85) (actual time=0.344..24.072 rows=86 loops=3)\n                                 Buffers: shared hit=62479 read=11589\n                                 ->  Parallel Index Only Scan using _dta_index_date_dim_6_661577395__k7_k4_k9_k1 on date_dim  (cost=0.42..1870.06 rows=315 width=4) (actual time=0.223..1.071 rows=244 loops=3)\n                                       Index Cond: ((d_month_seq >= 1193) AND (d_month_seq <= 1216))\n                                       Heap Fetches: 0\n                                       Buffers: shared hit=5 read=280\n                                 ->  Nested Loop  (cost=0.56..200.48 rows=18 width=70) (actual time=0.076..0.094 rows=0 loops=731)\n                                       Buffers: shared hit=62474 read=11309\n                                       ->  Seq Scan on call_center  (cost=0.00..2.30 rows=3 width=18) (actual time=0.000..0.002 rows=3 loops=731)\n                                             Filter: ((cc_class)::text = 'small'::text)\n                                             Rows Removed by Filter: 21\n                                             Buffers: shared hit=1462\n                                       ->  Nested Loop  (cost=0.56..66.00 rows=6 width=60) (actual time=0.027..0.031 rows=0 loops=2193)\n                                             Buffers: shared hit=61012 read=11309\n                                             ->  Seq Scan on warehouse  (cost=0.00..1.12 rows=2 width=21) (actual time=0.000..0.001 rows=2 loops=2193)\n                                                   Filter: (w_gmt_offset = '-5'::numeric)\n                                                   Rows Removed by Filter: 8\n                                                   Buffers: shared hit=2193\n                                             ->  Nested Loop  (cost=0.56..32.41 rows=3 width=47) (actual time=0.014..0.015 rows=0 loops=4386)\n                                                   Buffers: shared hit=58819 read=11309\n                                                   ->  Seq Scan on ship_mode  (cost=0.00..1.25 rows=3 width=35) (actual time=0.000..0.001 rows=3 loops=4386)\n                                                         Filter: (sm_type = 'REGULAR'::bpchar)\n                                                         Rows Removed by Filter: 17\n                                                         Buffers: shared hit=4386\n                                                   ->  Index Scan using _dta_index_catalog_sales_6_1301579675__k3_k12_k14_k15_16_18 on catalog_sales  (cost=0.56..10.38 rows=1 width=20) (actual time=0.004..0.004 rows=0 loops=13158)\n                                                         Index Cond: ((cs_ship_date_sk = date_dim.d_date_sk) AND (cs_call_center_sk = call_center.cc_call_center_sk) AND (cs_ship_mode_sk = ship_mode.sm_ship_mode_sk) AND (cs_warehouse_sk = warehouse.w_warehouse_sk))\n                                                         Filter: ((cs_list_price >= '271'::numeric) AND (cs_list_price <= '300'::numeric))\n                                                         Rows Removed by Filter: 1\n                                                         Buffers: shared hit=54433 read=11309\n Planning:\n   Buffers: shared hit=697 read=53\n Planning Time: 1.486 ms\n Execution Time: 28.162 ms\n(51 rows)",
          "explain_timing": {
            "original_s": 0.06,
            "optimized_s": 0.05
          },
          "plan_signature": {
            "original_buffers": 74084,
            "optimized_buffers": 74084,
            "buffer_reduction": 1.0,
            "original_time_ms": 40.793,
            "optimized_time_ms": 28.162,
            "original_high_loops": [
              {
                "node": "N",
                "table": null,
                "loops": 731,
                "rows_per_loop": 0
              },
              {
                "node": "S",
                "table": null,
                "loops": 731,
                "rows_per_loop": 3
              },
              {
                "node": "N",
                "table": null,
                "loops": 2193,
                "rows_per_loop": 0
              }
            ]
          }
        },
        {
          "id": "pg_dimension_prefetch_star",
          "queries": [
            "DSB Q080_multi"
          ],
          "speedup": "3.32x",
          "principle": "Multi-Dimension Prefetch (PG): pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax. PostgreSQL's optimizer gets better cardinality estimates from pre-materialized small dimension results.",
          "original_sql": "with ssr as\n (select  s_store_id as store_id,\n          sum(ss_ext_sales_price) as sales,\n          sum(coalesce(sr_return_amt, 0)) as returns,\n          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit\n  from store_sales left outer join store_returns on\n         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),\n     date_dim,\n     store,\n     item,\n     promotion\n where ss_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-23' as date)\n                  and cast('1998-08-23' as date) + interval '30 day'\n       and ss_store_sk = s_store_sk\n       and ss_item_sk = i_item_sk\n       and i_current_price > 50\n       and ss_promo_sk = p_promo_sk\n       and p_channel_email = 'Y'\n       and p_channel_tv = 'Y'\n       and p_channel_radio = 'N'\n       and p_channel_press = 'N'\n       and p_channel_event = 'Y'\n       and ss_wholesale_cost BETWEEN 63 AND 78\n       and i_category IN ('Jewelry', 'Music')\n group by s_store_id)\n ,\n csr as\n (select  cp_catalog_page_id as catalog_page_id,\n          sum(cs_ext_sales_price) as sales,\n          sum(coalesce(cr_return_amount, 0)) as returns,\n          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit\n  from catalog_sales left outer join catalog_returns on\n         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),\n     date_dim,\n     catalog_page,\n     item,\n     promotion\n where cs_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-23' as date)\n                  and cast('1998-08-23' as date) + interval '30 day'\n        and cs_catalog_page_sk = cp_catalog_page_sk\n       and cs_item_sk = i_item_sk\n       and i_current_price > 50\n       and cs_promo_sk = p_promo_sk\n       and p_channel_email = 'Y'\n       and p_channel_tv = 'Y'\n       and p_channel_radio = 'N'\n       and p_channel_press = 'N'\n       and p_channel_event = 'Y'\n       and cs_wholesale_cost BETWEEN 63 AND 78\n       and i_category IN ('Jewelry', 'Music')\ngroup by cp_catalog_page_id)\n ,\n wsr as\n (select  web_site_id,\n          sum(ws_ext_sales_price) as sales,\n          sum(coalesce(wr_return_amt, 0)) as returns,\n          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit\n  from web_sales left outer join web_returns on\n         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),\n     date_dim,\n     web_site,\n     item,\n     promotion\n where ws_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-23' as date)\n                  and cast('1998-08-23' as date) + interval '30 day'\n        and ws_web_site_sk = web_site_sk\n       and ws_item_sk = i_item_sk\n       and i_current_price > 50\n       and ws_promo_sk = p_promo_sk\n       and p_channel_email = 'Y'\n       and p_channel_tv = 'Y'\n       and p_channel_radio = 'N'\n       and p_channel_press = 'N'\n       and p_channel_event = 'Y'\n       and ws_wholesale_cost BETWEEN 63 AND 78\n       and i_category IN ('Jewelry', 'Music')\ngroup by web_site_id)\n  select  channel\n        , id\n        , sum(sales) as sales\n        , sum(returns) as returns\n        , sum(profit) as profit\n from\n (select 'store channel' as channel\n        , 'store' || store_id as id\n        , sales\n        , returns\n        , profit\n from   ssr\n union all\n select 'catalog channel' as channel\n        , 'catalog_page' || catalog_page_id as id\n        , sales\n        , returns\n        , profit\n from  csr\n union all\n select 'web channel' as channel\n        , 'web_site' || web_site_id as id\n        , sales\n        , returns\n        , profit\n from   wsr\n ) x\n group by rollup (channel, id)\n order by channel\n         ,id\n limit 100;",
          "optimized_sql": "WITH filtered_date AS (SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-23' AS DATE) AND CAST('1998-08-23' AS DATE) + INTERVAL '30 DAY'), filtered_item AS (SELECT i_item_sk FROM item WHERE i_current_price > 50 AND i_category IN ('Jewelry', 'Music')), filtered_promotion AS (SELECT p_promo_sk FROM promotion WHERE p_channel_email = 'Y' AND p_channel_tv = 'Y' AND p_channel_radio = 'N' AND p_channel_press = 'N' AND p_channel_event = 'Y'), ssr AS (SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS returns, SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) INNER JOIN filtered_date ON ss_sold_date_sk = filtered_date.d_date_sk INNER JOIN store ON ss_store_sk = s_store_sk INNER JOIN filtered_item ON ss_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ss_promo_sk = filtered_promotion.p_promo_sk WHERE ss_wholesale_cost BETWEEN 63 AND 78 GROUP BY s_store_id), csr AS (SELECT cp_catalog_page_id AS catalog_page_id, SUM(cs_ext_sales_price) AS sales, SUM(COALESCE(cr_return_amount, 0)) AS returns, SUM(cs_net_profit - COALESCE(cr_net_loss, 0)) AS profit FROM catalog_sales LEFT OUTER JOIN catalog_returns ON (cs_item_sk = cr_item_sk AND cs_order_number = cr_order_number) INNER JOIN filtered_date ON cs_sold_date_sk = filtered_date.d_date_sk INNER JOIN catalog_page ON cs_catalog_page_sk = cp_catalog_page_sk INNER JOIN filtered_item ON cs_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON cs_promo_sk = filtered_promotion.p_promo_sk WHERE cs_wholesale_cost BETWEEN 63 AND 78 GROUP BY cp_catalog_page_id), wsr AS (SELECT web_site_id, SUM(ws_ext_sales_price) AS sales, SUM(COALESCE(wr_return_amt, 0)) AS returns, SUM(ws_net_profit - COALESCE(wr_net_loss, 0)) AS profit FROM web_sales LEFT OUTER JOIN web_returns ON (ws_item_sk = wr_item_sk AND ws_order_number = wr_order_number) INNER JOIN filtered_date ON ws_sold_date_sk = filtered_date.d_date_sk INNER JOIN web_site ON ws_web_site_sk = web_site_sk INNER JOIN filtered_item ON ws_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ws_promo_sk = filtered_promotion.p_promo_sk WHERE ws_wholesale_cost BETWEEN 63 AND 78 GROUP BY web_site_id) SELECT channel, id, SUM(sales) AS sales, SUM(returns) AS returns, SUM(profit) AS profit FROM (SELECT 'store channel' AS channel, 'store' || store_id AS id, sales, returns, profit FROM ssr UNION ALL SELECT 'catalog channel' AS channel, 'catalog_page' || catalog_page_id AS id, sales, returns, profit FROM csr UNION ALL SELECT 'web channel' AS channel, 'web_site' || web_site_id AS id, sales, returns, profit FROM wsr) AS x GROUP BY ROLLUP (channel, id) ORDER BY channel, id LIMIT 100",
          "key_insight": "Principle: Multi-Dimension Prefetch (PG) \u2014 pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax for PostgreSQL optimizer join-order freedom. Even partial transformation helps when one branch dominates runtime. Here: date (30/73K), item (2 categories), promotion (5 filters) all become CTEs; comma joins converted to INNER JOIN.",
          "original_explain": "QUERY PLAN                                                                                                                                \n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=51606.66..51606.82 rows=7 width=160) (actual time=66.741..67.402 rows=3 loops=1)\n   Buffers: shared hit=4320 read=10068\n   ->  GroupAggregate  (cost=51606.66..51606.82 rows=7 width=160) (actual time=66.740..67.400 rows=3 loops=1)\n         Group Key: ('store channel'::text), (('store'::text || (ssr.store_id)::text))\n         Group Key: ('store channel'::text)\n         Group Key: ()\n         Buffers: shared hit=4320 read=10068\n         ->  Sort  (cost=51606.66..51606.66 rows=3 width=160) (actual time=66.726..67.387 rows=1 loops=1)\n               Sort Key: ('store channel'::text), (('store'::text || (ssr.store_id)::text))\n               Sort Method: quicksort  Memory: 25kB\n               Buffers: shared hit=4320 read=10068\n               ->  Append  (cost=18713.99..51606.63 rows=3 width=160) (actual time=33.597..67.371 rows=1 loops=1)\n                     Buffers: shared hit=4317 read=10068\n                     ->  Subquery Scan on ssr  (cost=18713.99..18714.04 rows=1 width=160) (actual time=33.596..33.658 rows=1 loops=1)\n                           Buffers: shared hit=1585 read=4282\n                           ->  GroupAggregate  (cost=18713.99..18714.03 rows=1 width=113) (actual time=33.592..33.653 rows=1 loops=1)\n                                 Group Key: store.s_store_id\n                                 Buffers: shared hit=1585 read=4282\n                                 ->  Sort  (cost=18713.99..18714.00 rows=1 width=41) (actual time=33.579..33.640 rows=1 loops=1)\n                                       Sort Key: store.s_store_id\n                                       Sort Method: quicksort  Memory: 25kB\n                                       Buffers: shared hit=1585 read=4282\n                                       ->  Nested Loop  (cost=1026.12..18713.98 rows=1 width=41) (actual time=22.647..33.631 rows=1 loops=1)\n                                             Buffers: shared hit=1585 read=4282\n                                             ->  Nested Loop Left Join  (cost=1025.98..18713.82 rows=1 width=28) (actual time=22.636..33.618 rows=1 loops=1)\n                                                   Buffers: shared hit=1584 read=4281\n                                                   ->  Gather  (cost=1025.55..18711.67 rows=1 width=24) (actual time=22.620..33.601 rows=1 loops=1)\n                                                         Workers Planned: 2\n                                                         Workers Launched: 2\n                                                         Buffers: shared hit=1583 read=4279\n                                                         ->  Nested Loop  (cost=25.55..17711.57 rows=1 width=24) (actual time=9.334..12.977 rows=0 loops=3)\n                                                               Buffers: shared hit=1583 read=4279\n                                                               ->  Hash Join  (cost=25.25..17674.77 rows=21 width=24) (actual time=3.263..12.110 rows=210 loops=3)\n                                                                     Hash Cond: (store_sales.ss_promo_sk = promotion.p_promo_sk)\n                                                                     Buffers: shared hit=233 read=3742\n                                                                     ->  Nested Loop  (cost=0.85..17647.94 rows=919 width=28) (actual time=3.226..11.716 rows=9522 loops=3)\n                                                                           Buffers: shared hit=231 read=3731\n                                                                           ->  Parallel Index Scan using date_dim_pkey on date_dim  (cost=0.29..3038.09 rows=14 width=4) (actual time=3.210..3.223 rows=10 loops=3)\n                                                                                 Filter: ((d_date >= '1998-08-23'::date) AND (d_date <= '1998-09-22 00:00:00'::timestamp without time zone))\n                                                                                 Rows Removed by Filter: 24339\n                                                                                 Buffers: shared hit=122 read=1595\n                                                                           ->  Index Only Scan using _dta_index_store_sales_6_1333579789__k1_k23_k14_k6_k8_k5_k7_3_4 on store_sales  (cost=0.56..1019.82 rows=2374 width=32) (actual time=0.010..0.777 rows=921 loops=31)\n                                                                                 Index Cond: (ss_sold_date_sk = date_dim.d_date_sk)\n                                                                                 Filter: ((ss_wholesale_cost >= '63'::numeric) AND (ss_wholesale_cost <= '78'::numeric))\n                                                                                 Rows Removed by Filter: 4108\n                                                                                 Heap Fetches: 0\n                                                                                 Buffers: shared hit=109 read=2136\n                                                                     ->  Hash  (cost=24.25..24.25 rows=12 width=4) (actual time=0.091..0.094 rows=10 loops=1)\n                                                                           Buckets: 1024  Batches: 1  Memory Usage: 9kB\n                                                                           Buffers: shared hit=2 read=11\n                                                                           ->  Seq Scan on promotion  (cost=0.00..24.25 rows=12 width=4) (actual time=0.014..0.088 rows=10 loops=1)\n                                                                                 Filter: ((p_channel_email = 'Y'::bpchar) AND (p_channel_tv = 'Y'::bpchar) AND (p_channel_event = 'Y'::bpchar) AND (p_channel_radio = 'N'::bpchar) AND (p_channel_press = 'N'::bpchar))\n                                                                                 Rows Removed by Filter: 490\n                                                                                 Buffers: shared hit=2 read=11\n                                                               ->  Index Scan using item_pkey on item  (cost=0.29..1.75 rows=1 width=4) (actual time=0.004..0.004 rows=0 loops=629)\n                                                                     Index Cond: (i_item_sk = store_sales.ss_item_sk)\n                                                                     Filter: ((i_current_price > '50'::numeric) AND (i_category = ANY ('{Jewelry,Music}'::bpchar[])))\n                                                                     Rows Removed by Filter: 1\n                                                                     Buffers: shared hit=1350 read=537\n                                                   ->  Index Scan using store_returns_pkey on store_returns  (cost=0.43..2.15 rows=1 width=20) (actual time=0.014..0.014 rows=0 loops=1)\n                                                         Index Cond: ((sr_item_sk = store_sales.ss_item_sk) AND (sr_ticket_number = store_sales.ss_ticket_number))\n                                                         Buffers: shared hit=1 read=2\n                                             ->  Index Only Scan using _dta_index_store_6_885578193__k1_2_6 on store  (cost=0.14..0.16 rows=1 width=21) (actual time=0.009..0.009 rows=1 loops=1)\n                                                   Index Cond: (s_store_sk = store_sales.ss_store_sk)\n                                                   Heap Fetches: 1\n                                                   Buffers: shared hit=1 read=1\n                     ->  Subquery Scan on csr  (cost=20562.07..20562.40 rows=1 width=160) (actual time=17.058..17.086 rows=0 loops=1)\n                           Buffers: shared hit=739 read=3803\n                           ->  GroupAggregate  (cost=20562.07..20562.39 rows=1 width=113) (actual time=17.056..17.083 rows=0 loops=1)\n                                 Group Key: catalog_page.cp_catalog_page_id\n                                 Buffers: shared hit=739 read=3803\n                                 ->  Nested Loop Left Join  (cost=20562.07..20562.36 rows=1 width=41) (actual time=17.054..17.080 rows=0 loops=1)\n                                       Buffers: shared hit=739 read=3803\n                                       ->  Gather Merge  (cost=20561.64..20561.76 rows=1 width=37) (actual time=17.053..17.078 rows=0 loops=1)\n                                             Workers Planned: 1\n                                             Workers Launched: 1\n                                             Buffers: shared hit=739 read=3803\n                                             ->  Sort  (cost=19561.63..19561.63 rows=1 width=37) (actual time=11.752..11.755 rows=0 loops=2)\n                                                   Sort Key: catalog_page.cp_catalog_page_id\n                                                   Sort Method: quicksort  Memory: 25kB\n                                                   Buffers: shared hit=739 read=3803\n                                                   Worker 0:  Sort Method: quicksort  Memory: 25kB\n                                                   ->  Nested Loop  (cost=25.41..19561.62 rows=1 width=37) (actual time=11.737..11.741 rows=0 loops=2)\n                                                         Buffers: shared hit=732 read=3803\n                                                         ->  Nested Loop  (cost=25.13..19561.31 rows=1 width=24) (actual time=11.736..11.739 rows=0 loops=2)\n                                                               Buffers: shared hit=732 read=3803\n                                                               ->  Hash Join  (cost=24.83..19558.61 rows=8 width=24) (actual time=1.655..11.332 rows=88 loops=2)\n                                                                     Hash Cond: (catalog_sales.cs_promo_sk = promotion_1.p_promo_sk)\n                                                                     Buffers: shared hit=325 read=3681\n                                                                     ->  Nested Loop  (cost=0.43..19533.31 rows=339 width=28) (actual time=1.377..11.046 rows=3789 loops=2)\n                                                                           Buffers: shared hit=267 read=3666\n                                                                           ->  Parallel Seq Scan on date_dim date_dim_1  (cost=0.00..2049.55 rows=19 width=4) (actual time=1.339..2.713 rows=16 loops=2)\n                                                                                 Filter: ((d_date >= '1998-08-23'::date) AND (d_date <= '1998-09-22 00:00:00'::timestamp without time zone))\n                                                                                 Rows Removed by Filter: 36509\n                                                                                 Buffers: shared hit=124 read=1281\n                                                                           ->  Index Scan using _dta_index_catalog_sales_6_1301579675__k1_4 on catalog_sales  (cost=0.43..914.21 rows=599 width=32) (actual time=0.008..0.517 rows=244 loops=31)\n                                                                                 Index Cond: (cs_sold_date_sk = date_dim_1.d_date_sk)\n                                                                                 Filter: ((cs_wholesale_cost >= '63'::numeric) AND (cs_wholesale_cost <= '78'::numeric))\n                                                                                 Rows Removed by Filter: 2443\n                                                                                 Buffers: shared hit=143 read=2385\n                                                                     ->  Hash  (cost=24.25..24.25 rows=12 width=4) (actual time=0.067..0.067 rows=10 loops=2)\n                                                                           Buckets: 1024  Batches: 1  Memory Usage: 9kB\n                                                                           Buffers: shared hit=15 read=11\n                                                                           ->  Seq Scan on promotion promotion_1  (cost=0.00..24.25 rows=12 width=4) (actual time=0.011..0.064 rows=10 loops=2)\n                                                                                 Filter: ((p_channel_email = 'Y'::bpchar) AND (p_channel_tv = 'Y'::bpchar) AND (p_channel_event = 'Y'::bpchar) AND (p_channel_radio = 'N'::bpchar) AND (p_channel_press = 'N'::bpchar))\n                                                                                 Rows Removed by Filter: 490\n                                                                                 Buffers: shared hit=15 read=11\n                                                               ->  Index Scan using item_pkey on item item_1  (cost=0.29..0.34 rows=1 width=4) (actual time=0.004..0.004 rows=0 loops=176)\n                                                                     Index Cond: (i_item_sk = catalog_sales.cs_item_sk)\n                                                                     Filter: ((i_current_price > '50'::numeric) AND (i_category = ANY ('{Jewelry,Music}'::bpchar[])))\n                                                                     Rows Removed by Filter: 1\n                                                                     Buffers: shared hit=407 read=122\n                                                         ->  Index Scan using catalog_page_pkey on catalog_page  (cost=0.29..0.30 rows=1 width=21) (never executed)\n                                                               Index Cond: (cp_catalog_page_sk = catalog_sales.cs_catalog_page_sk)\n                                       ->  Index Scan using catalog_returns_pkey on catalog_returns  (cost=0.43..0.60 rows=1 width=20) (never executed)\n                                             Index Cond: ((cr_item_sk = catalog_sales.cs_item_sk) AND (cr_order_number = catalog_sales.cs_order_number))\n                     ->  Subquery Scan on wsr  (cost=12329.88..12330.17 rows=1 width=160) (actual time=16.054..16.622 rows=0 loops=1)\n                           Buffers: shared hit=1993 read=1983\n... (53 more lines truncated)",
          "optimized_explain": "QUERY PLAN                                                                                                                                \n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=90936.74..90938.71 rows=79 width=160) (actual time=69.944..69.964 rows=3 loops=1)\n   Buffers: shared hit=465 read=10926\n   CTE filtered_date\n     ->  Index Scan using _dta_index_date_dim_6_661577395__k4_k3 on date_dim  (cost=0.29..1599.11 rows=33 width=4) (actual time=0.540..1.318 rows=31 loops=1)\n           Index Cond: ((d_date >= '1998-08-23'::date) AND (d_date <= '1998-09-22 00:00:00'::timestamp without time zone))\n           Buffers: shared read=203\n   CTE filtered_item\n     ->  Bitmap Heap Scan on item  (cost=485.15..7693.80 rows=356 width=4) (actual time=1.470..16.322 rows=344 loops=1)\n           Recheck Cond: (i_category = ANY ('{Jewelry,Music}'::bpchar[]))\n           Filter: (i_current_price > '50'::numeric)\n           Rows Removed by Filter: 5924\n           Heap Blocks: exact=4241\n           Buffers: shared hit=18 read=4335\n           ->  Bitmap Index Scan on _dta_index_item_6_853578079__k13_k11_k1  (cost=0.00..485.06 rows=6429 width=0) (actual time=0.964..0.964 rows=6268 loops=1)\n                 Index Cond: (i_category = ANY ('{Jewelry,Music}'::bpchar[]))\n                 Buffers: shared hit=1 read=111\n   CTE filtered_promotion\n     ->  Seq Scan on promotion  (cost=0.00..24.25 rows=12 width=4) (actual time=0.011..0.065 rows=10 loops=1)\n           Filter: ((p_channel_email = 'Y'::bpchar) AND (p_channel_tv = 'Y'::bpchar) AND (p_channel_event = 'Y'::bpchar) AND (p_channel_radio = 'N'::bpchar) AND (p_channel_press = 'N'::bpchar))\n           Rows Removed by Filter: 490\n           Buffers: shared hit=13\n   ->  GroupAggregate  (cost=81619.58..81621.55 rows=79 width=160) (actual time=69.943..69.960 rows=3 loops=1)\n         Group Key: ('store channel'::text), (('store'::text || (ssr.store_id)::text))\n         Group Key: ('store channel'::text)\n         Group Key: ()\n         Buffers: shared hit=465 read=10926\n         ->  Sort  (cost=81619.58..81619.68 rows=39 width=160) (actual time=69.928..69.945 rows=1 loops=1)\n               Sort Key: ('store channel'::text), (('store'::text || (ssr.store_id)::text))\n               Sort Method: quicksort  Memory: 25kB\n               Buffers: shared hit=465 read=10926\n               ->  Append  (cost=34948.97..81618.55 rows=39 width=160) (actual time=43.410..69.934 rows=1 loops=1)\n                     Buffers: shared hit=462 read=10926\n                     ->  Subquery Scan on ssr  (cost=34948.97..34950.20 rows=26 width=160) (actual time=43.409..43.416 rows=1 loops=1)\n                           Buffers: shared hit=147 read=6678\n                           ->  GroupAggregate  (cost=34948.97..34949.81 rows=26 width=113) (actual time=43.405..43.411 rows=1 loops=1)\n                                 Group Key: store.s_store_id\n                                 Buffers: shared hit=147 read=6678\n                                 ->  Sort  (cost=34948.97..34949.03 rows=26 width=41) (actual time=43.396..43.402 rows=1 loops=1)\n                                       Sort Key: store.s_store_id\n                                       Sort Method: quicksort  Memory: 25kB\n                                       Buffers: shared hit=147 read=6678\n                                       ->  Nested Loop Left Join  (cost=12.96..34948.36 rows=26 width=41) (actual time=43.381..43.391 rows=1 loops=1)\n                                             Buffers: shared hit=144 read=6678\n                                             ->  Nested Loop  (cost=12.52..34894.62 rows=26 width=37) (actual time=43.364..43.374 rows=1 loops=1)\n                                                   Join Filter: (store_sales.ss_store_sk = store.s_store_sk)\n                                                   Rows Removed by Join Filter: 101\n                                                   Buffers: shared hit=144 read=6675\n                                                   ->  Seq Scan on store  (cost=0.00..6.02 rows=102 width=21) (actual time=0.003..0.021 rows=102 loops=1)\n                                                         Buffers: shared hit=1 read=4\n                                                   ->  Materialize  (cost=12.52..34847.35 rows=27 width=24) (actual time=0.325..0.425 rows=1 loops=102)\n                                                         Buffers: shared hit=143 read=6671\n                                                         ->  Hash Join  (cost=12.52..34847.22 rows=27 width=24) (actual time=33.152..43.327 rows=1 loops=1)\n                                                               Hash Cond: (store_sales.ss_item_sk = filtered_item.i_item_sk)\n                                                               Buffers: shared hit=143 read=6671\n                                                               ->  Hash Join  (cost=0.95..34750.21 rows=1793 width=24) (actual time=0.675..26.815 rows=629 loops=1)\n                                                                     Hash Cond: (store_sales.ss_promo_sk = filtered_promotion.p_promo_sk)\n                                                                     Buffers: shared hit=125 read=2336\n                                                                     ->  Nested Loop  (cost=0.56..34438.15 rows=78330 width=28) (actual time=0.583..25.600 rows=28566 loops=1)\n                                                                           Buffers: shared hit=112 read=2336\n                                                                           ->  CTE Scan on filtered_date  (cost=0.00..0.66 rows=33 width=4) (actual time=0.541..1.335 rows=31 loops=1)\n                                                                                 Buffers: shared read=203\n                                                                           ->  Index Only Scan using _dta_index_store_sales_6_1333579789__k1_k23_k14_k6_k8_k5_k7_3_4 on store_sales  (cost=0.56..1019.82 rows=2374 width=32) (actual time=0.009..0.739 rows=921 loops=31)\n                                                                                 Index Cond: (ss_sold_date_sk = filtered_date.d_date_sk)\n                                                                                 Filter: ((ss_wholesale_cost >= '63'::numeric) AND (ss_wholesale_cost <= '78'::numeric))\n                                                                                 Rows Removed by Filter: 4108\n                                                                                 Heap Fetches: 0\n                                                                                 Buffers: shared hit=112 read=2133\n                                                                     ->  Hash  (cost=0.24..0.24 rows=12 width=4) (actual time=0.078..0.079 rows=10 loops=1)\n                                                                           Buckets: 1024  Batches: 1  Memory Usage: 9kB\n                                                                           Buffers: shared hit=13\n                                                                           ->  CTE Scan on filtered_promotion  (cost=0.00..0.24 rows=12 width=4) (actual time=0.013..0.067 rows=10 loops=1)\n                                                                                 Buffers: shared hit=13\n                                                               ->  Hash  (cost=7.12..7.12 rows=356 width=4) (actual time=16.436..16.437 rows=344 loops=1)\n                                                                     Buckets: 1024  Batches: 1  Memory Usage: 21kB\n                                                                     Buffers: shared hit=18 read=4335\n                                                                     ->  CTE Scan on filtered_item  (cost=0.00..7.12 rows=356 width=4) (actual time=1.472..16.385 rows=344 loops=1)\n                                                                           Buffers: shared hit=18 read=4335\n                                             ->  Index Scan using store_returns_pkey on store_returns  (cost=0.43..2.07 rows=1 width=20) (actual time=0.014..0.014 rows=0 loops=1)\n                                                   Index Cond: ((sr_item_sk = store_sales.ss_item_sk) AND (sr_ticket_number = store_sales.ss_ticket_number))\n                                                   Buffers: shared read=3\n                     ->  Subquery Scan on csr  (cost=30487.04..30487.37 rows=7 width=160) (actual time=14.381..14.387 rows=0 loops=1)\n                           Buffers: shared hit=143 read=2384\n                           ->  GroupAggregate  (cost=30487.04..30487.27 rows=7 width=113) (actual time=14.380..14.385 rows=0 loops=1)\n                                 Group Key: catalog_page.cp_catalog_page_id\n                                 Buffers: shared hit=143 read=2384\n                                 ->  Sort  (cost=30487.04..30487.06 rows=7 width=41) (actual time=14.378..14.383 rows=0 loops=1)\n                                       Sort Key: catalog_page.cp_catalog_page_id\n                                       Sort Method: quicksort  Memory: 25kB\n                                       Buffers: shared hit=143 read=2384\n                                       ->  Nested Loop  (cost=13.11..30486.94 rows=7 width=41) (actual time=14.368..14.372 rows=0 loops=1)\n                                             Buffers: shared hit=143 read=2384\n                                             ->  Nested Loop Left Join  (cost=12.82..30484.82 rows=7 width=28) (actual time=14.367..14.371 rows=0 loops=1)\n                                                   Buffers: shared hit=143 read=2384\n                                                   ->  Hash Join  (cost=12.39..30480.60 rows=7 width=24) (actual time=14.366..14.369 rows=0 loops=1)\n                                                         Hash Cond: (catalog_sales.cs_item_sk = filtered_item_1.i_item_sk)\n                                                         Buffers: shared hit=143 read=2384\n                                                         ->  Hash Join  (cost=0.83..30446.49 rows=473 width=24) (actual time=0.302..14.312 rows=176 loops=1)\n                                                               Hash Cond: (catalog_sales.cs_promo_sk = filtered_promotion_1.p_promo_sk)\n                                                               Buffers: shared hit=143 read=2384\n                                                               ->  Nested Loop  (cost=0.43..30367.20 rows=19781 width=28) (actual time=0.025..13.950 rows=7578 loops=1)\n                                                                     Buffers: shared hit=143 read=2384\n                                                                     ->  CTE Scan on filtered_date filtered_date_1  (cost=0.00..0.66 rows=33 width=4) (actual time=0.000..0.008 rows=31 loops=1)\n                                                                     ->  Index Scan using _dta_index_catalog_sales_6_1301579675__k1_4 on catalog_sales  (cost=0.43..914.21 rows=599 width=32) (actual time=0.006..0.429 rows=244 loops=31)\n                                                                           Index Cond: (cs_sold_date_sk = filtered_date_1.d_date_sk)\n                                                                           Filter: ((cs_wholesale_cost >= '63'::numeric) AND (cs_wholesale_cost <= '78'::numeric))\n                                                                           Rows Removed by Filter: 2443\n                                                                           Buffers: shared hit=143 read=2384\n                                                               ->  Hash  (cost=0.24..0.24 rows=12 width=4) (actual time=0.004..0.005 rows=10 loops=1)\n                                                                     Buckets: 1024  Batches: 1  Memory Usage: 9kB\n                                                                     ->  CTE Scan on filtered_promotion filtered_promotion_1  (cost=0.00..0.24 rows=12 width=4) (actual time=0.000..0.001 rows=10 loops=1)\n                                                         ->  Hash  (cost=7.12..7.12 rows=356 width=4) (actual time=0.026..0.026 rows=344 loops=1)\n                                                               Buckets: 1024  Batches: 1  Memory Usage: 21kB\n                                                               ->  CTE Scan on filtered_item filtered_item_1  (cost=0.00..7.12 rows=356 width=4) (actual time=0.001..0.011 rows=344 loops=1)\n                                                   ->  Index Scan using catalog_returns_pkey on catalog_returns  (cost=0.43..0.60 rows=1 width=20) (never executed)\n                                                         Index Cond: ((cr_item_sk = catalog_sales.cs_item_sk) AND (cr_order_number = catalog_sales.cs_order_number))\n                                             ->  Index Scan using catalog_page_pkey on catalog_page  (cost=0.29..0.30 rows=1 width=21) (never executed)\n                                                   Index Cond: (cp_catalog_page_sk = catalog_sales.cs_catalog_page_sk)\n                     ->  Subquery Scan on wsr  (cost=16180.49..16180.78 rows=6 width=160) (actual time=12.124..12.126 rows=0 loops=1)\n... (44 more lines truncated)",
          "explain_timing": {
            "original_s": 0.09,
            "optimized_s": 0.09
          },
          "plan_signature": {
            "original_buffers": 14388,
            "optimized_buffers": 11391,
            "buffer_reduction": 1.26,
            "original_time_ms": 67.736,
            "optimized_time_ms": 70.286,
            "original_high_loops": [
              {
                "node": "I",
                "table": null,
                "loops": 31,
                "rows_per_loop": 921
              },
              {
                "node": "I",
                "table": null,
                "loops": 629,
                "rows_per_loop": 0
              },
              {
                "node": "I",
                "table": null,
                "loops": 31,
                "rows_per_loop": 244
              }
            ]
          }
        }
      ],
      "regressions": [],
      "guard_rails": []
    },
    {
      "id": "CORRELATED_SUBQUERY_PARALYSIS",
      "priority": "HIGH",
      "what": "Cannot automatically decorrelate complex correlated subqueries. Correlated scalar subqueries with aggregates are executed as nested-loop with repeated evaluation.",
      "why": "Same limitation as DuckDB \u2014 correlation requires recognizing GROUP BY + JOIN equivalence. PostgreSQL does basic decorrelation for simple IN/EXISTS but fails on complex aggregate correlations.",
      "opportunity": "Convert correlated WHERE to explicit CTE with GROUP BY + JOIN.",
      "what_worked": [
        "Q092: 4428x \u2014 timeout recovery. Unbounded correlated subquery converted to explicit JOIN.",
        "Q032: 391x \u2014 same pattern, timeout to sub-second."
      ],
      "what_didnt_work": [],
      "field_notes": [
        "Look for WHERE col > (SELECT AGG FROM ... WHERE outer.key = inner.key) patterns.",
        "EXPLAIN will show SubPlan or nested-loop with repeated subquery execution if the optimizer failed to decorrelate.",
        "These are often the queries that time out \u2014 if a DSB query runs >10s, check for correlated scalar subqueries first.",
        "Simple IN/EXISTS correlation is already handled by PG's semi-join optimization \u2014 only complex aggregate correlations need manual decorrelation.",
        "CRITICAL: when decorrelating, preserve ALL filters from the original subquery in the new CTE.",
        "Validate at target scale \u2014 decorrelation wins are usually robust across scales, but verify on SF10."
      ],
      "gold_examples": [
        {
          "id": "early_filter_decorrelate",
          "queries": [],
          "speedup": "1.13x",
          "principle": "Early Selection + Decorrelation: push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN.",
          "original_sql": "WITH customer_total_return AS (\n  SELECT sr_customer_sk AS ctr_customer_sk,\n         sr_store_sk AS ctr_store_sk,\n         sr_reason_sk AS ctr_reason_sk,\n         SUM(SR_REFUNDED_CASH) AS ctr_total_return\n  FROM store_returns, date_dim\n  WHERE sr_returned_date_sk = d_date_sk\n    AND d_year = 2001\n    AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295\n  GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk\n)\nSELECT c_customer_id\nFROM customer_total_return ctr1, store, customer, customer_demographics\nWHERE ctr1.ctr_total_return > (\n    SELECT AVG(ctr_total_return) * 1.2\n    FROM customer_total_return ctr2\n    WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk\n  )\n  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31\n  AND s_store_sk = ctr1.ctr_store_sk\n  AND s_state IN ('MI', 'NC', 'WI')\n  AND ctr1.ctr_customer_sk = c_customer_sk\n  AND c_current_cdemo_sk = cd_demo_sk\n  AND cd_marital_status IN ('W', 'W')\n  AND cd_education_status IN ('4 yr Degree', 'College')\n  AND cd_gender = 'M'\n  AND c_birth_month = 5\n  AND c_birth_year BETWEEN 1950 AND 1956\nORDER BY c_customer_id\nLIMIT 100",
          "optimized_sql": "WITH customer_total_return AS (\n    SELECT sr_customer_sk AS ctr_customer_sk,\n           sr_store_sk AS ctr_store_sk,\n           sr_reason_sk AS ctr_reason_sk,\n           SUM(SR_REFUNDED_CASH) AS ctr_total_return\n    FROM store_returns\n    JOIN date_dim ON sr_returned_date_sk = d_date_sk\n    JOIN store ON sr_store_sk = s_store_sk\n    WHERE d_year = 2001\n      AND s_state IN ('MI', 'NC', 'WI')\n      AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295\n    GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk\n),\nstore_thresholds AS (\n    SELECT ctr_store_sk,\n           AVG(ctr_total_return) * 1.2 AS avg_limit\n    FROM customer_total_return\n    GROUP BY ctr_store_sk\n)\nSELECT c_customer_id\nFROM customer_total_return ctr1\nJOIN store_thresholds st ON ctr1.ctr_store_sk = st.ctr_store_sk\nJOIN customer ON ctr1.ctr_customer_sk = c_customer_sk\nJOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk\nJOIN store s ON ctr1.ctr_store_sk = s.s_store_sk\nWHERE ctr1.ctr_total_return > st.avg_limit\n  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31\n  AND s.s_state IN ('MI', 'NC', 'WI')\n  AND cd_marital_status = 'W'\n  AND cd_education_status IN ('4 yr Degree', 'College')\n  AND cd_gender = 'M'\n  AND c_birth_month = 5\n  AND c_birth_year BETWEEN 1950 AND 1956\nORDER BY c_customer_id\nLIMIT 100",
          "key_insight": "Principle: Early Selection + Decorrelation \u2014 push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN. Here: dimension filters pushed into CTEs, AVG threshold pre-computed and JOINed.",
          "original_explain": "QUERY PLAN                                                                                                   \n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=56617.64..56617.65 rows=1 width=17) (actual time=1208.062..1208.133 rows=0 loops=1)\n   Buffers: shared hit=557450 read=844599\n   CTE customer_total_return\n     ->  Finalize GroupAggregate  (cost=55898.70..55921.07 rows=172 width=44) (actual time=1130.848..1134.758 rows=6963 loops=1)\n           Group Key: store_returns.sr_customer_sk, store_returns.sr_store_sk, store_returns.sr_reason_sk\n           Buffers: shared hit=556877 read=844552\n           ->  Gather Merge  (cost=55898.70..55917.12 rows=144 width=44) (actual time=1130.842..1132.625 rows=6966 loops=1)\n                 Workers Planned: 2\n                 Workers Launched: 2\n                 Buffers: shared hit=556877 read=844552\n                 ->  Partial GroupAggregate  (cost=54898.68..54900.48 rows=72 width=44) (actual time=752.173..753.001 rows=2322 loops=3)\n                       Group Key: store_returns.sr_customer_sk, store_returns.sr_store_sk, store_returns.sr_reason_sk\n                       Buffers: shared hit=556877 read=844552\n                       ->  Sort  (cost=54898.68..54898.86 rows=72 width=18) (actual time=752.166..752.299 rows=2324 loops=3)\n                             Sort Key: store_returns.sr_customer_sk, store_returns.sr_store_sk, store_returns.sr_reason_sk\n                             Sort Method: quicksort  Memory: 363kB\n                             Buffers: shared hit=556877 read=844552\n                             Worker 0:  Sort Method: quicksort  Memory: 25kB\n                             Worker 1:  Sort Method: quicksort  Memory: 372kB\n                             ->  Nested Loop  (cost=0.72..54896.46 rows=72 width=18) (actual time=0.924..750.962 rows=2324 loops=3)\n                                   Buffers: shared hit=556863 read=844552\n                                   ->  Parallel Index Only Scan using _dta_index_date_dim_6_661577395__k1_k7_k9 on date_dim  (cost=0.29..1677.67 rows=151 width=4) (actual time=0.487..0.675 rows=122 loops=3)\n                                         Index Cond: (d_year = 2001)\n                                         Heap Fetches: 0\n                                         Buffers: shared hit=6 read=277\n                                   ->  Index Scan using _dta_index_store_returns_6_1013578649__k1_3_4_10 on store_returns  (cost=0.43..352.28 rows=16 width=22) (actual time=0.301..6.161 rows=19 loops=365)\n                                         Index Cond: (sr_returned_date_sk = date_dim.d_date_sk)\n                                         Filter: (((sr_return_amt / (sr_return_quantity)::numeric) >= '236'::numeric) AND ((sr_return_amt / (sr_return_quantity)::numeric) <= '295'::numeric))\n                                         Rows Removed by Filter: 4456\n                                         Buffers: shared hit=556857 read=844275\n   ->  Sort  (cost=696.57..696.57 rows=1 width=17) (actual time=1208.060..1208.063 rows=0 loops=1)\n         Sort Key: customer.c_customer_id\n         Sort Method: quicksort  Memory: 25kB\n         Buffers: shared hit=265176 read=427434\n         ->  Nested Loop  (cost=0.85..696.56 rows=1 width=17) (actual time=1208.047..1208.049 rows=0 loops=1)\n               Buffers: shared hit=265173 read=427434\n               ->  Nested Loop  (cost=0.42..688.38 rows=1 width=21) (actual time=1208.047..1208.048 rows=0 loops=1)\n                     Buffers: shared hit=265173 read=427434\n                     ->  Nested Loop  (cost=0.00..679.91 rows=1 width=4) (actual time=1143.098..1207.876 rows=18 loops=1)\n                           Join Filter: (ctr1.ctr_store_sk = store.s_store_sk)\n                           Rows Removed by Join Filter: 1015\n                           Buffers: shared hit=265143 read=427392\n                           ->  CTE Scan on customer_total_return ctr1  (cost=0.00..673.38 rows=1 width=8) (actual time=1135.590..1206.504 rows=122 loops=1)\n                                 Filter: ((ctr_reason_sk >= 28) AND (ctr_reason_sk <= 31) AND (ctr_total_return > (SubPlan 2)))\n                                 Rows Removed by Filter: 6841\n                                 Buffers: shared hit=264603 read=427387\n                                 SubPlan 2\n                                   ->  Aggregate  (cost=3.87..3.89 rows=1 width=32) (actual time=0.189..0.189 rows=1 loops=399)\n                                         ->  CTE Scan on customer_total_return ctr2  (cost=0.00..3.87 rows=1 width=32) (actual time=0.002..0.179 rows=177 loops=399)\n                                               Filter: (ctr1.ctr_store_sk = ctr_store_sk)\n                                               Rows Removed by Filter: 6786\n                           ->  Seq Scan on store  (cost=0.00..6.40 rows=10 width=4) (actual time=0.001..0.010 rows=8 loops=122)\n                                 Filter: (s_state = ANY ('{MI,NC,WI}'::bpchar[]))\n                                 Rows Removed by Filter: 82\n                                 Buffers: shared hit=540 read=5\n                     ->  Index Scan using _dta_index_customer_6_949578421__k1_k5 on customer  (cost=0.42..8.45 rows=1 width=25) (actual time=0.009..0.009 rows=0 loops=18)\n                           Index Cond: (c_customer_sk = ctr1.ctr_customer_sk)\n                           Filter: ((c_birth_year >= 1950) AND (c_birth_year <= 1956) AND (c_birth_month = 5))\n                           Rows Removed by Filter: 1\n                           Buffers: shared hit=30 read=42\n               ->  Index Scan using customer_demographics_pkey on customer_demographics  (cost=0.43..8.18 rows=1 width=4) (never executed)\n                     Index Cond: (cd_demo_sk = customer.c_current_cdemo_sk)\n                     Filter: ((cd_marital_status = ANY ('{W,W}'::bpchar[])) AND (cd_education_status = ANY ('{\"4 yr Degree\",College}'::bpchar[])) AND (cd_gender = 'M'::bpchar))\n Planning:\n   Buffers: shared hit=517 read=61\n Planning Time: 1.020 ms\n Execution Time: 1208.313 ms\n(67 rows)",
          "optimized_explain": "QUERY PLAN                                                                                                      \n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=55924.18..55924.19 rows=1 width=17) (actual time=1185.976..1186.031 rows=0 loops=1)\n   Buffers: shared hit=540637 read=861075\n   CTE customer_total_return\n     ->  Finalize GroupAggregate  (cost=55901.99..55904.15 rows=16 width=44) (actual time=1184.623..1185.364 rows=1186 loops=1)\n           Group Key: store_returns.sr_customer_sk, store_returns.sr_store_sk, store_returns.sr_reason_sk\n           Buffers: shared hit=540604 read=861033\n           ->  Gather Merge  (cost=55901.99..55903.78 rows=14 width=44) (actual time=1184.615..1184.955 rows=1186 loops=1)\n                 Workers Planned: 2\n                 Workers Launched: 2\n                 Buffers: shared hit=540604 read=861033\n                 ->  Partial GroupAggregate  (cost=54901.96..54902.14 rows=7 width=44) (actual time=785.039..785.182 rows=395 loops=3)\n                       Group Key: store_returns.sr_customer_sk, store_returns.sr_store_sk, store_returns.sr_reason_sk\n                       Buffers: shared hit=540604 read=861033\n                       ->  Sort  (cost=54901.96..54901.98 rows=7 width=18) (actual time=785.033..785.055 rows=395 loops=3)\n                             Sort Key: store_returns.sr_customer_sk, store_returns.sr_store_sk, store_returns.sr_reason_sk\n                             Sort Method: quicksort  Memory: 70kB\n                             Buffers: shared hit=540604 read=861033\n                             Worker 0:  Sort Method: quicksort  Memory: 25kB\n                             Worker 1:  Sort Method: quicksort  Memory: 72kB\n                             ->  Nested Loop  (cost=0.88..54901.86 rows=7 width=18) (actual time=1.675..784.614 rows=395 loops=3)\n                                   Buffers: shared hit=540590 read=861033\n                                   ->  Nested Loop  (cost=0.72..54896.46 rows=72 width=18) (actual time=0.826..783.048 rows=2324 loops=3)\n                                         Buffers: shared hit=540386 read=861029\n                                         ->  Parallel Index Only Scan using _dta_index_date_dim_6_661577395__k1_k7_k9 on date_dim  (cost=0.29..1677.67 rows=151 width=4) (actual time=0.450..0.612 rows=122 loops=3)\n                                               Index Cond: (d_year = 2001)\n                                               Heap Fetches: 0\n                                               Buffers: shared hit=7 read=276\n                                         ->  Index Scan using _dta_index_store_returns_6_1013578649__k1_3_4_10 on store_returns  (cost=0.43..352.28 rows=16 width=22) (actual time=0.317..6.424 rows=19 loops=365)\n                                               Index Cond: (sr_returned_date_sk = date_dim.d_date_sk)\n                                               Filter: (((sr_return_amt / (sr_return_quantity)::numeric) >= '236'::numeric) AND ((sr_return_amt / (sr_return_quantity)::numeric) <= '295'::numeric))\n                                               Rows Removed by Filter: 4456\n                                               Buffers: shared hit=540379 read=860753\n                                   ->  Memoize  (cost=0.15..0.17 rows=1 width=4) (actual time=0.000..0.000 rows=0 loops=6973)\n                                         Cache Key: store_returns.sr_store_sk\n                                         Cache Mode: logical\n                                         Hits: 3377  Misses: 52  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n                                         Buffers: shared hit=204 read=4\n                                         Worker 1:  Hits: 3492  Misses: 52  Evictions: 0  Overflows: 0  Memory Usage: 4kB\n                                         ->  Index Scan using _dta_index_store_6_885578193__k1_2_6 on store  (cost=0.14..0.16 rows=1 width=4) (actual time=0.003..0.003 rows=0 loops=104)\n                                               Index Cond: (s_store_sk = store_returns.sr_store_sk)\n                                               Filter: (s_state = ANY ('{MI,NC,WI}'::bpchar[]))\n                                               Rows Removed by Filter: 1\n                                               Buffers: shared hit=204 read=4\n   ->  Sort  (cost=20.03..20.03 rows=1 width=17) (actual time=1185.974..1185.976 rows=0 loops=1)\n         Sort Key: customer.c_customer_id\n         Sort Method: quicksort  Memory: 25kB\n         Buffers: shared hit=250663 read=441504\n         ->  Nested Loop  (cost=1.39..20.02 rows=1 width=17) (actual time=1185.956..1185.958 rows=0 loops=1)\n               Join Filter: (ctr1.ctr_store_sk = s.s_store_sk)\n               Buffers: shared hit=250660 read=441504\n               ->  Nested Loop  (cost=1.25..18.09 rows=1 width=25) (actual time=1185.956..1185.957 rows=0 loops=1)\n                     Buffers: shared hit=250660 read=441504\n                     ->  Nested Loop  (cost=0.82..9.91 rows=1 width=29) (actual time=1185.956..1185.957 rows=0 loops=1)\n                           Buffers: shared hit=250660 read=441504\n                           ->  Nested Loop  (cost=0.40..1.44 rows=1 width=12) (actual time=1185.646..1185.784 rows=18 loops=1)\n                                 Join Filter: ((ctr1.ctr_total_return > ((avg(customer_total_return.ctr_total_return) * 1.2))) AND (ctr1.ctr_store_sk = customer_total_return.ctr_store_sk))\n                                 Rows Removed by Join Filter: 369\n                                 Buffers: shared hit=250630 read=441462\n                                 ->  CTE Scan on customer_total_return ctr1  (cost=0.00..0.40 rows=1 width=40) (actual time=1184.630..1184.666 rows=73 loops=1)\n                                       Filter: ((ctr_reason_sk >= 28) AND (ctr_reason_sk <= 31))\n                                       Rows Removed by Filter: 1113\n                                       Buffers: shared hit=250630 read=441462\n                                 ->  HashAggregate  (cost=0.40..0.64 rows=16 width=36) (actual time=0.014..0.015 rows=5 loops=73)\n                                       Group Key: customer_total_return.ctr_store_sk\n                                       Batches: 1  Memory Usage: 24kB\n                                       ->  CTE Scan on customer_total_return  (cost=0.00..0.32 rows=16 width=36) (actual time=0.001..0.862 rows=1186 loops=1)\n                           ->  Index Scan using _dta_index_customer_6_949578421__k1_k5 on customer  (cost=0.42..8.45 rows=1 width=25) (actual time=0.009..0.009 rows=0 loops=18)\n                                 Index Cond: (c_customer_sk = ctr1.ctr_customer_sk)\n                                 Filter: ((c_birth_year >= 1950) AND (c_birth_year <= 1956) AND (c_birth_month = 5))\n                                 Rows Removed by Filter: 1\n                                 Buffers: shared hit=30 read=42\n                     ->  Index Scan using customer_demographics_pkey on customer_demographics  (cost=0.43..8.18 rows=1 width=4) (never executed)\n                           Index Cond: (cd_demo_sk = customer.c_current_cdemo_sk)\n                           Filter: ((cd_education_status = ANY ('{\"4 yr Degree\",College}'::bpchar[])) AND (cd_marital_status = 'W'::bpchar) AND (cd_gender = 'M'::bpchar))\n               ->  Index Scan using _dta_index_store_6_885578193__k1_2_6 on store s  (cost=0.14..1.91 rows=1 width=4) (never executed)\n                     Index Cond: (s_store_sk = customer_total_return.ctr_store_sk)\n                     Filter: (s_state = ANY ('{MI,NC,WI}'::bpchar[]))\n Planning:\n   Buffers: shared hit=551 read=83\n Planning Time: 1.235 ms\n Execution Time: 1186.172 ms\n(81 rows)",
          "explain_timing": {
            "original_s": 1.23,
            "optimized_s": 1.21
          },
          "plan_signature": {
            "original_buffers": 1402049,
            "optimized_buffers": 1401712,
            "buffer_reduction": 1.0,
            "original_time_ms": 1208.313,
            "optimized_time_ms": 1186.172,
            "original_high_loops": [
              {
                "node": "I",
                "table": null,
                "loops": 365,
                "rows_per_loop": 19
              },
              {
                "node": "A",
                "table": null,
                "loops": 399,
                "rows_per_loop": 1
              },
              {
                "node": "C",
                "table": null,
                "loops": 399,
                "rows_per_loop": 177
              }
            ]
          }
        },
        {
          "id": "inline_decorrelate_materialized",
          "queries": [],
          "speedup": "timeout_rescue",
          "principle": "Inline Decorrelation with MATERIALIZED CTEs: When a WHERE clause contains a correlated scalar subquery (e.g., col > (SELECT 1.3 * avg(col) FROM ... WHERE correlated_key = outer.key)), PostgreSQL re-executes the subquery per outer row. Fix: decompose into 3 MATERIALIZED CTEs \u2014 (1) pre-filter dimension table, (2) pre-filter fact table by date range, (3) compute per-key aggregate threshold from filtered data \u2014 then JOIN the threshold CTE in the final query. MATERIALIZED keyword prevents PG from inlining the CTEs back into correlated form.",
          "original_sql": "select  sum(cs_ext_discount_amt)  as \"excess discount amount\"\nfrom\n   catalog_sales\n   ,item\n   ,date_dim\nwhere\n(i_manufact_id in (1, 78, 97, 516, 521)\nor i_manager_id BETWEEN 25 and 54)\nand i_item_sk = cs_item_sk\nand d_date between '1999-03-07' and\n        cast('1999-03-07' as date) + interval '90 day'\nand d_date_sk = cs_sold_date_sk\nand cs_ext_discount_amt\n     > (\n         select\n            1.3 * avg(cs_ext_discount_amt)\n         from\n            catalog_sales\n           ,date_dim\n         where\n              cs_item_sk = i_item_sk\n          and d_date between '1999-03-07' and\n                             cast('1999-03-07' as date) + interval '90 day'\n          and d_date_sk = cs_sold_date_sk\n          and cs_list_price between 16 and 45\n          and cs_sales_price / cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01\n      )\norder by sum(cs_ext_discount_amt)\nlimit 100;",
          "optimized_sql": "WITH filtered_items AS MATERIALIZED (\n    SELECT i_item_sk\n    FROM item\n    WHERE i_manufact_id IN (1, 78, 97, 516, 521)\n       OR i_manager_id BETWEEN 25 AND 54\n),\ndate_filtered_sales AS MATERIALIZED (\n    SELECT cs.cs_item_sk, cs.cs_ext_discount_amt,\n           cs.cs_list_price, cs.cs_sales_price\n    FROM catalog_sales cs\n    JOIN date_dim d ON d.d_date_sk = cs.cs_sold_date_sk\n    WHERE d.d_date BETWEEN '1999-03-07' AND cast('1999-03-07' as date) + interval '90 day'\n),\nitem_avg_discount AS MATERIALIZED (\n    SELECT dfs.cs_item_sk,\n           1.3 * avg(dfs.cs_ext_discount_amt) AS threshold\n    FROM date_filtered_sales dfs\n    JOIN filtered_items fi ON fi.i_item_sk = dfs.cs_item_sk\n    WHERE dfs.cs_list_price BETWEEN 16 AND 45\n      AND dfs.cs_sales_price / dfs.cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01\n    GROUP BY dfs.cs_item_sk\n)\nSELECT sum(dfs.cs_ext_discount_amt) AS \"excess discount amount\"\nFROM date_filtered_sales dfs\nJOIN item_avg_discount iad ON iad.cs_item_sk = dfs.cs_item_sk\nWHERE dfs.cs_ext_discount_amt > iad.threshold\nORDER BY 1\nLIMIT 100;",
          "key_insight": "Principle: Inline Decorrelation \u2014 when WHERE has a correlated scalar subquery that re-scans the fact table per outer row, decompose into 3 MATERIALIZED CTEs: (1) dimension filter, (2) date-filtered fact rows, (3) per-key aggregate threshold. The final query JOINs the threshold CTE, replacing O(N*M) correlated scans with a single hash join. CRITICAL: use AS MATERIALIZED on PostgreSQL to prevent the optimizer from inlining CTEs back into the original correlated form.",
          "original_explain": "TIMEOUT: query exceeded 120s",
          "optimized_explain": "QUERY PLAN                                                                                                    \n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=68371.91..68371.92 rows=1 width=32) (actual time=242.194..242.264 rows=1 loops=1)\n   Buffers: shared hit=452 read=22825, temp read=2125 written=2125\n   CTE filtered_items\n     ->  Seq Scan on item  (cost=0.00..9137.50 rows=30902 width=4) (actual time=0.011..20.667 rows=31390 loops=1)\n           Filter: ((i_manufact_id = ANY ('{1,78,97,516,521}'::integer[])) OR ((i_manager_id >= 25) AND (i_manager_id <= 54)))\n           Rows Removed by Filter: 70610\n           Buffers: shared read=6970\n   CTE date_filtered_sales\n     ->  Gather  (cost=1000.43..57384.66 rows=18828 width=22) (actual time=3.703..69.466 rows=506190 loops=1)\n           Workers Planned: 1\n           Workers Launched: 1\n           Buffers: shared hit=446 read=15855\n           ->  Nested Loop  (cost=0.43..54501.86 rows=11075 width=22) (actual time=1.761..65.697 rows=253095 loops=2)\n                 Buffers: shared hit=446 read=15855\n                 ->  Parallel Seq Scan on date_dim d  (cost=0.00..2049.55 rows=56 width=4) (actual time=1.722..3.291 rows=46 loops=2)\n                       Filter: ((d_date >= '1999-03-07'::date) AND (d_date <= '1999-06-05 00:00:00'::timestamp without time zone))\n                       Rows Removed by Filter: 36479\n                       Buffers: shared hit=6 read=1399\n                 ->  Index Scan using _dta_index_catalog_sales_6_1301579675__k1_4 on catalog_sales cs  (cost=0.43..869.33 rows=6732 width=26) (actual time=0.005..0.870 rows=5563 loops=91)\n                       Index Cond: (cs_sold_date_sk = d.d_date_sk)\n                       Buffers: shared hit=440 read=14456\n   CTE item_avg_discount\n     ->  GroupAggregate  (cost=1400.10..1401.28 rows=1 width=36) (actual time=180.534..182.189 rows=3391 loops=1)\n           Group Key: dfs_1.cs_item_sk\n           Buffers: shared hit=447 read=22126, temp written=2124\n           ->  Sort  (cost=1400.10..1400.49 rows=155 width=18) (actual time=180.526..180.707 rows=8496 loops=1)\n                 Sort Key: dfs_1.cs_item_sk\n                 Sort Method: quicksort  Memory: 783kB\n                 Buffers: shared hit=447 read=22126, temp written=2124\n                 ->  Hash Join  (cost=658.99..1394.46 rows=155 width=18) (actual time=151.768..179.696 rows=8496 loops=1)\n                       Hash Cond: (fi.i_item_sk = dfs_1.cs_item_sk)\n                       Buffers: shared hit=444 read=22126, temp written=2124\n                       ->  CTE Scan on filtered_items fi  (cost=0.00..618.04 rows=30902 width=4) (actual time=0.011..23.596 rows=31390 loops=1)\n                             Buffers: shared read=6970\n                       ->  Hash  (cost=658.98..658.98 rows=1 width=18) (actual time=151.730..151.731 rows=24217 loops=1)\n                             Buckets: 32768 (originally 1024)  Batches: 1 (originally 1)  Memory Usage: 1271kB\n                             Buffers: shared hit=444 read=15156, temp written=2124\n                             ->  CTE Scan on date_filtered_sales dfs_1  (cost=0.00..658.98 rows=1 width=18) (actual time=0.011..149.573 rows=24217 loops=1)\n                                   Filter: ((cs_list_price >= '16'::numeric) AND (cs_list_price <= '45'::numeric) AND ((cs_sales_price / cs_list_price) >= 0.63) AND ((cs_sales_price / cs_list_price) <= 0.83))\n                                   Rows Removed by Filter: 481973\n                                   Buffers: shared hit=444 read=15156, temp written=2124\n   ->  Sort  (cost=448.47..448.48 rows=1 width=32) (actual time=242.193..242.195 rows=1 loops=1)\n         Sort Key: (sum(dfs.cs_ext_discount_amt))\n         Sort Method: quicksort  Memory: 25kB\n         Buffers: shared hit=452 read=22825, temp read=2125 written=2125\n         ->  Aggregate  (cost=448.45..448.46 rows=1 width=32) (actual time=242.175..242.177 rows=1 loops=1)\n               Buffers: shared hit=449 read=22825, temp read=2125 written=2125\n               ->  Hash Join  (cost=0.03..448.37 rows=31 width=14) (actual time=186.437..238.866 rows=71795 loops=1)\n                     Hash Cond: (dfs.cs_item_sk = iad.cs_item_sk)\n                     Join Filter: (dfs.cs_ext_discount_amt > iad.threshold)\n                     Rows Removed by Join Filter: 47490\n                     Buffers: shared hit=449 read=22825, temp read=2125 written=2125\n                     ->  CTE Scan on date_filtered_sales dfs  (cost=0.00..376.56 rows=18828 width=18) (actual time=3.705..22.601 rows=506190 loops=1)\n                           Buffers: shared hit=2 read=699, temp read=2125 written=1\n                     ->  Hash  (cost=0.02..0.02 rows=1 width=36) (actual time=182.696..182.696 rows=3391 loops=1)\n                           Buckets: 4096 (originally 1024)  Batches: 1 (originally 1)  Memory Usage: 175kB\n                           Buffers: shared hit=447 read=22126, temp written=2124\n                           ->  CTE Scan on item_avg_discount iad  (cost=0.00..0.02 rows=1 width=36) (actual time=180.536..182.522 rows=3391 loops=1)\n                                 Buffers: shared hit=447 read=22126, temp written=2124\n Planning:\n   Buffers: shared hit=600 read=77\n Planning Time: 1.145 ms\n Execution Time: 243.970 ms\n(63 rows)",
          "explain_timing": {
            "original_s": 120.1,
            "optimized_s": 0.26
          }
        }
      ],
      "regressions": [],
      "guard_rails": []
    },
    {
      "id": "NON_EQUI_JOIN_INPUT_BLINDNESS",
      "priority": "HIGH",
      "what": "Cannot pre-filter fact tables before non-equi join operations (date arithmetic, range comparisons, quantity < quantity). Non-equi joins fall back to nested-loop, which is O(N*M).",
      "why": "Hash joins require equi-conditions. Non-equi joins fall back to nested-loop, which processes all input rows. The optimizer cannot recognize that reducing N or M via pre-filtering would dramatically reduce cost.",
      "opportunity": "Reduce fact table input size via filtered CTE before the non-equi join.",
      "what_worked": [
        "Q072: 2.68x \u2014 pre-filtered catalog_sales by wholesale_cost range before non-equi quantity comparison with inventory. Reduced nested-loop input by ~70%."
      ],
      "what_didnt_work": [
        "Q013: 0.79x \u2014 pre-filtered with UNION/OR superset (loose filter). CTE fence blocked dimension predicate pushdown."
      ],
      "field_notes": [
        "Look for non-equi join conditions: >, <, BETWEEN, date arithmetic, quantity comparisons.",
        "EXPLAIN will show nested-loop join with high row estimates on both sides.",
        "A simple range filter on the fact table (e.g., wholesale_cost BETWEEN 34 AND 54) works well. A union/OR superset filter does NOT \u2014 it materializes too many rows.",
        "Only pre-filter when one side of the non-equi join is a large fact table. Small dimension tables (<10K rows) don't benefit.",
        "The CTE fence cost is negligible vs the non-equi join savings when the filter is tight.",
        "Validate at target scale \u2014 non-equi join cost grows super-linearly, so wins tend to hold or improve at larger scales."
      ],
      "gold_examples": [
        {
          "id": "pg_materialized_dimension_fact_prefilter",
          "queries": [
            "DSB Q072_agg"
          ],
          "speedup": "2.68x",
          "principle": "Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.",
          "original_sql": "select  i_item_desc\n      ,w_warehouse_name\n      ,d1.d_week_seq\n      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo\n      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo\n      ,count(*) total_cnt\nfrom catalog_sales\njoin inventory on (cs_item_sk = inv_item_sk)\njoin warehouse on (w_warehouse_sk=inv_warehouse_sk)\njoin item on (i_item_sk = cs_item_sk)\njoin customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)\njoin household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)\njoin date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)\njoin date_dim d2 on (inv_date_sk = d2.d_date_sk)\njoin date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)\nleft outer join promotion on (cs_promo_sk=p_promo_sk)\nleft outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)\nwhere d1.d_week_seq = d2.d_week_seq\n  and inv_quantity_on_hand < cs_quantity\n  and d3.d_date > d1.d_date + interval '3 day'\n  and hd_buy_potential = '501-1000'\n  and d1.d_year = 1998\n  and cd_marital_status = 'M'\n  and cd_dep_count between 9 and 11\n  and i_category IN ('Home', 'Men', 'Music')\n  and cs_wholesale_cost BETWEEN 34 AND 54\ngroup by i_item_desc,w_warehouse_name,d1.d_week_seq\norder by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq\nlimit 100;",
          "optimized_sql": "WITH filtered_date AS MATERIALIZED (\n  SELECT d_date_sk, d_date, d_week_seq\n  FROM date_dim\n  WHERE d_year = 1998\n),\nfiltered_item AS MATERIALIZED (\n  SELECT i_item_sk, i_item_desc\n  FROM item\n  WHERE i_category IN ('Home', 'Men', 'Music')\n),\nfiltered_cd AS MATERIALIZED (\n  SELECT cd_demo_sk\n  FROM customer_demographics\n  WHERE cd_marital_status = 'M'\n    AND cd_dep_count BETWEEN 9 AND 11\n),\nfiltered_hd AS MATERIALIZED (\n  SELECT hd_demo_sk\n  FROM household_demographics\n  WHERE hd_buy_potential = '501-1000'\n),\ncs_filtered AS MATERIALIZED (\n  SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk,\n         cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost,\n         cs_order_number\n  FROM catalog_sales\n  WHERE cs_wholesale_cost BETWEEN 34 AND 54\n)\nSELECT i.i_item_desc,\n       w.w_warehouse_name,\n       d1.d_week_seq,\n       SUM(CASE WHEN p.p_promo_sk IS NULL THEN 1 ELSE 0 END) AS no_promo,\n       SUM(CASE WHEN p.p_promo_sk IS NOT NULL THEN 1 ELSE 0 END) AS promo,\n       COUNT(*) AS total_cnt\nFROM cs_filtered cs\nJOIN inventory inv ON cs.cs_item_sk = inv.inv_item_sk\nJOIN warehouse w ON w.w_warehouse_sk = inv.inv_warehouse_sk\nJOIN filtered_item i ON i.i_item_sk = cs.cs_item_sk\nJOIN filtered_cd cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk\nJOIN filtered_hd hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk\nJOIN filtered_date d1 ON cs.cs_sold_date_sk = d1.d_date_sk\nJOIN date_dim d2 ON inv.inv_date_sk = d2.d_date_sk\nJOIN date_dim d3 ON cs.cs_ship_date_sk = d3.d_date_sk\nLEFT OUTER JOIN promotion p ON cs.cs_promo_sk = p.p_promo_sk\nLEFT OUTER JOIN catalog_returns cr ON cr.cr_item_sk = cs.cs_item_sk \n  AND cr.cr_order_number = cs.cs_order_number\nWHERE d1.d_week_seq = d2.d_week_seq\n  AND inv.inv_quantity_on_hand < cs.cs_quantity\n  AND d3.d_date > d1.d_date + INTERVAL '3 day'\nGROUP BY i.i_item_desc, w.w_warehouse_name, d1.d_week_seq\nORDER BY total_cnt DESC, i.i_item_desc, w.w_warehouse_name, d1.d_week_seq\nLIMIT 100;",
          "key_insight": "Principle: Staged Reduction for Non-Equi Joins \u2014 when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join to shrink the search space. MATERIALIZED on PG12+ forces early execution. Here: fact table CTE removes ~70% of catalog_sales rows, dimension CTEs reduce date (365/73K), item (3 categories), and demographics to tiny sets \u2014 all before the expensive inventory non-equi join.",
          "original_explain": "QUERY PLAN                                                                                                                           \n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=141742.33..141742.34 rows=1 width=148) (actual time=358.272..360.158 rows=0 loops=1)\n   Buffers: shared hit=104676 read=76906\n   ->  Sort  (cost=141742.33..141742.34 rows=1 width=148) (actual time=358.271..360.156 rows=0 loops=1)\n         Sort Key: (count(*)) DESC, item.i_item_desc, warehouse.w_warehouse_name, d1.d_week_seq\n         Sort Method: quicksort  Memory: 25kB\n         Buffers: shared hit=104676 read=76906\n         ->  GroupAggregate  (cost=141737.90..141742.32 rows=1 width=148) (actual time=358.259..360.144 rows=0 loops=1)\n               Group Key: item.i_item_desc, warehouse.w_warehouse_name, d1.d_week_seq\n               Buffers: shared hit=104673 read=76906\n               ->  Nested Loop  (cost=141737.90..141742.30 rows=1 width=128) (actual time=358.257..360.142 rows=0 loops=1)\n                     Join Filter: (d3.d_date > (d1.d_date + '3 days'::interval))\n                     Buffers: shared hit=104673 read=76906\n                     ->  Gather Merge  (cost=141737.61..141737.72 rows=1 width=136) (actual time=358.256..360.140 rows=0 loops=1)\n                           Workers Planned: 1\n                           Workers Launched: 1\n                           Buffers: shared hit=104673 read=76906\n                           ->  Sort  (cost=140737.60..140737.60 rows=1 width=136) (actual time=355.013..355.021 rows=0 loops=2)\n                                 Sort Key: item.i_item_desc, warehouse.w_warehouse_name, d1.d_week_seq\n                                 Sort Method: quicksort  Memory: 25kB\n                                 Buffers: shared hit=104673 read=76906\n                                 Worker 0:  Sort Method: quicksort  Memory: 25kB\n                                 ->  Nested Loop Left Join  (cost=138673.76..140737.59 rows=1 width=136) (actual time=354.995..355.002 rows=0 loops=2)\n                                       Buffers: shared hit=104658 read=76906\n                                       ->  Nested Loop  (cost=138673.48..140733.44 rows=1 width=136) (actual time=354.994..355.002 rows=0 loops=2)\n                                             Buffers: shared hit=104658 read=76906\n                                             ->  Nested Loop  (cost=138673.19..140728.87 rows=1 width=41) (actual time=354.993..355.000 rows=0 loops=2)\n                                                   Join Filter: (inventory.inv_warehouse_sk = warehouse.w_warehouse_sk)\n                                                   Buffers: shared hit=104658 read=76906\n                                                   ->  Nested Loop  (cost=138673.19..140727.64 rows=1 width=28) (actual time=354.993..354.999 rows=0 loops=2)\n                                                         Buffers: shared hit=104658 read=76906\n                                                         ->  Parallel Hash Join  (cost=138672.62..140668.50 rows=4 width=28) (actual time=354.992..354.998 rows=0 loops=2)\n                                                               Hash Cond: (d2.d_week_seq = d1.d_week_seq)\n                                                               Buffers: shared hit=104658 read=76906\n                                                               ->  Parallel Seq Scan on date_dim d2  (cost=0.00..1834.70 rows=42970 width=8) (never executed)\n                                                               ->  Parallel Hash  (cost=138672.61..138672.61 rows=1 width=24) (actual time=354.921..354.924 rows=0 loops=2)\n                                                                     Buckets: 1024  Batches: 1  Memory Usage: 0kB\n                                                                     Buffers: shared hit=104612 read=76905\n                                                                     ->  Nested Loop  (cost=159.16..138672.61 rows=1 width=24) (actual time=242.881..242.884 rows=0 loops=2)\n                                                                           Buffers: shared hit=104612 read=76905\n                                                                           ->  Hash Join  (cost=158.73..134671.49 rows=844 width=28) (actual time=2.751..196.009 rows=15384 loops=2)\n                                                                                 Hash Cond: (catalog_sales.cs_bill_hdemo_sk = household_demographics.hd_demo_sk)\n                                                                                 Buffers: shared hit=2842 read=55674\n                                                                                 ->  Nested Loop  (cost=0.73..134500.12 rows=5089 width=32) (actual time=2.280..185.811 rows=163368 loops=2)\n                                                                                       Buffers: shared hit=2789 read=55621\n                                                                                       ->  Parallel Index Scan using date_dim_pkey on date_dim d1  (cost=0.29..2962.00 rows=151 width=12) (actual time=2.245..4.097 rows=182 loops=2)\n                                                                                             Filter: (d_year = 1998)\n                                                                                             Rows Removed by Filter: 36342\n                                                                                             Buffers: shared hit=11 read=1597\n                                                                                       ->  Index Scan using _dta_index_catalog_sales_6_1301579675__k1_4 on catalog_sales  (cost=0.43..859.56 rows=1155 width=32) (actual time=0.004..0.945 rows=895 loops=365)\n                                                                                             Index Cond: (cs_sold_date_sk = d1.d_date_sk)\n                                                                                             Filter: ((cs_wholesale_cost >= '34'::numeric) AND (cs_wholesale_cost <= '54'::numeric))\n                                                                                             Rows Removed by Filter: 4383\n                                                                                             Buffers: shared hit=2778 read=54024\n                                                                                 ->  Hash  (cost=143.00..143.00 rows=1200 width=4) (actual time=0.449..0.449 rows=1200 loops=2)\n                                                                                       Buckets: 2048  Batches: 1  Memory Usage: 59kB\n                                                                                       Buffers: shared hit=53 read=53\n                                                                                       ->  Seq Scan on household_demographics  (cost=0.00..143.00 rows=1200 width=4) (actual time=0.007..0.381 rows=1200 loops=2)\n                                                                                             Filter: (hd_buy_potential = '501-1000'::bpchar)\n                                                                                             Rows Removed by Filter: 6000\n                                                                                             Buffers: shared hit=53 read=53\n                                                                           ->  Index Scan using customer_demographics_pkey on customer_demographics  (cost=0.43..4.74 rows=1 width=4) (actual time=0.003..0.003 rows=0 loops=30768)\n                                                                                 Index Cond: (cd_demo_sk = catalog_sales.cs_bill_cdemo_sk)\n                                                                                 Filter: ((cd_dep_count >= 9) AND (cd_dep_count <= 11) AND (cd_marital_status = 'M'::bpchar))\n                                                                                 Rows Removed by Filter: 1\n                                                                                 Buffers: shared hit=101770 read=21231\n                                                         ->  Index Scan using inventory_pkey on inventory  (cost=0.57..14.77 rows=2 width=16) (never executed)\n                                                               Index Cond: ((inv_date_sk = d2.d_date_sk) AND (inv_item_sk = catalog_sales.cs_item_sk))\n                                                               Filter: (inv_quantity_on_hand < catalog_sales.cs_quantity)\n                                                   ->  Seq Scan on warehouse  (cost=0.00..1.10 rows=10 width=21) (never executed)\n                                             ->  Index Scan using item_pkey on item  (cost=0.29..4.57 rows=1 width=107) (never executed)\n                                                   Index Cond: (i_item_sk = catalog_sales.cs_item_sk)\n                                                   Filter: (i_category = ANY ('{Home,Men,Music}'::bpchar[]))\n                                       ->  Index Only Scan using promotion_pkey on promotion  (cost=0.27..4.14 rows=1 width=4) (never executed)\n                                             Index Cond: (p_promo_sk = catalog_sales.cs_promo_sk)\n                                             Heap Fetches: 0\n                     ->  Index Scan using date_dim_pkey on date_dim d3  (cost=0.29..4.56 rows=1 width=8) (never executed)\n                           Index Cond: (d_date_sk = catalog_sales.cs_ship_date_sk)\n Planning:\n   Buffers: shared hit=862 read=147\n Planning Time: 19.080 ms\n Execution Time: 360.637 ms\n(81 rows)",
          "optimized_explain": "QUERY PLAN                                                                                            \n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=3142313.22..3142313.47 rows=100 width=463) (actual time=75.436..75.761 rows=0 loops=1)\n   Buffers: shared hit=36 read=30230, temp written=139\n   CTE filtered_date\n     ->  Index Scan using _dta_index_date_dim_6_661577395__k7_k9 on date_dim  (cost=0.29..579.77 rows=363 width=12) (never executed)\n           Index Cond: (d_year = 1998)\n   CTE filtered_item\n     ->  Seq Scan on item  (cost=0.00..8372.50 rows=17354 width=107) (actual time=0.011..19.141 rows=17487 loops=1)\n           Filter: (i_category = ANY ('{Home,Men,Music}'::bpchar[]))\n           Rows Removed by Filter: 84513\n           Buffers: shared read=6970\n   CTE filtered_cd\n     ->  Gather  (cost=1000.00..36833.93 rows=1 width=4) (actual time=35.535..35.847 rows=0 loops=1)\n           Workers Planned: 2\n           Workers Launched: 2\n           Buffers: shared hit=18 read=21810\n           ->  Parallel Seq Scan on customer_demographics  (cost=0.00..35833.83 rows=1 width=4) (actual time=31.813..31.814 rows=0 loops=3)\n                 Filter: ((cd_dep_count >= 9) AND (cd_dep_count <= 11) AND (cd_marital_status = 'M'::bpchar))\n                 Rows Removed by Filter: 640267\n                 Buffers: shared hit=18 read=21810\n   CTE filtered_hd\n     ->  Seq Scan on household_demographics  (cost=0.00..143.00 rows=1200 width=4) (actual time=0.012..0.412 rows=1200 loops=1)\n           Filter: (hd_buy_potential = '501-1000'::bpchar)\n           Rows Removed by Filter: 6000\n           Buffers: shared read=53\n   CTE cs_filtered\n     ->  Seq Scan on catalog_sales  (cost=0.00..584898.84 rows=2470089 width=38) (actual time=0.013..0.013 rows=1 loops=1)\n           Filter: ((cs_wholesale_cost >= '34'::numeric) AND (cs_wholesale_cost <= '54'::numeric))\n           Buffers: shared read=1\n   ->  Sort  (cost=2511485.18..2511989.94 rows=201902 width=463) (actual time=75.435..75.444 rows=0 loops=1)\n         Sort Key: (count(*)) DESC, i.i_item_desc, w.w_warehouse_name, d1.d_week_seq\n         Sort Method: quicksort  Memory: 25kB\n         Buffers: shared hit=36 read=30230, temp written=139\n         ->  GroupAggregate  (cost=2498216.33..2503768.63 rows=201902 width=463) (actual time=75.417..75.425 rows=0 loops=1)\n               Group Key: i.i_item_desc, w.w_warehouse_name, d1.d_week_seq\n               Buffers: shared hit=27 read=30230, temp written=139\n               ->  Sort  (cost=2498216.33..2498721.08 rows=201902 width=443) (actual time=75.414..75.423 rows=0 loops=1)\n                     Sort Key: i.i_item_desc, w.w_warehouse_name, d1.d_week_seq\n                     Sort Method: quicksort  Memory: 25kB\n                     Buffers: shared hit=27 read=30230, temp written=139\n                     ->  Hash Left Join  (cost=7686.86..2398987.43 rows=201902 width=443) (actual time=75.410..75.418 rows=0 loops=1)\n                           Hash Cond: (cs.cs_promo_sk = p.p_promo_sk)\n                           Buffers: shared hit=27 read=30230, temp written=139\n                           ->  Hash Join  (cost=7662.61..2398428.70 rows=201902 width=443) (actual time=75.409..75.416 rows=0 loops=1)\n                                 Hash Cond: (cs.cs_ship_date_sk = d3.d_date_sk)\n                                 Join Filter: (d3.d_date > (d1.d_date + '3 days'::interval))\n                                 Buffers: shared hit=27 read=30230, temp written=139\n                                 ->  Hash Join  (cost=4614.01..2393790.07 rows=605706 width=451) (actual time=61.404..61.411 rows=0 loops=1)\n                                       Hash Cond: (cs.cs_bill_hdemo_sk = hd.hd_demo_sk)\n                                       Buffers: shared hit=18 read=28834, temp written=139\n                                       ->  Hash Join  (cost=4575.01..2372298.98 rows=100951 width=455) (actual time=60.809..60.815 rows=0 loops=1)\n                                             Hash Cond: (cs.cs_item_sk = i.i_item_sk)\n                                             Buffers: shared hit=18 read=28781, temp written=139\n                                             ->  Nested Loop  (cost=3061.00..2366278.67 rows=1163 width=45) (actual time=35.564..35.570 rows=0 loops=1)\n                                                   Join Filter: (inv.inv_warehouse_sk = w.w_warehouse_sk)\n                                                   Buffers: shared hit=18 read=21811\n                                                   ->  Nested Loop  (cost=3061.00..2366117.33 rows=1163 width=32) (actual time=35.563..35.568 rows=0 loops=1)\n                                                         Buffers: shared hit=18 read=21811\n                                                         ->  Hash Join  (cost=3060.43..64486.66 rows=157517 width=32) (actual time=35.562..35.566 rows=0 loops=1)\n                                                               Hash Cond: (d1.d_week_seq = d2.d_week_seq)\n                                                               Buffers: shared hit=18 read=21811\n                                                               ->  Hash Join  (cost=11.83..59610.72 rows=22415 width=28) (actual time=35.561..35.564 rows=0 loops=1)\n                                                                     Hash Cond: (cs.cs_sold_date_sk = d1.d_date_sk)\n                                                                     Buffers: shared hit=18 read=21811\n                                                                     ->  Hash Join  (cost=0.03..58788.15 rows=12350 width=24) (actual time=35.559..35.562 rows=0 loops=1)\n                                                                           Hash Cond: (cs.cs_bill_cdemo_sk = cd.cd_demo_sk)\n                                                                           Buffers: shared hit=18 read=21811\n                                                                           ->  CTE Scan on cs_filtered cs  (cost=0.00..49401.78 rows=2470089 width=32) (actual time=0.014..0.015 rows=1 loops=1)\n                                                                                 Buffers: shared read=1\n                                                                           ->  Hash  (cost=0.02..0.02 rows=1 width=4) (actual time=35.537..35.538 rows=0 loops=1)\n                                                                                 Buckets: 1024  Batches: 1  Memory Usage: 8kB\n                                                                                 Buffers: shared hit=18 read=21810\n                                                                                 ->  CTE Scan on filtered_cd cd  (cost=0.00..0.02 rows=1 width=4) (actual time=35.536..35.536 rows=0 loops=1)\n                                                                                       Buffers: shared hit=18 read=21810\n                                                                     ->  Hash  (cost=7.26..7.26 rows=363 width=12) (never executed)\n                                                                           ->  CTE Scan on filtered_date d1  (cost=0.00..7.26 rows=363 width=12) (never executed)\n                                                               ->  Hash  (cost=2135.49..2135.49 rows=73049 width=8) (never executed)\n                                                                     ->  Seq Scan on date_dim d2  (cost=0.00..2135.49 rows=73049 width=8) (never executed)\n                                                         ->  Index Scan using inventory_pkey on inventory inv  (cost=0.57..14.59 rows=2 width=16) (never executed)\n                                                               Index Cond: ((inv_date_sk = d2.d_date_sk) AND (inv_item_sk = cs.cs_item_sk))\n                                                               Filter: (inv_quantity_on_hand < cs.cs_quantity)\n                                                   ->  Materialize  (cost=0.00..1.15 rows=10 width=21) (never executed)\n                                                         ->  Seq Scan on warehouse w  (cost=0.00..1.10 rows=10 width=21) (never executed)\n                                             ->  Hash  (cost=347.08..347.08 rows=17354 width=422) (actual time=25.042..25.042 rows=17487 loops=1)\n                                                   Buckets: 16384  Batches: 2  Memory Usage: 1323kB\n                                                   Buffers: shared read=6970, temp written=138\n                                                   ->  CTE Scan on filtered_item i  (cost=0.00..347.08 rows=17354 width=422) (actual time=0.013..22.074 rows=17487 loops=1)\n                                                         Buffers: shared read=6970\n                                       ->  Hash  (cost=24.00..24.00 rows=1200 width=4) (actual time=0.578..0.578 rows=1200 loops=1)\n                                             Buckets: 2048  Batches: 1  Memory Usage: 59kB\n                                             Buffers: shared read=53\n                                             ->  CTE Scan on filtered_hd hd  (cost=0.00..24.00 rows=1200 width=4) (actual time=0.015..0.514 rows=1200 loops=1)\n                                                   Buffers: shared read=53\n                                 ->  Hash  (cost=2135.49..2135.49 rows=73049 width=8) (actual time=13.731..13.731 rows=73049 loops=1)\n                                       Buckets: 131072  Batches: 1  Memory Usage: 3878kB\n                                       Buffers: shared hit=9 read=1396\n                                       ->  Seq Scan on date_dim d3  (cost=0.00..2135.49 rows=73049 width=8) (actual time=0.014..7.888 rows=73049 loops=1)\n                                             Buffers: shared hit=9 read=1396\n                           ->  Hash  (cost=18.00..18.00 rows=500 width=4) (never executed)\n                                 ->  Seq Scan on promotion p  (cost=0.00..18.00 rows=500 width=4) (never executed)\n Planning:\n   Buffers: shared hit=807 read=94\n Planning Time: 3.995 ms\n Execution Time: 76.825 ms\n(103 rows)",
          "explain_timing": {
            "original_s": 0.4,
            "optimized_s": 0.1
          },
          "plan_signature": {
            "original_buffers": 181582,
            "optimized_buffers": 30266,
            "buffer_reduction": 6.0,
            "original_time_ms": 360.637,
            "optimized_time_ms": 76.825,
            "original_high_loops": [
              {
                "node": "I",
                "table": null,
                "loops": 365,
                "rows_per_loop": 895
              },
              {
                "node": "I",
                "table": null,
                "loops": 30768,
                "rows_per_loop": 0
              }
            ]
          }
        }
      ],
      "regressions": [],
      "guard_rails": [
        {
          "id": "PG_LOOSE_PREFILTER_BLOCK",
          "severity": "MEDIUM",
          "instruction": "POSTGRESQL RULE: Do NOT pre-filter fact tables into CTEs when the WHERE has correlated OR conditions (the union/superset filter materializes too many rows, 0.79x regression). BUT DO pre-filter fact tables when the query has expensive non-equi joins (quantity comparisons, date arithmetic) - reducing the fact table before these joins is highly effective (2.68x win on Q072).",
          "evidence": "DSB Q013_agg 0.79x \u2014 Loose CTE filter is a superset of correlated OR conditions. CTE fence blocks dimension predicate pushdown."
        }
      ]
    },
    {
      "id": "CTE_MATERIALIZATION_FENCE",
      "priority": "MEDIUM",
      "what": "PostgreSQL materializes CTEs by default (multi-referenced) or by choice (AS MATERIALIZED). This creates a hard optimization fence \u2014 no predicate pushdown from outer query into CTE. This makes CTE-based strategies a double-edged sword on PG.",
      "why": "CTE is computed and stored in memory/temp before the outer query executes. Any WHERE clause filters in the outer query cannot be pushed back into the CTE definition. Single-reference CTEs may be inlined in PG 12+, but multi-referenced CTEs are always materialized.",
      "opportunity": "Use materialization STRATEGICALLY: materialize when the CTE is expensive and reused multiple times. Avoid CTEs that fence off predicate pushdown for single-use cases.",
      "what_worked": [
        "Q065: 1.95x \u2014 strategic materialization prevented redundant fact table scan multiplication"
      ],
      "what_didnt_work": [
        "Q031: 0.74x \u2014 CTE fence blocked predicate pushdown that worked in original",
        "Q038: 0.77x \u2014 date_cte_isolate added fence that blocked INTERSECT optimization",
        "Q064: 0.65x \u2014 duplicated 18-table CTE body to push filters inside. NEVER do this \u2014 computing an 18-table join twice is always worse than computing once and filtering."
      ],
      "field_notes": [
        "NEVER duplicate a CTE body to push a filter inside when the CTE contains 5+ table joins. Filter the materialized result with WHERE, don't recompute.",
        "Do NOT use the AS MATERIALIZED keyword on CTEs. Write plain CTEs: 'name AS (SELECT ...)'. PG auto-materializes when beneficial. Forcing materialization on small dimension CTEs (<1000 rows) adds temp-table I/O overhead (0.69x observed on Q080).",
        "CTE fence + EXISTS = disaster. If the query uses EXISTS/NOT EXISTS, a CTE that fences off the semi-join optimization is actively harmful.",
        "CTE fence + INTERSECT/EXCEPT = harmful. Set operations handle their inputs efficiently inline. A CTE fence per branch adds overhead.",
        "A CTE result referenced 2+ times is materialized once, probed many \u2014 this IS the valid use case for CTEs on PG.",
        "When a date_cte_isolate CTE is applied to UNION ALL branches, apply to ALL branches or NONE. Partial application creates asymmetric plans."
      ],
      "gold_examples": [],
      "regressions": [],
      "guard_rails": [
        {
          "id": "PG_CTE_DUPLICATION_BLOCK",
          "severity": "HIGH",
          "instruction": "POSTGRESQL RULE: NEVER duplicate a CTE body to push a single-column filter inside. If the original has one CTE referenced multiple times, keep it as one CTE and filter in the WHERE clause. PostgreSQL materializes CTEs, so computing an expensive multi-table join twice is always worse than computing once and filtering. Observed 0.65x regression on 18-table CTE duplication.",
          "evidence": "DSB Q064_multi 0.65x \u2014 18-table join executed TWICE instead of once. Original computed it once and self-joined with year filter."
        },
        {
          "id": "NO_MATERIALIZED_KEYWORD_PG",
          "severity": "HIGH",
          "instruction": "Do NOT use the AS MATERIALIZED keyword on CTEs. Write plain CTEs: 'name AS (SELECT ...)'. PostgreSQL automatically materializes CTEs when beneficial. Forcing materialization on small dimension CTEs (< 1000 rows) adds temp-table I/O overhead that causes regressions (0.69x observed). The proven gold examples use plain CTEs without MATERIALIZED.",
          "evidence": "Q080_multi 0.69x (57ms -> 83ms) \u2014 MATERIALIZED keyword forced temp-table spill for tiny CTEs (30 rows), adding overhead that exceeded filtering benefit."
        }
      ]
    },
    {
      "id": "CROSS_CTE_PREDICATE_BLINDNESS",
      "priority": "MEDIUM",
      "what": "Same gap as DuckDB but WORSE on PostgreSQL because CTE materialization fence makes it more impactful. Predicates in the outer WHERE cannot propagate into materialized CTEs.",
      "why": "Even single-reference CTEs may be materialized (version-dependent). The optimizer does not trace data lineage through CTE boundaries.",
      "opportunity": "Same as DuckDB: pre-filter into CTE definition. But be more cautious \u2014 only when the CTE is clearly suboptimal.",
      "what_worked": [
        "Q080: 3.32x \u2014 date filter + comma-join conversion (the combo is key)",
        "Q099: 2.28x \u2014 date CTE with explicit JOIN"
      ],
      "what_didnt_work": [
        "Q027: 0.97x \u2014 won at SF5 (9.62x) but neutral at SF10. Cost model unreliability across scale.",
        "Q031: 0.55x \u2014 over-decomposed an already-efficient query"
      ],
      "field_notes": [
        "Convert comma-joins to explicit JOINs simultaneously \u2014 the CTE alone often isn't enough on PG.",
        "EXPLAIN will show sequential scan on dimension table without index condition \u2014 that's the signal.",
        "Don't use this on queries with INTERSECT, EXCEPT, or set operations \u2014 the CTE fence blocks set operation optimization.",
        "If the query already returns quickly (<100ms), the CTE materialization overhead can negate any savings.",
        "Validate at target scale \u2014 SF5 wins don't reliably predict SF10 on PostgreSQL."
      ],
      "gold_examples": [
        {
          "id": "pg_self_join_decomposition",
          "queries": [
            "DSB Q065_multi"
          ],
          "speedup": "3.93x",
          "principle": "Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.",
          "original_sql": "select \n\ts_store_name,\n\ti_item_desc,\n\tsc.revenue,\n\ti_current_price,\n\ti_wholesale_cost,\n\ti_brand\n from store, item,\n     (select ss_store_sk, avg(revenue) as ave\n\tfrom\n\t    (select  ss_store_sk, ss_item_sk,\n\t\t     sum(ss_sales_price) as revenue\n\t\tfrom store_sales, date_dim\n\t\twhere ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11\n   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01\n\t\tgroup by ss_store_sk, ss_item_sk) sa\n\tgroup by ss_store_sk) sb,\n     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue\n\tfrom store_sales, date_dim\n\twhere ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11\n  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01\n\tgroup by ss_store_sk, ss_item_sk) sc\n where sb.ss_store_sk = sc.ss_store_sk and\n       sc.revenue <= 0.1 * sb.ave and\n       s_store_sk = sc.ss_store_sk and\n       i_item_sk = sc.ss_item_sk\n       and i_manager_id BETWEEN 32 and 36\n       and s_state in ('TN','TX','VA')\n order by s_store_name, i_item_desc\nlimit 100;",
          "optimized_sql": "WITH date_filter AS (SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1213 + 11), store_sales_revenue AS (SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON store_sales.ss_sold_date_sk = date_filter.d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01 GROUP BY ss_store_sk, ss_item_sk), store_avg_revenue AS (SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk), filtered_store AS (SELECT s_store_sk, s_store_name, s_state FROM store WHERE s_state IN ('TN', 'TX', 'VA')), filtered_item AS (SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand, i_manager_id FROM item WHERE i_manager_id BETWEEN 32 AND 36) SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100",
          "key_insight": "Principle: Shared Materialization (PG) \u2014 when the same fact+dimension scan appears multiple times, materialize it once as a CTE and reference it from each consumer. PostgreSQL CTE materialization guarantees single execution. Here: store_sales+date_dim scanned twice with identical predicates becomes one materialized CTE, reused for both per-item revenue and per-store averages. Combined with dimension pre-filtering to reduce I/O.",
          "original_explain": "QUERY PLAN                                                                                                                                  \n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=233852.29..233852.30 rows=1 width=202) (actual time=1916.203..1920.810 rows=100 loops=1)\n   Buffers: shared hit=11488 read=76605, temp read=2360 written=3300\n   ->  Sort  (cost=233852.29..233852.30 rows=1 width=202) (actual time=1916.202..1920.805 rows=100 loops=1)\n         Sort Key: store.s_store_name, item.i_item_desc\n         Sort Method: quicksort  Memory: 60kB\n         Buffers: shared hit=11488 read=76605, temp read=2360 written=3300\n         ->  Nested Loop  (cost=233539.23..233852.28 rows=1 width=202) (actual time=1781.335..1920.704 rows=116 loops=1)\n               Buffers: shared hit=11485 read=76605, temp read=2360 written=3300\n               ->  Merge Join  (cost=233538.94..233743.82 rows=19 width=40) (actual time=1780.883..1911.972 rows=2713 loops=1)\n                     Merge Cond: (store_sales.ss_store_sk = store_sales_1.ss_store_sk)\n                     Join Filter: ((sum(store_sales.ss_sales_price)) <= (0.1 * (avg((sum(store_sales_1.ss_sales_price))))))\n                     Rows Removed by Join Filter: 16754\n                     Buffers: shared hit=6379 read=73572, temp read=2360 written=3300\n                     ->  Finalize GroupAggregate  (cost=116766.11..116855.61 rows=709 width=40) (actual time=867.966..947.714 rows=122947 loops=1)\n                           Group Key: store_sales.ss_store_sk, store_sales.ss_item_sk\n                           Buffers: shared hit=3187 read=36786, temp read=1012 written=1650\n                           ->  Gather Merge  (cost=116766.11..116840.85 rows=590 width=40) (actual time=867.955..909.969 rows=127296 loops=1)\n                                 Workers Planned: 2\n                                 Workers Launched: 2\n                                 Buffers: shared hit=3187 read=36786, temp read=1012 written=1650\n                                 ->  Partial GroupAggregate  (cost=115766.09..115772.72 rows=295 width=40) (actual time=545.967..566.709 rows=42605 loops=3)\n                                       Group Key: store_sales.ss_store_sk, store_sales.ss_item_sk\n                                       Buffers: shared hit=3187 read=36786, temp read=1012 written=1650\n                                       ->  Sort  (cost=115766.09..115766.82 rows=295 width=14) (actual time=545.959..551.441 rows=86683 loops=3)\n                                             Sort Key: store_sales.ss_store_sk, store_sales.ss_item_sk\n                                             Sort Method: external merge  Disk: 6160kB\n                                             Buffers: shared hit=3187 read=36786, temp read=1012 written=1650\n                                             Worker 0:  Sort Method: quicksort  Memory: 25kB\n                                             Worker 1:  Sort Method: external merge  Disk: 6968kB\n                                             ->  Nested Loop  (cost=0.98..115753.98 rows=295 width=14) (actual time=0.538..508.677 rows=179719 loops=3)\n                                                   Buffers: shared hit=3173 read=36786\n                                                   ->  Parallel Index Only Scan using _dta_index_date_dim_6_661577395__k7_k4_k9_k1 on date_dim  (cost=0.42..1868.48 rows=157 width=4) (actual time=0.512..0.576 rows=122 loops=3)\n                                                         Index Cond: ((d_month_seq >= 1213) AND (d_month_seq <= 1224))\n                                                         Heap Fetches: 0\n                                                         Buffers: shared hit=1 read=283\n                                                   ->  Index Only Scan using _dta_index_store_sales_6_1333579789__k1_k5_k8_k3_11_13_14_20 on store_sales  (cost=0.56..724.72 rows=67 width=18) (actual time=0.008..4.103 rows=1477 loops=365)\n                                                         Index Cond: (ss_sold_date_sk = date_dim.d_date_sk)\n                                                         Filter: (((ss_sales_price / ss_list_price) >= 0.38) AND ((ss_sales_price / ss_list_price) <= 0.48))\n                                                         Rows Removed by Filter: 12258\n                                                         Heap Fetches: 0\n                                                         Buffers: shared hit=3172 read=36503\n                     ->  Materialize  (cost=116772.83..116878.25 rows=16 width=44) (actual time=871.464..957.310 rows=13414 loops=1)\n                           Buffers: shared hit=3192 read=36786, temp read=1348 written=1650\n                           ->  Merge Join  (cost=116772.83..116878.21 rows=16 width=44) (actual time=871.461..956.856 rows=4 loops=1)\n                                 Merge Cond: (store.s_store_sk = store_sales_1.ss_store_sk)\n                                 Buffers: shared hit=3192 read=36786, temp read=1348 written=1650\n                                 ->  Sort  (cost=6.72..6.76 rows=16 width=8) (actual time=0.049..0.054 rows=16 loops=1)\n                                       Sort Key: store.s_store_sk\n                                       Sort Method: quicksort  Memory: 25kB\n                                       Buffers: shared read=5\n                                       ->  Seq Scan on store  (cost=0.00..6.40 rows=16 width=8) (actual time=0.015..0.040 rows=16 loops=1)\n                                             Filter: (s_state = ANY ('{TN,TX,VA}'::bpchar[]))\n                                             Rows Removed by Filter: 86\n                                             Buffers: shared read=5\n                                 ->  GroupAggregate  (cost=116766.11..116868.74 rows=200 width=36) (actual time=871.407..956.776 rows=27 loops=1)\n                                       Group Key: store_sales_1.ss_store_sk\n                                       Buffers: shared hit=3192 read=36781, temp read=1348 written=1650\n                                       ->  Finalize GroupAggregate  (cost=116766.11..116855.61 rows=709 width=40) (actual time=866.026..950.203 rows=132510 loops=1)\n                                             Group Key: store_sales_1.ss_store_sk, store_sales_1.ss_item_sk\n                                             Buffers: shared hit=3192 read=36781, temp read=1348 written=1650\n                                             ->  Gather Merge  (cost=116766.11..116840.85 rows=590 width=40) (actual time=866.017..910.681 rows=137379 loops=1)\n                                                   Workers Planned: 2\n                                                   Workers Launched: 2\n                                                   Buffers: shared hit=3192 read=36781, temp read=1348 written=1650\n                                                   ->  Partial GroupAggregate  (cost=115766.09..115772.72 rows=295 width=40) (actual time=535.328..557.835 rows=45977 loops=3)\n                                                         Group Key: store_sales_1.ss_store_sk, store_sales_1.ss_item_sk\n                                                         Buffers: shared hit=3192 read=36781, temp read=1348 written=1650\n                                                         ->  Sort  (cost=115766.09..115766.82 rows=295 width=14) (actual time=535.321..541.354 rows=93682 loops=3)\n                                                               Sort Key: store_sales_1.ss_store_sk, store_sales_1.ss_item_sk\n                                                               Sort Method: external merge  Disk: 6160kB\n                                                               Buffers: shared hit=3192 read=36781, temp read=1348 written=1650\n                                                               Worker 0:  Sort Method: external merge  Disk: 6968kB\n                                                               Worker 1:  Sort Method: quicksort  Memory: 25kB\n                                                               ->  Nested Loop  (cost=0.98..115753.98 rows=295 width=14) (actual time=0.470..498.620 rows=179719 loops=3)\n                                                                     Buffers: shared hit=3179 read=36780\n                                                                     ->  Parallel Index Only Scan using _dta_index_date_dim_6_661577395__k7_k4_k9_k1 on date_dim date_dim_1  (cost=0.42..1868.48 rows=157 width=4) (actual time=0.443..0.507 rows=122 loops=3)\n                                                                           Index Cond: ((d_month_seq >= 1213) AND (d_month_seq <= 1224))\n                                                                           Heap Fetches: 0\n                                                                           Buffers: shared hit=3 read=281\n                                                                     ->  Index Only Scan using _dta_index_store_sales_6_1333579789__k1_k5_k8_k3_11_13_14_20 on store_sales store_sales_1  (cost=0.56..724.72 rows=67 width=18) (actual time=0.008..4.022 rows=1477 loops=365)\n                                                                           Index Cond: (ss_sold_date_sk = date_dim_1.d_date_sk)\n                                                                           Filter: (((ss_sales_price / ss_list_price) >= 0.38) AND ((ss_sales_price / ss_list_price) <= 0.48))\n                                                                           Rows Removed by Filter: 12258\n                                                                           Heap Fetches: 0\n                                                                           Buffers: shared hit=3176 read=36499\n               ->  Index Scan using item_pkey on item  (cost=0.29..5.71 rows=1 width=170) (actual time=0.003..0.003 rows=0 loops=2713)\n                     Index Cond: (i_item_sk = store_sales.ss_item_sk)\n                     Filter: ((i_manager_id >= 32) AND (i_manager_id <= 36))\n                     Rows Removed by Filter: 1\n                     Buffers: shared hit=5106 read=3033\n Planning:\n   Buffers: shared hit=957 read=95\n Planning Time: 1.694 ms\n Execution Time: 1922.589 ms\n(94 rows)",
          "optimized_explain": "QUERY PLAN                                                                                                          \n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Limit  (cost=117012.23..117012.23 rows=1 width=202) (actual time=1118.969..1119.044 rows=100 loops=1)\n   Buffers: shared hit=8784 read=39336, temp read=2223 written=2232\n   CTE store_sales_revenue\n     ->  Finalize GroupAggregate  (cost=116766.11..116855.61 rows=709 width=40) (actual time=896.177..1044.380 rows=191850 loops=1)\n           Group Key: store_sales.ss_store_sk, store_sales.ss_item_sk\n           Buffers: shared hit=3189 read=36784, temp read=1641 written=1650\n           ->  Gather Merge  (cost=116766.11..116840.85 rows=590 width=40) (actual time=896.170..975.492 rows=219776 loops=1)\n                 Workers Planned: 2\n                 Workers Launched: 2\n                 Buffers: shared hit=3189 read=36784, temp read=1641 written=1650\n                 ->  Partial GroupAggregate  (cost=115766.09..115772.72 rows=295 width=40) (actual time=557.268..598.613 rows=73259 loops=3)\n                       Group Key: store_sales.ss_store_sk, store_sales.ss_item_sk\n                       Buffers: shared hit=3189 read=36784, temp read=1641 written=1650\n                       ->  Sort  (cost=115766.09..115766.82 rows=295 width=14) (actual time=557.261..569.099 rows=179719 loops=3)\n                             Sort Key: store_sales.ss_store_sk, store_sales.ss_item_sk\n                             Sort Method: external merge  Disk: 6160kB\n                             Buffers: shared hit=3189 read=36784, temp read=1641 written=1650\n                             Worker 0:  Sort Method: external merge  Disk: 6968kB\n                             Worker 1:  Sort Method: quicksort  Memory: 25kB\n                             ->  Nested Loop  (cost=0.98..115753.98 rows=295 width=14) (actual time=0.542..516.920 rows=179719 loops=3)\n                                   Buffers: shared hit=3175 read=36784\n                                   ->  Parallel Index Only Scan using _dta_index_date_dim_6_661577395__k7_k4_k9_k1 on date_dim  (cost=0.42..1868.48 rows=157 width=4) (actual time=0.518..0.587 rows=122 loops=3)\n                                         Index Cond: ((d_month_seq >= 1213) AND (d_month_seq <= 1224))\n                                         Heap Fetches: 0\n                                         Buffers: shared hit=2 read=282\n                                   ->  Index Only Scan using _dta_index_store_sales_6_1333579789__k1_k5_k8_k3_11_13_14_20 on store_sales  (cost=0.56..724.72 rows=67 width=18) (actual time=0.008..4.165 rows=1477 loops=365)\n                                         Index Cond: (ss_sold_date_sk = date_dim.d_date_sk)\n                                         Filter: (((ss_sales_price / ss_list_price) >= 0.38) AND ((ss_sales_price / ss_list_price) <= 0.48))\n                                         Rows Removed by Filter: 12258\n                                         Heap Fetches: 0\n                                         Buffers: shared hit=3173 read=36502\n   ->  Sort  (cost=156.62..156.62 rows=1 width=202) (actual time=1118.967..1118.973 rows=100 loops=1)\n         Sort Key: store.s_store_name, item.i_item_desc\n         Sort Method: quicksort  Memory: 60kB\n         Buffers: shared hit=7658 read=19818, temp read=1352 written=1356\n         ->  Nested Loop  (cost=29.86..156.61 rows=1 width=202) (actual time=1095.841..1118.875 rows=116 loops=1)\n               Buffers: shared hit=7655 read=19818, temp read=1352 written=1356\n               ->  Hash Join  (cost=29.56..48.14 rows=19 width=40) (actual time=1095.610..1111.218 rows=2713 loops=1)\n                     Hash Cond: (sc.ss_store_sk = store_sales_revenue.ss_store_sk)\n                     Join Filter: (sc.revenue <= (0.1 * (avg(store_sales_revenue.revenue))))\n                     Rows Removed by Join Filter: 16754\n                     Buffers: shared hit=2063 read=17271, temp read=1352 written=1356\n                     ->  CTE Scan on store_sales_revenue sc  (cost=0.00..14.18 rows=709 width=40) (actual time=896.180..902.895 rows=191850 loops=1)\n                           Buffers: shared hit=2063 read=17266, temp read=1072 written=775\n                     ->  Hash  (cost=29.36..29.36 rows=16 width=44) (actual time=199.410..199.413 rows=4 loops=1)\n                           Buckets: 1024  Batches: 1  Memory Usage: 9kB\n                           Buffers: shared read=5, temp read=280 written=581\n                           ->  Hash Join  (cost=24.33..29.36 rows=16 width=44) (actual time=199.399..199.409 rows=4 loops=1)\n                                 Hash Cond: (store_sales_revenue.ss_store_sk = store.s_store_sk)\n                                 Buffers: shared read=5, temp read=280 written=581\n                                 ->  HashAggregate  (cost=17.73..20.23 rows=200 width=36) (actual time=199.333..199.343 rows=31 loops=1)\n                                       Group Key: store_sales_revenue.ss_store_sk\n                                       Batches: 1  Memory Usage: 48kB\n                                       Buffers: temp read=280 written=581\n                                       ->  CTE Scan on store_sales_revenue  (cost=0.00..14.18 rows=709 width=36) (actual time=0.001..176.791 rows=191850 loops=1)\n                                             Buffers: temp read=280 written=581\n                                 ->  Hash  (cost=6.40..6.40 rows=16 width=8) (actual time=0.047..0.048 rows=16 loops=1)\n                                       Buckets: 1024  Batches: 1  Memory Usage: 9kB\n                                       Buffers: shared read=5\n                                       ->  Seq Scan on store  (cost=0.00..6.40 rows=16 width=8) (actual time=0.021..0.043 rows=16 loops=1)\n                                             Filter: (s_state = ANY ('{TN,TX,VA}'::bpchar[]))\n                                             Rows Removed by Filter: 86\n                                             Buffers: shared read=5\n               ->  Index Scan using item_pkey on item  (cost=0.29..5.71 rows=1 width=170) (actual time=0.003..0.003 rows=0 loops=2713)\n                     Index Cond: (i_item_sk = sc.ss_item_sk)\n                     Filter: ((i_manager_id >= 32) AND (i_manager_id <= 36))\n                     Rows Removed by Filter: 1\n                     Buffers: shared hit=5592 read=2547\n Planning:\n   Buffers: shared hit=936 read=104\n Planning Time: 1.636 ms\n Execution Time: 1121.079 ms\n(72 rows)",
          "explain_timing": {
            "original_s": 1.94,
            "optimized_s": 1.14
          },
          "plan_signature": {
            "original_buffers": 88093,
            "optimized_buffers": 48120,
            "buffer_reduction": 1.83,
            "original_time_ms": 1922.589,
            "optimized_time_ms": 1121.079,
            "original_high_loops": [
              {
                "node": "I",
                "table": null,
                "loops": 365,
                "rows_per_loop": 1477
              },
              {
                "node": "I",
                "table": null,
                "loops": 365,
                "rows_per_loop": 1477
              },
              {
                "node": "I",
                "table": null,
                "loops": 2713,
                "rows_per_loop": 0
              }
            ]
          }
        }
      ],
      "regressions": [],
      "guard_rails": [
        {
          "id": "PG_DATE_CTE_CAUTION",
          "severity": "MEDIUM",
          "instruction": "POSTGRESQL RULE: date_cte_isolate is ONLY beneficial when combined with converting comma-joins to explicit JOINs on star-schema queries. DO NOT use it on queries with EXISTS/NOT EXISTS (kills semi-join), INTERSECT/EXCEPT (adds CTE overhead per branch), or when the query already has efficient CTEs. If applying to UNION ALL branches, apply to ALL or NONE.",
          "evidence": "DSB Q069_multi 0.50x \u2014 "
        }
      ]
    }
  ],
  "set_local_config_intel": {
    "briefing_note": "Field intelligence from programmatic EXPLAIN analysis + 6-step interleaved benchmark on 21 DSB queries at SF10 (PG 14.3). SET LOCAL configs are per-query session-scoped tuning that reverts on COMMIT. Config alone delivered 6.8x on Q100 and 2.3x additive on Q014. Avg additive across all configured queries: 1.31x.",
    "rules": [
      {
        "id": "SORT_SPILL_WORK_MEM",
        "trigger": "EXPLAIN shows Sort Space Type = 'Disk'",
        "config": "work_mem sized by sort/hash op count: <=2 ops \u2192 1GB, 3-5 \u2192 512MB, 6-10 \u2192 256MB, 10+ \u2192 128MB",
        "evidence": "Q100_agg: 6.82x additive (1390ms \u2192 204ms). Sort spills to disk eliminated. Q050_agg: 1.07x. Q014: 1.61x (template with work_mem=256MB).",
        "risk": "LOW. work_mem is per-operation, not per-query. Count sort+hash ops in EXPLAIN before sizing."
      },
      {
        "id": "JIT_OVERHEAD_DISABLE",
        "trigger": "JIT total > 5% of exec time, or >2% when exec < 10s, or absolute JIT > 500ms",
        "config": "SET LOCAL jit = 'off'",
        "evidence": "Q010: 1.07x additive (53ms \u2192 50ms, 582ms JIT was 6.8% of 8.5s exec). Q094: 1.05x. Minor but consistent lift on medium queries.",
        "risk": "LOW. JIT helps long analytical queries but overhead dominates on <30s queries."
      },
      {
        "id": "PARALLEL_COST_REDUCTION",
        "trigger": "EXPLAIN shows Workers Launched < Workers Planned",
        "config": "SET LOCAL parallel_setup_cost = '100.0'; SET LOCAL parallel_tuple_cost = '0.001'",
        "evidence": "Q081: 1.09x additive (502ms \u2192 444ms). Encourages parallelism where planner thinks it helps.",
        "risk": "LOW. Only reduces cost thresholds \u2014 planner still decides. Does not force workers."
      },
      {
        "id": "FORCED_PARALLELISM_DANGER",
        "trigger": "NEVER force max_parallel_workers_per_gather on queries that run < 500ms",
        "config": "Do NOT set max_parallel_workers_per_gather on fast queries",
        "evidence": "Q039: 7.34x REGRESSION (244ms \u2192 1792ms). Worker startup + coordination overhead dominates when the query is already fast. Template config with forced parallelism caused 9.5x regression.",
        "risk": "CRITICAL. Only set max_parallel_workers_per_gather when EXPLAIN shows large unparallelized SeqScans (>500K rows) with no Gather node above. Never on queries < 500ms."
      },
      {
        "id": "HASH_MEM_MULTIPLIER_CAUTION",
        "trigger": "EXPLAIN shows Hash Batches > 1",
        "config": "SET LOCAL hash_mem_multiplier = min(8, batches/2)",
        "evidence": "Q064: 0.56x REGRESSION (1901ms \u2192 3368ms). High multiplier (8.0) caused planner to choose a worse hash join plan. Approach with caution.",
        "risk": "MEDIUM-HIGH. Can cause plan regression if multiplier is too aggressive. Test values 2.0-4.0 first."
      },
      {
        "id": "EFFECTIVE_CACHE_SIZE_ADVISORY",
        "trigger": "Shared Read Blocks > 10x Shared Hit Blocks (cold buffer ratio), or Temp I/O > 1000 blocks",
        "config": "SET LOCAL effective_cache_size = '48GB'",
        "evidence": "Q087: 0.99x \u2014 neutral alone but safe. Usually combined with work_mem. Q100: part of 6.82x combo.",
        "risk": "LOW. Advisory only \u2014 tells planner how much OS cache to expect. Does not allocate memory."
      }
    ],
    "key_findings": [
      "Config tuning is ADDITIVE to SQL rewrite \u2014 not a substitute. Best results combine good rewrite + targeted config.",
      "work_mem for sort spills is the single biggest config lever on PostgreSQL (Q100: 6.8x).",
      "Forced parallelism (max_parallel_workers_per_gather) is DANGEROUS on fast queries. Use parallel cost reduction instead \u2014 it nudges the planner without forcing overhead.",
      "hash_mem_multiplier > 4.0 can cause plan regressions. Start conservative (2.0) and test.",
      "JIT overhead is consistent but small (1.05-1.07x). Worth disabling on queries < 30s.",
      "Template configs (one-size-fits-all) are inferior to EXPLAIN-driven configs. Q039 proved this."
    ]
  },
  "scale_sensitivity_warning": "PostgreSQL optimizations validated at SF5 do NOT reliably predict SF10 behavior. 7 queries that won at SF5 regressed at SF10 (Q027 9.62x at SF5 but 0.97x at SF10). Always validate at target scale. Cost estimates are overconfident on sample data.",
  "global_guard_rails": [
    {
      "id": "SEMANTIC_EQUIVALENCE",
      "severity": "CRITICAL",
      "instruction": "The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set \u2014 even by one row, one column, or a different sort order \u2014 is WRONG and will be REJECTED."
    },
    {
      "id": "LITERAL_PRESERVATION",
      "severity": "CRITICAL",
      "instruction": "CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.",
      "evidence": "Q2  \u2014 "
    },
    {
      "id": "CTE_COLUMN_COMPLETENESS",
      "severity": "CRITICAL",
      "instruction": "CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.",
      "evidence": "Q21  \u2014 "
    },
    {
      "id": "COMPLETE_OUTPUT",
      "severity": "CRITICAL",
      "instruction": "The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original."
    },
    {
      "id": "EXPLICIT_JOINS",
      "severity": "MEDIUM",
      "instruction": "Convert comma-separated implicit joins to explicit JOIN ... ON syntax. This gives the optimizer better join-order freedom."
    },
    {
      "id": "KEEP_EXISTS_AS_EXISTS",
      "severity": "HIGH",
      "instruction": "DEFAULT: Preserve EXISTS/NOT EXISTS as-is. NOT EXISTS\u2192NOT IN breaks with NULLs; EXISTS\u2192JOIN can duplicate rows. HOWEVER: if the join column is NOT NULL (PK or explicit constraint), EXISTS\u2192IN is safe. If the subquery is 1:1 with the outer query, EXISTS\u2192JOIN is safe. The exploration worker MAY convert EXISTS with written proof of NULL safety or 1:1 cardinality.",
      "evidence": "Converting NOT EXISTS to NOT IN changes behavior when the subquery column contains NULLs. NOT IN with NULLs returns no rows."
    },
    {
      "id": "NO_MATERIALIZE_EXISTS",
      "severity": "HIGH",
      "instruction": "DEFAULT: Keep EXISTS/NOT EXISTS as-is \u2014 semi-join short-circuiting is usually faster than materialization. Converting to CTEs caused 0.14x on Q16 and 0.54x on Q95. HOWEVER: if the correlated EXISTS is executed many times and the optimizer fails to decorrelate it, materializing into a small CTE (<10K rows) probed via JOIN may help. The exploration worker MAY attempt this with reasoning about correlation frequency and CTE size.",
      "evidence": "Q16 0.14x (18ms -> 126ms) \u2014 WITH multi_warehouse_orders AS (SELECT DISTINCT cs_order_number FROM catalog_sales GROUP BY cs_order_number HAVING MIN(cs_warehouse_sk) <> MAX(cs_warehouse_sk))"
    },
    {
      "id": "MIN_BASELINE_THRESHOLD",
      "severity": "MEDIUM",
      "instruction": "DEFAULT: If baseline is under 100ms, prefer minimal rewrites. CTE materialization overhead (hash tables, intermediate storage) can exceed filtering benefit on fast queries. HOWEVER: transforms that reduce scan count without adding CTEs (pushdown, decorrelate) may still help. The exploration worker MAY attempt structural changes on fast queries if the transform is scan-reducing, not CTE-adding.",
      "evidence": "Q25 0.50x (31ms -> 62ms) \u2014 "
    },
    {
      "id": "REMOVE_REPLACED_CTES",
      "severity": "HIGH",
      "instruction": "When creating replacement CTEs, overwrite the original by using the same node_id in your rewrite_sets, or ensure the original is removed from the WITH clause. Every CTE in the final query should be actively used \u2014 dead CTEs still get materialized and waste resources (caused 0.49x on Q31, 0.68x on Q74).",
      "evidence": "Q31 0.49x (99ms -> 201ms) \u2014 Created new store_sales_agg and web_sales_agg CTEs but left the original ss and ws CTEs in the WITH clause. Both old and new CTEs coexist, wasting materialization."
    },
    {
      "id": "DECORRELATE_MUST_FILTER_FIRST",
      "severity": "MEDIUM",
      "instruction": "When decorrelating a correlated subquery into a JOIN, ensure all original WHERE filters are preserved in the replacement CTE or JOIN condition. A decorrelation without selective filters creates a cross-product that is larger than the original per-row correlated execution. The replacement CTE must filter to at most the same cardinality as the original subquery.",
      "evidence": "multiple  \u2014 Correlated subquery was converted to JOIN without carrying over the original WHERE filters, producing a much larger intermediate result than the correlated version."
    }
  ],
  "transform_catalog": {
    "date_cte_isolate": {
      "wins": 4,
      "avg_speedup": 2.24,
      "reliability": "MEDIUM",
      "note": "Must combine with explicit JOIN conversion"
    },
    "early_filter": {
      "wins": 3,
      "avg_speedup": 2.05,
      "reliability": "HIGH"
    },
    "decorrelate": {
      "wins": 2,
      "max_speedup": 4428,
      "reliability": "HIGH",
      "note": "Timeout rescues on correlated scalar subqueries"
    },
    "materialize_cte": {
      "wins": 2,
      "avg_speedup": 2.94,
      "reliability": "MEDIUM",
      "note": "PG auto-materializes; use for self-join dedup"
    },
    "explicit_join_conversion": {
      "wins": 3,
      "avg_speedup": 2.25,
      "reliability": "HIGH"
    },
    "dimension_prefetch": {
      "wins": 2,
      "avg_speedup": 2.8,
      "reliability": "HIGH"
    }
  }
}