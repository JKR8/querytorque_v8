<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>QueryTorque — Fleet C2 Help</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
<style>
:root {
  --bg: #ffffff;
  --bg-elevated: #f8fafc;
  --bg-subtle: #f1f5f9;
  --border: #e2e8f0;
  --border-hover: #cbd5e1;
  --t1: #0f172a;
  --t2: #64748b;
  --t3: #94a3b8;
  --green: #059669;
  --green-bg: #ecfdf5;
  --blue: #2563eb;
  --blue-bg: #eff6ff;
  --amber: #f59e0b;
  --amber-bg: #fffbeb;
  --red: #ef4444;
  --red-bg: #fef2f2;
  --purple: #7c3aed;
  --purple-bg: #f5f3ff;
  --mono: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
  --sans: 'Inter', -apple-system, system-ui, sans-serif;
  --radius: 6px;
}

* { box-sizing: border-box; margin: 0; padding: 0; }

body {
  font-family: var(--sans);
  background: var(--bg);
  color: var(--t1);
  line-height: 1.7;
  -webkit-font-smoothing: antialiased;
}

::selection { background: #c7d2fe; color: #0f172a; }
::-webkit-scrollbar { width: 6px; }
::-webkit-scrollbar-track { background: #f8fafc; }
::-webkit-scrollbar-thumb { background: #cbd5e1; border-radius: 3px; }

/* ── Header ── */
.header {
  background: rgba(255,255,255,0.92);
  border-bottom: 1px solid var(--border);
  padding: 16px 32px;
  display: flex;
  align-items: center;
  justify-content: space-between;
  position: sticky;
  top: 0;
  z-index: 100;
  backdrop-filter: blur(12px);
}

.header-left {
  display: flex;
  align-items: center;
  gap: 16px;
}

.logo {
  display: flex;
  align-items: center;
  gap: 8px;
  text-decoration: none;
  color: var(--t1);
}

.logo-icon {
  width: 28px;
  height: 28px;
  border-radius: 6px;
  background: #2563eb;
  display: flex;
  align-items: center;
  justify-content: center;
}

.logo-icon svg { width: 16px; height: 16px; }

.logo-text {
  font-family: var(--mono);
  font-size: 15px;
  font-weight: 500;
}

.header-sep {
  width: 1px;
  height: 20px;
  background: var(--border);
}

.header-title {
  font-size: 14px;
  font-weight: 500;
  color: var(--t2);
}

/* ── Main Content ── */
.main {
  max-width: 860px;
  margin: 0 auto;
  padding: 40px 32px 80px;
}

h1 {
  font-size: 28px;
  font-weight: 700;
  margin-bottom: 8px;
}

.subtitle {
  color: var(--t2);
  font-size: 15px;
  margin-bottom: 40px;
}

h2 {
  font-size: 20px;
  font-weight: 600;
  margin-top: 48px;
  margin-bottom: 16px;
  padding-bottom: 8px;
  border-bottom: 1px solid var(--border);
}

h3 {
  font-size: 16px;
  font-weight: 600;
  margin-top: 28px;
  margin-bottom: 10px;
}

p {
  margin-bottom: 12px;
  color: var(--t1);
  font-size: 14px;
}

ul, ol {
  margin-bottom: 12px;
  padding-left: 24px;
  font-size: 14px;
}

li { margin-bottom: 6px; }

code {
  font-family: var(--mono);
  font-size: 13px;
  background: var(--bg-subtle);
  padding: 2px 6px;
  border-radius: 4px;
  color: var(--purple);
}

pre {
  font-family: var(--mono);
  font-size: 13px;
  background: var(--bg-elevated);
  border: 1px solid var(--border);
  border-radius: var(--radius);
  padding: 16px 20px;
  overflow-x: auto;
  margin-bottom: 16px;
  line-height: 1.5;
}

pre code {
  background: none;
  padding: 0;
  color: var(--t1);
}

/* ── Table of Contents ── */
.toc {
  background: var(--bg-elevated);
  border: 1px solid var(--border);
  border-radius: var(--radius);
  padding: 20px 24px;
  margin-bottom: 32px;
}

.toc-title {
  font-size: 13px;
  font-weight: 600;
  text-transform: uppercase;
  letter-spacing: 0.05em;
  color: var(--t3);
  margin-bottom: 10px;
}

.toc a {
  display: block;
  color: var(--blue);
  text-decoration: none;
  font-size: 14px;
  padding: 3px 0;
}

.toc a:hover { text-decoration: underline; }

/* ── Glossary Table ── */
.glossary-table {
  width: 100%;
  border-collapse: collapse;
  font-size: 14px;
  margin-bottom: 24px;
}

.glossary-table th {
  text-align: left;
  font-weight: 600;
  font-size: 12px;
  text-transform: uppercase;
  letter-spacing: 0.05em;
  color: var(--t3);
  padding: 10px 12px;
  border-bottom: 2px solid var(--border);
}

.glossary-table td {
  padding: 10px 12px;
  border-bottom: 1px solid var(--border);
  vertical-align: top;
}

.glossary-table tr:last-child td { border-bottom: none; }

.glossary-table td:first-child {
  font-family: var(--mono);
  font-size: 13px;
  font-weight: 500;
  white-space: nowrap;
  color: var(--t1);
  width: 200px;
}

.glossary-table td:last-child { color: var(--t2); }

/* ── Config Table ── */
.config-table {
  width: 100%;
  border-collapse: collapse;
  font-size: 13px;
  margin-bottom: 24px;
}

.config-table th {
  text-align: left;
  font-weight: 600;
  font-size: 11px;
  text-transform: uppercase;
  letter-spacing: 0.05em;
  color: var(--t3);
  padding: 8px 10px;
  border-bottom: 2px solid var(--border);
}

.config-table td {
  padding: 8px 10px;
  border-bottom: 1px solid var(--border);
  vertical-align: top;
}

.config-table td:first-child {
  font-family: var(--mono);
  font-size: 12px;
  font-weight: 500;
  white-space: nowrap;
  color: var(--purple);
}

.config-table td:nth-child(2) {
  font-family: var(--mono);
  font-size: 12px;
  color: var(--t3);
  white-space: nowrap;
}

.config-table td:nth-child(3) {
  font-family: var(--mono);
  font-size: 12px;
  color: var(--t2);
  white-space: nowrap;
}

.config-table td:last-child { color: var(--t2); font-size: 13px; }

/* ── Info Card ── */
.info-card {
  background: var(--blue-bg);
  border: 1px solid #bfdbfe;
  border-radius: var(--radius);
  padding: 14px 18px;
  margin-bottom: 16px;
  font-size: 14px;
  color: #1e40af;
}

/* ── Tab Badge (inline) ── */
.tab-badge {
  display: inline-block;
  font-family: var(--mono);
  font-size: 11px;
  font-weight: 600;
  letter-spacing: 0.04em;
  padding: 2px 8px;
  border-radius: 4px;
  vertical-align: middle;
}

.tab-badge.triage  { background: var(--blue-bg);   color: var(--blue); }
.tab-badge.exec    { background: var(--amber-bg);  color: #b45309; }
.tab-badge.done    { background: var(--green-bg);  color: var(--green); }
.tab-badge.editor  { background: var(--purple-bg); color: var(--purple); }

/* ── Status Badge ── */
.status-badge {
  display: inline-block;
  font-family: var(--mono);
  font-size: 11px;
  font-weight: 600;
  padding: 2px 8px;
  border-radius: 4px;
}

.status-badge.win        { background: var(--green-bg);  color: var(--green); }
.status-badge.improved   { background: var(--blue-bg);   color: var(--blue); }
.status-badge.neutral    { background: var(--bg-subtle); color: var(--t2); }
.status-badge.regression { background: var(--red-bg);    color: var(--red); }
.status-badge.error      { background: var(--red-bg);    color: var(--red); }

/* ── Back link ── */
.back-link {
  display: inline-flex;
  align-items: center;
  gap: 6px;
  color: var(--blue);
  text-decoration: none;
  font-size: 14px;
  font-weight: 500;
  margin-bottom: 24px;
}

.back-link:hover { text-decoration: underline; }
</style>
</head>
<body>

<header class="header">
  <div class="header-left">
    <a class="logo" href="/">
      <div class="logo-icon">
        <svg viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <ellipse cx="12" cy="5" rx="9" ry="3"/><path d="M3 5V19A9 3 0 0 0 21 19V5"/><path d="M3 12A9 3 0 0 0 21 12"/>
        </svg>
      </div>
      <span class="logo-text">QueryTorque</span>
    </a>
    <div class="header-sep"></div>
    <span class="header-title">Help &amp; Glossary</span>
  </div>
</header>

<div class="main">

<a class="back-link" href="/">&larr; Back to Dashboard</a>

<h1>Fleet C2 Help</h1>
<p class="subtitle">Everything you need to know about the Fleet Command Centre dashboard.</p>

<nav class="toc">
  <div class="toc-title">Contents</div>
  <a href="#getting-started">1. Getting Started</a>
  <a href="#four-tabs">2. The Four Tabs</a>
  <a href="#glossary">3. Glossary</a>
  <a href="#config-reference">4. Configuration Reference</a>
  <a href="#folder-structure">5. Folder Structure</a>
  <a href="#output">6. Output &amp; Results</a>
</nav>

<!-- ═══════════════════════════════════════════════════════════
     1. GETTING STARTED
     ═══════════════════════════════════════════════════════════ -->
<h2 id="getting-started">1. Getting Started</h2>

<h3>Prerequisites</h3>
<ul>
  <li>Python 3.10+</li>
  <li>DuckDB or PostgreSQL database with benchmark data loaded (e.g. TPC-DS, DSB)</li>
  <li>An LLM API key (DeepSeek, OpenAI, or Anthropic)</li>
</ul>

<h3>Environment</h3>
<p>Create a <code>.env</code> file in the project root with your LLM configuration:</p>
<pre><code>QT_LLM_PROVIDER=deepseek
QT_LLM_MODEL=deepseek-reasoner
QT_DEEPSEEK_API_KEY=sk-...
</code></pre>
<p>All environment variables use the <code>QT_</code> prefix.</p>

<h3>Benchmark Configuration</h3>
<p>Each benchmark lives in a folder under <code>qt_sql/benchmarks/</code> with a <code>config.json</code> file specifying the database connection, engine, and tuning parameters. See the <a href="#config-reference">Configuration Reference</a> for all fields.</p>

<h3>Launch</h3>
<pre><code>qt run &lt;benchmark&gt; --mode fleet --live</code></pre>
<p>This starts the fleet pipeline with a live web dashboard. Your browser will open to <code>http://127.0.0.1:8765</code> automatically.</p>

<div class="info-card">
  The fleet pipeline follows this sequence: survey (baseline timing) &rarr; triage (bucket assignment) &rarr; browser opens &rarr; you approve &rarr; execution (parallel optimization) &rarr; done (scorecard).
</div>

<!-- ═══════════════════════════════════════════════════════════
     2. THE FOUR TABS
     ═══════════════════════════════════════════════════════════ -->
<h2 id="four-tabs">2. The Four Tabs</h2>

<h3><span class="tab-badge triage">TRIAGE</span> Workload Analysis</h3>
<p>The first screen you see. All queries are displayed sorted by estimated impact, with each assigned to a <strong>bucket</strong> (HIGH / MEDIUM / LOW / SKIP) based on baseline runtime. Review the assignments, then click <strong>Approve</strong> to start optimization.</p>
<p>Columns shown: query ID, baseline runtime, bucket, overlap %, estimated annual cost, confidence, and matched transforms.</p>

<h3><span class="tab-badge exec">EXECUTION</span> Live Monitoring</h3>
<p>Once approved, queries are optimized in parallel (default: 4 concurrent). The progress strip at the top shows running totals of WIN / IMPROVED / NEUTRAL / REGRESSION / ERROR counts. Each row updates in real time as workers produce candidates and benchmarks complete.</p>
<p>The event log at the bottom streams every significant event (candidate produced, benchmark started, validation result, etc.).</p>

<h3><span class="tab-badge done">DONE</span> Final Scorecard</h3>
<p>After all queries finish, the Done tab shows the final scorecard: total savings, per-query verdicts, and the best rewrite SQL for each winner. Queries are sorted by speedup descending.</p>

<h3><span class="tab-badge editor">EDITOR</span> Manual Optimization</h3>
<p>A SQL workbench for ad-hoc optimization. Select a query, edit its SQL, then fire a <strong>Beam</strong> (multi-iteration with snipe refinement) or <strong>Strike</strong> (single iteration, no snipe). The split pane shows original SQL on the left and the best rewrite on the right.</p>
<p>Use the Editor tab to re-optimize specific queries, try different strategies, or experiment with SQL you wrote yourself.</p>

<!-- ═══════════════════════════════════════════════════════════
     3. GLOSSARY
     ═══════════════════════════════════════════════════════════ -->
<h2 id="glossary">3. Glossary</h2>

<h3>Buckets &amp; Rounds</h3>
<table class="glossary-table">
  <thead><tr><th>Term</th><th>Definition</th></tr></thead>
  <tbody>
    <tr>
      <td>Bucket</td>
      <td>Impact tier based on baseline runtime. <strong>HIGH</strong> &ge; 10s, <strong>MEDIUM</strong> 1&ndash;10s, <strong>LOW</strong> 100ms&ndash;1s, <strong>SKIP</strong> &lt; 100ms. Higher buckets get more optimization rounds.</td>
    </tr>
    <tr>
      <td>Rounds</td>
      <td>Optimization iterations per query. HIGH = 5, MEDIUM = 3, LOW = 1, SKIP = 0 (skipped entirely).</td>
    </tr>
  </tbody>
</table>

<h3>Verdicts &amp; Speedup</h3>
<table class="glossary-table">
  <thead><tr><th>Term</th><th>Definition</th></tr></thead>
  <tbody>
    <tr>
      <td>Speedup</td>
      <td>Ratio of original runtime to optimized runtime. A 2.0x speedup means the rewrite runs twice as fast.</td>
    </tr>
    <tr>
      <td><span class="status-badge win">WIN</span></td>
      <td>Speedup &ge; 1.10x. Meaningful, validated improvement.</td>
    </tr>
    <tr>
      <td><span class="status-badge improved">IMPROVED</span></td>
      <td>Speedup 1.05x&ndash;1.10x. Marginal improvement detected.</td>
    </tr>
    <tr>
      <td><span class="status-badge neutral">NEUTRAL</span></td>
      <td>Speedup 0.95x&ndash;1.05x. No significant difference from original.</td>
    </tr>
    <tr>
      <td><span class="status-badge regression">REGRESSION</span></td>
      <td>Speedup &lt; 0.95x. The rewrite is slower than the original. These are discarded.</td>
    </tr>
    <tr>
      <td><span class="status-badge error">ERROR</span></td>
      <td>The optimization attempt failed (syntax error, timeout, or execution error).</td>
    </tr>
  </tbody>
</table>

<h3>Triage Metrics</h3>
<table class="glossary-table">
  <thead><tr><th>Term</th><th>Definition</th></tr></thead>
  <tbody>
    <tr>
      <td>Overlap</td>
      <td>Percentage (0&ndash;100%) of a query's SQL structure that matches known optimization patterns. Higher overlap means the system has more prior knowledge to draw from.</td>
    </tr>
    <tr>
      <td>Confidence</td>
      <td>Visual 3-bar indicator based on overlap strength and evidence from prior optimizations.</td>
    </tr>
    <tr>
      <td>Q-error</td>
      <td>Cardinality estimation error ratio. Measures how far off the database optimizer's row-count prediction was. Higher values indicate worse estimates, which often signal optimization opportunity.</td>
    </tr>
    <tr>
      <td>Q-error Severity</td>
      <td>Color-coded scale: <strong>S1</strong> (red, severe) through <strong>S5</strong> (green, excellent). S1&ndash;S2 queries often have the biggest optimization potential.</td>
    </tr>
    <tr>
      <td>Est. Annual Cost</td>
      <td>Projected yearly cost of running this query at its current frequency: <code>runtime_ms &times; daily_frequency &times; 365</code>.</td>
    </tr>
    <tr>
      <td>Annualised Savings</td>
      <td>Dollar value saved per year by applying the optimization: <code>(original_ms - rewrite_ms) &times; frequency &times; 365</code>.</td>
    </tr>
  </tbody>
</table>

<h3>Transforms &amp; Families</h3>
<table class="glossary-table">
  <thead><tr><th>Term</th><th>Definition</th></tr></thead>
  <tbody>
    <tr>
      <td>Transform</td>
      <td>A named SQL optimization technique (e.g., <code>or_to_union</code>, <code>decorrelate</code>, <code>date_cte_isolate</code>). Each transform has a known track record of speedups on specific query patterns.</td>
    </tr>
    <tr>
      <td>Family A</td>
      <td><strong>Early Filtering</strong> &mdash; pushdown predicates, prune scans early.</td>
    </tr>
    <tr>
      <td>Family B</td>
      <td><strong>Decorrelation</strong> &mdash; convert correlated subqueries to joins.</td>
    </tr>
    <tr>
      <td>Family C</td>
      <td><strong>Aggregation</strong> &mdash; restructure GROUP BY / window functions.</td>
    </tr>
    <tr>
      <td>Family D</td>
      <td><strong>Set Operations</strong> &mdash; OR decomposition, UNION/INTERSECT rewrites.</td>
    </tr>
    <tr>
      <td>Family E</td>
      <td><strong>Materialization</strong> &mdash; CTE materialization, temp table strategies.</td>
    </tr>
    <tr>
      <td>Family F</td>
      <td><strong>Join Transform</strong> &mdash; join reordering, semi-join conversion.</td>
    </tr>
    <tr>
      <td>Gap</td>
      <td>A known optimizer weakness in the target engine that a transform exploits (e.g., <code>CROSS_CTE_PREDICATE_BLINDNESS</code>).</td>
    </tr>
  </tbody>
</table>

<h3>Execution &amp; Validation</h3>
<table class="glossary-table">
  <thead><tr><th>Term</th><th>Definition</th></tr></thead>
  <tbody>
    <tr>
      <td>Worker (W1&ndash;W4)</td>
      <td>Four parallel LLM processes, each with a different optimization strategy. They independently produce candidate rewrites.</td>
    </tr>
    <tr>
      <td>Race</td>
      <td>Parallel benchmark method: the original query + 4 candidates all run simultaneously on separate connections. Ensures fair comparison under identical system conditions.</td>
    </tr>
    <tr>
      <td>Beam</td>
      <td>Multi-iteration optimization loop. Analyst &rarr; 4 workers &rarr; benchmark &rarr; snipe &rarr; repeat. Used for thorough optimization.</td>
    </tr>
    <tr>
      <td>Strike</td>
      <td>Single-iteration optimization. One round, no snipe refinement. Faster but less thorough.</td>
    </tr>
    <tr>
      <td>Snipe</td>
      <td>Follow-up LLM pass that sees all prior iteration results (timings, EXPLAIN plans, failures) and produces a refined candidate.</td>
    </tr>
    <tr>
      <td>Semantic Validation</td>
      <td>Pre-benchmark correctness check. Runs the rewrite on a 2% sample of the data and compares row counts and values against the original. Catches semantic errors before expensive benchmarking.</td>
    </tr>
    <tr>
      <td>Equivalence Check</td>
      <td>Full-dataset correctness gate. Compares row count and MD5 checksum of the rewrite's result set against the original to ensure they produce identical output.</td>
    </tr>
    <tr>
      <td>Concurrency</td>
      <td>Number of queries being optimized in parallel (default: 4). Controls system load during execution.</td>
    </tr>
  </tbody>
</table>

<!-- ═══════════════════════════════════════════════════════════
     4. CONFIGURATION REFERENCE
     ═══════════════════════════════════════════════════════════ -->
<h2 id="config-reference">4. Configuration Reference</h2>
<p>These fields are set in the benchmark's <code>config.json</code> file.</p>

<h3>Database Connection</h3>
<table class="config-table">
  <thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead>
  <tbody>
    <tr><td>engine</td><td>str</td><td>&mdash;</td><td>Database engine: <code>duckdb</code>, <code>postgresql</code>, or <code>snowflake</code></td></tr>
    <tr><td>db_path</td><td>str</td><td>&mdash;</td><td>Path to DuckDB database file</td></tr>
    <tr><td>dsn</td><td>str</td><td>&mdash;</td><td>Connection string for PostgreSQL or Snowflake</td></tr>
    <tr><td>benchmark_dsn</td><td>str</td><td>&mdash;</td><td>Separate connection for benchmarking (avoids interference)</td></tr>
  </tbody>
</table>

<h3>Benchmark Parameters</h3>
<table class="config-table">
  <thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead>
  <tbody>
    <tr><td>scale_factor</td><td>int</td><td>10</td><td>TPC-DS / DSB scale factor</td></tr>
    <tr><td>n_queries</td><td>int</td><td>99</td><td>Number of queries in benchmark</td></tr>
    <tr><td>timeout_seconds</td><td>int</td><td>300</td><td>Max execution time per query (seconds)</td></tr>
  </tbody>
</table>

<h3>Validation</h3>
<table class="config-table">
  <thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead>
  <tbody>
    <tr><td>validation_method</td><td>str</td><td>race</td><td>Benchmark method: <code>race</code> (parallel) or <code>sequential</code> (3-run)</td></tr>
    <tr><td>race_min_runtime_ms</td><td>int</td><td>2000</td><td>Minimum original runtime to use race validation</td></tr>
    <tr><td>race_min_margin</td><td>float</td><td>0.05</td><td>Minimum speedup margin to declare a race winner (5%)</td></tr>
    <tr><td>semantic_validation_enabled</td><td>bool</td><td>true</td><td>Enable 2%-sample pre-benchmark correctness check</td></tr>
    <tr><td>semantic_sample_pct</td><td>float</td><td>2.0</td><td>TABLESAMPLE percentage for semantic validation</td></tr>
    <tr><td>semantic_timeout_ms</td><td>int</td><td>30000</td><td>Max execution time per sample query</td></tr>
  </tbody>
</table>

<h3>Optimization</h3>
<table class="config-table">
  <thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead>
  <tbody>
    <tr><td>workers_state_0</td><td>int</td><td>4</td><td>Number of parallel workers in first iteration</td></tr>
    <tr><td>workers_state_n</td><td>int</td><td>1</td><td>Number of workers in subsequent iterations (snipe)</td></tr>
    <tr><td>promote_threshold</td><td>float</td><td>1.05</td><td>Minimum speedup ratio to promote a candidate</td></tr>
  </tbody>
</table>

<!-- ═══════════════════════════════════════════════════════════
     5. FOLDER STRUCTURE
     ═══════════════════════════════════════════════════════════ -->
<h2 id="folder-structure">5. Folder Structure</h2>
<pre><code>benchmarks/&lt;name&gt;/
&#9500;&#9472;&#9472; config.json            # Database + benchmark configuration
&#9500;&#9472;&#9472; queries/               # SQL files (one per query)
&#9500;&#9472;&#9472; explains/              # EXPLAIN ANALYZE results (JSON)
&#9500;&#9472;&#9472; classifications.json   # Pre-computed AST classifications
&#9492;&#9472;&#9472; beam_sessions/         # Output: per-query session logs
    &#9492;&#9472;&#9472; &lt;query_id&gt;_&lt;timestamp&gt;/
        &#9500;&#9472;&#9472; metadata.json
        &#9500;&#9472;&#9472; iter0_analyst_prompt.txt
        &#9500;&#9472;&#9472; iter0_analyst_response.txt
        &#9492;&#9472;&#9472; iter0_result.txt
</code></pre>

<!-- ═══════════════════════════════════════════════════════════
     6. OUTPUT & RESULTS
     ═══════════════════════════════════════════════════════════ -->
<h2 id="output">6. Output &amp; Results</h2>

<h3>Session Logs</h3>
<p>Each optimization attempt creates a timestamped folder under <code>beam_sessions/</code> containing the full prompt/response trace, benchmark timings, and final verdict. Use these for debugging or auditing.</p>

<h3>Using Optimized SQL</h3>
<p>Winning rewrites are saved in the session's <code>metadata.json</code> under the <code>best_sql</code> field. Copy the SQL into your application or query scheduler to realize the speedup in production.</p>

<h3>Validation Rules</h3>
<p>All reported speedups are validated using one of two methods:</p>
<ul>
  <li><strong>Race</strong>: Original + candidates run simultaneously. Winner must beat original by &ge; 5% with matching row counts.</li>
  <li><strong>Sequential 5x trimmed mean</strong>: 5 runs, discard min/max, average remaining 3. Used when original runtime is under 2 seconds.</li>
</ul>
<p>Single-run comparisons are never used for final reporting.</p>

</div>
</body>
</html>
