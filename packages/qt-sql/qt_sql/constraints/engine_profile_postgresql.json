{
  "version_tested": "14.3+",
  "profile_type": "engine_profile",
  "briefing_note": "Field intelligence from 53 DSB queries at SF5-SF10. PostgreSQL has bitmap index scans, JIT compilation, and aggressive CTE materialization. Techniques that work on DuckDB often regress here.",
  "strengths": [
    {
      "id": "BITMAP_OR_SCAN",
      "summary": "Multi-branch OR conditions on indexed columns handled via BitmapOr \u2014 single scan with bitmap combination.",
      "implication": "NEVER split OR conditions into UNION ALL. 0.21x and 0.26x observed."
    },
    {
      "id": "SEMI_JOIN_EXISTS",
      "summary": "EXISTS/NOT EXISTS uses semi-join with early termination.",
      "implication": "NEVER convert EXISTS to IN/NOT IN or materialized CTEs. 0.50x, 0.75x observed."
    },
    {
      "id": "INNER_JOIN_REORDERING",
      "summary": "Freely reorders INNER JOINs based on estimated selectivity.",
      "implication": "Don't restructure INNER JOIN orders. Focus on LEFT JOIN blocking or comma-join confusion."
    },
    {
      "id": "INDEX_ONLY_SCAN",
      "summary": "Reads only index when covering all requested columns.",
      "implication": "Small dimension lookups (<10K rows) may not need CTEs."
    },
    {
      "id": "PARALLEL_QUERY_EXECUTION",
      "summary": "Parallelizes large scans and aggregations across worker processes.",
      "implication": "CTEs may reduce parallelism \u2014 CTE materialization is single-threaded."
    },
    {
      "id": "JIT_COMPILATION",
      "summary": "JIT-compiles complex expressions for long-running queries (>100ms).",
      "implication": "Complex WHERE expressions have low per-row overhead due to JIT."
    }
  ],
  "gaps": [
    {
      "id": "COMMA_JOIN_WEAKNESS",
      "priority": "HIGH",
      "goal": "ARM_THE_OPTIMIZER",
      "detect": "FROM t1, t2, t3 WHERE t1.key = t2.key (comma joins, no explicit JOIN). Poor row estimates in EXPLAIN.",
      "gates": "Multiple tables in comma-separated FROM with equi-join predicates. Dimension filters available. 1-2 fact tables only. Max 3-4 dimension CTEs. Stop if all JOINs already explicit.",
      "what": "Implicit comma-separated FROM tables treated as cross products initially. Cost model significantly weaker on comma-joins.",
      "why": "Planner's join search space less constrained with comma-joins. Explicit JOINs provide structural hints.",
      "opportunity": "Convert comma-joins to explicit JOIN...ON syntax. Best when combined with date_cte_isolate.",
      "what_worked": [
        "3.32x \u2014 comma-joins to explicit JOINs + date CTE",
        "2.28x \u2014 same pattern on star schema",
        "1.14x \u2014 JOIN conversion alone"
      ],
      "what_didnt_work": [],
      "field_notes": [
        "Most reliable PG optimization. 5+ comma-separated tables is the sweet spot.",
        "Win usually comes from explicit JOINs + CTE together, not CTE alone."
      ]
    },
    {
      "id": "CORRELATED_SUBQUERY_PARALYSIS",
      "priority": "HIGH",
      "goal": "SETS_OVER_LOOPS",
      "detect": "Nested loop in EXPLAIN, inner re-executes aggregate per outer row. SQL: WHERE col > (SELECT AGG FROM ... WHERE outer.key = inner.key). Hash join on correlation key \u2192 already decorrelated \u2192 STOP.",
      "gates": "Correlated scalar subquery with aggregate. NOT EXISTS: NEVER decorrelate (0.50x). Inner = outer table \u2192 shared CTE. ALWAYS use AS MATERIALIZED. 1-2 fact tables safe, 3+ \u2192 STOP.",
      "what": "Cannot decorrelate complex correlated subqueries. Nested-loop with repeated evaluation.",
      "why": "Same limitation as DuckDB \u2014 PG does basic decorrelation for IN/EXISTS but fails on complex aggregate correlations.",
      "opportunity": "Convert correlated WHERE to explicit CTE with GROUP BY + JOIN.",
      "what_worked": [
        "4428x \u2014 timeout recovery, unbounded correlated \u2192 explicit JOIN",
        "391x \u2014 same pattern, timeout to sub-second"
      ],
      "what_didnt_work": [
        "0.51x \u2014 multi-fact join lock",
        "0.75x \u2014 EXISTS materialized"
      ],
      "field_notes": [
        "HIGHEST IMPACT pathology. 9 of 31 wins including 8044x, 1465x, 439x.",
        "Queries that time out (>10s) \u2014 check for correlated scalar subqueries first.",
        "MUST preserve all WHERE filters. ALWAYS use AS MATERIALIZED."
      ]
    },
    {
      "id": "NON_EQUI_JOIN_INPUT_BLINDNESS",
      "priority": "HIGH",
      "goal": "MINIMIZE_ROWS_TOUCHED",
      "detect": "Expensive non-equi join (BETWEEN, <, >) with large inputs on both sides. Neither side filtered.",
      "gates": "Non-equi join predicate exists. Both inputs > 10K rows. At least one side has selective dimension filter.",
      "what": "Cannot pre-filter fact tables before non-equi join operations. Non-equi joins fall back to nested-loop O(N*M).",
      "why": "Hash joins require equi-conditions. Optimizer cannot recognize that reducing N or M via pre-filtering would reduce cost.",
      "opportunity": "Reduce fact table input size via filtered CTE before the non-equi join.",
      "what_worked": [
        "2.68x \u2014 pre-filtered catalog_sales by wholesale_cost range before non-equi join"
      ],
      "what_didnt_work": [
        "0.79x \u2014 loose UNION/OR superset filter, CTE fence blocked pushdown"
      ],
      "field_notes": [
        "ZERO REGRESSIONS with tight filters. Loose superset filters harmful.",
        "Only pre-filter when one side is large fact table. Small dimensions (<10K) don't benefit."
      ]
    },
    {
      "id": "CTE_MATERIALIZATION_FENCE",
      "priority": "MEDIUM",
      "goal": "ARM_THE_OPTIMIZER",
      "detect": "Large CTE + small post-filter. Multi-referenced CTE that blocks predicate pushdown.",
      "gates": "NEVER duplicate CTE body with 5+ table joins. Do NOT force AS MATERIALIZED on small dims. CTE + EXISTS = disaster. CTE + INTERSECT/EXCEPT = harmful.",
      "what": "CTE materialization creates hard optimization fence \u2014 no predicate pushdown from outer query into CTE.",
      "why": "CTE computed and stored before outer query executes. Outer WHERE cannot reach into CTE.",
      "opportunity": "Materialize STRATEGICALLY: only when CTE is expensive and reused. Avoid fencing single-use cases.",
      "what_worked": [
        "1.95x \u2014 strategic materialization prevented redundant fact scan multiplication"
      ],
      "what_didnt_work": [
        "0.74x \u2014 CTE fence blocked predicate pushdown",
        "0.77x \u2014 date_cte_isolate fence blocked INTERSECT optimization",
        "0.65x \u2014 duplicated 18-table CTE body to push filters inside"
      ],
      "field_notes": [
        "NEVER duplicate a CTE body to push a filter inside. Filter the materialized result with WHERE.",
        "Write plain CTEs: 'name AS (SELECT ...)'. PG auto-materializes when beneficial."
      ]
    },
    {
      "id": "CROSS_CTE_PREDICATE_BLINDNESS",
      "priority": "MEDIUM",
      "goal": "SMALLEST_SET_FIRST",
      "detect": "Sequential scan on dimension table without index condition. Late filter after large scan/join.",
      "gates": "Convert comma-joins simultaneously \u2014 CTE alone often insufficient. No INTERSECT/EXCEPT queries. Baseline > 100ms.",
      "what": "Same gap as DuckDB but WORSE due to CTE materialization fence.",
      "why": "Even single-reference CTEs may be materialized. No data lineage tracing through CTE boundaries.",
      "opportunity": "Pre-filter into CTE definition. But be more cautious than on DuckDB.",
      "what_worked": [
        "3.32x \u2014 date filter + comma-join conversion (combo is key)",
        "2.28x \u2014 date CTE with explicit JOIN"
      ],
      "what_didnt_work": [
        "0.97x \u2014 won at SF5 (9.62x) but neutral at SF10",
        "0.55x \u2014 over-decomposed already-efficient query"
      ],
      "field_notes": [
        "Always convert comma-joins to explicit JOINs simultaneously.",
        "Validate at target scale \u2014 SF5 wins don't reliably predict SF10."
      ]
    }
  ],
  "set_local_config_intel": {
    "briefing_note": "Field intelligence from 52 DSB queries at SF10 (PG 14.3). 25 config wins, 3-race validated. Config tuning is ADDITIVE to SQL rewrite. CRITICAL: EXPLAIN cost gaps do NOT predict runtime gains \u2014 6 false positives caught.",
    "rules": [
      {
        "id": "MERGE_JOIN_DISABLE",
        "trigger": "EXPLAIN shows Merge Join with Sort node below it on inputs > 10K rows",
        "config": "/*+ Set(enable_mergejoin off) */ or SET LOCAL enable_mergejoin = 'off'",
        "evidence": "6 wins: +82.5%, +68.2%, +66.9%, +60.2%, +17.1%, +8.6%. Highest impact single hint.",
        "risk": "LOW when Sort+MJ visible. Do NOT disable on pre-sorted data."
      },
      {
        "id": "SSD_COST_MODEL_FIX",
        "trigger": "Seq Scan on fact table despite btree index on join/filter columns",
        "config": "SET LOCAL random_page_cost = '1.1'; SET LOCAL effective_cache_size = '48GB'",
        "evidence": "6 wins: +89.0%, +83.2%, +73.4%, +82.5%, +52.5%, +46.0%. Rescued 3 rewrite regressions. Nonlinear interaction.",
        "risk": "LOW on SSD. Zero regressions."
      },
      {
        "id": "PARALLEL_COST_REDUCTION",
        "trigger": "Large Seq Scan (>100K rows) without Gather/Parallel node, query > 500ms",
        "config": "SET LOCAL max_parallel_workers_per_gather = '4'; SET LOCAL parallel_setup_cost = '100'; SET LOCAL parallel_tuple_cost = '0.001'",
        "evidence": "5 standalone wins: +28.2%, +17.4%, +12.5%, +7.0%, +6.2%. Also in 10+ combo wins.",
        "risk": "MEDIUM. 7.34x REGRESSION on 244ms query. NEVER < 500ms. par4-alone -15.3% \u2014 must include work_mem."
      },
      {
        "id": "SORT_SPILL_WORK_MEM",
        "trigger": "Hash Batches > 1 or Sort Space Type = 'Disk'",
        "config": "work_mem sized by op count: \u22642 ops \u2192 512MB, 3-5 \u2192 256MB, 6+ \u2192 128MB",
        "evidence": "4 wins: +41.5%, +17.9%, +16.0%, +11.4%. Often needs par4.",
        "risk": "LOW. Per-operation \u2014 count sort+hash ops."
      },
      {
        "id": "NESTED_LOOP_DISABLE",
        "trigger": "Nested Loop with both inputs > 10K rows and equi-join condition exists",
        "config": "/*+ Set(enable_nestloop off) */ or SET LOCAL enable_nestloop = 'off'",
        "evidence": "3 wins: +81.3%, +57.5%, +42.5%.",
        "risk": "HIGH. -1454% regression. NEVER on correlated subqueries."
      },
      {
        "id": "SORT_DISABLE",
        "trigger": "Sort node on index-ordered data or where hash aggregation is viable",
        "config": "SET LOCAL enable_sort = 'off'",
        "evidence": "2 wins: +68.2%, +4.7%. High variance (3.2-7.7%).",
        "risk": "MEDIUM. Forces hash-based execution."
      },
      {
        "id": "EXPLAIN_FALSE_POSITIVE_WARNING",
        "trigger": "ALWAYS \u2014 applies to all config tuning decisions",
        "config": "3-race validate ALL config changes",
        "evidence": "6 false positives: geqo_off (+38% EXPLAIN \u2192 -254% runtime), 12 configs (+84% \u2192 0%), 10 hints (+15% \u2192 0%), par4 (+25% \u2192 -15.3%).",
        "risk": "CRITICAL. EXPLAIN cost gaps measure plan cost, not runtime."
      }
    ],
    "combo_patterns": [
      "rpc+cache (C2) + MJ_off (C1): +82.5%",
      "NL_off (C5) + par4 (C3): +57.5%, +42.5%",
      "wm512 (C4) + par4 (C3): +41.5%, +6.2%",
      "sort_off (C6) + MJ_off (C1): +68.2%",
      "rpc+cache (C2) + par4 (C3): +73.4%, +52.5%"
    ]
  },
  "scale_sensitivity_warning": "PostgreSQL optimizations at SF5 do NOT reliably predict SF10. 7 queries won at SF5, regressed at SF10 (one 9.62x \u2192 0.97x). Always validate at target scale.",
  "dialect": "postgresql"
}
