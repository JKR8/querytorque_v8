{
  "engine": "duckdb",
  "version_tested": "1.1+",
  "profile_type": "engine_profile",
  "briefing_note": "Field intelligence from 88 TPC-DS queries at SF1-SF10. Use it to guide analysis but apply your own judgment — every query is different.",

  "strengths": [
    {
      "id": "INTRA_SCAN_PREDICATE_PUSHDOWN",
      "summary": "Pushes WHERE filters directly into SEQ_SCAN. Single-table predicates are applied at scan time, zero overhead.",
      "implication": "If EXPLAIN shows the filter inside the scan node, do not create a CTE to push it."
    },
    {
      "id": "SAME_COLUMN_OR",
      "summary": "OR on the SAME column handled in a single scan with range checks.",
      "implication": "Never split same-column ORs into UNION ALL. 0.59x and 0.23x observed."
    },
    {
      "id": "HASH_JOIN_SELECTION",
      "summary": "Selects hash joins automatically. Join ordering sound for 2-4 tables.",
      "implication": "Focus on reducing join inputs, not reordering joins."
    },
    {
      "id": "CTE_INLINING",
      "summary": "Single-reference CTEs inlined automatically. Multi-referenced CTEs may be materialized.",
      "implication": "Single-ref CTEs are free — use for clarity. CTE-based strategies are low-cost on DuckDB."
    },
    {
      "id": "COLUMNAR_PROJECTION",
      "summary": "Only referenced columns read. Unused columns have zero I/O cost.",
      "implication": "When creating pre-filter CTEs, only SELECT columns downstream needs."
    },
    {
      "id": "PARALLEL_AGGREGATION",
      "summary": "Scans and aggregations parallelized across threads. PERFECT_HASH_GROUP_BY efficient.",
      "implication": "Restructuring simple aggregation queries rarely helps unless reducing input rows."
    },
    {
      "id": "EXISTS_SEMI_JOIN",
      "summary": "EXISTS/NOT EXISTS uses semi-join with early termination.",
      "implication": "NEVER materialize EXISTS into CTEs. 0.14x and 0.54x from this mistake."
    }
  ],

  "gaps": [
    {
      "id": "CROSS_CTE_PREDICATE_BLINDNESS",
      "priority": "HIGH",
      "goal": "SMALLEST_SET_FIRST",
      "detect": "Row counts flat through CTE chain, sharp drop at late filter. 2+ stage CTE chain + late predicate with columns available earlier.",
      "gates": "Filter ratio >5:1 strong, 2:1-5:1 moderate if baseline >200ms. 1 fact = safe, 2 = careful, 3+ = STOP. ROLLUP/WINDOW downstream: CAUTION. CTE already filtered: skip.",
      "what": "Cannot push predicates from the outer query backward into CTE definitions.",
      "why": "CTEs are planned as independent subplans. The optimizer does not trace data lineage through CTE boundaries.",
      "opportunity": "Move selective predicates INTO the CTE definition. Pre-filter dimensions/facts before materialization.",
      "what_worked": [
        "4.76x — self-joined CTE split into per-month CTEs",
        "4.00x — date filter moved into CTE",
        "3.77x — pre-joined filtered dates with fact table",
        "2.97x — dimension filter applied before LEFT JOIN chain",
        "1.93x — all dimensions pre-filtered into separate CTEs",
        "1.80x — prefetch_fact_join on store_sales with date pre-filter"
      ],
      "what_didnt_work": [
        "0.0076x — cross-joined 3 dim CTEs: Cartesian product",
        "0.50x — 3-way fact join locked optimizer order",
        "0.85x — CTE blocked ROLLUP pushdown",
        "0.71x — over-decomposed already-efficient query"
      ],
      "field_notes": [
        "~35% of all wins exploit this gap. Most productive on star-join queries with late dim filters.",
        "NEVER cross-join 3+ dim CTEs — join each filtered dimension directly to fact table.",
        "Max 2 cascading fact-table CTE chains. Every CTE MUST have a WHERE clause.",
        "Remove dead CTEs when restructuring — orphaned CTEs still get materialized."
      ]
    },
    {
      "id": "REDUNDANT_SCAN_ELIMINATION",
      "priority": "HIGH",
      "goal": "DONT_REPEAT_WORK",
      "detect": "N separate SEQ_SCAN nodes on same table, identical joins, different bucket filters.",
      "gates": "Identical join structure across all subqueries, max 8 branches, COUNT/SUM/AVG/MIN/MAX only (not STDDEV/VARIANCE/PERCENTILE).",
      "what": "Cannot detect when the same fact table is scanned N times with similar filters across subquery boundaries.",
      "why": "Common Subexpression Elimination doesn't cross scalar subquery boundaries.",
      "opportunity": "Consolidate N subqueries into 1 scan with CASE WHEN / FILTER() inside aggregates.",
      "what_worked": [
        "6.28x — 8 time-bucket subqueries consolidated into 1 scan",
        "4.47x — 15 separate scans consolidated into 1 with 5 CASE buckets",
        "2.27x — single_pass_aggregation consolidated channel subqueries"
      ],
      "what_didnt_work": [],
      "field_notes": [
        "ZERO REGRESSIONS. DuckDB supports native FILTER clause: COUNT(*) FILTER (WHERE cond).",
        "~37% of benchmark wins exploit this gap (tied with CROSS_CTE_PREDICATE_BLINDNESS)."
      ]
    },
    {
      "id": "CORRELATED_SUBQUERY_PARALYSIS",
      "priority": "LOW",
      "goal": "SETS_OVER_LOOPS",
      "detect": "Nested loop, inner re-executes aggregate per outer row. If hash join on correlation key → already decorrelated → STOP.",
      "gates": "NEVER decorrelate EXISTS (0.34x, 0.14x — semi-join destroyed). Preserve ALL WHERE filters. Check if outer <1000 rows after Phase 1.",
      "what": "Cannot decorrelate correlated aggregate subqueries into GROUP BY + JOIN.",
      "why": "Decorrelation requires recognizing correlated predicate = GROUP BY + JOIN equivalence.",
      "opportunity": "Convert correlated WHERE to CTE with GROUP BY on the correlation column, then JOIN back.",
      "what_worked": [
        "2.92x — correlated AVG converted to GROUP BY + JOIN"
      ],
      "what_didnt_work": [
        "0.34x — LEFT JOIN was already semi-join",
        "0.71x — already decorrelated"
      ],
      "field_notes": [
        "Only applies to correlated scalar subqueries with aggregates. EXISTS correlation handled by semi-join.",
        "When decorrelating, MUST preserve all WHERE filters from original subquery."
      ]
    },
    {
      "id": "CROSS_COLUMN_OR_DECOMPOSITION",
      "priority": "MEDIUM",
      "goal": "MINIMIZE_ROWS_TOUCHED",
      "detect": "Single scan, OR across DIFFERENT columns, 70%+ rows discarded. CRITICAL: same column in all OR arms → STOP.",
      "gates": "Max 3 branches, cross-column only, no self-join, no nested OR (multiplicative expansion).",
      "what": "Cannot decompose OR conditions spanning different columns into independent targeted scans.",
      "why": "The optimizer evaluates OR as a single filter.",
      "opportunity": "Split cross-column ORs into UNION ALL branches with targeted single-column filters.",
      "what_worked": [
        "6.28x — 8 time-bucket subqueries with distinct hour ranges",
        "3.17x — (zip OR state OR price) split to 3 targeted branches"
      ],
      "what_didnt_work": [
        "0.23x — nested OR expansion (3x3=9 branches = 9 fact scans)",
        "0.59x — same-column OR (engine handles natively)",
        "0.51x — self-join re-executed per UNION branch"
      ],
      "field_notes": [
        "HIGHEST VARIANCE: biggest win (6.28x) and worst regressions (0.23x) both from or_to_union.",
        "Count resulting branches before committing. 6+ branches almost certainly harmful."
      ]
    },
    {
      "id": "LEFT_JOIN_FILTER_ORDER_RIGIDITY",
      "priority": "HIGH",
      "goal": "ARM_THE_OPTIMIZER",
      "detect": "LEFT JOIN + WHERE on right-table column (proves right non-null).",
      "gates": "No CASE WHEN IS NULL / COALESCE on right-table column.",
      "what": "Cannot infer LEFT JOIN → INNER when WHERE eliminates NULLs, and cannot reorder LEFT JOINs.",
      "why": "LEFT JOIN must preserve all left rows. Optimizer can't move dimension filter before LEFT JOIN.",
      "opportunity": "Convert LEFT→INNER when WHERE proves right non-null, or pre-filter dimension into CTE.",
      "what_worked": [
        "3.44x — LEFT→INNER + early filter CTE",
        "2.97x — filtered dimension FIRST, then LEFT JOIN",
        "1.89x — dimension isolation before fact join"
      ],
      "what_didnt_work": [],
      "field_notes": [
        "ZERO REGRESSIONS. Only applies to LEFT JOINs — INNER JOINs freely reordered."
      ]
    },
    {
      "id": "UNION_CTE_SELF_JOIN_DECOMPOSITION",
      "priority": "LOW",
      "goal": "SMALLEST_SET_FIRST",
      "detect": "CTE joined to itself with different WHERE per arm (e.g., period=1 vs period=2).",
      "gates": "2-4 discriminator values, MUST remove original combined CTE after splitting.",
      "what": "UNION ALL CTE self-joined N times — optimizer materializes full UNION once, probes N times discarding most rows.",
      "why": "Cannot recognize each probe only needs a partition of the UNION result.",
      "opportunity": "Split into N separate CTEs (one per discriminator value).",
      "what_worked": [
        "4.76x — self_join_decomposition",
        "2.47x — rollup_to_union_windowing",
        "1.72x avg — union_cte_split"
      ],
      "what_didnt_work": [
        "0.49x — orphaned CTE (double materialization)",
        "0.68x — original CTE kept alongside split"
      ],
      "field_notes": [
        "MUST remove original UNION CTE and redirect all references to split CTEs."
      ]
    },
    {
      "id": "AGGREGATE_BELOW_JOIN_BLINDNESS",
      "priority": "HIGH",
      "goal": "MINIMIZE_ROWS_TOUCHED",
      "detect": "GROUP BY input rows >> distinct keys, aggregate node sits after join.",
      "gates": "GROUP BY keys must be superset of join keys (CORRECTNESS). Reconstruct AVG from SUM/COUNT when pre-aggregating for ROLLUP.",
      "what": "Cannot push GROUP BY below joins when aggregation keys align with join keys.",
      "why": "Optimizer joins first then aggregates, even when pre-aggregating would reduce join input dramatically.",
      "opportunity": "Pre-aggregate fact table by join key BEFORE dimension join.",
      "what_worked": [
        "42.90x — pre-aggregated inventory by item_sk before item dimension join + ROLLUP"
      ],
      "what_didnt_work": [],
      "field_notes": [
        "ZERO REGRESSIONS. Produced single biggest individual win (42.90x). Check for join→GROUP BY in every star-schema query."
      ]
    },
    {
      "id": "INTERSECT_MATERIALIZATION",
      "priority": "LOW",
      "goal": "SETS_OVER_LOOPS",
      "detect": "INTERSECT between 10K+ row result sets.",
      "gates": "Both sides >1K rows.",
      "what": "INTERSECT is implemented as set materialization + comparison, not as semi-join.",
      "why": "Optimizer doesn't recognize EXISTS semi-join is algebraically equivalent and can short-circuit.",
      "opportunity": "Replace INTERSECT with EXISTS semi-join.",
      "what_worked": [
        "2.7x — intersect_to_exists"
      ],
      "what_didnt_work": [],
      "field_notes": [
        "ZERO REGRESSIONS. Related: semi_join_exists (1.67x) for full JOIN where joined columns not in output."
      ]
    },
    {
      "id": "WINDOW_BEFORE_JOIN",
      "priority": "LOW",
      "goal": "MINIMIZE_ROWS_TOUCHED",
      "detect": "N WINDOW nodes inside CTEs, same ORDER BY key, CTEs then joined.",
      "gates": "Not LAG/LEAD (depends on pre-join row order), not ROWS BETWEEN with specific frame.",
      "what": "Cannot defer window computation past a join when partition/ordering is preserved.",
      "why": "Computes window in CTE because that's where SQL places it.",
      "opportunity": "Remove windows from CTEs, compute once on joined result.",
      "what_worked": [
        "1.4x — deferred_window_aggregation"
      ],
      "what_didnt_work": [],
      "field_notes": [
        "ZERO REGRESSIONS. SUM() OVER() naturally skips NULLs — handles FULL OUTER JOIN gaps."
      ]
    },
    {
      "id": "SHARED_SUBEXPRESSION",
      "priority": "LOW",
      "goal": "DONT_REPEAT_WORK",
      "detect": "Identical subtrees with identical costs scanning same tables. HARD STOP: EXISTS/NOT EXISTS → NEVER materialize (0.14x).",
      "gates": "NOT EXISTS, subquery is expensive (joins/aggregates), CTE must have WHERE.",
      "what": "May not CSE identical subqueries across different query branches.",
      "why": "Cost is N× what single execution would be when CSE fails.",
      "opportunity": "Extract shared subexpression into CTE.",
      "what_worked": [
        "1.4x — materialize_cte"
      ],
      "what_didnt_work": [
        "0.14x — EXISTS materialized, semi-join destroyed",
        "0.54x — correlated EXISTS pairs broken"
      ],
      "field_notes": [
        "Semi-join short-circuit destroyed by CTE materialization. NEVER on EXISTS."
      ]
    }
  ]
}
