# PostgreSQL Query Optimization Prompt

You are an expert PostgreSQL query optimizer specializing in analytical workloads. Your task is to rewrite the provided query to achieve better execution performance while preserving exact semantic equivalence.

---

## Input Context

### PostgreSQL Version & Configuration
```
PostgreSQL 15.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 11.3.0, 64-bit
```

**Relevant Settings:**
```
work_mem = 256MB
shared_buffers = 4GB
effective_cache_size = 12GB
random_page_cost = 1.1
effective_io_concurrency = 200
max_parallel_workers_per_gather = 4
enable_partitionwise_join = on
enable_partitionwise_aggregate = on
jit = on
```

---

### Database Schema

```sql
CREATE TABLE store_returns (
    sr_returned_date_sk INTEGER,
    sr_return_time_sk INTEGER,
    sr_item_sk INTEGER NOT NULL,
    sr_customer_sk INTEGER,
    sr_cdemo_sk INTEGER,
    sr_hdemo_sk INTEGER,
    sr_addr_sk INTEGER,
    sr_store_sk INTEGER,
    sr_reason_sk INTEGER,
    sr_ticket_number BIGINT NOT NULL,
    sr_return_quantity INTEGER,
    sr_return_amt DECIMAL(7,2),
    sr_return_tax DECIMAL(7,2),
    sr_return_amt_inc_tax DECIMAL(7,2),
    sr_fee DECIMAL(7,2),
    sr_return_ship_cost DECIMAL(7,2),
    sr_refunded_cash DECIMAL(7,2),
    sr_reversed_charge DECIMAL(7,2),
    sr_store_credit DECIMAL(7,2),
    sr_net_loss DECIMAL(7,2),
    PRIMARY KEY (sr_item_sk, sr_ticket_number)
);
CREATE INDEX sr_date_idx ON store_returns(sr_returned_date_sk);
CREATE INDEX sr_store_idx ON store_returns(sr_store_sk);
CREATE INDEX sr_customer_idx ON store_returns(sr_customer_sk);

CREATE TABLE date_dim (
    d_date_sk INTEGER NOT NULL PRIMARY KEY,
    d_date_id CHAR(16) NOT NULL,
    d_date DATE,
    d_month_seq INTEGER,
    d_week_seq INTEGER,
    d_quarter_seq INTEGER,
    d_year INTEGER,
    d_dow INTEGER,
    d_moy INTEGER,
    d_dom INTEGER,
    d_qoy INTEGER,
    d_fy_year INTEGER,
    d_fy_quarter_seq INTEGER,
    d_fy_week_seq INTEGER,
    d_day_name CHAR(9),
    d_quarter_name CHAR(6),
    d_holiday CHAR(1),
    d_weekend CHAR(1),
    d_following_holiday CHAR(1),
    d_first_dom INTEGER,
    d_last_dom INTEGER,
    d_same_day_ly INTEGER,
    d_same_day_lq INTEGER,
    d_current_day CHAR(1),
    d_current_week CHAR(1),
    d_current_month CHAR(1),
    d_current_quarter CHAR(1),
    d_current_year CHAR(1)
);
CREATE INDEX dd_year_idx ON date_dim(d_year);

CREATE TABLE store (
    s_store_sk INTEGER NOT NULL PRIMARY KEY,
    s_store_id CHAR(16) NOT NULL,
    s_rec_start_date DATE,
    s_rec_end_date DATE,
    s_closed_date_sk INTEGER,
    s_store_name VARCHAR(50),
    s_number_employees INTEGER,
    s_floor_space INTEGER,
    s_hours CHAR(20),
    s_manager VARCHAR(40),
    s_market_id INTEGER,
    s_geography_class VARCHAR(100),
    s_market_desc VARCHAR(100),
    s_market_manager VARCHAR(40),
    s_division_id INTEGER,
    s_division_name VARCHAR(50),
    s_company_id INTEGER,
    s_company_name VARCHAR(50),
    s_street_number VARCHAR(10),
    s_street_name VARCHAR(60),
    s_street_type CHAR(15),
    s_suite_number CHAR(10),
    s_city VARCHAR(60),
    s_county VARCHAR(30),
    s_state CHAR(2),
    s_zip CHAR(10),
    s_country VARCHAR(20),
    s_gmt_offset DECIMAL(5,2),
    s_tax_percentage DECIMAL(5,2)
);
CREATE INDEX s_state_idx ON store(s_state);

CREATE TABLE customer (
    c_customer_sk INTEGER NOT NULL PRIMARY KEY,
    c_customer_id CHAR(16) NOT NULL,
    c_current_cdemo_sk INTEGER,
    c_current_hdemo_sk INTEGER,
    c_current_addr_sk INTEGER,
    c_first_shipto_date_sk INTEGER,
    c_first_sales_date_sk INTEGER,
    c_salutation CHAR(10),
    c_first_name CHAR(20),
    c_last_name CHAR(30),
    c_preferred_cust_flag CHAR(1),
    c_birth_day INTEGER,
    c_birth_month INTEGER,
    c_birth_year INTEGER,
    c_birth_country VARCHAR(20),
    c_login CHAR(13),
    c_email_address CHAR(50),
    c_last_review_date_sk INTEGER
);
```

---

### Table Statistics

```
store_returns: 28,795,080 rows
  sr_returned_date_sk: ndistinct=1823, null_frac=0.0001, correlation=0.92
  sr_store_sk: ndistinct=402, null_frac=0.0001
  sr_customer_sk: ndistinct=1,892,041, null_frac=0.03
  sr_fee: avg_width=6, ndistinct=8721

date_dim: 73,049 rows
  d_date_sk: ndistinct=73049, null_frac=0
  d_year: ndistinct=201, null_frac=0

store: 402 rows
  s_store_sk: ndistinct=402, null_frac=0
  s_state: ndistinct=33, null_frac=0

customer: 2,000,000 rows
  c_customer_sk: ndistinct=2000000, null_frac=0
  c_customer_id: ndistinct=2000000, null_frac=0
```

---

### Original Query

```sql
WITH customer_total_return AS (
    SELECT sr_customer_sk AS ctr_customer_sk,
           sr_store_sk AS ctr_store_sk,
           SUM(SR_FEE) AS ctr_total_return
    FROM store_returns, date_dim
    WHERE sr_returned_date_sk = d_date_sk
      AND d_year = 2000
    GROUP BY sr_customer_sk, sr_store_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1, store, customer
WHERE ctr1.ctr_total_return > (
    SELECT avg(ctr_total_return) * 1.2
    FROM customer_total_return ctr2
    WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk
)
  AND s_store_sk = ctr1.ctr_store_sk
  AND s_state = 'SD'
  AND ctr1.ctr_customer_sk = c_customer_sk
ORDER BY c_customer_id
LIMIT 100
```

---

### Current Execution Plan

```
Limit  (cost=892456.78..892456.81 rows=100 width=17) (actual time=45231.456..45231.512 rows=100 loops=1)
  ->  Sort  (cost=892456.78..892467.89 rows=4444 width=17) (actual time=45231.454..45231.498 rows=100 loops=1)
        Sort Key: c.c_customer_id
        Sort Method: top-N heapsort  Memory: 32kB
        ->  Nested Loop  (cost=445123.45..892234.56 rows=4444 width=17) (actual time=12456.789..45198.234 rows=4521 loops=1)
              ->  Nested Loop  (cost=445122.89..891567.89 rows=4444 width=4) (actual time=12456.123..44987.654 rows=4521 loops=1)
                    ->  Hash Join  (cost=445122.45..567890.12 rows=8888 width=12) (actual time=12455.456..23456.789 rows=9042 loops=1)
                          Hash Cond: (ctr1.ctr_store_sk = s.s_store_sk)
                          ->  CTE Scan on customer_total_return ctr1  (cost=445012.34..456789.01 rows=532120 width=16) (actual time=12345.678..22345.678 rows=532120 loops=1)
                          ->  Hash  (cost=110.00..110.00 rows=8 width=4) (actual time=0.123..0.124 rows=12 loops=1)
                                Buckets: 1024  Batches: 1  Memory Usage: 9kB
                                ->  Seq Scan on store s  (cost=0.00..110.00 rows=8 width=4) (actual time=0.012..0.098 rows=12 loops=1)
                                      Filter: (s_state = 'SD'::bpchar)
                                      Rows Removed by Filter: 390
                    ->  SubPlan 1 (CORRELATED - executes per outer row)
                          ->  Aggregate  (cost=47.89..47.90 rows=1 width=32) (actual time=2.345..2.346 rows=1 loops=9042)
                                ->  CTE Scan on customer_total_return ctr2  (cost=0.00..47.67 rows=88 width=8) (actual time=0.001..2.234 rows=44343 loops=9042)
                                      Filter: (ctr1.ctr_store_sk = ctr_store_sk)
                                      Rows Removed by Filter: 487777
              ->  Index Scan using customer_pkey on customer c  (cost=0.43..0.15 rows=1 width=21) (actual time=0.045..0.046 rows=1 loops=4521)
                    Index Cond: (c_customer_sk = ctr1.ctr_customer_sk)
  CTE customer_total_return
    ->  HashAggregate  (cost=345678.90..445012.34 rows=532120 width=16) (actual time=11234.567..12234.567 rows=532120 loops=1)
          Group Key: store_returns.sr_customer_sk, store_returns.sr_store_sk
          Batches: 1  Memory Usage: 98305kB
          ->  Hash Join  (cost=1823.45..323456.78 rows=2876543 width=10) (actual time=45.678..8765.432 rows=2876543 loops=1)
                Hash Cond: (store_returns.sr_returned_date_sk = date_dim.d_date_sk)
                ->  Seq Scan on store_returns  (cost=0.00..234567.80 rows=28795080 width=14) (actual time=0.012..3456.789 rows=28795080 loops=1)
                ->  Hash  (cost=1811.23..1811.23 rows=365 width=4) (actual time=45.234..45.235 rows=366 loops=1)
                      Buckets: 1024  Batches: 1  Memory Usage: 22kB
                      ->  Seq Scan on date_dim  (cost=0.00..1811.23 rows=365 width=4) (actual time=0.023..44.567 rows=366 loops=1)
                            Filter: (d_year = 2000)
                            Rows Removed by Filter: 72683
Planning Time: 2.345 ms
Execution Time: 45234.567 ms
```

---

## Optimization Analysis Framework

Analyze the query and execution plan systematically:

### Step 1: Identify Performance Bottlenecks

Examine the execution plan for these red flags:
1. **Cardinality misestimates**: rows=X vs actual=Y where ratio > 10x
2. **Nested loop joins on large tables**: Look for "Nested Loop" with high loop counts
3. **Sequential scans on large tables**: When indexes exist but aren't used
4. **Repeated subplan execution**: "SubPlan" nodes with loops >> 1
5. **Spilling to disk**: "Sort Method: external merge" or "Batches: N"
6. **CTE materialization blocking predicate pushdown**: "CTE Scan" without pushed filters

### Step 2: Match Bottlenecks to Rewrite Patterns

Apply these high-impact rewrites in priority order:

#### Pattern A: Correlated Subquery -> JOIN (100-3000x improvement potential)

**Detect**: Scalar subquery in SELECT or correlated subquery in WHERE executed per-row
```sql
-- BEFORE: Executes subquery once per outer row
SELECT a.id, (SELECT SUM(b.val) FROM b WHERE b.aid = a.id) as total
FROM a;

-- AFTER: Single hash/merge join
SELECT a.id, COALESCE(b_agg.total, 0) as total
FROM a
LEFT JOIN (SELECT aid, SUM(val) as total FROM b GROUP BY aid) b_agg
  ON b_agg.aid = a.id;
```

#### Pattern B: NOT IN -> NOT EXISTS (Enables anti-join)

**Detect**: "Seq Scan" or "Index Scan" inside "SubPlan" for NOT IN check
```sql
-- BEFORE: Cannot use anti-join due to NULL semantics
SELECT * FROM a WHERE a.x NOT IN (SELECT b.x FROM b);

-- AFTER: Enables hash/merge anti-join
SELECT * FROM a WHERE NOT EXISTS (SELECT 1 FROM b WHERE b.x = a.x);
```

#### Pattern C: IN Subquery -> EXISTS or JOIN

**Detect**: Large "SubPlan" result being materialized for IN check
```sql
-- BEFORE: Materializes entire subquery result
SELECT * FROM a WHERE a.x IN (SELECT b.x FROM b WHERE b.flag = true);

-- AFTER (semi-join):
SELECT * FROM a WHERE EXISTS (SELECT 1 FROM b WHERE b.x = a.x AND b.flag = true);

-- AFTER (explicit join, if duplicates acceptable or known unique):
SELECT DISTINCT a.* FROM a JOIN b ON a.x = b.x WHERE b.flag = true;
```

#### Pattern D: Correlated Comparison -> Window Function

**Detect**: Correlated subquery computing aggregate for comparison (avg, max, etc.)
```sql
-- BEFORE: Recomputes average for each row
SELECT * FROM sales s1
WHERE s1.amount > (SELECT AVG(amount) FROM sales s2 WHERE s2.region = s1.region);

-- AFTER: Single-pass window computation
SELECT * FROM (
  SELECT *, AVG(amount) OVER (PARTITION BY region) as region_avg
  FROM sales
) sub WHERE amount > region_avg;
```

#### Pattern E: CTE Materialization Control (PostgreSQL 12+)

**Detect**: CTE scan without predicate pushdown when predicates exist in outer query
```sql
-- BEFORE: Full scan of CTE, then filter
WITH data AS (SELECT * FROM large_table)
SELECT * FROM data WHERE id = 100;

-- AFTER: Force inlining for predicate pushdown
WITH data AS NOT MATERIALIZED (SELECT * FROM large_table)
SELECT * FROM data WHERE id = 100;

-- Or simply inline:
SELECT * FROM (SELECT * FROM large_table) data WHERE id = 100;
```

**Conversely**, force materialization when CTE is expensive and referenced multiple times:
```sql
WITH expensive AS MATERIALIZED (
  SELECT id, complex_function(data) as result FROM source
)
SELECT * FROM expensive e1 JOIN expensive e2 ON e1.result = e2.result;
```

#### Pattern F: Join Order Optimization

**Detect**: Nested loops or hash joins processing rows in suboptimal order (large intermediate results early)
```sql
-- Force specific join order when optimizer chooses poorly:
SET LOCAL join_collapse_limit = 1;

-- Explicit order: filter dimensions first, then join to facts
SELECT *
FROM (small_dimension d1
      JOIN fact_table f ON d1.sk = f.d1_sk)
JOIN small_dimension d2 ON f.d2_sk = d2.sk
WHERE d1.filter_col = 'value';
```

#### Pattern G: UNION ALL -> Single Scan with CASE

**Detect**: Multiple sequential scans of same table with different filters
```sql
-- BEFORE: Two full scans
SELECT 'type_a' as type, col1, col2 FROM t WHERE flag = 'A'
UNION ALL
SELECT 'type_b' as type, col1, col2 FROM t WHERE flag = 'B';

-- AFTER: Single scan
SELECT CASE flag WHEN 'A' THEN 'type_a' WHEN 'B' THEN 'type_b' END as type,
       col1, col2
FROM t WHERE flag IN ('A', 'B');
```

#### Pattern H: DISTINCT Elimination

**Detect**: DISTINCT on columns that are already unique due to joins/keys
```sql
-- BEFORE: Unnecessary sort/hash for uniqueness
SELECT DISTINCT a.id, a.name FROM a JOIN b ON a.id = b.aid;

-- AFTER: If a.id is PRIMARY KEY and b.aid has unique constraint on a.id
SELECT a.id, a.name FROM a WHERE EXISTS (SELECT 1 FROM b WHERE b.aid = a.id);
```

#### Pattern I: Predicate Pushdown Through Outer Joins

**Detect**: Filter on nullable side applied after outer join
```sql
-- BEFORE: Filter cannot push through LEFT JOIN
SELECT * FROM a LEFT JOIN b ON a.id = b.aid WHERE b.col = 'x';

-- AFTER: If filter implies non-NULL, convert to INNER JOIN
SELECT * FROM a INNER JOIN b ON a.id = b.aid WHERE b.col = 'x';
```

### Step 3: Verify Semantic Equivalence

For each rewrite, verify:
1. **NULL handling**: Does the rewrite preserve NULL behavior?
   - NOT IN vs NOT EXISTS have different NULL semantics
   - LEFT JOIN + filter may convert to INNER JOIN semantics
2. **Duplicate handling**: Does the rewrite preserve row multiplicity?
   - Converting IN to JOIN may introduce duplicates
   - Removing DISTINCT requires uniqueness guarantee
3. **Aggregate semantics**: Are empty groups handled correctly?
   - COALESCE needed when converting correlated aggregates to LEFT JOINs

---

## Output Format

Output ONLY the complete optimized SQL query. No explanation. No analysis. Just SQL.

Example output format:
```sql
WITH cte1 AS (
  SELECT ...
)
SELECT ...
FROM cte1
...
```

---

## Constraints

1. **Preserve exact semantics** - The rewritten query must return identical results for all possible data states
2. **No schema changes required** - Rewrites should work with existing schema
3. **Standard SQL preferred** - Avoid PostgreSQL-specific syntax unless necessary for the optimization

---

## Your Optimized Query

```sql
