# Sample Complete Prompt for Q1 (TPC-DS Query 1)
#
# This file shows what the LLM actually receives when processing Q1.
# It demonstrates how templates, examples, and DAG context are combined.
#
# Generated for documentation purposes.

================================================================================
EXAMPLES SECTION (from decorrelate.json - ML selected)
================================================================================

## Verified Example: Decorrelate Subquery (2.92x speedup on Q1)

**Pattern**: Convert correlated subquery to separate CTE with GROUP BY, then JOIN

**Input (problematic pattern):**
```
[customer_total_return] CORRELATED:
SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(SR_FEE) AS ctr_total_return
FROM store_returns, date_dim
WHERE sr_returned_date_sk = d_date_sk AND d_year = 2000
GROUP BY sr_customer_sk, sr_store_sk

[main_query]:
SELECT c_customer_id FROM customer_total_return ctr1, store, customer
WHERE ctr1.ctr_total_return > (SELECT avg(ctr_total_return)*1.2 FROM customer_total_return ctr2 WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk)
  AND s_store_sk = ctr1.ctr_store_sk AND s_state = 'SD' AND ctr1.ctr_customer_sk = c_customer_sk
ORDER BY c_customer_id LIMIT 100
```

**Output (optimized):**
```json
{
  "rewrite_sets": [{
    "id": "rs_01",
    "transform": "decorrelate",
    "nodes": {
      "filtered_returns": "SELECT sr.sr_customer_sk, sr.sr_store_sk, sr.sr_fee FROM store_returns sr JOIN date_dim d ON sr.sr_returned_date_sk = d.d_date_sk JOIN store s ON sr.sr_store_sk = s.s_store_sk WHERE d.d_year = 2000 AND s.s_state = 'SD'",
      "customer_total_return": "SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(sr_fee) AS ctr_total_return FROM filtered_returns GROUP BY sr_customer_sk, sr_store_sk",
      "store_avg_return": "SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return_threshold FROM customer_total_return GROUP BY ctr_store_sk",
      "main_query": "SELECT c.c_customer_id FROM customer_total_return ctr1 JOIN store_avg_return sar ON ctr1.ctr_store_sk = sar.ctr_store_sk JOIN customer c ON ctr1.ctr_customer_sk = c.c_customer_sk WHERE ctr1.ctr_total_return > sar.avg_return_threshold ORDER BY c.c_customer_id LIMIT 100"
    },
    "invariants_kept": ["same result rows", "same ordering", "same column output"],
    "expected_speedup": "2.90x",
    "risk": "low"
  }]
}
```

**Key Insight**: Push s_state='SD' filter EARLY into first CTE. Compute average as SEPARATE CTE with GROUP BY (NOT window function). Join on average instead of correlated subquery.

---

================================================================================
SYSTEM PROMPT (from dag_rewriter.txt template)
================================================================================

You are an autonomous Query Rewrite Engine. Your goal is to maximize execution speed while strictly preserving semantic invariants.

Output atomic rewrite sets in JSON.

RULES:
- Primary Goal: Maximize execution speed while strictly preserving semantic invariants.
- Allowed Transforms: Use the provided list. If a standard SQL optimization applies that is not listed, label it "semantic_rewrite".
- Atomic Sets: Group dependent changes (e.g., creating a CTE and joining it) into a single rewrite_set.
- Contracts: Output columns, grain, and total result rows must remain invariant.
- Naming: Use descriptive CTE names (e.g., `filtered_returns` vs `cte1`).
- Column Aliasing: Permitted only for aggregations or disambiguation.

ALLOWED TRANSFORMS: pushdown, decorrelate, or_to_union, early_filter, date_cte_isolate, materialize_cte, flatten_subquery, reorder_join, multi_push_predicate, inline_cte, remove_redundant, semantic_rewrite

OUTPUT FORMAT:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "transform_name",
      "nodes": {
        "node_id": "new SQL..."
      },
      "invariants_kept": ["list of preserved semantics"],
      "expected_speedup": "2x",
      "risk": "low"
    }
  ],
  "explanation": "what was changed and why"
}
```

================================================================================
DAG CONTEXT (generated by dag_v2.py)
================================================================================

## Query DAG

### Node: customer_total_return
**Type**: CTE
**SQL**:
```sql
SELECT sr_customer_sk AS ctr_customer_sk,
       sr_store_sk AS ctr_store_sk,
       SUM(SR_FEE) AS ctr_total_return
FROM store_returns, date_dim
WHERE sr_returned_date_sk = d_date_sk
  AND d_year = 2000
GROUP BY sr_customer_sk, sr_store_sk
```
**Contracts**:
- Output columns: ctr_customer_sk, ctr_store_sk, ctr_total_return
- Grain: (sr_customer_sk, sr_store_sk)

### Node: main_query
**Type**: SELECT
**SQL**:
```sql
SELECT c_customer_id
FROM customer_total_return ctr1, store, customer
WHERE ctr1.ctr_total_return > (
    SELECT avg(ctr_total_return)*1.2
    FROM customer_total_return ctr2
    WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk
  )
  AND s_store_sk = ctr1.ctr_store_sk
  AND s_state = 'SD'
  AND ctr1.ctr_customer_sk = c_customer_sk
ORDER BY c_customer_id
LIMIT 100
```
**Contracts**:
- Output columns: c_customer_id
- Ordering: c_customer_id ASC
- Limit: 100

### Detected Opportunities:
1. **DECORRELATE**: Correlated subquery in main_query WHERE clause
2. **PUSHDOWN**: s_state='SD' filter can be pushed into customer_total_return

================================================================================
EXECUTION PLAN
================================================================================

```
Limit  (cost=1234567.89..1234567.99 rows=100 width=16)
  ->  Sort  (cost=1234567.89..1234578.89 rows=4400 width=16)
        Sort Key: c.c_customer_id
        ->  Nested Loop  (cost=1000.00..1234456.78 rows=4400 width=16)
              ->  Nested Loop  (cost=1000.00..123456.78 rows=8800 width=24)
                    ->  Hash Join  (cost=100.00..12345.67 rows=88 width=8)
                          Hash Cond: (ctr1.ctr_store_sk = s.s_store_sk)
                          ->  CTE Scan on customer_total_return ctr1  (cost=0.00..10000.00 rows=500000 width=24)
                          ->  Hash  (cost=90.00..90.00 rows=8 width=4)
                                ->  Seq Scan on store s  (cost=0.00..90.00 rows=8 width=4)
                                      Filter: (s_state = 'SD')
                    ->  SubPlan 1 (CORRELATED - executed 88 times)
                          ->  Aggregate  (cost=123.45..123.46 rows=1 width=32)
                                ->  CTE Scan on customer_total_return ctr2  (cost=0.00..12500.00 rows=5000 width=8)
                                      Filter: (ctr1.ctr_store_sk = ctr2.ctr_store_sk)
              ->  Index Scan using customer_pkey on customer c  (cost=0.43..12.34 rows=1 width=20)
                    Index Cond: (c_customer_sk = ctr1.ctr_customer_sk)
```

================================================================================
END OF PROMPT - LLM RESPONDS WITH REWRITE_SETS JSON
================================================================================

Now output your rewrite_sets:
