[
  {
    "id": "aggregate_pushdown",
    "name": "Aggregate Pushdown Below Joins",
    "description": "Pre-aggregate fact table by join key before dimension joins to reduce rows entering the join from millions to thousands",
    "benchmark_queries": [
      "Q22"
    ],
    "verified_speedup": "42.90x",
    "principle": "Push aggregation below joins: when a GROUP BY + aggregate operates on a single fact table joined with dimensions, pre-aggregate the fact table on the join key first, THEN join with dimensions. Reduces rows entering the join from millions to thousands.",
    "example": {
      "opportunity": "AGGREGATE_PUSHDOWN",
      "input_slice": "SELECT i_product_name, i_brand, i_class, i_category, avg(inv_quantity_on_hand) qoh\nFROM inventory, date_dim, item\nWHERE inv_date_sk=d_date_sk AND inv_item_sk=i_item_sk\n  AND d_month_seq BETWEEN 1188 AND 1188 + 11\nGROUP BY ROLLUP(i_product_name, i_brand, i_class, i_category)\nORDER BY qoh, i_product_name, i_brand, i_class, i_category\nLIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "aggregate_pushdown",
            "nodes": {
              "date_filtered": "SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1188 AND 1188 + 11",
              "inventory_date": "SELECT inv_item_sk, inv_quantity_on_hand FROM inventory JOIN date_filtered ON inv_date_sk = d_date_sk",
              "inventory_agg": "SELECT inv_item_sk, SUM(inv_quantity_on_hand) AS sum_qty, COUNT(inv_quantity_on_hand) AS cnt FROM inventory_date GROUP BY inv_item_sk",
              "join_item": "SELECT i_product_name, i_brand, i_class, i_category, sum_qty, cnt FROM inventory_agg JOIN item ON inv_item_sk = i_item_sk",
              "rollup_aggregate": "SELECT i_product_name, i_brand, i_class, i_category, CASE WHEN SUM(cnt) > 0 THEN SUM(sum_qty) / SUM(cnt) END AS qoh FROM join_item GROUP BY ROLLUP(i_product_name, i_brand, i_class, i_category)",
              "main_query": "SELECT i_product_name, i_brand, i_class, i_category, qoh FROM rollup_aggregate ORDER BY qoh ASC, i_product_name ASC, i_brand ASC, i_class ASC, i_category ASC LIMIT 100"
            },
            "invariants_kept": [
              "output columns unchanged",
              "grain preserved",
              "same result rows"
            ],
            "expected_speedup": "42.90x",
            "risk": "medium"
          }
        ]
      },
      "key_insight": "Principle: Aggregate Pushdown \u2014 pre-aggregate the fact table (inventory) by the join key (inv_item_sk) BEFORE joining with the dimension table (item). The original query joins 7M inventory rows with date_dim and item, then aggregates with ROLLUP. The rewrite filters dates first, pre-aggregates inventory to ~150K rows (one per item), THEN joins item. AVG is reconstructed from SUM/COUNT since pre-aggregation changes the row count. This produced our single biggest individual win (42.90x).",
      "when_not_to_use": "Only works when GROUP BY keys are a superset of join keys \u2014 misaligned keys produce wrong results. When ROLLUP/CUBE is present, must reconstruct AVG from SUM/COUNT since pre-aggregation changes the row count."
    },
    "original_sql": "select i_product_name\n             ,i_brand\n             ,i_class\n             ,i_category\n             ,avg(inv_quantity_on_hand) qoh\n       from inventory\n           ,date_dim\n           ,item\n       where inv_date_sk=d_date_sk\n              and inv_item_sk=i_item_sk\n              and d_month_seq between 1188 and 1188 + 11\n       group by rollup(i_product_name\n                       ,i_brand\n                       ,i_class\n                       ,i_category)\norder by qoh, i_product_name, i_brand, i_class, i_category\n LIMIT 100;",
    "optimized_sql": "WITH date_filtered AS (SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1188 AND 1188 + 11), inventory_date AS (SELECT inv_item_sk, inv_quantity_on_hand FROM inventory JOIN date_filtered ON inv_date_sk = d_date_sk), inventory_agg AS (SELECT inv_item_sk, SUM(inv_quantity_on_hand) AS sum_qty, COUNT(inv_quantity_on_hand) AS cnt FROM inventory_date GROUP BY inv_item_sk), join_item AS (SELECT i_product_name, i_brand, i_class, i_category, sum_qty, cnt FROM inventory_agg JOIN item ON inv_item_sk = i_item_sk), rollup_aggregate AS (SELECT i_product_name, i_brand, i_class, i_category, CASE WHEN SUM(cnt) > 0 THEN SUM(sum_qty) / SUM(cnt) END AS qoh FROM join_item GROUP BY ROLLUP(i_product_name, i_brand, i_class, i_category)) SELECT i_product_name, i_brand, i_class, i_category, qoh FROM rollup_aggregate ORDER BY qoh ASC, i_product_name ASC, i_brand ASC, i_class ASC, i_category ASC LIMIT 100",
    "optimized_source": "swarm_w1",
    "benchmark_query_num": 22,
    "sf10_baseline_ms": null,
    "sf10_speedup": 42.9,
    "sf10_rows_match": true
  },
  {
    "id": "channel_bitmap_aggregation",
    "name": "Channel Bitmap Aggregation",
    "description": "Consolidate repeated scans of the same fact table (one per time/channel bucket) into a single scan with CASE WHEN labels and conditional aggregation",
    "benchmark_queries": [
      "Q88"
    ],
    "verified_speedup": "6.24x",
    "engine": "duckdb",
    "example": {
      "opportunity": "SINGLE_PASS_AGGREGATION + DIMENSION_CTE_ISOLATE",
      "input_slice": "select * from\n (select count(*) h8_30_to_9\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 8 and time_dim.t_minute >= 30\n   and ((hd_dep_count = -1 and hd_vehicle_count <= 1) or ...)\n   and store.s_store_name = 'ese') s1,\n (select count(*) h9_to_9_30 ...same pattern for 8 time buckets...)",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "single_pass_aggregation",
            "nodes": {
              "filtered_store": "SELECT s_store_sk FROM store WHERE s_store_name = 'ese'",
              "filtered_hd": "SELECT hd_demo_sk FROM household_demographics WHERE (hd_dep_count = -1 AND hd_vehicle_count <= 1) OR (hd_dep_count = 4 AND hd_vehicle_count <= 6) OR (hd_dep_count = 3 AND hd_vehicle_count <= 5)",
              "time_ranges": "SELECT t_time_sk, CASE WHEN t_hour = 8 AND t_minute >= 30 THEN 1 WHEN t_hour = 9 AND t_minute < 30 THEN 2 WHEN t_hour = 9 AND t_minute >= 30 THEN 3 WHEN t_hour = 10 AND t_minute < 30 THEN 4 WHEN t_hour = 10 AND t_minute >= 30 THEN 5 WHEN t_hour = 11 AND t_minute < 30 THEN 6 WHEN t_hour = 11 AND t_minute >= 30 THEN 7 WHEN t_hour = 12 AND t_minute < 30 THEN 8 END AS time_window FROM time_dim WHERE (t_hour BETWEEN 8 AND 12)",
              "sales_with_time": "SELECT tr.time_window FROM store_sales ss JOIN filtered_store fs ON ss.ss_store_sk = fs.s_store_sk JOIN filtered_hd fhd ON ss.ss_hdemo_sk = fhd.hd_demo_sk JOIN time_ranges tr ON ss.ss_sold_time_sk = tr.t_time_sk",
              "main_query": "SELECT COUNT(CASE WHEN time_window = 1 THEN 1 END) AS h8_30_to_9, COUNT(CASE WHEN time_window = 2 THEN 1 END) AS h9_to_9_30, COUNT(CASE WHEN time_window = 3 THEN 1 END) AS h9_30_to_10, COUNT(CASE WHEN time_window = 4 THEN 1 END) AS h10_to_10_30, COUNT(CASE WHEN time_window = 5 THEN 1 END) AS h10_30_to_11, COUNT(CASE WHEN time_window = 6 THEN 1 END) AS h11_to_11_30, COUNT(CASE WHEN time_window = 7 THEN 1 END) AS h11_30_to_12, COUNT(CASE WHEN time_window = 8 THEN 1 END) AS h12_to_12_30 FROM sales_with_time"
            },
            "invariants_kept": [
              "output columns unchanged",
              "same row counts per bucket"
            ],
            "expected_speedup": "6.24x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "The original query scans store_sales 8 times (once per time bucket), each with identical dimension joins. Consolidating into a single scan with CASE WHEN labels inside COUNT() reduces I/O from 8x to 1x. Dimension pre-filtering CTEs further reduce the join probe size.",
      "when_not_to_use": "Do not use when the number of distinct buckets exceeds 8 (diminishing returns from CASE evaluation overhead). Also not applicable when each subquery has structurally different joins or table references."
    },
    "original_sql": "select * from\n (select count(*) h8_30_to_9\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 8 and time_dim.t_minute >= 30\n   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or\n        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\n        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))\n   and store.s_store_name = 'ese') s1,\n (select count(*) h9_to_9_30\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 9 and time_dim.t_minute < 30\n   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or\n        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\n        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))\n   and store.s_store_name = 'ese') s2,\n (select count(*) h9_30_to_10\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 9 and time_dim.t_minute >= 30\n   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or\n        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\n        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))\n   and store.s_store_name = 'ese') s3,\n (select count(*) h10_to_10_30\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 10 and time_dim.t_minute < 30\n   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or\n        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\n        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))\n   and store.s_store_name = 'ese') s4,\n (select count(*) h10_30_to_11\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 10 and time_dim.t_minute >= 30\n   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or\n        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\n        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))\n   and store.s_store_name = 'ese') s5,\n (select count(*) h11_to_11_30\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 11 and time_dim.t_minute < 30\n   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or\n        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\n        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))\n   and store.s_store_name = 'ese') s6,\n (select count(*) h11_30_to_12\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 11 and time_dim.t_minute >= 30\n   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or\n        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\n        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))\n   and store.s_store_name = 'ese') s7,\n (select count(*) h12_to_12_30\n from store_sales, household_demographics, time_dim, store\n where ss_sold_time_sk = time_dim.t_time_sk\n   and ss_hdemo_sk = household_demographics.hd_demo_sk\n   and ss_store_sk = s_store_sk\n   and time_dim.t_hour = 12 and time_dim.t_minute < 30\n   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or\n        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or\n        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))\n   and store.s_store_name = 'ese') s8;",
    "optimized_sql": "WITH filtered_store AS (SELECT s_store_sk FROM store WHERE s_store_name = 'ese'), filtered_hd AS (SELECT hd_demo_sk FROM household_demographics WHERE (hd_dep_count = -1 AND hd_vehicle_count <= -1 + 2) OR (hd_dep_count = 4 AND hd_vehicle_count <= 4 + 2) OR (hd_dep_count = 3 AND hd_vehicle_count <= 3 + 2)), time_ranges AS (SELECT t_time_sk, CASE WHEN t_hour = 8 AND t_minute >= 30 THEN 1 WHEN t_hour = 9 AND t_minute < 30 THEN 2 WHEN t_hour = 9 AND t_minute >= 30 THEN 3 WHEN t_hour = 10 AND t_minute < 30 THEN 4 WHEN t_hour = 10 AND t_minute >= 30 THEN 5 WHEN t_hour = 11 AND t_minute < 30 THEN 6 WHEN t_hour = 11 AND t_minute >= 30 THEN 7 WHEN t_hour = 12 AND t_minute < 30 THEN 8 END AS time_window FROM time_dim WHERE (t_hour = 8 AND t_minute >= 30) OR (t_hour = 9 AND t_minute < 30) OR (t_hour = 9 AND t_minute >= 30) OR (t_hour = 10 AND t_minute < 30) OR (t_hour = 10 AND t_minute >= 30) OR (t_hour = 11 AND t_minute < 30) OR (t_hour = 11 AND t_minute >= 30) OR (t_hour = 12 AND t_minute < 30)), sales_with_time AS (SELECT tr.time_window FROM store_sales ss JOIN filtered_store fs ON ss.ss_store_sk = fs.s_store_sk JOIN filtered_hd fhd ON ss.ss_hdemo_sk = fhd.hd_demo_sk JOIN time_ranges tr ON ss.ss_sold_time_sk = tr.t_time_sk)\nSELECT COUNT(CASE WHEN time_window = 1 THEN 1 END) AS h8_30_to_9, COUNT(CASE WHEN time_window = 2 THEN 1 END) AS h9_to_9_30, COUNT(CASE WHEN time_window = 3 THEN 1 END) AS h9_30_to_10, COUNT(CASE WHEN time_window = 4 THEN 1 END) AS h10_to_10_30, COUNT(CASE WHEN time_window = 5 THEN 1 END) AS h10_30_to_11, COUNT(CASE WHEN time_window = 6 THEN 1 END) AS h11_to_11_30, COUNT(CASE WHEN time_window = 7 THEN 1 END) AS h11_30_to_12, COUNT(CASE WHEN time_window = 8 THEN 1 END) AS h12_to_12_30 FROM sales_with_time;",
    "optimized_source": "swarm_w2",
    "benchmark_query_num": 88,
    "sf10_baseline_ms": 1415.64,
    "sf10_speedup": 6.24,
    "sf10_rows_match": true
  },
  {
    "id": "composite_decorrelate_union",
    "name": "Decorrelate EXISTS + OR-to-UNION Composite",
    "description": "Decorrelate multiple correlated EXISTS subqueries into pre-materialized DISTINCT customer CTEs with a shared date filter, and replace OR(EXISTS a, EXISTS b) with UNION of key sets",
    "benchmark_queries": [
      "Q35"
    ],
    "verified_speedup": "2.42x",
    "principle": "Composite Decorrelation: when multiple correlated EXISTS share common filters, extract shared dimensions into a single CTE and decorrelate the EXISTS checks into pre-materialized key sets joined via UNION.",
    "example": {
      "opportunity": "DECORRELATE + DATE_CTE_ISOLATE + OR_TO_UNION",
      "input_slice": "[main_query]:\nSELECT ca_state, cd_gender, cd_marital_status, cd_dep_count, count(*) cnt1, ...\nFROM customer c, customer_address ca, customer_demographics\nWHERE c.c_current_addr_sk = ca.ca_address_sk\n  AND cd_demo_sk = c.c_current_cdemo_sk\n  AND EXISTS (SELECT * FROM store_sales, date_dim\n              WHERE c.c_customer_sk = ss_customer_sk\n              AND ss_sold_date_sk = d_date_sk AND d_year = 2001 AND d_qoy < 4)\n  AND (EXISTS (SELECT * FROM web_sales, date_dim\n               WHERE c.c_customer_sk = ws_bill_customer_sk\n               AND ws_sold_date_sk = d_date_sk AND d_year = 2001 AND d_qoy < 4)\n       OR EXISTS (SELECT * FROM catalog_sales, date_dim\n                  WHERE c.c_customer_sk = cs_ship_customer_sk\n                  AND cs_sold_date_sk = d_date_sk AND d_year = 2001 AND d_qoy < 4))\nGROUP BY ... ORDER BY ... LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "decorrelate",
            "nodes": {
              "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_year = 2001 AND d_qoy < 4",
              "store_customers": "SELECT DISTINCT ss_customer_sk FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk",
              "web_customers": "SELECT DISTINCT ws_bill_customer_sk FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk",
              "catalog_customers": "SELECT DISTINCT cs_ship_customer_sk FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk",
              "web_or_catalog_customers": "SELECT ws_bill_customer_sk AS customer_sk FROM web_customers UNION SELECT cs_ship_customer_sk AS customer_sk FROM catalog_customers",
              "main_query": "SELECT ca_state, cd_gender, cd_marital_status, cd_dep_count, COUNT(*) AS cnt1, MAX(cd_dep_count), SUM(cd_dep_count), MAX(cd_dep_count), cd_dep_employed_count, COUNT(*) AS cnt2, MAX(cd_dep_employed_count), SUM(cd_dep_employed_count), MAX(cd_dep_employed_count), cd_dep_college_count, COUNT(*) AS cnt3, MAX(cd_dep_college_count), SUM(cd_dep_college_count), MAX(cd_dep_college_count) FROM customer AS c JOIN customer_address AS ca ON c.c_current_addr_sk = ca.ca_address_sk JOIN customer_demographics ON cd_demo_sk = c.c_current_cdemo_sk JOIN store_customers AS sc ON c.c_customer_sk = sc.ss_customer_sk JOIN web_or_catalog_customers AS wcc ON c.c_customer_sk = wcc.customer_sk GROUP BY ca_state, cd_gender, cd_marital_status, cd_dep_count, cd_dep_employed_count, cd_dep_college_count ORDER BY ca_state, cd_gender, cd_marital_status, cd_dep_count, cd_dep_employed_count, cd_dep_college_count LIMIT 100"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output"
            ],
            "expected_speedup": "2.40x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Composite Decorrelation \u2014 when multiple correlated EXISTS share common filters, extract shared dimensions once, decorrelate each EXISTS into a DISTINCT CTE, and replace OR(EXISTS) with UNION at the set level. Here: (1) shared date filter CTE, (2) each EXISTS becomes SELECT DISTINCT customer_sk joined with filtered_dates, (3) OR(EXISTS web, EXISTS catalog) becomes UNION of key CTEs. Works because the query only checks membership, which DISTINCT + JOIN achieves."
    },
    "original_sql": "select  \n  ca_state,\n  cd_gender,\n  cd_marital_status,\n  cd_dep_count,\n  count(*) cnt1,\n  max(cd_dep_count),\n  sum(cd_dep_count),\n  max(cd_dep_count),\n  cd_dep_employed_count,\n  count(*) cnt2,\n  max(cd_dep_employed_count),\n  sum(cd_dep_employed_count),\n  max(cd_dep_employed_count),\n  cd_dep_college_count,\n  count(*) cnt3,\n  max(cd_dep_college_count),\n  sum(cd_dep_college_count),\n  max(cd_dep_college_count)\n from\n  customer c,customer_address ca,customer_demographics\n where\n  c.c_current_addr_sk = ca.ca_address_sk and\n  cd_demo_sk = c.c_current_cdemo_sk and \n  exists (select *\n          from store_sales,date_dim\n          where c.c_customer_sk = ss_customer_sk and\n                ss_sold_date_sk = d_date_sk and\n                d_year = 2001 and\n                d_qoy < 4) and\n   (exists (select *\n            from web_sales,date_dim\n            where c.c_customer_sk = ws_bill_customer_sk and\n                  ws_sold_date_sk = d_date_sk and\n                  d_year = 2001 and\n                  d_qoy < 4) or \n    exists (select * \n            from catalog_sales,date_dim\n            where c.c_customer_sk = cs_ship_customer_sk and\n                  cs_sold_date_sk = d_date_sk and\n                  d_year = 2001 and\n                  d_qoy < 4))\n group by ca_state,\n          cd_gender,\n          cd_marital_status,\n          cd_dep_count,\n          cd_dep_employed_count,\n          cd_dep_college_count\n order by ca_state,\n          cd_gender,\n          cd_marital_status,\n          cd_dep_count,\n          cd_dep_employed_count,\n          cd_dep_college_count\n LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2001 AND d_qoy < 4), store_customers AS (SELECT DISTINCT ss_customer_sk FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk), web_customers AS (SELECT DISTINCT ws_bill_customer_sk FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk), catalog_customers AS (SELECT DISTINCT cs_ship_customer_sk FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk), web_or_catalog_customers AS (SELECT ws_bill_customer_sk AS customer_sk FROM web_customers UNION SELECT cs_ship_customer_sk AS customer_sk FROM catalog_customers)\nSELECT ca_state, cd_gender, cd_marital_status, cd_dep_count, COUNT(*) AS cnt1, MAX(cd_dep_count), SUM(cd_dep_count), MAX(cd_dep_count), cd_dep_employed_count, COUNT(*) AS cnt2, MAX(cd_dep_employed_count), SUM(cd_dep_employed_count), MAX(cd_dep_employed_count), cd_dep_college_count, COUNT(*) AS cnt3, MAX(cd_dep_college_count), SUM(cd_dep_college_count), MAX(cd_dep_college_count) FROM customer AS c JOIN customer_address AS ca ON c.c_current_addr_sk = ca.ca_address_sk JOIN customer_demographics ON cd_demo_sk = c.c_current_cdemo_sk JOIN store_customers AS sc ON c.c_customer_sk = sc.ss_customer_sk JOIN web_or_catalog_customers AS wcc ON c.c_customer_sk = wcc.customer_sk GROUP BY ca_state, cd_gender, cd_marital_status, cd_dep_count, cd_dep_employed_count, cd_dep_college_count ORDER BY ca_state, cd_gender, cd_marital_status, cd_dep_count, cd_dep_employed_count, cd_dep_college_count LIMIT 100;",
    "optimized_source": "dsr1",
    "benchmark_query_num": 35,
    "sf10_baseline_ms": 282.02,
    "sf10_speedup": 2.01,
    "sf10_rows_match": true
  },
  {
    "id": "date_cte_isolate",
    "name": "Date CTE Isolation",
    "description": "Extract date filtering into a separate CTE to enable predicate pushdown and reduce scans",
    "benchmark_queries": [
      "Q6",
      "Q11"
    ],
    "verified_speedup": "4.00x",
    "principle": "Dimension Isolation: extract small dimension lookups into CTEs so they materialize once and subsequent joins probe a tiny hash table instead of rescanning.",
    "example": {
      "opportunity": "DATE_CTE_ISOLATE + CATEGORY_AVG",
      "input_slice": "[main_query]:\nSELECT a.ca_state state, count(*) cnt\nFROM customer_address a, customer c, store_sales s, date_dim d, item i\nWHERE a.ca_address_sk = c.c_current_addr_sk\n  AND c.c_customer_sk = s.ss_customer_sk\n  AND s.ss_sold_date_sk = d.d_date_sk\n  AND s.ss_item_sk = i.i_item_sk\n  AND d.d_month_seq = (SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1)\n  AND i.i_current_price > 1.2 * (SELECT avg(j.i_current_price) FROM item j WHERE j.i_category = i.i_category)\nGROUP BY a.ca_state HAVING count(*) >= 10\nORDER BY cnt, a.ca_state LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "date_cte_isolate",
            "nodes": {
              "target_month": "SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1",
              "category_avg_price": "SELECT i_category, AVG(i_current_price) * 1.2 AS avg_threshold FROM item GROUP BY i_category",
              "filtered_dates": "SELECT d_date_sk FROM date_dim JOIN target_month ON d_month_seq = target_month.d_month_seq",
              "filtered_sales": "SELECT ss_customer_sk, ss_item_sk FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk",
              "main_query": "SELECT a.ca_state AS state, COUNT(*) AS cnt FROM customer_address a JOIN customer c ON a.ca_address_sk = c.c_current_addr_sk JOIN filtered_sales s ON c.c_customer_sk = s.ss_customer_sk JOIN item i ON s.ss_item_sk = i.i_item_sk JOIN category_avg_price cap ON i.i_category = cap.i_category WHERE i.i_current_price > cap.avg_threshold GROUP BY a.ca_state HAVING COUNT(*) >= 10 ORDER BY cnt, a.ca_state LIMIT 100"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output",
              "same grouping and aggregation"
            ],
            "expected_speedup": "2.0x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Dimension Isolation \u2014 extract small dimension lookups into CTEs so they materialize once and subsequent joins probe a tiny hash table. Here: extract date month_seq subquery into CTE, extract category average into separate CTE with GROUP BY, then JOIN instead of correlated subquery. Each CTE is scanned once.",
      "when_not_to_use": "Do not use when the optimizer already pushes date predicates effectively (e.g., simple equality filters on date columns in self-joins). Do not decompose an already-efficient existing CTE into sub-CTEs \u2014 this adds materialization overhead without reducing scans. Caused 0.49x regression on Q31 (DuckDB already optimized the date pushdown) and 0.71x on Q1 (decomposed a well-structured CTE into slower pieces)."
    },
    "original_sql": "select a.ca_state state, count(*) cnt\n from customer_address a\n     ,customer c\n     ,store_sales s\n     ,date_dim d\n     ,item i\n where       a.ca_address_sk = c.c_current_addr_sk\n \tand c.c_customer_sk = s.ss_customer_sk\n \tand s.ss_sold_date_sk = d.d_date_sk\n \tand s.ss_item_sk = i.i_item_sk\n \tand d.d_month_seq = \n \t     (select distinct (d_month_seq)\n \t      from date_dim\n               where d_year = 2002\n \t        and d_moy = 3 )\n \tand i.i_current_price > 1.2 * \n             (select avg(j.i_current_price) \n \t     from item j \n \t     where j.i_category = i.i_category)\n group by a.ca_state\n having count(*) >= 10\n order by cnt, a.ca_state\n LIMIT 100;",
    "optimized_sql": "WITH target_month AS (SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2002 AND d_moy = 3), category_avg AS (SELECT i_category, AVG(i_current_price) * 1.2 AS price_threshold FROM item GROUP BY i_category)\nSELECT a.ca_state AS state, COUNT(*) AS cnt FROM customer_address AS a JOIN customer AS c ON a.ca_address_sk = c.c_current_addr_sk JOIN store_sales AS s ON c.c_customer_sk = s.ss_customer_sk JOIN date_dim AS d ON s.ss_sold_date_sk = d.d_date_sk JOIN target_month AS tm ON d.d_month_seq = tm.d_month_seq JOIN item AS i ON s.ss_item_sk = i.i_item_sk JOIN category_avg AS ca ON i.i_category = ca.i_category WHERE i.i_current_price > ca.price_threshold GROUP BY a.ca_state HAVING COUNT(*) >= 10 ORDER BY cnt, a.ca_state LIMIT 100;",
    "optimized_source": "kimi",
    "benchmark_query_num": 6,
    "sf10_baseline_ms": 90.88,
    "sf10_speedup": 1.86,
    "sf10_rows_match": true
  },
  {
    "id": "decorrelate",
    "name": "Decorrelate Subquery",
    "description": "Convert correlated subquery to separate CTE with GROUP BY, then JOIN",
    "benchmark_queries": [
      "Q1"
    ],
    "verified_speedup": "2.92x",
    "principle": "Decorrelation: convert correlated subqueries to standalone CTEs with GROUP BY, then JOIN. Correlated subqueries re-execute per outer row; a pre-computed CTE executes once.",
    "example": {
      "opportunity": "DECORRELATE + PUSHDOWN",
      "input_slice": "[customer_total_return] CORRELATED:\nSELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(SR_FEE) AS ctr_total_return\nFROM store_returns, date_dim\nWHERE sr_returned_date_sk = d_date_sk AND d_year = 2000\nGROUP BY sr_customer_sk, sr_store_sk\n\n[main_query]:\nSELECT c_customer_id FROM customer_total_return ctr1, store, customer\nWHERE ctr1.ctr_total_return > (SELECT avg(ctr_total_return)*1.2 FROM customer_total_return ctr2 WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk)\n  AND s_store_sk = ctr1.ctr_store_sk AND s_state = 'SD' AND ctr1.ctr_customer_sk = c_customer_sk\nORDER BY c_customer_id LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "decorrelate",
            "nodes": {
              "filtered_returns": "SELECT sr.sr_customer_sk, sr.sr_store_sk, sr.sr_fee FROM store_returns sr JOIN date_dim d ON sr.sr_returned_date_sk = d.d_date_sk JOIN store s ON sr.sr_store_sk = s.s_store_sk WHERE d.d_year = 2000 AND s.s_state = 'SD'",
              "customer_total_return": "SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(sr_fee) AS ctr_total_return FROM filtered_returns GROUP BY sr_customer_sk, sr_store_sk",
              "store_avg_return": "SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return_threshold FROM customer_total_return GROUP BY ctr_store_sk",
              "main_query": "SELECT c.c_customer_id FROM customer_total_return ctr1 JOIN store_avg_return sar ON ctr1.ctr_store_sk = sar.ctr_store_sk JOIN customer c ON ctr1.ctr_customer_sk = c.c_customer_sk WHERE ctr1.ctr_total_return > sar.avg_return_threshold ORDER BY c.c_customer_id LIMIT 100"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output"
            ],
            "expected_speedup": "2.90x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Decorrelation \u2014 convert correlated subqueries to standalone CTEs with GROUP BY, then JOIN. Correlated subqueries re-execute per outer row; a pre-computed CTE executes once. Here: push s_state='SD' filter early into first CTE, compute average as separate CTE with GROUP BY (not window function), then JOIN on the average threshold."
    },
    "original_sql": "with customer_total_return as\n(select sr_customer_sk as ctr_customer_sk\n,sr_store_sk as ctr_store_sk\n,sum(SR_FEE) as ctr_total_return\nfrom store_returns\n,date_dim\nwhere sr_returned_date_sk = d_date_sk\nand d_year =2000\ngroup by sr_customer_sk\n,sr_store_sk)\n select c_customer_id\nfrom customer_total_return ctr1\n,store\n,customer\nwhere ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2\nfrom customer_total_return ctr2\nwhere ctr1.ctr_store_sk = ctr2.ctr_store_sk)\nand s_store_sk = ctr1.ctr_store_sk\nand s_state = 'SD'\nand ctr1.ctr_customer_sk = c_customer_sk\norder by c_customer_id\n LIMIT 100;",
    "optimized_sql": "WITH filtered_returns AS (SELECT sr.sr_customer_sk, sr.sr_store_sk, sr.SR_FEE FROM store_returns AS sr JOIN date_dim AS d ON sr.sr_returned_date_sk = d.d_date_sk JOIN store AS s ON sr.sr_store_sk = s.s_store_sk WHERE d.d_year = 2000 AND s.s_state = 'SD'), customer_total_return AS (SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(SR_FEE) AS ctr_total_return FROM filtered_returns GROUP BY sr_customer_sk, sr_store_sk), store_avg_return AS (SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return_threshold FROM customer_total_return GROUP BY ctr_store_sk)\nSELECT c.c_customer_id FROM customer_total_return AS ctr1 JOIN store_avg_return AS sar ON ctr1.ctr_store_sk = sar.ctr_store_sk JOIN customer AS c ON ctr1.ctr_customer_sk = c.c_customer_sk WHERE ctr1.ctr_total_return > sar.avg_return_threshold ORDER BY c.c_customer_id LIMIT 100;",
    "optimized_source": "kimi",
    "benchmark_query_num": 1,
    "sf10_baseline_ms": 39.56,
    "sf10_speedup": 1.87,
    "sf10_rows_match": true
  },
  {
    "id": "deferred_window_aggregation",
    "name": "Deferred Window Aggregation",
    "description": "When multiple CTEs each perform GROUP BY + WINDOW (cumulative sum), then are joined with FULL OUTER JOIN followed by another WINDOW pass for NULL carry-forward: defer the WINDOW out of the CTEs, join daily totals, then compute cumulative sums once on the joined result. SUM() OVER() naturally skips NULLs, eliminating the need for a separate MAX() carry-forward window.",
    "benchmark_queries": [
      "Q51"
    ],
    "verified_speedup": "1.36x",
    "principle": "Deferred Aggregation: delay expensive operations (window functions) until after joins reduce the dataset. Computing window functions inside individual CTEs then joining is more expensive than joining first and computing windows once on the combined result.",
    "example": {
      "opportunity": "CONSOLIDATE WINDOW PASSES",
      "input_slice": "[web_v1] type=cte\nSELECT ws_item_sk AS item_sk, d_date,\n  SUM(SUM(ws_sales_price)) OVER (PARTITION BY ws_item_sk ORDER BY d_date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cume_sales\nFROM web_sales, date_dim\nWHERE ws_sold_date_sk = d_date_sk AND d_month_seq BETWEEN 1216 AND 1216+11 AND ws_item_sk IS NOT NULL\nGROUP BY ws_item_sk, d_date\n\n[store_v1] type=cte\nSELECT ss_item_sk AS item_sk, d_date,\n  SUM(SUM(ss_sales_price)) OVER (PARTITION BY ss_item_sk ORDER BY d_date ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cume_sales\nFROM store_sales, date_dim\nWHERE ss_sold_date_sk = d_date_sk AND d_month_seq BETWEEN 1216 AND 1216+11 AND ss_item_sk IS NOT NULL\nGROUP BY ss_item_sk, d_date\n\n[main_query] type=main\nSELECT * FROM (\n  SELECT item_sk, d_date, web_sales, store_sales,\n    MAX(web_sales) OVER (PARTITION BY item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS web_cumulative,\n    MAX(store_sales) OVER (PARTITION BY item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS store_cumulative\n  FROM (\n    SELECT COALESCE(web.item_sk, store.item_sk) AS item_sk, COALESCE(web.d_date, store.d_date) AS d_date,\n      web.cume_sales AS web_sales, store.cume_sales AS store_sales\n    FROM web_v1 web FULL OUTER JOIN store_v1 store ON (web.item_sk = store.item_sk AND web.d_date = store.d_date)\n  ) x\n) y\nWHERE web_cumulative > store_cumulative ORDER BY item_sk, d_date LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "semantic_rewrite",
            "nodes": {
              "web_daily": "SELECT ws_item_sk AS item_sk, d_date, SUM(ws_sales_price) AS daily_sales FROM web_sales, date_dim WHERE ws_sold_date_sk = d_date_sk AND d_month_seq BETWEEN 1216 AND 1216 + 11 AND ws_item_sk IS NOT NULL GROUP BY ws_item_sk, d_date",
              "store_daily": "SELECT ss_item_sk AS item_sk, d_date, SUM(ss_sales_price) AS daily_sales FROM store_sales, date_dim WHERE ss_sold_date_sk = d_date_sk AND d_month_seq BETWEEN 1216 AND 1216 + 11 AND ss_item_sk IS NOT NULL GROUP BY ss_item_sk, d_date",
              "main_query": "SELECT * FROM (SELECT COALESCE(web.item_sk, store.item_sk) AS item_sk, COALESCE(web.d_date, store.d_date) AS d_date, SUM(web.daily_sales) OVER (PARTITION BY COALESCE(web.item_sk, store.item_sk) ORDER BY COALESCE(web.d_date, store.d_date) ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS web_cumulative, SUM(store.daily_sales) OVER (PARTITION BY COALESCE(web.item_sk, store.item_sk) ORDER BY COALESCE(web.d_date, store.d_date) ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS store_cumulative FROM web_daily web FULL OUTER JOIN store_daily store ON web.item_sk = store.item_sk AND web.d_date = store.d_date) y WHERE web_cumulative > store_cumulative ORDER BY item_sk, d_date LIMIT 100"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output",
              "same cumulative semantics"
            ],
            "expected_speedup": "1.4x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Deferred Aggregation \u2014 delay expensive operations (window functions) until after joins reduce the dataset. Computing windows in CTEs before joining wastes work on rows that get filtered. Here: remove WINDOW from CTEs (keep only GROUP BY for daily totals), join the reduced results, then compute SUM() OVER() once on the joined output. Reduces 3 WINDOW passes to 1, and SUM() naturally skips NULLs from the FULL OUTER JOIN.",
      "when_not_to_use": "Do not use when the CTE window function is referenced by other consumers besides the final join (the cumulative value is needed elsewhere). Do not use when the window function is not a monotonically accumulating SUM - e.g., AVG, COUNT, or non-monotonic window functions require separate computation. Only applies when the join is FULL OUTER and the carry-forward window is MAX/LAST_VALUE over a cumulative sum."
    },
    "original_sql": "WITH web_v1 as (\nselect\n  ws_item_sk item_sk, d_date,\n  sum(sum(ws_sales_price))\n      over (partition by ws_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\nfrom web_sales\n    ,date_dim\nwhere ws_sold_date_sk=d_date_sk\n  and d_month_seq between 1216 and 1216+11\n  and ws_item_sk is not NULL\ngroup by ws_item_sk, d_date),\nstore_v1 as (\nselect\n  ss_item_sk item_sk, d_date,\n  sum(sum(ss_sales_price))\n      over (partition by ss_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\nfrom store_sales\n    ,date_dim\nwhere ss_sold_date_sk=d_date_sk\n  and d_month_seq between 1216 and 1216+11\n  and ss_item_sk is not NULL\ngroup by ss_item_sk, d_date)\n select *\nfrom (select item_sk\n     ,d_date\n     ,web_sales\n     ,store_sales\n     ,max(web_sales)\n         over (partition by item_sk order by d_date rows between unbounded preceding and current row) web_cumulative\n     ,max(store_sales)\n         over (partition by item_sk order by d_date rows between unbounded preceding and current row) store_cumulative\n     from (select case when web.item_sk is not null then web.item_sk else store.item_sk end item_sk\n                 ,case when web.d_date is not null then web.d_date else store.d_date end d_date\n                 ,web.cume_sales web_sales\n                 ,store.cume_sales store_sales\n           from web_v1 web full outer join store_v1 store on (web.item_sk = store.item_sk\n                                                          and web.d_date = store.d_date)\n          )x )y\nwhere web_cumulative > store_cumulative\norder by item_sk\n        ,d_date\n LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk, d_date FROM date_dim WHERE d_month_seq BETWEEN 1216 AND 1216 + 11), filtered_web_sales AS (SELECT ws_item_sk AS item_sk, d_date, ws_sales_price FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk WHERE NOT ws_item_sk IS NULL), filtered_store_sales AS (SELECT ss_item_sk AS item_sk, d_date, ss_sales_price FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk WHERE NOT ss_item_sk IS NULL), web_v1 AS (SELECT item_sk, d_date, SUM(SUM(ws_sales_price)) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS cume_sales FROM filtered_web_sales GROUP BY item_sk, d_date), store_v1 AS (SELECT item_sk, d_date, SUM(SUM(ss_sales_price)) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS cume_sales FROM filtered_store_sales GROUP BY item_sk, d_date)\nSELECT * FROM (SELECT item_sk, d_date, web_sales, store_sales, MAX(web_sales) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS web_cumulative, MAX(store_sales) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS store_cumulative FROM (SELECT CASE WHEN NOT web.item_sk IS NULL THEN web.item_sk ELSE store.item_sk END AS item_sk, CASE WHEN NOT web.d_date IS NULL THEN web.d_date ELSE store.d_date END AS d_date, web.cume_sales AS web_sales, store.cume_sales AS store_sales FROM web_v1 AS web FULL OUTER JOIN store_v1 AS store ON (web.item_sk = store.item_sk AND web.d_date = store.d_date)) AS x) AS y WHERE web_cumulative > store_cumulative ORDER BY item_sk, d_date LIMIT 100;",
    "optimized_source": "dsr1",
    "benchmark_query_num": 51,
    "sf10_baseline_ms": 1735.51
  },
  {
    "id": "dimension_cte_isolate",
    "name": "Dimension CTE Isolation",
    "description": "Pre-filter ALL dimension tables into CTEs before joining with fact table, not just date_dim",
    "benchmark_queries": [
      "Q26"
    ],
    "verified_speedup": "1.93x",
    "principle": "Early Selection: pre-filter dimension tables into CTEs returning only surrogate keys before joining with fact tables. Each dimension CTE is tiny, creating small hash tables that speed up the fact table probe.",
    "example": {
      "opportunity": "DIMENSION CTE ISOLATION",
      "input_slice": "SELECT i_item_id, avg(cs_quantity) agg1, avg(cs_list_price) agg2, avg(cs_coupon_amt) agg3, avg(cs_sales_price) agg4\nFROM catalog_sales, customer_demographics, date_dim, item, promotion\nWHERE cs_sold_date_sk = d_date_sk AND cs_item_sk = i_item_sk\n  AND cs_bill_cdemo_sk = cd_demo_sk AND cs_promo_sk = p_promo_sk\n  AND cd_gender = 'M' AND cd_marital_status = 'S' AND cd_education_status = 'College'\n  AND (p_channel_email = 'N' OR p_channel_event = 'N') AND d_year = 2000\nGROUP BY i_item_id ORDER BY i_item_id LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "dimension_cte_isolate",
            "nodes": {
              "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_year = 2000",
              "filtered_customer_demographics": "SELECT cd_demo_sk FROM customer_demographics WHERE cd_gender = 'M' AND cd_marital_status = 'S' AND cd_education_status = 'College'",
              "filtered_promotions": "SELECT p_promo_sk FROM promotion WHERE p_channel_email = 'N' OR p_channel_event = 'N'",
              "joined_facts": "SELECT cs_item_sk, cs_quantity, cs_list_price, cs_coupon_amt, cs_sales_price FROM catalog_sales AS cs JOIN filtered_dates AS fd ON cs.cs_sold_date_sk = fd.d_date_sk JOIN filtered_customer_demographics AS fcd ON cs.cs_bill_cdemo_sk = fcd.cd_demo_sk JOIN filtered_promotions AS fp ON cs.cs_promo_sk = fp.p_promo_sk",
              "main_query": "SELECT i_item_id, AVG(cs_quantity) AS agg1, AVG(cs_list_price) AS agg2, AVG(cs_coupon_amt) AS agg3, AVG(cs_sales_price) AS agg4 FROM joined_facts AS jf JOIN item AS i ON jf.cs_item_sk = i.i_item_sk GROUP BY i_item_id ORDER BY i_item_id LIMIT 100"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output"
            ],
            "expected_speedup": "1.90x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Early Selection \u2014 pre-filter dimension tables into CTEs returning only surrogate keys before joining with fact tables. Each CTE creates a tiny hash table that the fact join probes against, reducing intermediate cardinality. Here: isolate date, demographics, and promotions into separate filtered CTEs, then join their keys with the fact table. Most effective when dimension filters are highly selective."
    },
    "original_sql": "select i_item_id, \n        avg(cs_quantity) agg1,\n        avg(cs_list_price) agg2,\n        avg(cs_coupon_amt) agg3,\n        avg(cs_sales_price) agg4 \n from catalog_sales, customer_demographics, date_dim, item, promotion\n where cs_sold_date_sk = d_date_sk and\n       cs_item_sk = i_item_sk and\n       cs_bill_cdemo_sk = cd_demo_sk and\n       cs_promo_sk = p_promo_sk and\n       cd_gender = 'M' and \n       cd_marital_status = 'S' and\n       cd_education_status = 'Unknown' and\n       (p_channel_email = 'N' or p_channel_event = 'N') and\n       d_year = 2001 \n group by i_item_id\n order by i_item_id\n LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2000), filtered_customer_demographics AS (SELECT cd_demo_sk FROM customer_demographics WHERE cd_gender = 'M' AND cd_marital_status = 'S' AND cd_education_status = 'College'), prejoined_sales AS (SELECT cs.cs_quantity, cs.cs_list_price, cs.cs_coupon_amt, cs.cs_sales_price, i.i_item_id, p.p_channel_email, p.p_channel_event FROM catalog_sales AS cs JOIN filtered_dates AS fd ON cs.cs_sold_date_sk = fd.d_date_sk JOIN filtered_customer_demographics AS fcd ON cs.cs_bill_cdemo_sk = fcd.cd_demo_sk JOIN item AS i ON cs.cs_item_sk = i.i_item_sk JOIN promotion AS p ON cs.cs_promo_sk = p.p_promo_sk), branch_both AS (SELECT cs_quantity, cs_list_price, cs_coupon_amt, cs_sales_price, i_item_id FROM prejoined_sales WHERE p_channel_email = 'N' AND p_channel_event = 'N'), branch_email AS (SELECT cs_quantity, cs_list_price, cs_coupon_amt, cs_sales_price, i_item_id FROM prejoined_sales WHERE p_channel_email = 'N' AND p_channel_event <> 'N'), branch_event AS (SELECT cs_quantity, cs_list_price, cs_coupon_amt, cs_sales_price, i_item_id FROM prejoined_sales WHERE p_channel_email <> 'N' AND p_channel_event = 'N'), combined_sales AS (SELECT * FROM branch_email UNION ALL SELECT * FROM branch_event UNION ALL SELECT * FROM branch_both)\nSELECT i_item_id, AVG(cs_quantity) AS agg1, AVG(cs_list_price) AS agg2, AVG(cs_coupon_amt) AS agg3, AVG(cs_sales_price) AS agg4 FROM combined_sales GROUP BY i_item_id ORDER BY i_item_id LIMIT 100;",
    "optimized_source": "dsr1",
    "benchmark_query_num": 26,
    "sf10_baseline_ms": 77.89
  },
  {
    "id": "early_filter",
    "name": "Early Dimension Filter",
    "description": "Filter dimension tables FIRST, then join to fact tables to reduce expensive joins",
    "benchmark_queries": [
      "Q93",
      "Q11"
    ],
    "verified_speedup": "4.00x",
    "principle": "Early Selection: filter small dimension tables first, then join to large fact tables. This reduces the fact table scan to only rows matching the filter, rather than scanning all rows and filtering after the join.",
    "example": {
      "opportunity": "EARLY_FILTER",
      "input_slice": "[main_query]:\nSELECT ss_customer_sk, SUM(act_sales) AS sumsales\nFROM (SELECT ss.ss_customer_sk, CASE WHEN sr.sr_return_quantity IS NOT NULL\n        THEN (ss.ss_quantity - sr.sr_return_quantity) * ss.ss_sales_price\n        ELSE ss.ss_quantity * ss.ss_sales_price END AS act_sales\n      FROM store_sales ss LEFT JOIN store_returns sr ON ss.ss_item_sk = sr.sr_item_sk\n      JOIN reason r ON sr.sr_reason_sk = r.r_reason_sk\n      WHERE r.r_reason_desc = 'duplicate purchase') t\nGROUP BY ss_customer_sk ORDER BY sumsales, ss_customer_sk LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "early_filter",
            "nodes": {
              "filtered_reason": "SELECT r_reason_sk FROM reason WHERE r_reason_desc = 'duplicate purchase'",
              "filtered_returns": "SELECT sr_item_sk, sr_ticket_number, sr_return_quantity FROM store_returns JOIN filtered_reason ON sr_reason_sk = r_reason_sk",
              "main_query": "SELECT ss_customer_sk, SUM(act_sales) AS sumsales FROM (SELECT ss.ss_customer_sk, CASE WHEN NOT fr.sr_return_quantity IS NULL THEN (ss.ss_quantity - fr.sr_return_quantity) * ss.ss_sales_price ELSE (ss.ss_quantity * ss.ss_sales_price) END AS act_sales FROM store_sales ss JOIN filtered_returns fr ON (fr.sr_item_sk = ss.ss_item_sk AND fr.sr_ticket_number = ss.ss_ticket_number)) AS t GROUP BY ss_customer_sk ORDER BY sumsales, ss_customer_sk LIMIT 100"
            },
            "invariants_kept": [
              "output columns unchanged",
              "grain preserved",
              "same result rows"
            ],
            "expected_speedup": "2.71x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Early Selection \u2014 filter small dimension tables first, then join to large fact tables. This reduces the fact table scan to only rows matching the filter, rather than scanning all rows and filtering after the join. Here: filter reason table to 'duplicate purchase' first, then join to store_returns, then to store_sales \u2014 dramatically reducing the rows entering the expensive fact join."
    },
    "original_sql": "select ss_customer_sk\n            ,sum(act_sales) sumsales\n      from (select ss_item_sk\n                  ,ss_ticket_number\n                  ,ss_customer_sk\n                  ,case when sr_return_quantity is not null then (ss_quantity-sr_return_quantity)*ss_sales_price\n                                                            else (ss_quantity*ss_sales_price) end act_sales\n            from store_sales left outer join store_returns on (sr_item_sk = ss_item_sk\n                                                               and sr_ticket_number = ss_ticket_number)\n                ,reason\n            where sr_reason_sk = r_reason_sk\n              and r_reason_desc = 'duplicate purchase') t\n      group by ss_customer_sk\n      order by sumsales, ss_customer_sk\n LIMIT 100;",
    "optimized_sql": "WITH filtered_reason AS (SELECT r_reason_sk FROM reason WHERE r_reason_desc = 'duplicate purchase'), filtered_returns AS (SELECT sr_item_sk, sr_ticket_number, sr_return_quantity FROM store_returns JOIN filtered_reason ON sr_reason_sk = r_reason_sk)\nSELECT ss_customer_sk, SUM(act_sales) AS sumsales FROM (SELECT ss.ss_customer_sk, CASE WHEN NOT fr.sr_return_quantity IS NULL THEN (ss.ss_quantity - fr.sr_return_quantity) * ss.ss_sales_price ELSE (ss.ss_quantity * ss.ss_sales_price) END AS act_sales FROM store_sales AS ss JOIN filtered_returns AS fr ON (fr.sr_item_sk = ss.ss_item_sk AND fr.sr_ticket_number = ss.ss_ticket_number)) AS t GROUP BY ss_customer_sk ORDER BY sumsales, ss_customer_sk LIMIT 100;",
    "optimized_source": "kimi",
    "benchmark_query_num": 93,
    "sf10_baseline_ms": 499.71,
    "sf10_speedup": 2.97,
    "sf10_rows_match": true
  },
  {
    "id": "inner_join_conversion",
    "name": "Inner Join Conversion",
    "description": "Convert LEFT JOIN + right-table WHERE filter to INNER JOIN + early filter CTE when the WHERE eliminates NULL rows",
    "benchmark_queries": [
      "Q93"
    ],
    "verified_speedup": "3.44x",
    "principle": "When a LEFT JOIN is immediately followed by a WHERE filter on the right table that eliminates NULL rows, convert to INNER JOIN + early filter CTE. The WHERE clause already makes the LEFT JOIN behave as an INNER JOIN, but the optimizer keeps the LEFT JOIN semantics (preserving all left rows), wasting work on rows that are filtered out.",
    "example": {
      "opportunity": "INNER_JOIN_CONVERSION",
      "input_slice": "SELECT ss_customer_sk, SUM(act_sales) sumsales\nFROM (SELECT ss_item_sk, ss_ticket_number, ss_customer_sk,\n        CASE WHEN sr_return_quantity IS NOT NULL\n          THEN (ss_quantity-sr_return_quantity)*ss_sales_price\n          ELSE (ss_quantity*ss_sales_price) END act_sales\n      FROM store_sales LEFT OUTER JOIN store_returns\n        ON (sr_item_sk = ss_item_sk AND sr_ticket_number = ss_ticket_number)\n        , reason\n      WHERE sr_reason_sk = r_reason_sk\n        AND r_reason_desc = 'duplicate purchase') t\nGROUP BY ss_customer_sk\nORDER BY sumsales, ss_customer_sk LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "inner_join_conversion",
            "nodes": {
              "filtered_reason": "SELECT r_reason_sk, r_reason_desc FROM reason WHERE r_reason_desc = 'duplicate purchase'",
              "joined_returns_sales": "SELECT ss.ss_customer_sk, ss.ss_quantity, ss.ss_sales_price, sr.sr_return_quantity FROM store_sales ss INNER JOIN store_returns sr ON (ss.ss_item_sk = sr.sr_item_sk AND ss.ss_ticket_number = sr.sr_ticket_number) INNER JOIN filtered_reason fr ON sr.sr_reason_sk = fr.r_reason_sk",
              "main_query": "SELECT ss_customer_sk, SUM((ss_quantity - sr_return_quantity) * ss_sales_price) AS sumsales FROM joined_returns_sales GROUP BY ss_customer_sk ORDER BY sumsales ASC, ss_customer_sk ASC LIMIT 100"
            },
            "invariants_kept": [
              "output columns unchanged",
              "grain preserved",
              "same result rows"
            ],
            "expected_speedup": "3.44x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Inner Join Conversion \u2014 when a LEFT JOIN is followed by a WHERE filter on the right table (sr_reason_sk = r_reason_sk), the WHERE already eliminates NULL rows from the LEFT JOIN, making it behave as an INNER JOIN. Converting explicitly to INNER JOIN + early filter CTE lets the optimizer skip preserving left-side rows. Here: filtered reason \u2192 INNER JOIN store_returns + store_sales \u2192 aggregate. The optimizer cannot infer that the WHERE makes LEFT JOIN equivalent to INNER JOIN.",
      "when_not_to_use": "Do NOT convert if CASE WHEN checks for IS NULL on the right-table column \u2014 the NULL branch is semantically meaningful and the LEFT JOIN is intentional."
    },
    "original_sql": "select ss_customer_sk\n            ,sum(act_sales) sumsales\n      from (select ss_item_sk\n                  ,ss_ticket_number\n                  ,ss_customer_sk\n                  ,case when sr_return_quantity is not null then (ss_quantity-sr_return_quantity)*ss_sales_price\n                                                            else (ss_quantity*ss_sales_price) end act_sales\n            from store_sales left outer join store_returns on (sr_item_sk = ss_item_sk\n                                                               and sr_ticket_number = ss_ticket_number)\n                ,reason\n            where sr_reason_sk = r_reason_sk\n              and r_reason_desc = 'duplicate purchase') t\n      group by ss_customer_sk\n      order by sumsales, ss_customer_sk\n LIMIT 100;",
    "optimized_sql": "WITH filtered_reason AS (SELECT r_reason_sk, r_reason_desc FROM reason WHERE r_reason_desc = 'duplicate purchase'), joined_returns_sales AS (SELECT ss.ss_customer_sk, ss.ss_quantity, ss.ss_sales_price, sr.sr_return_quantity FROM store_sales ss INNER JOIN store_returns sr ON (ss.ss_item_sk = sr.sr_item_sk AND ss.ss_ticket_number = sr.sr_ticket_number) INNER JOIN filtered_reason fr ON sr.sr_reason_sk = fr.r_reason_sk), aggregated AS (SELECT ss_customer_sk, SUM((ss_quantity - sr_return_quantity) * ss_sales_price) AS sumsales FROM joined_returns_sales GROUP BY ss_customer_sk), top_n AS (SELECT ss_customer_sk, sumsales FROM aggregated ORDER BY sumsales ASC, ss_customer_sk ASC LIMIT 100) SELECT ss_customer_sk, sumsales FROM top_n",
    "optimized_source": "swarm_w2",
    "benchmark_query_num": 93,
    "sf10_baseline_ms": null,
    "sf10_speedup": 3.44,
    "sf10_rows_match": true
  },
  {
    "id": "intersect_to_exists",
    "name": "INTERSECT to EXISTS",
    "description": "Convert INTERSECT subquery pattern to multiple EXISTS clauses for better join planning",
    "benchmark_queries": [
      "Q14"
    ],
    "verified_speedup": "1.83x",
    "principle": "Semi-Join Short-Circuit: replace INTERSECT with EXISTS to avoid full materialization and sorting. INTERSECT must compute complete result sets before intersecting; EXISTS stops at the first match per row, enabling semi-join optimizations.",
    "example": {
      "opportunity": "INTERSECT_TO_EXISTS",
      "input_slice": "[cross_items] type=cte:\nSELECT i_item_sk AS ss_item_sk FROM item,\n  (SELECT iss.i_brand_id, iss.i_class_id, iss.i_category_id\n   FROM store_sales, item iss, date_dim d1\n   WHERE ss_item_sk = iss.i_item_sk AND ss_sold_date_sk = d1.d_date_sk AND d1.d_year BETWEEN 1999 AND 2001\n   INTERSECT\n   SELECT ics.i_brand_id, ics.i_class_id, ics.i_category_id\n   FROM catalog_sales, item ics, date_dim d2\n   WHERE cs_item_sk = ics.i_item_sk AND cs_sold_date_sk = d2.d_date_sk AND d2.d_year BETWEEN 1999 AND 2001\n   INTERSECT\n   SELECT iws.i_brand_id, iws.i_class_id, iws.i_category_id\n   FROM web_sales, item iws, date_dim d3\n   WHERE ws_item_sk = iws.i_item_sk AND ws_sold_date_sk = d3.d_date_sk AND d3.d_year BETWEEN 1999 AND 2001)\nWHERE i_brand_id = brand_id AND i_class_id = class_id AND i_category_id = category_id",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "intersect_to_exists",
            "nodes": {
              "cross_items_flat": "SELECT i.i_item_sk AS ss_item_sk FROM item i WHERE EXISTS (SELECT 1 FROM store_sales, item iss, date_dim d1 WHERE ss_item_sk = iss.i_item_sk AND ss_sold_date_sk = d1.d_date_sk AND d1.d_year BETWEEN 1999 AND 2001 AND iss.i_brand_id = i.i_brand_id AND iss.i_class_id = i.i_class_id AND iss.i_category_id = i.i_category_id) AND EXISTS (SELECT 1 FROM catalog_sales, item ics, date_dim d2 WHERE cs_item_sk = ics.i_item_sk AND cs_sold_date_sk = d2.d_date_sk AND d2.d_year BETWEEN 1999 AND 2001 AND ics.i_brand_id = i.i_brand_id AND ics.i_class_id = i.i_class_id AND ics.i_category_id = i.i_category_id) AND EXISTS (SELECT 1 FROM web_sales, item iws, date_dim d3 WHERE ws_item_sk = iws.i_item_sk AND ws_sold_date_sk = d3.d_date_sk AND d3.d_year BETWEEN 1999 AND 2001 AND iws.i_brand_id = i.i_brand_id AND iws.i_class_id = i.i_class_id AND iws.i_category_id = i.i_category_id)",
              "main_query": "SELECT ... FROM ... WHERE i_item_sk IN (SELECT ss_item_sk FROM cross_items_flat) ..."
            },
            "invariants_kept": [
              "same result rows",
              "same columns",
              "same grouping"
            ],
            "expected_speedup": "1.83x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Semi-Join Short-Circuit \u2014 replace INTERSECT with EXISTS to avoid full materialization and sorting. INTERSECT must compute complete result sets before intersecting; EXISTS stops at the first match per row, enabling semi-join optimizations. Here: convert three INTERSECT subqueries to EXISTS clauses, allowing the optimizer to short-circuit and use index-based semi-joins."
    },
    "original_sql": "with  cross_items as\n (select i_item_sk ss_item_sk\n from item,\n (select iss.i_brand_id brand_id\n     ,iss.i_class_id class_id\n     ,iss.i_category_id category_id\n from store_sales\n     ,item iss\n     ,date_dim d1\n where ss_item_sk = iss.i_item_sk\n   and ss_sold_date_sk = d1.d_date_sk\n   and d1.d_year between 2000 AND 2000 + 2\n intersect \n select ics.i_brand_id\n     ,ics.i_class_id\n     ,ics.i_category_id\n from catalog_sales\n     ,item ics\n     ,date_dim d2\n where cs_item_sk = ics.i_item_sk\n   and cs_sold_date_sk = d2.d_date_sk\n   and d2.d_year between 2000 AND 2000 + 2\n intersect\n select iws.i_brand_id\n     ,iws.i_class_id\n     ,iws.i_category_id\n from web_sales\n     ,item iws\n     ,date_dim d3\n where ws_item_sk = iws.i_item_sk\n   and ws_sold_date_sk = d3.d_date_sk\n   and d3.d_year between 2000 AND 2000 + 2)\n where i_brand_id = brand_id\n      and i_class_id = class_id\n      and i_category_id = category_id\n),\n avg_sales as\n (select avg(quantity*list_price) average_sales\n  from (select ss_quantity quantity\n             ,ss_list_price list_price\n       from store_sales\n           ,date_dim\n       where ss_sold_date_sk = d_date_sk\n         and d_year between 2000 and 2000 + 2\n       union all \n       select cs_quantity quantity \n             ,cs_list_price list_price\n       from catalog_sales\n           ,date_dim\n       where cs_sold_date_sk = d_date_sk\n         and d_year between 2000 and 2000 + 2 \n       union all\n       select ws_quantity quantity\n             ,ws_list_price list_price\n       from web_sales\n           ,date_dim\n       where ws_sold_date_sk = d_date_sk\n         and d_year between 2000 and 2000 + 2) x)\n  select channel, i_brand_id,i_class_id,i_category_id,sum(sales), sum(number_sales)\n from(\n       select 'store' channel, i_brand_id,i_class_id\n             ,i_category_id,sum(ss_quantity*ss_list_price) sales\n             , count(*) number_sales\n       from store_sales\n           ,item\n           ,date_dim\n       where ss_item_sk in (select ss_item_sk from cross_items)\n         and ss_item_sk = i_item_sk\n         and ss_sold_date_sk = d_date_sk\n         and d_year = 2000+2 \n         and d_moy = 11\n       group by i_brand_id,i_class_id,i_category_id\n       having sum(ss_quantity*ss_list_price) > (select average_sales from avg_sales)\n       union all\n       select 'catalog' channel, i_brand_id,i_class_id,i_category_id, sum(cs_quantity*cs_list_price) sales, count(*) number_sales\n       from catalog_sales\n           ,item\n           ,date_dim\n       where cs_item_sk in (select ss_item_sk from cross_items)\n         and cs_item_sk = i_item_sk\n         and cs_sold_date_sk = d_date_sk\n         and d_year = 2000+2 \n         and d_moy = 11\n       group by i_brand_id,i_class_id,i_category_id\n       having sum(cs_quantity*cs_list_price) > (select average_sales from avg_sales)\n       union all\n       select 'web' channel, i_brand_id,i_class_id,i_category_id, sum(ws_quantity*ws_list_price) sales , count(*) number_sales\n       from web_sales\n           ,item\n           ,date_dim\n       where ws_item_sk in (select ss_item_sk from cross_items)\n         and ws_item_sk = i_item_sk\n         and ws_sold_date_sk = d_date_sk\n         and d_year = 2000+2\n         and d_moy = 11\n       group by i_brand_id,i_class_id,i_category_id\n       having sum(ws_quantity*ws_list_price) > (select average_sales from avg_sales)\n ) y\n group by rollup (channel, i_brand_id,i_class_id,i_category_id)\n order by channel,i_brand_id,i_class_id,i_category_id\n LIMIT 100;",
    "optimized_sql": "WITH cross_items AS (SELECT i.i_item_sk AS ss_item_sk FROM item AS i WHERE EXISTS(SELECT 1 FROM store_sales, item AS iss, date_dim AS d1 WHERE ss_item_sk = iss.i_item_sk AND ss_sold_date_sk = d1.d_date_sk AND d1.d_year BETWEEN 2000 AND 2000 + 2 AND iss.i_brand_id = i.i_brand_id AND iss.i_class_id = i.i_class_id AND iss.i_category_id = i.i_category_id) AND EXISTS(SELECT 1 FROM catalog_sales, item AS ics, date_dim AS d2 WHERE cs_item_sk = ics.i_item_sk AND cs_sold_date_sk = d2.d_date_sk AND d2.d_year BETWEEN 2000 AND 2000 + 2 AND ics.i_brand_id = i.i_brand_id AND ics.i_class_id = i.i_class_id AND ics.i_category_id = i.i_category_id) AND EXISTS(SELECT 1 FROM web_sales, item AS iws, date_dim AS d3 WHERE ws_item_sk = iws.i_item_sk AND ws_sold_date_sk = d3.d_date_sk AND d3.d_year BETWEEN 2000 AND 2000 + 2 AND iws.i_brand_id = i.i_brand_id AND iws.i_class_id = i.i_class_id AND iws.i_category_id = i.i_category_id)), avg_sales AS (SELECT AVG(quantity * list_price) AS average_sales FROM (SELECT ss_quantity AS quantity, ss_list_price AS list_price FROM store_sales, date_dim WHERE ss_sold_date_sk = d_date_sk AND d_year BETWEEN 2000 AND 2000 + 2 UNION ALL SELECT cs_quantity AS quantity, cs_list_price AS list_price FROM catalog_sales, date_dim WHERE cs_sold_date_sk = d_date_sk AND d_year BETWEEN 2000 AND 2000 + 2 UNION ALL SELECT ws_quantity AS quantity, ws_list_price AS list_price FROM web_sales, date_dim WHERE ws_sold_date_sk = d_date_sk AND d_year BETWEEN 2000 AND 2000 + 2) AS x)\nSELECT channel, i_brand_id, i_class_id, i_category_id, SUM(sales), SUM(number_sales) FROM (SELECT 'store' AS channel, i_brand_id, i_class_id, i_category_id, SUM(ss_quantity * ss_list_price) AS sales, COUNT(*) AS number_sales FROM store_sales, item, date_dim WHERE ss_item_sk IN (SELECT ss_item_sk FROM cross_items) AND ss_item_sk = i_item_sk AND ss_sold_date_sk = d_date_sk AND d_year = 2000 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING SUM(ss_quantity * ss_list_price) > (SELECT average_sales FROM avg_sales) UNION ALL SELECT 'catalog' AS channel, i_brand_id, i_class_id, i_category_id, SUM(cs_quantity * cs_list_price) AS sales, COUNT(*) AS number_sales FROM catalog_sales, item, date_dim WHERE cs_item_sk IN (SELECT ss_item_sk FROM cross_items) AND cs_item_sk = i_item_sk AND cs_sold_date_sk = d_date_sk AND d_year = 2000 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING SUM(cs_quantity * cs_list_price) > (SELECT average_sales FROM avg_sales) UNION ALL SELECT 'web' AS channel, i_brand_id, i_class_id, i_category_id, SUM(ws_quantity * ws_list_price) AS sales, COUNT(*) AS number_sales FROM web_sales, item, date_dim WHERE ws_item_sk IN (SELECT ss_item_sk FROM cross_items) AND ws_item_sk = i_item_sk AND ws_sold_date_sk = d_date_sk AND d_year = 2000 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING SUM(ws_quantity * ws_list_price) > (SELECT average_sales FROM avg_sales)) AS y GROUP BY ROLLUP (channel, i_brand_id, i_class_id, i_category_id) ORDER BY channel, i_brand_id, i_class_id, i_category_id LIMIT 100;",
    "optimized_source": "dsr1",
    "benchmark_query_num": 14,
    "sf10_baseline_ms": 1462.81,
    "sf10_speedup": 2.72,
    "sf10_rows_match": false
  },
  {
    "id": "materialize_cte",
    "name": "Materialize Repeated Subquery",
    "description": "Extract repeated subquery patterns into a CTE to avoid recomputation",
    "benchmark_queries": [
      "Q95"
    ],
    "verified_speedup": "1.37x",
    "principle": "Shared Materialization: extract repeated subquery patterns into CTEs to avoid recomputation. When the same logical check appears multiple times, compute it once and reference the result.",
    "example": {
      "opportunity": "MATERIALIZE_CTE",
      "input_slice": "[main_query]:\nSELECT COUNT(DISTINCT ws_order_number) AS order_count,\n       SUM(ws_ext_ship_cost) AS total_shipping\nFROM web_sales ws1, date_dim, customer_address, web_site\nWHERE d_date BETWEEN '2000-03-01' AND '2000-05-01'\n  AND ws1.ws_ship_date_sk = d_date_sk\n  AND ws1.ws_ship_addr_sk = ca_address_sk\n  AND ca_state = 'IL'\n  AND ws1.ws_web_site_sk = web_site_sk\n  AND web_company_name = 'pri'\n  AND EXISTS (SELECT * FROM web_sales ws2 WHERE ws1.ws_order_number = ws2.ws_order_number AND ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)\n  AND NOT EXISTS (SELECT * FROM web_returns wr1 WHERE ws1.ws_order_number = wr1.wr_order_number)",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "materialize_cte",
            "nodes": {
              "multi_warehouse_orders": "SELECT DISTINCT ws_order_number FROM web_sales ws1 WHERE EXISTS (SELECT 1 FROM web_sales ws2 WHERE ws1.ws_order_number = ws2.ws_order_number AND ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)",
              "returned_orders": "SELECT DISTINCT wr_order_number FROM web_returns",
              "main_query": "SELECT COUNT(DISTINCT ws_order_number) AS order_count, SUM(ws_ext_ship_cost) AS total_shipping FROM web_sales ws1 JOIN date_dim ON ws1.ws_ship_date_sk = d_date_sk JOIN customer_address ON ws1.ws_ship_addr_sk = ca_address_sk JOIN web_site ON ws1.ws_web_site_sk = web_site_sk JOIN multi_warehouse_orders mwo ON ws1.ws_order_number = mwo.ws_order_number LEFT JOIN returned_orders ro ON ws1.ws_order_number = ro.wr_order_number WHERE d_date BETWEEN '2000-03-01' AND '2000-05-01' AND ca_state = 'IL' AND web_company_name = 'pri' AND ro.wr_order_number IS NULL"
            },
            "invariants_kept": [
              "same result rows",
              "same aggregation"
            ],
            "expected_speedup": "1.8x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Shared Materialization \u2014 extract repeated subquery patterns into CTEs to avoid recomputation. When the same logical check appears in multiple places (EXISTS, WHERE, JOIN), computing it once as a CTE and referencing it is cheaper. Here: extract multi-warehouse order detection into one CTE, returned orders into another, then JOIN instead of nested EXISTS checks.",
      "when_not_to_use": "NEVER convert EXISTS or NOT EXISTS subqueries into materialized CTEs when the EXISTS is used as a filter (not a data source). EXISTS uses semi-join short-circuiting \u2014 the database stops scanning as soon as one match is found. Materializing into a CTE forces a full scan of the subquery table, destroying this optimization. Caused 0.14x on Q16 (7x slowdown \u2014 EXISTS on catalog_sales materialized into full CTE scan) and 0.54x on Q95 (EXISTS on web_sales forced full materialization)."
    },
    "original_sql": "with ws_wh as\n(select ws1.ws_order_number,ws1.ws_warehouse_sk wh1,ws2.ws_warehouse_sk wh2\n from web_sales ws1,web_sales ws2\n where ws1.ws_order_number = ws2.ws_order_number\n   and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)\n select \n   count(distinct ws_order_number) as \"order count\"\n  ,sum(ws_ext_ship_cost) as \"total shipping cost\"\n  ,sum(ws_net_profit) as \"total net profit\"\nfrom\n   web_sales ws1\n  ,date_dim\n  ,customer_address\n  ,web_site\nwhere\n    d_date between '1999-2-01' and \n           (cast('1999-2-01' as date) + INTERVAL 60 DAY)\nand ws1.ws_ship_date_sk = d_date_sk\nand ws1.ws_ship_addr_sk = ca_address_sk\nand ca_state = 'NC'\nand ws1.ws_web_site_sk = web_site_sk\nand web_company_name = 'pri'\nand ws1.ws_order_number in (select ws_order_number\n                            from ws_wh)\nand ws1.ws_order_number in (select wr_order_number\n                            from web_returns,ws_wh\n                            where wr_order_number = ws_wh.ws_order_number)\norder by count(distinct ws_order_number)\n LIMIT 100;",
    "optimized_sql": "WITH ws_wh AS (SELECT ws1.ws_order_number, ws1.ws_warehouse_sk AS wh1, ws2.ws_warehouse_sk AS wh2 FROM web_sales AS ws1, web_sales AS ws2 WHERE ws1.ws_order_number = ws2.ws_order_number AND ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)\nSELECT COUNT(DISTINCT ws_order_number) AS \"order count\", SUM(ws_ext_ship_cost) AS \"total shipping cost\", SUM(ws_net_profit) AS \"total net profit\" FROM web_sales AS ws1 JOIN date_dim ON ws1.ws_ship_date_sk = d_date_sk JOIN customer_address ON ws1.ws_ship_addr_sk = ca_address_sk JOIN web_site ON ws1.ws_web_site_sk = web_site_sk WHERE d_date BETWEEN '1999-2-01' AND (CAST('1999-2-01' AS DATE) + INTERVAL '60' DAY) AND ca_state = 'NC' AND web_company_name = 'pri' AND EXISTS(SELECT 1 FROM ws_wh WHERE ws_wh.ws_order_number = ws1.ws_order_number) AND EXISTS(SELECT 1 FROM web_returns JOIN ws_wh ON wr_order_number = ws_wh.ws_order_number WHERE wr_order_number = ws1.ws_order_number) ORDER BY COUNT(DISTINCT ws_order_number) LIMIT 100;",
    "optimized_source": "kimi",
    "benchmark_query_num": 95,
    "sf10_baseline_ms": 869.38,
    "sf10_speedup": 1.43,
    "sf10_rows_match": true
  },
  {
    "id": "multi_date_range_cte",
    "name": "Multi Date Range CTE",
    "description": "When query uses multiple date_dim aliases with different filters (d1, d2, d3), create separate CTEs for each date range and pre-join with fact tables",
    "benchmark_queries": [
      "Q29"
    ],
    "verified_speedup": "2.35x",
    "principle": "Early Selection per Alias: when a query joins the same dimension table multiple times with different filters (d1, d2, d3), create separate CTEs for each filter and pre-join with fact tables to reduce rows entering the main join.",
    "example": {
      "opportunity": "MULTI DATE RANGE CTE",
      "input_slice": "SELECT i_item_id, i_item_desc, s_store_id, s_store_name,\n  sum(ss_quantity) AS store_sales_quantity,\n  sum(sr_return_quantity) AS store_returns_quantity,\n  sum(cs_quantity) AS catalog_sales_quantity\nFROM store_sales, store_returns, catalog_sales,\n  date_dim d1, date_dim d2, date_dim d3, store, item\nWHERE d1.d_moy = 9 AND d1.d_year = 1999 AND d1.d_date_sk = ss_sold_date_sk\n  AND d2.d_moy BETWEEN 9 AND 12 AND d2.d_year = 1999 AND sr_returned_date_sk = d2.d_date_sk\n  AND d3.d_year IN (1999, 2000, 2001) AND cs_sold_date_sk = d3.d_date_sk\n  AND ss_customer_sk = sr_customer_sk AND ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number\n  AND sr_customer_sk = cs_bill_customer_sk AND sr_item_sk = cs_item_sk\nGROUP BY i_item_id, i_item_desc, s_store_id, s_store_name LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "multi_date_range_cte",
            "nodes": {
              "d1_dates": "SELECT d_date_sk FROM date_dim WHERE d_moy = 9 AND d_year = 1999",
              "d2_dates": "SELECT d_date_sk FROM date_dim WHERE d_moy BETWEEN 9 AND 12 AND d_year = 1999",
              "d3_dates": "SELECT d_date_sk FROM date_dim WHERE d_year IN (1999, 2000, 2001)",
              "filtered_store_sales": "SELECT ss_item_sk, ss_customer_sk, ss_ticket_number, ss_store_sk, ss_quantity FROM store_sales JOIN d1_dates ON store_sales.ss_sold_date_sk = d1_dates.d_date_sk",
              "filtered_store_returns": "SELECT sr_item_sk, sr_customer_sk, sr_ticket_number, sr_return_quantity FROM store_returns JOIN d2_dates ON store_returns.sr_returned_date_sk = d2_dates.d_date_sk",
              "filtered_catalog_sales": "SELECT cs_item_sk, cs_bill_customer_sk, cs_quantity FROM catalog_sales JOIN d3_dates ON catalog_sales.cs_sold_date_sk = d3_dates.d_date_sk",
              "main_query": "SELECT i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name, SUM(fss.ss_quantity) AS store_sales_quantity, SUM(fsr.sr_return_quantity) AS store_returns_quantity, SUM(fcs.cs_quantity) AS catalog_sales_quantity FROM filtered_store_sales AS fss JOIN filtered_store_returns AS fsr ON fss.ss_customer_sk = fsr.sr_customer_sk AND fss.ss_item_sk = fsr.sr_item_sk AND fss.ss_ticket_number = fsr.sr_ticket_number JOIN filtered_catalog_sales AS fcs ON fsr.sr_customer_sk = fcs.cs_bill_customer_sk AND fsr.sr_item_sk = fcs.cs_item_sk JOIN store AS s ON fss.ss_store_sk = s.s_store_sk JOIN item AS i ON fss.ss_item_sk = i.i_item_sk GROUP BY i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name ORDER BY i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name LIMIT 100"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output"
            ],
            "expected_speedup": "2.35x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Early Selection per Alias \u2014 when a query joins the same dimension table multiple times with different filters (d1, d2, d3 pattern), create separate filtered CTEs for each alias. Pre-join each date CTE with its corresponding fact table reference. This filters fact rows early before the expensive multi-way join, avoiding repeated full dimension scans."
    },
    "original_sql": "select  \n     i_item_id\n    ,i_item_desc\n    ,s_store_id\n    ,s_store_name\n    ,avg(ss_quantity)        as store_sales_quantity\n    ,avg(sr_return_quantity) as store_returns_quantity\n    ,avg(cs_quantity)        as catalog_sales_quantity\n from\n    store_sales\n   ,store_returns\n   ,catalog_sales\n   ,date_dim             d1\n   ,date_dim             d2\n   ,date_dim             d3\n   ,store\n   ,item\n where\n     d1.d_moy               = 4 \n and d1.d_year              = 1999\n and d1.d_date_sk           = ss_sold_date_sk\n and i_item_sk              = ss_item_sk\n and s_store_sk             = ss_store_sk\n and ss_customer_sk         = sr_customer_sk\n and ss_item_sk             = sr_item_sk\n and ss_ticket_number       = sr_ticket_number\n and sr_returned_date_sk    = d2.d_date_sk\n and d2.d_moy               between 4 and  4 + 3 \n and d2.d_year              = 1999\n and sr_customer_sk         = cs_bill_customer_sk\n and sr_item_sk             = cs_item_sk\n and cs_sold_date_sk        = d3.d_date_sk     \n and d3.d_year              in (1999,1999+1,1999+2)\n group by\n    i_item_id\n   ,i_item_desc\n   ,s_store_id\n   ,s_store_name\n order by\n    i_item_id \n   ,i_item_desc\n   ,s_store_id\n   ,s_store_name\n LIMIT 100;",
    "optimized_sql": "WITH d1_filtered AS (SELECT d_date_sk FROM date_dim WHERE d_moy = 4 AND d_year = 1999), d2_filtered AS (SELECT d_date_sk FROM date_dim WHERE d_moy BETWEEN 4 AND 7 AND d_year = 1999), d3_filtered AS (SELECT d_date_sk FROM date_dim WHERE d_year IN (1999, 2000, 2001)), filtered_store_sales AS (SELECT ss.ss_item_sk, ss.ss_store_sk, ss.ss_customer_sk, ss.ss_ticket_number, ss.ss_quantity FROM store_sales AS ss JOIN d1_filtered AS d1 ON ss.ss_sold_date_sk = d1.d_date_sk), filtered_store_returns AS (SELECT sr.sr_customer_sk, sr.sr_item_sk, sr.sr_ticket_number, sr.sr_return_quantity FROM store_returns AS sr JOIN d2_filtered AS d2 ON sr.sr_returned_date_sk = d2.d_date_sk), filtered_catalog_sales AS (SELECT cs.cs_bill_customer_sk, cs.cs_item_sk, cs.cs_quantity FROM catalog_sales AS cs JOIN d3_filtered AS d3 ON cs.cs_sold_date_sk = d3.d_date_sk)\nSELECT i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name, AVG(ss.ss_quantity) AS store_sales_quantity, AVG(sr.sr_return_quantity) AS store_returns_quantity, AVG(cs.cs_quantity) AS catalog_sales_quantity FROM filtered_store_sales AS ss JOIN item AS i ON ss.ss_item_sk = i.i_item_sk JOIN store AS s ON ss.ss_store_sk = s.s_store_sk JOIN filtered_store_returns AS sr ON ss.ss_customer_sk = sr.sr_customer_sk AND ss.ss_item_sk = sr.sr_item_sk AND ss.ss_ticket_number = sr.sr_ticket_number JOIN filtered_catalog_sales AS cs ON sr.sr_customer_sk = cs.cs_bill_customer_sk AND sr.sr_item_sk = cs.cs_item_sk GROUP BY i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name ORDER BY i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name LIMIT 100;",
    "optimized_source": "kimi",
    "benchmark_query_num": 29,
    "sf10_baseline_ms": 111.91
  },
  {
    "id": "multi_dimension_prefetch",
    "name": "Multi Dimension Prefetch",
    "description": "Pre-filter multiple dimension tables (date + store) into separate CTEs before joining with fact table",
    "benchmark_queries": [
      "Q43"
    ],
    "verified_speedup": "2.71x",
    "principle": "Multi-Dimension Prefetch: when multiple dimension tables have selective filters, pre-filter ALL of them into CTEs before the fact table join. Combined selectivity compounds \u2014 each dimension CTE reduces the fact scan further.",
    "example": {
      "opportunity": "MULTI DIMENSION PREFETCH",
      "input_slice": "SELECT s_store_name, s_store_id,\n  sum(CASE WHEN (d_day_name='Sunday') THEN ss_sales_price ELSE NULL END) sun_sales,\n  sum(CASE WHEN (d_day_name='Monday') THEN ss_sales_price ELSE NULL END) mon_sales,\n  sum(CASE WHEN (d_day_name='Tuesday') THEN ss_sales_price ELSE NULL END) tue_sales,\n  sum(CASE WHEN (d_day_name='Wednesday') THEN ss_sales_price ELSE NULL END) wed_sales,\n  sum(CASE WHEN (d_day_name='Thursday') THEN ss_sales_price ELSE NULL END) thu_sales,\n  sum(CASE WHEN (d_day_name='Friday') THEN ss_sales_price ELSE NULL END) fri_sales,\n  sum(CASE WHEN (d_day_name='Saturday') THEN ss_sales_price ELSE NULL END) sat_sales\nFROM date_dim, store_sales, store\nWHERE d_date_sk = ss_sold_date_sk AND s_store_sk = ss_store_sk\n  AND s_gmt_offset = -5 AND d_year = 2000\nGROUP BY s_store_name, s_store_id\nORDER BY s_store_name, s_store_id, sun_sales, mon_sales, tue_sales, wed_sales, thu_sales, fri_sales, sat_sales\nLIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "multi_dimension_prefetch",
            "nodes": {
              "filtered_dates": "SELECT d_date_sk, d_day_name FROM date_dim WHERE d_year = 2000",
              "filtered_stores": "SELECT s_store_sk, s_store_name, s_store_id FROM store WHERE s_gmt_offset = -5",
              "main_query": "SELECT s_store_name, s_store_id, SUM(CASE WHEN (d_day_name = 'Sunday') THEN ss_sales_price ELSE NULL END) AS sun_sales, SUM(CASE WHEN (d_day_name = 'Monday') THEN ss_sales_price ELSE NULL END) AS mon_sales, SUM(CASE WHEN (d_day_name = 'Tuesday') THEN ss_sales_price ELSE NULL END) AS tue_sales, SUM(CASE WHEN (d_day_name = 'Wednesday') THEN ss_sales_price ELSE NULL END) AS wed_sales, SUM(CASE WHEN (d_day_name = 'Thursday') THEN ss_sales_price ELSE NULL END) AS thu_sales, SUM(CASE WHEN (d_day_name = 'Friday') THEN ss_sales_price ELSE NULL END) AS fri_sales, SUM(CASE WHEN (d_day_name = 'Saturday') THEN ss_sales_price ELSE NULL END) AS sat_sales FROM store_sales JOIN filtered_dates ON d_date_sk = ss_sold_date_sk JOIN filtered_stores ON s_store_sk = ss_store_sk GROUP BY s_store_name, s_store_id ORDER BY s_store_name, s_store_id, sun_sales, mon_sales, tue_sales, wed_sales, thu_sales, fri_sales, sat_sales LIMIT 100"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output"
            ],
            "expected_speedup": "2.71x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Multi-Dimension Prefetch \u2014 when multiple dimension tables have selective filters, pre-filter ALL of them into CTEs before the fact join. Each CTE creates a small hash table; the fact scan probes multiple tiny tables instead of large ones. Here: pre-filter both date_dim and store into separate CTEs with only the columns needed for join and grouping.",
      "when_not_to_use": "Do not create dimension CTEs without a WHERE clause that actually reduces rows \u2014 an unfiltered dimension CTE is pure overhead (full scan + materialization for zero selectivity benefit). Avoid on queries with 5+ tables and complex inter-table predicates where forcing join order via CTEs prevents the optimizer from choosing a better plan. Caused 0.85x on Q67 (unfiltered dimension CTEs added overhead) and 0.77x on Q72 (forced suboptimal join ordering on complex multi-table query)."
    },
    "original_sql": "select s_store_name, s_store_id,\n        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,\n        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,\n        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,\n        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,\n        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,\n        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,\n        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales\n from date_dim, store_sales, store\n where d_date_sk = ss_sold_date_sk and\n       s_store_sk = ss_store_sk and\n       s_gmt_offset = -5 and\n       d_year = 2000 \n group by s_store_name, s_store_id\n order by s_store_name, s_store_id,sun_sales,mon_sales,tue_sales,wed_sales,thu_sales,fri_sales,sat_sales\n LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk, d_day_name FROM date_dim WHERE d_year = 2000), filtered_stores AS (SELECT s_store_sk, s_store_id, s_store_name FROM store WHERE s_gmt_offset = -5), filtered_sales AS (SELECT ss_sales_price, d_day_name, s_store_id, s_store_name FROM store_sales JOIN filtered_dates ON d_date_sk = ss_sold_date_sk JOIN filtered_stores ON s_store_sk = ss_store_sk)\nSELECT s_store_name, s_store_id, SUM(CASE WHEN (d_day_name = 'Sunday') THEN ss_sales_price ELSE NULL END) AS sun_sales, SUM(CASE WHEN (d_day_name = 'Monday') THEN ss_sales_price ELSE NULL END) AS mon_sales, SUM(CASE WHEN (d_day_name = 'Tuesday') THEN ss_sales_price ELSE NULL END) AS tue_sales, SUM(CASE WHEN (d_day_name = 'Wednesday') THEN ss_sales_price ELSE NULL END) AS wed_sales, SUM(CASE WHEN (d_day_name = 'Thursday') THEN ss_sales_price ELSE NULL END) AS thu_sales, SUM(CASE WHEN (d_day_name = 'Friday') THEN ss_sales_price ELSE NULL END) AS fri_sales, SUM(CASE WHEN (d_day_name = 'Saturday') THEN ss_sales_price ELSE NULL END) AS sat_sales FROM filtered_sales GROUP BY s_store_name, s_store_id ORDER BY s_store_name, s_store_id, sun_sales, mon_sales, tue_sales, wed_sales, thu_sales, fri_sales, sat_sales LIMIT 100;",
    "optimized_source": "dsr1",
    "benchmark_query_num": 43,
    "sf10_baseline_ms": 129.93,
    "sf10_speedup": 1.07,
    "sf10_rows_match": true
  },
  {
    "id": "multi_intersect_exists_cte",
    "name": "Multi-INTERSECT to EXISTS with CTEs",
    "description": "Convert cascading INTERSECT operations into correlated EXISTS subqueries with pre-materialized date and channel CTEs",
    "benchmark_queries": [
      "Q14"
    ],
    "verified_speedup": "2.39x",
    "engine": "duckdb",
    "example": {
      "opportunity": "INTERSECT_TO_EXISTS + DATE_CTE_ISOLATE + MATERIALIZE_CTE",
      "input_slice": "with cross_items as\n (select i_item_sk ss_item_sk from item,\n  (select iss.i_brand_id brand_id, iss.i_class_id class_id, iss.i_category_id category_id\n   from store_sales, item iss, date_dim d1\n   where ss_item_sk = iss.i_item_sk and ss_sold_date_sk = d1.d_date_sk\n     and d1.d_year between 2000 AND 2002\n   intersect\n   select ics.i_brand_id, ics.i_class_id, ics.i_category_id\n   from catalog_sales, item ics, date_dim d2\n   where cs_item_sk = ics.i_item_sk and cs_sold_date_sk = d2.d_date_sk\n     and d2.d_year between 2000 AND 2002\n   intersect\n   select iws.i_brand_id, iws.i_class_id, iws.i_category_id\n   from web_sales, item iws, date_dim d3\n   where ws_item_sk = iws.i_item_sk and ws_sold_date_sk = d3.d_date_sk\n     and d3.d_year between 2000 AND 2002)\n  where i_brand_id = brand_id and i_class_id = class_id and i_category_id = category_id)",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "intersect_to_exists",
            "nodes": {
              "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_year BETWEEN 2000 AND 2002",
              "cross_items": "SELECT i_item_sk AS ss_item_sk, i_brand_id, i_class_id, i_category_id FROM item WHERE EXISTS (SELECT 1 FROM store_sales JOIN item iss ON ss_item_sk = iss.i_item_sk JOIN filtered_dates d1 ON ss_sold_date_sk = d1.d_date_sk WHERE iss.i_brand_id = item.i_brand_id AND iss.i_class_id = item.i_class_id AND iss.i_category_id = item.i_category_id) AND EXISTS (SELECT 1 FROM catalog_sales JOIN item ics ON cs_item_sk = ics.i_item_sk JOIN filtered_dates d2 ON cs_sold_date_sk = d2.d_date_sk WHERE ics.i_brand_id = item.i_brand_id AND ics.i_class_id = item.i_class_id AND ics.i_category_id = item.i_category_id) AND EXISTS (SELECT 1 FROM web_sales JOIN item iws ON ws_item_sk = iws.i_item_sk JOIN filtered_dates d3 ON ws_sold_date_sk = d3.d_date_sk WHERE iws.i_brand_id = item.i_brand_id AND iws.i_class_id = item.i_class_id AND iws.i_category_id = item.i_category_id)"
            },
            "invariants_kept": [
              "same cross-channel items identified",
              "output columns unchanged"
            ],
            "expected_speedup": "2.39x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "INTERSECT materializes full intermediate result sets (brand_id, class_id, category_id triples) from each channel before intersecting. EXISTS with correlated predicates short-circuits early \u2014 once a matching row is found for each channel, processing stops. Pre-filtering date_dim into a CTE avoids repeated scans of the 73K-row date table.",
      "when_not_to_use": "Do not use when the INTERSECT operates on small result sets (< 1000 rows) where materialization cost is negligible. Also not applicable when the EXISTS correlation would be on non-indexed columns, as the correlated probe could be slower than the hash-based INTERSECT."
    },
    "original_sql": "with cross_items as\n (select i_item_sk ss_item_sk\n from item,\n (select iss.i_brand_id brand_id, iss.i_class_id class_id, iss.i_category_id category_id\n from store_sales, item iss, date_dim d1\n where ss_item_sk = iss.i_item_sk and ss_sold_date_sk = d1.d_date_sk\n   and d1.d_year between 2000 AND 2000 + 2\n intersect\n select ics.i_brand_id, ics.i_class_id, ics.i_category_id\n from catalog_sales, item ics, date_dim d2\n where cs_item_sk = ics.i_item_sk and cs_sold_date_sk = d2.d_date_sk\n   and d2.d_year between 2000 AND 2000 + 2\n intersect\n select iws.i_brand_id, iws.i_class_id, iws.i_category_id\n from web_sales, item iws, date_dim d3\n where ws_item_sk = iws.i_item_sk and ws_sold_date_sk = d3.d_date_sk\n   and d3.d_year between 2000 AND 2000 + 2)\n where i_brand_id = brand_id and i_class_id = class_id and i_category_id = category_id),\n avg_sales as\n (select avg(quantity*list_price) average_sales\n  from (select ss_quantity quantity, ss_list_price list_price from store_sales, date_dim where ss_sold_date_sk = d_date_sk and d_year between 2000 and 2000 + 2\n   union all select cs_quantity, cs_list_price from catalog_sales, date_dim where cs_sold_date_sk = d_date_sk and d_year between 2000 and 2000 + 2\n   union all select ws_quantity, ws_list_price from web_sales, date_dim where ws_sold_date_sk = d_date_sk and d_year between 2000 and 2000 + 2) x)\n select channel, i_brand_id, i_class_id, i_category_id, sum(sales), sum(number_sales)\n from (\n  select 'store' channel, i_brand_id, i_class_id, i_category_id, sum(ss_quantity*ss_list_price) sales, count(*) number_sales\n  from store_sales, item, date_dim\n  where ss_item_sk in (select ss_item_sk from cross_items) and ss_item_sk = i_item_sk and ss_sold_date_sk = d_date_sk and d_year = 2000+2 and d_moy = 11\n  group by i_brand_id, i_class_id, i_category_id\n  having sum(ss_quantity*ss_list_price) > (select average_sales from avg_sales)\n  union all\n  select 'catalog' channel, i_brand_id, i_class_id, i_category_id, sum(cs_quantity*cs_list_price) sales, count(*) number_sales\n  from catalog_sales, item, date_dim\n  where cs_item_sk in (select ss_item_sk from cross_items) and cs_item_sk = i_item_sk and cs_sold_date_sk = d_date_sk and d_year = 2000+2 and d_moy = 11\n  group by i_brand_id, i_class_id, i_category_id\n  having sum(cs_quantity*cs_list_price) > (select average_sales from avg_sales)\n  union all\n  select 'web' channel, i_brand_id, i_class_id, i_category_id, sum(ws_quantity*ws_list_price) sales, count(*) number_sales\n  from web_sales, item, date_dim\n  where ws_item_sk in (select ss_item_sk from cross_items) and ws_item_sk = i_item_sk and ws_sold_date_sk = d_date_sk and d_year = 2000+2 and d_moy = 11\n  group by i_brand_id, i_class_id, i_category_id\n  having sum(ws_quantity*ws_list_price) > (select average_sales from avg_sales)\n ) y\n group by rollup (channel, i_brand_id, i_class_id, i_category_id)\n order by channel, i_brand_id, i_class_id, i_category_id\n LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year BETWEEN 2000 AND 2002), cross_items AS (SELECT i_item_sk AS ss_item_sk, i_brand_id, i_class_id, i_category_id FROM item WHERE EXISTS (SELECT 1 FROM store_sales JOIN item iss ON ss_item_sk = iss.i_item_sk JOIN filtered_dates d1 ON ss_sold_date_sk = d1.d_date_sk WHERE iss.i_brand_id = item.i_brand_id AND iss.i_class_id = item.i_class_id AND iss.i_category_id = item.i_category_id) AND EXISTS (SELECT 1 FROM catalog_sales JOIN item ics ON cs_item_sk = ics.i_item_sk JOIN filtered_dates d2 ON cs_sold_date_sk = d2.d_date_sk WHERE ics.i_brand_id = item.i_brand_id AND ics.i_class_id = item.i_class_id AND ics.i_category_id = item.i_category_id) AND EXISTS (SELECT 1 FROM web_sales JOIN item iws ON ws_item_sk = iws.i_item_sk JOIN filtered_dates d3 ON ws_sold_date_sk = d3.d_date_sk WHERE iws.i_brand_id = item.i_brand_id AND iws.i_class_id = item.i_class_id AND iws.i_category_id = item.i_category_id)), avg_sales AS (SELECT AVG(quantity * list_price) AS average_sales FROM (SELECT ss_quantity AS quantity, ss_list_price AS list_price FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk UNION ALL SELECT cs_quantity, cs_list_price FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk UNION ALL SELECT ws_quantity, ws_list_price FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk) x), nov2002_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2002 AND d_moy = 11), store_sales_data AS (SELECT 'store' AS channel, i.i_brand_id, i.i_class_id, i.i_category_id, SUM(ss_quantity * ss_list_price) AS sales, COUNT(*) AS number_sales FROM store_sales ss JOIN item i ON ss.ss_item_sk = i.i_item_sk JOIN nov2002_dates nd ON ss.ss_sold_date_sk = nd.d_date_sk WHERE EXISTS (SELECT 1 FROM cross_items ci WHERE ci.ss_item_sk = ss.ss_item_sk) GROUP BY i.i_brand_id, i.i_class_id, i.i_category_id HAVING SUM(ss_quantity * ss_list_price) > (SELECT average_sales FROM avg_sales)), catalog_sales_data AS (SELECT 'catalog' AS channel, i.i_brand_id, i.i_class_id, i.i_category_id, SUM(cs_quantity * cs_list_price) AS sales, COUNT(*) AS number_sales FROM catalog_sales cs JOIN item i ON cs.cs_item_sk = i.i_item_sk JOIN nov2002_dates nd ON cs.cs_sold_date_sk = nd.d_date_sk WHERE EXISTS (SELECT 1 FROM cross_items ci WHERE ci.ss_item_sk = cs.cs_item_sk) GROUP BY i.i_brand_id, i.i_class_id, i.i_category_id HAVING SUM(cs_quantity * cs_list_price) > (SELECT average_sales FROM avg_sales)), web_sales_data AS (SELECT 'web' AS channel, i.i_brand_id, i.i_class_id, i.i_category_id, SUM(ws_quantity * ws_list_price) AS sales, COUNT(*) AS number_sales FROM web_sales ws JOIN item i ON ws.ws_item_sk = i.i_item_sk JOIN nov2002_dates nd ON ws.ws_sold_date_sk = nd.d_date_sk WHERE EXISTS (SELECT 1 FROM cross_items ci WHERE ci.ss_item_sk = ws.ws_item_sk) GROUP BY i.i_brand_id, i.i_class_id, i.i_category_id HAVING SUM(ws_quantity * ws_list_price) > (SELECT average_sales FROM avg_sales))\nSELECT channel, i_brand_id, i_class_id, i_category_id, SUM(sales) AS \"SUM(sales)\", SUM(number_sales) AS \"SUM(number_sales)\" FROM (SELECT * FROM store_sales_data UNION ALL SELECT * FROM catalog_sales_data UNION ALL SELECT * FROM web_sales_data) y GROUP BY ROLLUP(channel, i_brand_id, i_class_id, i_category_id) ORDER BY channel, i_brand_id, i_class_id, i_category_id LIMIT 100;",
    "optimized_source": "swarm_final_worker",
    "benchmark_query_num": 14,
    "sf10_baseline_ms": 9211.0,
    "sf10_speedup": 2.39,
    "sf10_rows_match": true
  },
  {
    "id": "or_to_union",
    "name": "OR to UNION ALL",
    "description": "Split OR conditions on different columns into UNION ALL branches for better index usage",
    "benchmark_queries": [
      "Q15"
    ],
    "verified_speedup": "3.17x",
    "principle": "OR-to-UNION Decomposition: split OR conditions on different columns into separate UNION ALL branches, each with a focused predicate. The optimizer can use different access paths per branch instead of a single scan with a complex filter.",
    "example": {
      "opportunity": "OR_TO_UNION + EARLY_FILTER",
      "input_slice": "[main_query]:\nSELECT ca_zip, sum(cs_sales_price)\nFROM catalog_sales, customer, customer_address, date_dim\nWHERE cs_bill_customer_sk = c_customer_sk\n  AND c_current_addr_sk = ca_address_sk\n  AND (substr(ca_zip,1,5) IN ('85669', '86197', '88274', '83405', '86475')\n       OR ca_state IN ('CA','WA','GA')\n       OR cs_sales_price > 500)\n  AND cs_sold_date_sk = d_date_sk\n  AND d_qoy = 1 AND d_year = 2001\nGROUP BY ca_zip ORDER BY ca_zip LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "or_to_union",
            "nodes": {
              "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_qoy = 1 AND d_year = 2001",
              "filtered_sales": "SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE substr(ca_zip,1,5) IN ('85669', '86197', '88274', '83405', '86475', '85392', '85460', '80348', '81792') UNION ALL SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE ca_state IN ('CA','WA','GA') UNION ALL SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE cs_sales_price > 500",
              "main_query": "SELECT ca_zip, SUM(cs_sales_price) FROM filtered_sales GROUP BY ca_zip ORDER BY ca_zip LIMIT 100"
            },
            "invariants_kept": [
              "output columns unchanged",
              "same rows after aggregation"
            ],
            "expected_speedup": "2.98x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: OR-to-UNION Decomposition \u2014 split OR conditions on different columns into separate UNION ALL branches, each with a focused predicate. The optimizer can use different access paths per branch instead of a single scan with a complex filter. Here: three OR branches (zip codes, states, price threshold) become three UNION ALL branches, each with its own focused predicate. Date filter extracted as shared CTE.",
      "when_not_to_use": "Do not split OR when all branches filter the SAME column on the same table (e.g., t_hour >= 8 OR t_hour <= 17). This duplicates the entire fact table scan for each branch with no selectivity benefit. Only apply when OR conditions span DIFFERENT tables or fundamentally different column families. Also never split into more than 3 UNION branches \u2014 each branch rescans the fact table. Caused 0.59x on Q90 (same-column time range split doubled fact scans) and historically 0.23x-0.41x on queries with 9+ UNION branches."
    },
    "original_sql": "select ca_zip\n       ,sum(cs_sales_price)\n from catalog_sales\n     ,customer\n     ,customer_address\n     ,date_dim\n where cs_bill_customer_sk = c_customer_sk\n \tand c_current_addr_sk = ca_address_sk \n \tand ( substr(ca_zip,1,5) in ('85669', '86197','88274','83405','86475',\n                                   '85392', '85460', '80348', '81792')\n \t      or ca_state in ('CA','WA','GA')\n \t      or cs_sales_price > 500)\n \tand cs_sold_date_sk = d_date_sk\n \tand d_qoy = 1 and d_year = 2001\n group by ca_zip\n order by ca_zip\n LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_qoy = 1 AND d_year = 2001), filtered_sales AS (SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE SUBSTRING(ca_zip, 1, 5) IN ('85669', '86197', '88274', '83405', '86475', '85392', '85460', '80348', '81792') UNION ALL SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE ca_state IN ('CA', 'WA', 'GA') UNION ALL SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE cs_sales_price > 500)\nSELECT ca_zip, SUM(cs_sales_price) FROM filtered_sales GROUP BY ca_zip ORDER BY ca_zip LIMIT 100;",
    "optimized_source": "kimi",
    "benchmark_query_num": 15,
    "sf10_baseline_ms": 76.08,
    "sf10_speedup": 1.52,
    "sf10_rows_match": true
  },
  {
    "id": "prefetch_fact_join",
    "name": "Prefetch Fact Join",
    "description": "Pre-filter dimension table into CTE, then pre-join with fact table in second CTE before joining other dimensions",
    "benchmark_queries": [
      "Q63",
      "Q65"
    ],
    "verified_speedup": "3.77x",
    "principle": "Staged Join Pipeline: build a CTE chain that progressively reduces data \u2014 first CTE filters the dimension, second CTE pre-joins filtered dimension keys with the fact table, subsequent CTEs join remaining dimensions against the already-reduced fact set.",
    "example": {
      "opportunity": "PREFETCH FACT JOIN",
      "input_slice": "SELECT * FROM (\n  SELECT i_manager_id, sum(ss_sales_price) sum_sales,\n    avg(sum(ss_sales_price)) OVER (PARTITION BY i_manager_id) avg_monthly_sales\n  FROM item, store_sales, date_dim, store\n  WHERE ss_item_sk = i_item_sk AND ss_sold_date_sk = d_date_sk AND ss_store_sk = s_store_sk\n    AND d_month_seq IN (1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211)\n    AND ((i_category IN ('Books','Children','Electronics') AND i_class IN ('personal','portable','reference','self-help') AND i_brand IN (...))\n      OR (i_category IN ('Women','Music','Men') AND i_class IN ('accessories','classical','fragrances','pants') AND i_brand IN (...)))\n  GROUP BY i_manager_id, d_moy\n) AS tmp1\nWHERE CASE WHEN avg_monthly_sales > 0 THEN ABS(sum_sales - avg_monthly_sales) / avg_monthly_sales ELSE NULL END > 0.1\nORDER BY i_manager_id, avg_monthly_sales, sum_sales LIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "prefetch_fact_join",
            "nodes": {
              "filtered_dates": "SELECT d_date_sk, d_moy FROM date_dim WHERE d_month_seq IN (1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211)",
              "filtered_sales": "SELECT ss_item_sk, ss_store_sk, ss_sales_price, d_moy FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk",
              "main_query": "SELECT * FROM (SELECT i_manager_id, SUM(ss_sales_price) AS sum_sales, AVG(SUM(ss_sales_price)) OVER (PARTITION BY i_manager_id) AS avg_monthly_sales FROM item JOIN filtered_sales ON ss_item_sk = i_item_sk JOIN store ON ss_store_sk = s_store_sk WHERE ((i_category IN ('Books', 'Children', 'Electronics') AND i_class IN ('personal', 'portable', 'reference', 'self-help') AND i_brand IN (...)) OR (i_category IN ('Women', 'Music', 'Men') AND i_class IN ('accessories', 'classical', 'fragrances', 'pants') AND i_brand IN (...))) GROUP BY i_manager_id, d_moy) AS tmp1 WHERE CASE WHEN avg_monthly_sales > 0 THEN ABS(sum_sales - avg_monthly_sales) / avg_monthly_sales ELSE NULL END > 0.1 ORDER BY i_manager_id, avg_monthly_sales, sum_sales LIMIT 100"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output"
            ],
            "expected_speedup": "3.77x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Staged Join Pipeline \u2014 build a CTE chain that progressively reduces data: first CTE filters the dimension, second CTE pre-joins the filtered dimension with the fact table to materialize a small intermediate result. Subsequent dimension joins then operate on this reduced dataset instead of the full fact table. Here: filter date_dim first, pre-join with store_sales, then join the smaller result with remaining dimensions.",
      "when_not_to_use": "Do not use on queries with baseline runtime under 50ms \u2014 CTE materialization overhead dominates on fast queries. Do not use on window-function-dominated queries where filtering is not the bottleneck. Avoid on queries with 5+ table joins and complex inter-table predicates where forcing join order via CTEs prevents the optimizer from choosing a better plan. Caused 0.50x on Q25 (fast baseline query), 0.87x on Q51 (window-function bottleneck), and 0.77x on Q72 (complex multi-table join reordering)."
    },
    "original_sql": "select * \nfrom (select i_manager_id\n             ,sum(ss_sales_price) sum_sales\n             ,avg(sum(ss_sales_price)) over (partition by i_manager_id) avg_monthly_sales\n      from item\n          ,store_sales\n          ,date_dim\n          ,store\n      where ss_item_sk = i_item_sk\n        and ss_sold_date_sk = d_date_sk\n        and ss_store_sk = s_store_sk\n        and d_month_seq in (1181,1181+1,1181+2,1181+3,1181+4,1181+5,1181+6,1181+7,1181+8,1181+9,1181+10,1181+11)\n        and ((    i_category in ('Books','Children','Electronics')\n              and i_class in ('personal','portable','reference','self-help')\n              and i_brand in ('scholaramalgamalg #14','scholaramalgamalg #7',\n\t\t                  'exportiunivamalg #9','scholaramalgamalg #9'))\n           or(    i_category in ('Women','Music','Men')\n              and i_class in ('accessories','classical','fragrances','pants')\n              and i_brand in ('amalgimporto #1','edu packscholar #1','exportiimporto #1',\n\t\t                 'importoamalg #1')))\ngroup by i_manager_id, d_moy) tmp1\nwhere case when avg_monthly_sales > 0 then abs (sum_sales - avg_monthly_sales) / avg_monthly_sales else null end > 0.1\norder by i_manager_id\n        ,avg_monthly_sales\n        ,sum_sales\n LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk, d_moy FROM date_dim WHERE d_month_seq IN (1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211)), filtered_sales AS (SELECT ss_item_sk, ss_store_sk, ss_sales_price, d_moy FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk), first_branch AS (SELECT i_manager_id, d_moy, ss_sales_price FROM item JOIN filtered_sales ON ss_item_sk = i_item_sk JOIN store ON ss_store_sk = s_store_sk WHERE i_category IN ('Books', 'Children', 'Electronics') AND i_class IN ('personal', 'portable', 'reference', 'self-help') AND i_brand IN ('scholaramalgamalg #14', 'scholaramalgamalg #7', 'exportiunivamalg #9', 'scholaramalgamalg #9')), second_branch AS (SELECT i_manager_id, d_moy, ss_sales_price FROM item JOIN filtered_sales ON ss_item_sk = i_item_sk JOIN store ON ss_store_sk = s_store_sk WHERE i_category IN ('Women', 'Music', 'Men') AND i_class IN ('accessories', 'classical', 'fragrances', 'pants') AND i_brand IN ('amalgimporto #1', 'edu packscholar #1', 'exportiimporto #1', 'importoamalg #1')), combined_sales AS (SELECT * FROM first_branch UNION ALL SELECT * FROM second_branch)\nSELECT i_manager_id, SUM(ss_sales_price) AS sum_sales, AVG(SUM(ss_sales_price)) OVER (PARTITION BY i_manager_id) AS avg_monthly_sales FROM combined_sales GROUP BY i_manager_id, d_moy HAVING CASE WHEN AVG(SUM(ss_sales_price)) OVER (PARTITION BY i_manager_id) > 0 THEN ABS(SUM(ss_sales_price) - AVG(SUM(ss_sales_price)) OVER (PARTITION BY i_manager_id)) / AVG(SUM(ss_sales_price)) OVER (PARTITION BY i_manager_id) ELSE NULL END > 0.1 ORDER BY i_manager_id, avg_monthly_sales, sum_sales LIMIT 100;",
    "optimized_source": "dsr1",
    "benchmark_query_num": 63,
    "sf10_baseline_ms": 65.25
  },
  {
    "id": "pushdown",
    "name": "Filter Pushdown",
    "description": "Push filters from outer query into CTEs/subqueries to reduce intermediate result sizes",
    "benchmark_queries": [
      "Q9"
    ],
    "verified_speedup": "2.11x",
    "principle": "Scan Consolidation: when multiple subqueries scan the same table with similar patterns, consolidate them into CTEs that compute all needed aggregates in fewer passes. Reduces N scans to fewer scans.",
    "example": {
      "opportunity": "PUSHDOWN",
      "input_slice": "[main_query]:\nSELECT CASE WHEN (SELECT COUNT(*) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20) > 2972190 \n  THEN (SELECT AVG(ss_ext_sales_price) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20)\n  ELSE (SELECT AVG(ss_net_profit) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20) END AS bucket1,\n  CASE WHEN (SELECT COUNT(*) FROM store_sales WHERE ss_quantity BETWEEN 21 AND 40) > 4505785\n  THEN (SELECT AVG(ss_ext_sales_price) FROM store_sales WHERE ss_quantity BETWEEN 21 AND 40)\n  ELSE (SELECT AVG(ss_net_profit) FROM store_sales WHERE ss_quantity BETWEEN 21 AND 40) END AS bucket2\nFROM reason WHERE r_reason_sk = 1",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "pushdown",
            "nodes": {
              "quantity_1_20_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20",
              "quantity_21_40_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 21 AND 40",
              "quantity_41_60_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 41 AND 60",
              "quantity_61_80_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 61 AND 80",
              "quantity_81_100_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 81 AND 100",
              "main_query": "SELECT CASE WHEN q1.cnt > 2972190 THEN q1.avg_ext_price ELSE q1.avg_net_profit END AS bucket1, CASE WHEN q2.cnt > 4505785 THEN q2.avg_ext_price ELSE q2.avg_net_profit END AS bucket2, CASE WHEN q3.cnt > 1575726 THEN q3.avg_ext_price ELSE q3.avg_net_profit END AS bucket3, CASE WHEN q4.cnt > 3188917 THEN q4.avg_ext_price ELSE q4.avg_net_profit END AS bucket4, CASE WHEN q5.cnt > 3525216 THEN q5.avg_ext_price ELSE q5.avg_net_profit END AS bucket5 FROM reason CROSS JOIN quantity_1_20_stats AS q1 CROSS JOIN quantity_21_40_stats AS q2 CROSS JOIN quantity_41_60_stats AS q3 CROSS JOIN quantity_61_80_stats AS q4 CROSS JOIN quantity_81_100_stats AS q5 WHERE r_reason_sk = 1"
            },
            "invariants_kept": [
              "same result rows",
              "same aggregation results",
              "same output columns"
            ],
            "expected_speedup": "2.11x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Scan Consolidation \u2014 when multiple subqueries scan the same table with similar patterns, consolidate them into a single CTE that computes all needed aggregates in one pass. Reduces N scans to 1. Here: 15+ scalar subqueries with different quantity-range filters on store_sales become CTEs, each computing count, avg_ext_price, avg_net_profit in one scan per range."
    },
    "original_sql": "select case when (select count(*) \n                  from store_sales \n                  where ss_quantity between 1 and 20) > 2972190\n            then (select avg(ss_ext_sales_price) \n                  from store_sales \n                  where ss_quantity between 1 and 20) \n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 1 and 20) end bucket1 ,\n       case when (select count(*)\n                  from store_sales\n                  where ss_quantity between 21 and 40) > 4505785\n            then (select avg(ss_ext_sales_price)\n                  from store_sales\n                  where ss_quantity between 21 and 40) \n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 21 and 40) end bucket2,\n       case when (select count(*)\n                  from store_sales\n                  where ss_quantity between 41 and 60) > 1575726\n            then (select avg(ss_ext_sales_price)\n                  from store_sales\n                  where ss_quantity between 41 and 60)\n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 41 and 60) end bucket3,\n       case when (select count(*)\n                  from store_sales\n                  where ss_quantity between 61 and 80) > 3188917\n            then (select avg(ss_ext_sales_price)\n                  from store_sales\n                  where ss_quantity between 61 and 80)\n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 61 and 80) end bucket4,\n       case when (select count(*)\n                  from store_sales\n                  where ss_quantity between 81 and 100) > 3525216\n            then (select avg(ss_ext_sales_price)\n                  from store_sales\n                  where ss_quantity between 81 and 100)\n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 81 and 100) end bucket5\nfrom reason\nwhere r_reason_sk = 1;",
    "optimized_sql": "WITH quantity_aggregations AS (SELECT CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 WHEN ss_quantity BETWEEN 21 AND 40 THEN 2 WHEN ss_quantity BETWEEN 41 AND 60 THEN 3 WHEN ss_quantity BETWEEN 61 AND 80 THEN 4 WHEN ss_quantity BETWEEN 81 AND 100 THEN 5 END AS bucket, COUNT(*) AS cnt, AVG(ss_ext_discount_amt) AS avg_disc, AVG(ss_net_paid) AS avg_net FROM store_sales WHERE ss_quantity BETWEEN 1 AND 100 GROUP BY CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 WHEN ss_quantity BETWEEN 21 AND 40 THEN 2 WHEN ss_quantity BETWEEN 41 AND 60 THEN 3 WHEN ss_quantity BETWEEN 61 AND 80 THEN 4 WHEN ss_quantity BETWEEN 81 AND 100 THEN 5 END)\nSELECT CASE WHEN q1.cnt > 74129 THEN q1.avg_disc ELSE q1.avg_net END AS bucket1, CASE WHEN q2.cnt > 122840 THEN q2.avg_disc ELSE q2.avg_net END AS bucket2, CASE WHEN q3.cnt > 56580 THEN q3.avg_disc ELSE q3.avg_net END AS bucket3, CASE WHEN q4.cnt > 10097 THEN q4.avg_disc ELSE q4.avg_net END AS bucket4, CASE WHEN q5.cnt > 165306 THEN q5.avg_disc ELSE q5.avg_net END AS bucket5 FROM reason CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 1) AS q1 CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 2) AS q2 CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 3) AS q3 CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 4) AS q4 CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 5) AS q5 WHERE r_reason_sk = 1;",
    "optimized_source": "dsr1",
    "benchmark_query_num": 9,
    "sf10_baseline_ms": 309.52,
    "sf10_speedup": 0.49,
    "sf10_rows_match": true
  },
  {
    "id": "rollup_to_union_windowing",
    "name": "ROLLUP to UNION ALL Windowing",
    "description": "Replace GROUP BY ROLLUP with explicit UNION ALL of pre-aggregated CTEs at each hierarchy level, combined with window functions for ranking",
    "benchmark_queries": [
      "Q36"
    ],
    "verified_speedup": "2.47x",
    "engine": "duckdb",
    "example": {
      "opportunity": "EARLY_FILTER + MATERIALIZE_CTE + UNION_CTE_SPLIT",
      "input_slice": "select sum(ss_net_profit)/sum(ss_ext_sales_price) as gross_margin,\n  i_category, i_class,\n  grouping(i_category)+grouping(i_class) as lochierarchy,\n  rank() over (partition by grouping(i_category)+grouping(i_class),\n    case when grouping(i_class) = 0 then i_category end\n    order by sum(ss_net_profit)/sum(ss_ext_sales_price) asc) as rank_within_parent\nfrom store_sales, date_dim d1, item, store\nwhere d1.d_year = 2002 and d1.d_date_sk = ss_sold_date_sk\n  and i_item_sk = ss_item_sk and s_store_sk = ss_store_sk\n  and s_state in ('SD','TN','GA','SC','MO','AL','MI','OH')\ngroup by rollup(i_category,i_class)\norder by lochierarchy desc, case when lochierarchy = 0 then i_category end, rank_within_parent\nLIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "early_filter",
            "nodes": {
              "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_year = 2002",
              "filtered_stores": "SELECT s_store_sk FROM store WHERE s_state IN ('SD', 'TN', 'GA', 'SC', 'MO', 'AL', 'MI', 'OH')",
              "item_sums": "SELECT ss_item_sk, SUM(ss_net_profit) AS net_profit, SUM(ss_ext_sales_price) AS sales_price FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk JOIN filtered_stores ON ss_store_sk = s_store_sk GROUP BY ss_item_sk",
              "item_aggregates": "SELECT i.i_category, i.i_class, SUM(item_sums.net_profit) AS net_profit, SUM(item_sums.sales_price) AS sales_price FROM item_sums JOIN item i ON item_sums.ss_item_sk = i.i_item_sk GROUP BY i.i_category, i.i_class",
              "detailed": "SELECT net_profit / sales_price AS gross_margin, i_category, i_class, 0 AS lochierarchy FROM item_aggregates WHERE sales_price <> 0",
              "category_summary": "SELECT SUM(net_profit) / SUM(sales_price) AS gross_margin, i_category, NULL AS i_class, 1 AS lochierarchy FROM item_aggregates WHERE sales_price <> 0 GROUP BY i_category",
              "grand_total": "SELECT SUM(net_profit) / SUM(sales_price) AS gross_margin, NULL AS i_category, NULL AS i_class, 2 AS lochierarchy FROM item_aggregates WHERE sales_price <> 0",
              "all_levels": "SELECT * FROM detailed UNION ALL SELECT * FROM category_summary UNION ALL SELECT * FROM grand_total",
              "main_query": "SELECT gross_margin, i_category, i_class, lochierarchy, CASE WHEN lochierarchy < 2 THEN RANK() OVER (PARTITION BY lochierarchy, CASE WHEN lochierarchy = 0 THEN i_category END ORDER BY gross_margin ASC) ELSE 1 END AS rank_within_parent FROM all_levels ORDER BY lochierarchy DESC, CASE WHEN lochierarchy = 0 THEN i_category END, rank_within_parent LIMIT 100"
            },
            "invariants_kept": [
              "output columns unchanged",
              "same hierarchy levels"
            ],
            "expected_speedup": "2.47x",
            "risk": "medium"
          }
        ]
      },
      "key_insight": "ROLLUP generates all grouping levels in a single pass, but the optimizer cannot specialize each level's aggregation. Breaking into explicit UNION ALL of pre-computed CTEs allows each level to use the already-aggregated item_aggregates CTE, and dimension filters are pushed into early CTEs.",
      "when_not_to_use": "Do not use when ROLLUP generates all levels efficiently (small dimension tables, few groups) or when the query genuinely needs all possible grouping set combinations. Only beneficial when specific levels need different optimization paths."
    },
    "original_sql": "select sum(ss_net_profit)/sum(ss_ext_sales_price) as gross_margin, i_category, i_class, grouping(i_category)+grouping(i_class) as lochierarchy, rank() over (partition by grouping(i_category)+grouping(i_class), case when grouping(i_class) = 0 then i_category end order by sum(ss_net_profit)/sum(ss_ext_sales_price) asc) as rank_within_parent from store_sales, date_dim d1, item, store where d1.d_year = 2002 and d1.d_date_sk = ss_sold_date_sk and i_item_sk = ss_item_sk and s_store_sk = ss_store_sk and s_state in ('SD','TN','GA','SC','MO','AL','MI','OH') group by rollup(i_category,i_class) order by lochierarchy desc, case when lochierarchy = 0 then i_category end, rank_within_parent LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2002), filtered_stores AS (SELECT s_store_sk FROM store WHERE s_state IN ('SD', 'TN', 'GA', 'SC', 'MO', 'AL', 'MI', 'OH')), item_sums AS (SELECT ss_item_sk, SUM(ss_net_profit) AS net_profit, SUM(ss_ext_sales_price) AS sales_price FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = filtered_dates.d_date_sk JOIN filtered_stores ON ss_store_sk = filtered_stores.s_store_sk GROUP BY ss_item_sk), item_aggregates AS (SELECT i.i_category, i.i_class, SUM(item_sums.net_profit) AS net_profit, SUM(item_sums.sales_price) AS sales_price FROM item_sums JOIN item i ON item_sums.ss_item_sk = i.i_item_sk GROUP BY i.i_category, i.i_class), detailed AS (SELECT net_profit / sales_price AS gross_margin, i_category, i_class, 0 AS lochierarchy FROM item_aggregates WHERE sales_price <> 0), category_summary AS (SELECT SUM(net_profit) / SUM(sales_price) AS gross_margin, i_category, NULL AS i_class, 1 AS lochierarchy FROM item_aggregates WHERE sales_price <> 0 GROUP BY i_category), grand_total AS (SELECT SUM(net_profit) / SUM(sales_price) AS gross_margin, NULL AS i_category, NULL AS i_class, 2 AS lochierarchy FROM item_aggregates WHERE sales_price <> 0), all_levels AS (SELECT * FROM detailed UNION ALL SELECT * FROM category_summary UNION ALL SELECT * FROM grand_total), ranked AS (SELECT gross_margin, i_category, i_class, lochierarchy, CASE WHEN lochierarchy < 2 THEN RANK() OVER (PARTITION BY lochierarchy, CASE WHEN lochierarchy = 0 THEN i_category END ORDER BY gross_margin ASC) ELSE 1 END AS rank_within_parent FROM all_levels)\nSELECT gross_margin, i_category, i_class, lochierarchy, rank_within_parent FROM ranked ORDER BY lochierarchy DESC, CASE WHEN lochierarchy = 0 THEN i_category END, rank_within_parent LIMIT 100;",
    "optimized_source": "swarm_final_worker",
    "benchmark_query_num": 36,
    "sf10_baseline_ms": 305.12,
    "sf10_speedup": 2.47,
    "sf10_rows_match": true
  },
  {
    "id": "self_join_decomposition",
    "name": "Self-Join Decomposition",
    "description": "Split self-joined CTE with different filter values into separate per-filter CTEs to avoid full materialization and post-filtering",
    "benchmark_queries": [
      "Q39"
    ],
    "verified_speedup": "4.76x",
    "principle": "When a CTE is self-joined with different filter values (e.g., inv1.d_moy=1 AND inv2.d_moy=2), split into separate CTEs each embedding their filter. The optimizer cannot push the outer WHERE filter into the CTE's GROUP BY, causing full materialization and post-filtering.",
    "example": {
      "opportunity": "SELF_JOIN_DECOMPOSITION",
      "input_slice": "WITH inv AS (\n  SELECT w_warehouse_name, w_warehouse_sk, i_item_sk, d_moy,\n    stdev, mean, CASE mean WHEN 0 THEN NULL ELSE stdev/mean END cov\n  FROM (SELECT w_warehouse_name, w_warehouse_sk, i_item_sk, d_moy,\n          stddev_samp(inv_quantity_on_hand) stdev, avg(inv_quantity_on_hand) mean\n        FROM inventory, item, warehouse, date_dim\n        WHERE inv_item_sk = i_item_sk AND inv_warehouse_sk = w_warehouse_sk\n          AND inv_date_sk = d_date_sk AND d_year = 1998\n        GROUP BY w_warehouse_name, w_warehouse_sk, i_item_sk, d_moy) foo\n  WHERE CASE mean WHEN 0 THEN 0 ELSE stdev/mean END > 1)\nSELECT inv1.w_warehouse_sk, inv1.i_item_sk, inv1.d_moy, inv1.mean, inv1.cov,\n       inv2.w_warehouse_sk, inv2.i_item_sk, inv2.d_moy, inv2.mean, inv2.cov\nFROM inv inv1, inv inv2\nWHERE inv1.i_item_sk = inv2.i_item_sk AND inv1.w_warehouse_sk = inv2.w_warehouse_sk\n  AND inv1.d_moy=1 AND inv2.d_moy=1+1\nORDER BY inv1.w_warehouse_sk, inv1.i_item_sk, inv1.d_moy, inv1.mean, inv1.cov,\n         inv2.d_moy, inv2.mean, inv2.cov",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "self_join_decomposition",
            "nodes": {
              "month1_stats": "SELECT w_warehouse_sk, i_item_sk, 1 AS d_moy, stddev_samp(inv_quantity_on_hand) AS stdev, avg(inv_quantity_on_hand) AS mean, CASE WHEN avg(inv_quantity_on_hand) = 0 THEN NULL ELSE stddev_samp(inv_quantity_on_hand)/avg(inv_quantity_on_hand) END AS cov FROM inventory JOIN item ON inv_item_sk = i_item_sk JOIN warehouse ON inv_warehouse_sk = w_warehouse_sk JOIN date_dim ON inv_date_sk = d_date_sk WHERE d_year = 1998 AND d_moy = 1 GROUP BY w_warehouse_sk, i_item_sk HAVING CASE WHEN avg(inv_quantity_on_hand) = 0 THEN 0 ELSE stddev_samp(inv_quantity_on_hand)/avg(inv_quantity_on_hand) END > 1",
              "month2_stats": "SELECT w_warehouse_sk, i_item_sk, 2 AS d_moy, stddev_samp(inv_quantity_on_hand) AS stdev, avg(inv_quantity_on_hand) AS mean, CASE WHEN avg(inv_quantity_on_hand) = 0 THEN NULL ELSE stddev_samp(inv_quantity_on_hand)/avg(inv_quantity_on_hand) END AS cov FROM inventory JOIN item ON inv_item_sk = i_item_sk JOIN warehouse ON inv_warehouse_sk = w_warehouse_sk JOIN date_dim ON inv_date_sk = d_date_sk WHERE d_year = 1998 AND d_moy = 2 GROUP BY w_warehouse_sk, i_item_sk HAVING CASE WHEN avg(inv_quantity_on_hand) = 0 THEN 0 ELSE stddev_samp(inv_quantity_on_hand)/avg(inv_quantity_on_hand) END > 1",
              "main_query": "SELECT month1_stats.w_warehouse_sk, month1_stats.i_item_sk, month1_stats.d_moy, month1_stats.mean, month1_stats.cov, month2_stats.w_warehouse_sk, month2_stats.i_item_sk, month2_stats.d_moy, month2_stats.mean, month2_stats.cov FROM month1_stats JOIN month2_stats ON month1_stats.w_warehouse_sk = month2_stats.w_warehouse_sk AND month1_stats.i_item_sk = month2_stats.i_item_sk ORDER BY month1_stats.w_warehouse_sk, month1_stats.i_item_sk, month1_stats.d_moy, month1_stats.mean, month1_stats.cov, month2_stats.d_moy, month2_stats.mean, month2_stats.cov"
            },
            "invariants_kept": [
              "output columns unchanged",
              "grain preserved",
              "same result rows"
            ],
            "expected_speedup": "4.76x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Self-Join Decomposition \u2014 when a CTE is self-joined with different discriminator filters (d_moy=1 vs d_moy=2), the optimizer materializes the CTE for ALL months then post-filters. Splitting into month1_stats and month2_stats CTEs each with their own d_moy filter means each CTE aggregates only its month's rows. The comma join is also converted to explicit JOIN ON. 4.76x speedup from processing 1/12th of the data in each CTE.",
      "when_not_to_use": "Only applies when the CTE is self-joined with different discriminator values. If the self-join uses the same filter on both aliases, decomposition provides no benefit."
    },
    "original_sql": "with inv as\n(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy\n       ,stdev,mean, case mean when 0 then null else stdev/mean end cov\n from(select w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy\n            ,stddev_samp(inv_quantity_on_hand) stdev,avg(inv_quantity_on_hand) mean\n      from inventory\n          ,item\n          ,warehouse\n          ,date_dim\n      where inv_item_sk = i_item_sk\n        and inv_warehouse_sk = w_warehouse_sk\n        and inv_date_sk = d_date_sk\n        and d_year =1998\n      group by w_warehouse_name,w_warehouse_sk,i_item_sk,d_moy) foo\n where case mean when 0 then 0 else stdev/mean end > 1)\nselect inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean, inv1.cov\n        ,inv2.w_warehouse_sk,inv2.i_item_sk,inv2.d_moy,inv2.mean, inv2.cov\nfrom inv inv1,inv inv2\nwhere inv1.i_item_sk = inv2.i_item_sk\n  and inv1.w_warehouse_sk =  inv2.w_warehouse_sk\n  and inv1.d_moy=1\n  and inv2.d_moy=1+1\norder by inv1.w_warehouse_sk,inv1.i_item_sk,inv1.d_moy,inv1.mean,inv1.cov\n        ,inv2.d_moy,inv2.mean, inv2.cov\n;",
    "optimized_sql": "WITH month1_stats AS (SELECT w_warehouse_sk, i_item_sk, 1 AS d_moy, stddev_samp(inv_quantity_on_hand) AS stdev, avg(inv_quantity_on_hand) AS mean, CASE WHEN avg(inv_quantity_on_hand) = 0 THEN NULL ELSE stddev_samp(inv_quantity_on_hand)/avg(inv_quantity_on_hand) END AS cov FROM inventory JOIN item ON inv_item_sk = i_item_sk JOIN warehouse ON inv_warehouse_sk = w_warehouse_sk JOIN date_dim ON inv_date_sk = d_date_sk WHERE d_year = 1998 AND d_moy = 1 GROUP BY w_warehouse_sk, i_item_sk HAVING CASE WHEN avg(inv_quantity_on_hand) = 0 THEN 0 ELSE stddev_samp(inv_quantity_on_hand)/avg(inv_quantity_on_hand) END > 1), month2_stats AS (SELECT w_warehouse_sk, i_item_sk, 2 AS d_moy, stddev_samp(inv_quantity_on_hand) AS stdev, avg(inv_quantity_on_hand) AS mean, CASE WHEN avg(inv_quantity_on_hand) = 0 THEN NULL ELSE stddev_samp(inv_quantity_on_hand)/avg(inv_quantity_on_hand) END AS cov FROM inventory JOIN item ON inv_item_sk = i_item_sk JOIN warehouse ON inv_warehouse_sk = w_warehouse_sk JOIN date_dim ON inv_date_sk = d_date_sk WHERE d_year = 1998 AND d_moy = 2 GROUP BY w_warehouse_sk, i_item_sk HAVING CASE WHEN avg(inv_quantity_on_hand) = 0 THEN 0 ELSE stddev_samp(inv_quantity_on_hand)/avg(inv_quantity_on_hand) END > 1) SELECT month1_stats.w_warehouse_sk, month1_stats.i_item_sk, month1_stats.d_moy, month1_stats.mean, month1_stats.cov, month2_stats.w_warehouse_sk, month2_stats.i_item_sk, month2_stats.d_moy, month2_stats.mean, month2_stats.cov FROM month1_stats JOIN month2_stats ON month1_stats.w_warehouse_sk = month2_stats.w_warehouse_sk AND month1_stats.i_item_sk = month2_stats.i_item_sk ORDER BY month1_stats.w_warehouse_sk, month1_stats.i_item_sk, month1_stats.d_moy, month1_stats.mean, month1_stats.cov, month2_stats.d_moy, month2_stats.mean, month2_stats.cov",
    "optimized_source": "swarm_w2",
    "benchmark_query_num": 39,
    "sf10_baseline_ms": null,
    "sf10_speedup": 4.76,
    "sf10_rows_match": true
  },
  {
    "id": "shared_dimension_multi_channel",
    "name": "Shared Dimension CTEs Across Multi-Channel Queries",
    "description": "Extract shared dimension filters (date, item, promotion) into CTEs when multiple channel CTEs (store/catalog/web) apply identical filters independently",
    "benchmark_queries": [
      "Q80"
    ],
    "verified_speedup": "1.30x",
    "principle": "Shared Dimension Extraction: when multiple channel CTEs (store/catalog/web) apply identical dimension filters, extract those shared filters into one CTE and reference it from each channel. Avoids redundant dimension scans.",
    "example": {
      "opportunity": "DIMENSION_CTE_ISOLATE + PREFETCH_FACT_JOIN",
      "input_slice": "[ssr] type=cte:\nSELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, ...\nFROM store_sales LEFT OUTER JOIN store_returns ON (...), date_dim, store, item, promotion\nWHERE ss_sold_date_sk = d_date_sk\n  AND d_date BETWEEN '1998-08-28' AND '1998-08-28' + 30 days\n  AND ss_item_sk = i_item_sk AND i_current_price > 50\n  AND ss_promo_sk = p_promo_sk AND p_channel_tv = 'N'\nGROUP BY s_store_id\n\n[wsr] type=cte:\nSELECT web_site_id, SUM(ws_ext_sales_price) AS sales, ...\nFROM web_sales LEFT OUTER JOIN web_returns ON (...), date_dim, web_site, item, promotion\nWHERE ws_sold_date_sk = d_date_sk\n  AND d_date BETWEEN '1998-08-28' AND '1998-08-28' + 30 days\n  AND ws_item_sk = i_item_sk AND i_current_price > 50\n  AND ws_promo_sk = p_promo_sk AND p_channel_tv = 'N'\nGROUP BY web_site_id\n\n[csr] type=cte: (same pattern for catalog_sales)\n\n[main_query]: SELECT channel, id, SUM(sales), SUM(returns), SUM(profit)\nFROM (ssr UNION ALL csr UNION ALL wsr) GROUP BY ROLLUP(channel, id)",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "dimension_cte_isolate",
            "nodes": {
              "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-28' AS DATE) AND (CAST('1998-08-28' AS DATE) + INTERVAL '30' DAY)",
              "filtered_items": "SELECT i_item_sk FROM item WHERE i_current_price > 50",
              "filtered_promotions": "SELECT p_promo_sk FROM promotion WHERE p_channel_tv = 'N'",
              "prefiltered_store_sales": "SELECT ss_item_sk, ss_store_sk, ss_ticket_number, ss_ext_sales_price, ss_net_profit FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk JOIN filtered_items ON ss_item_sk = i_item_sk JOIN filtered_promotions ON ss_promo_sk = p_promo_sk",
              "prefiltered_web_sales": "SELECT ws_item_sk, ws_web_site_sk, ws_order_number, ws_ext_sales_price, ws_net_profit FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk JOIN filtered_items ON ws_item_sk = i_item_sk JOIN filtered_promotions ON ws_promo_sk = p_promo_sk",
              "ssr": "SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS returns, SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM prefiltered_store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) JOIN store ON ss_store_sk = s_store_sk GROUP BY s_store_id",
              "wsr": "SELECT web_site_id, SUM(ws_ext_sales_price) AS sales, SUM(COALESCE(wr_return_amt, 0)) AS returns, SUM(ws_net_profit - COALESCE(wr_net_loss, 0)) AS profit FROM prefiltered_web_sales LEFT OUTER JOIN web_returns ON (ws_item_sk = wr_item_sk AND ws_order_number = wr_order_number) JOIN web_site ON ws_web_site_sk = web_site_sk GROUP BY web_site_id"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output",
              "same ROLLUP semantics"
            ],
            "expected_speedup": "1.30x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Shared Dimension Extraction \u2014 when multiple channel CTEs (store/catalog/web) apply identical dimension filters, extract those shared filters into common dimension CTEs and reference them from each channel. This eliminates redundant dimension scans across channels. Here: shared date, item, and promotion filters extracted once, then pre-joined with each channel's fact table. Only apply where join structure is straightforward."
    },
    "original_sql": "with ssr as\n (select  s_store_id as store_id,\n          sum(ss_ext_sales_price) as sales,\n          sum(coalesce(sr_return_amt, 0)) as \"returns\",\n          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit\n  from store_sales left outer join store_returns on\n         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),\n     date_dim,\n     store,\n     item,\n     promotion\n where ss_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-28' as date) \n                  and (cast('1998-08-28' as date) + INTERVAL 30 DAY)\n       and ss_store_sk = s_store_sk\n       and ss_item_sk = i_item_sk\n       and i_current_price > 50\n       and ss_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\n group by s_store_id)\n ,\n csr as\n (select  cp_catalog_page_id as catalog_page_id,\n          sum(cs_ext_sales_price) as sales,\n          sum(coalesce(cr_return_amount, 0)) as \"returns\",\n          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit\n  from catalog_sales left outer join catalog_returns on\n         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),\n     date_dim,\n     catalog_page,\n     item,\n     promotion\n where cs_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-28' as date)\n                  and (cast('1998-08-28' as date) + INTERVAL 30 DAY)\n        and cs_catalog_page_sk = cp_catalog_page_sk\n       and cs_item_sk = i_item_sk\n       and i_current_price > 50\n       and cs_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\ngroup by cp_catalog_page_id)\n ,\n wsr as\n (select  web_site_id,\n          sum(ws_ext_sales_price) as sales,\n          sum(coalesce(wr_return_amt, 0)) as \"returns\",\n          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit\n  from web_sales left outer join web_returns on\n         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),\n     date_dim,\n     web_site,\n     item,\n     promotion\n where ws_sold_date_sk = d_date_sk\n       and d_date between cast('1998-08-28' as date)\n                  and (cast('1998-08-28' as date) + INTERVAL 30 DAY)\n        and ws_web_site_sk = web_site_sk\n       and ws_item_sk = i_item_sk\n       and i_current_price > 50\n       and ws_promo_sk = p_promo_sk\n       and p_channel_tv = 'N'\ngroup by web_site_id)\n  select channel\n        , id\n        , sum(sales) as sales\n        , sum(\"returns\") as \"returns\"\n        , sum(profit) as profit\n from \n (select 'store channel' as channel\n        , 'store' || store_id as id\n        , sales\n        , \"returns\"\n        , profit\n from   ssr\n union all\n select 'catalog channel' as channel\n        , 'catalog_page' || catalog_page_id as id\n        , sales\n        , \"returns\"\n        , profit\n from  csr\n union all\n select 'web channel' as channel\n        , 'web_site' || web_site_id as id\n        , sales\n        , \"returns\"\n        , profit\n from   wsr\n ) x\n group by rollup (channel, id)\n order by channel\n         ,id\n LIMIT 100;",
    "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-28' AS DATE) AND (CAST('1998-08-28' AS DATE) + INTERVAL '30' DAY)), filtered_items AS (SELECT i_item_sk FROM item WHERE i_current_price > 50), filtered_promotions AS (SELECT p_promo_sk FROM promotion WHERE p_channel_tv = 'N'), prefiltered_store_sales AS (SELECT ss_item_sk, ss_store_sk, ss_ticket_number, ss_ext_sales_price, ss_net_profit FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk JOIN filtered_items ON ss_item_sk = i_item_sk JOIN filtered_promotions ON ss_promo_sk = p_promo_sk), prefiltered_web_sales AS (SELECT ws_item_sk, ws_web_site_sk, ws_order_number, ws_ext_sales_price, ws_net_profit FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk JOIN filtered_items ON ws_item_sk = i_item_sk JOIN filtered_promotions ON ws_promo_sk = p_promo_sk), ssr AS (SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS \"returns\", SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM prefiltered_store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) JOIN store ON ss_store_sk = s_store_sk GROUP BY s_store_id), wsr AS (SELECT web_site_id, SUM(ws_ext_sales_price) AS sales, SUM(COALESCE(wr_return_amt, 0)) AS \"returns\", SUM(ws_net_profit - COALESCE(wr_net_loss, 0)) AS profit FROM prefiltered_web_sales LEFT OUTER JOIN web_returns ON (ws_item_sk = wr_item_sk AND ws_order_number = wr_order_number) JOIN web_site ON ws_web_site_sk = web_site_sk GROUP BY web_site_id), csr AS (SELECT cp_catalog_page_id AS catalog_page_id, SUM(cs_ext_sales_price) AS sales, SUM(COALESCE(cr_return_amount, 0)) AS \"returns\", SUM(cs_net_profit - COALESCE(cr_net_loss, 0)) AS profit FROM catalog_sales LEFT OUTER JOIN catalog_returns ON (cs_item_sk = cr_item_sk AND cs_order_number = cr_order_number), date_dim, catalog_page, item, promotion WHERE cs_sold_date_sk = d_date_sk AND d_date BETWEEN CAST('1998-08-28' AS DATE) AND (CAST('1998-08-28' AS DATE) + INTERVAL '30' DAY) AND cs_catalog_page_sk = cp_catalog_page_sk AND cs_item_sk = i_item_sk AND i_current_price > 50 AND cs_promo_sk = p_promo_sk AND p_channel_tv = 'N' GROUP BY cp_catalog_page_id)\nSELECT channel, id, SUM(sales) AS sales, SUM(\"returns\") AS \"returns\", SUM(profit) AS profit FROM (SELECT 'store channel' AS channel, 'store' || store_id AS id, sales, \"returns\", profit FROM ssr UNION ALL SELECT 'catalog channel' AS channel, 'catalog_page' || catalog_page_id AS id, sales, \"returns\", profit FROM csr UNION ALL SELECT 'web channel' AS channel, 'web_site' || web_site_id AS id, sales, \"returns\", profit FROM wsr) AS x GROUP BY ROLLUP (channel, id) ORDER BY channel, id LIMIT 100;",
    "optimized_source": "dsr1",
    "benchmark_query_num": 80,
    "sf10_baseline_ms": 268.48,
    "sf10_speedup": 1.4,
    "sf10_rows_match": true
  },
  {
    "id": "single_pass_aggregation",
    "name": "Single Pass Aggregation",
    "description": "Consolidate multiple subqueries scanning the same table into a single CTE with conditional aggregates",
    "benchmark_queries": [
      "Q9"
    ],
    "verified_speedup": "4.47x",
    "principle": "Single-Pass Aggregation: consolidate multiple scalar subqueries on the same table into one CTE using CASE expressions inside aggregate functions. Reduces N separate table scans to 1 pass.",
    "example": {
      "opportunity": "CONSOLIDATE REPEATED SCANS",
      "input_slice": "SELECT\n  CASE WHEN (SELECT count(*) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20) > 74129\n       THEN (SELECT avg(ss_ext_discount_amt) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20)\n       ELSE (SELECT avg(ss_net_paid) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20) END AS bucket1,\n  CASE WHEN (SELECT count(*) FROM store_sales WHERE ss_quantity BETWEEN 21 AND 40) > 122840\n       THEN (SELECT avg(ss_ext_discount_amt) FROM store_sales WHERE ss_quantity BETWEEN 21 AND 40)\n       ELSE (SELECT avg(ss_net_paid) FROM store_sales WHERE ss_quantity BETWEEN 21 AND 40) END AS bucket2,\n  -- ... 3 more buckets, 15 total scans of store_sales",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "single_pass_aggregation",
            "nodes": {
              "store_sales_aggregates": "SELECT SUM(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 ELSE 0 END) AS cnt1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_ext_discount_amt END) AS avg_disc1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_net_paid END) AS avg_paid1, SUM(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN 1 ELSE 0 END) AS cnt2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_ext_discount_amt END) AS avg_disc2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_net_paid END) AS avg_paid2, SUM(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN 1 ELSE 0 END) AS cnt3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_ext_discount_amt END) AS avg_disc3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_net_paid END) AS avg_paid3, SUM(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN 1 ELSE 0 END) AS cnt4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_ext_discount_amt END) AS avg_disc4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_net_paid END) AS avg_paid4, SUM(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN 1 ELSE 0 END) AS cnt5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_ext_discount_amt END) AS avg_disc5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_net_paid END) AS avg_paid5 FROM store_sales",
              "main_query": "SELECT CASE WHEN cnt1 > 74129 THEN avg_disc1 ELSE avg_paid1 END AS bucket1, CASE WHEN cnt2 > 122840 THEN avg_disc2 ELSE avg_paid2 END AS bucket2, CASE WHEN cnt3 > 56580 THEN avg_disc3 ELSE avg_paid3 END AS bucket3, CASE WHEN cnt4 > 10097 THEN avg_disc4 ELSE avg_paid4 END AS bucket4, CASE WHEN cnt5 > 165306 THEN avg_disc5 ELSE avg_paid5 END AS bucket5 FROM store_sales_aggregates"
            },
            "invariants_kept": [
              "same result values",
              "same column output"
            ],
            "expected_speedup": "4.50x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: Single-Pass Aggregation \u2014 consolidate multiple scalar subqueries on the same table into a single CTE using CASE expressions inside aggregate functions. Each CASE routes rows to the appropriate bucket without multiple scans. Reduces N separate table scans to 1 pass. Here: 15 scalar subqueries on store_sales (5 quantity ranges x 3 aggregates each) become one CTE with conditional COUNT/AVG."
    },
    "original_sql": "select case when (select count(*) \n                  from store_sales \n                  where ss_quantity between 1 and 20) > 2972190\n            then (select avg(ss_ext_sales_price) \n                  from store_sales \n                  where ss_quantity between 1 and 20) \n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 1 and 20) end bucket1 ,\n       case when (select count(*)\n                  from store_sales\n                  where ss_quantity between 21 and 40) > 4505785\n            then (select avg(ss_ext_sales_price)\n                  from store_sales\n                  where ss_quantity between 21 and 40) \n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 21 and 40) end bucket2,\n       case when (select count(*)\n                  from store_sales\n                  where ss_quantity between 41 and 60) > 1575726\n            then (select avg(ss_ext_sales_price)\n                  from store_sales\n                  where ss_quantity between 41 and 60)\n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 41 and 60) end bucket3,\n       case when (select count(*)\n                  from store_sales\n                  where ss_quantity between 61 and 80) > 3188917\n            then (select avg(ss_ext_sales_price)\n                  from store_sales\n                  where ss_quantity between 61 and 80)\n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 61 and 80) end bucket4,\n       case when (select count(*)\n                  from store_sales\n                  where ss_quantity between 81 and 100) > 3525216\n            then (select avg(ss_ext_sales_price)\n                  from store_sales\n                  where ss_quantity between 81 and 100)\n            else (select avg(ss_net_profit)\n                  from store_sales\n                  where ss_quantity between 81 and 100) end bucket5\nfrom reason\nwhere r_reason_sk = 1;",
    "optimized_sql": "WITH sales_stats AS (SELECT COUNT(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 END) AS cnt1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_ext_sales_price END) AS avg_price1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_net_profit END) AS avg_profit1, COUNT(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN 1 END) AS cnt2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_ext_sales_price END) AS avg_price2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_net_profit END) AS avg_profit2, COUNT(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN 1 END) AS cnt3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_ext_sales_price END) AS avg_price3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_net_profit END) AS avg_profit3, COUNT(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN 1 END) AS cnt4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_ext_sales_price END) AS avg_price4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_net_profit END) AS avg_profit4, COUNT(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN 1 END) AS cnt5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_ext_sales_price END) AS avg_price5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_net_profit END) AS avg_profit5 FROM store_sales)\nSELECT CASE WHEN s.cnt1 > 2972190 THEN s.avg_price1 ELSE s.avg_profit1 END AS bucket1, CASE WHEN s.cnt2 > 4505785 THEN s.avg_price2 ELSE s.avg_profit2 END AS bucket2, CASE WHEN s.cnt3 > 1575726 THEN s.avg_price3 ELSE s.avg_profit3 END AS bucket3, CASE WHEN s.cnt4 > 3188917 THEN s.avg_price4 ELSE s.avg_profit4 END AS bucket4, CASE WHEN s.cnt5 > 3525216 THEN s.avg_price5 ELSE s.avg_profit5 END AS bucket5 FROM reason AS r, sales_stats AS s WHERE r.r_reason_sk = 1;",
    "optimized_source": "kimi_ready",
    "benchmark_query_num": 9,
    "sf10_baseline_ms": 309.52
  },
  {
    "id": "union_cte_split",
    "name": "Union CTE Split/Specialization",
    "description": "Split a generic UNION ALL CTE into specialized CTEs when the main query filters by year or discriminator - eliminates redundant scans",
    "benchmark_queries": [
      "Q74"
    ],
    "verified_speedup": "1.36x",
    "principle": "CTE Specialization: when a generic CTE is scanned multiple times with different filters (e.g., by year), split it into specialized CTEs that embed the filter in their definition. Each specialized CTE processes only its relevant subset, eliminating redundant scans.",
    "example": {
      "opportunity": "UNION_CTE_SPLIT: CTE with UNION ALL is scanned twice with different year filters - split into year-specific CTEs",
      "input_slice": "WITH wscs AS (\n  SELECT ws_sold_date_sk AS sold_date_sk, ws_ext_sales_price AS sales_price FROM web_sales\n  UNION ALL\n  SELECT cs_sold_date_sk AS sold_date_sk, cs_ext_sales_price AS sales_price FROM catalog_sales\n), wswscs AS (\nSELECT d_week_seq, SUM(CASE WHEN d_day_name='Sunday' THEN sales_price ELSE NULL END) AS sun_sales,\n       SUM(CASE WHEN d_day_name='Monday' THEN sales_price ELSE NULL END) AS mon_sales\nFROM wscs, date_dim WHERE d_date_sk = sold_date_sk GROUP BY d_week_seq\n)\nSELECT y.d_week_seq AS d_week_seq1, ROUND(y.sun_sales/z.sun_sales,2)\nFROM (SELECT wswscs.d_week_seq, wswscs.sun_sales FROM wswscs, date_dim WHERE date_dim.d_week_seq = wswscs.d_week_seq AND d_year = 1998) y,\n     (SELECT wswscs.d_week_seq, wswscs.sun_sales FROM wswscs, date_dim WHERE date_dim.d_week_seq = wswscs.d_week_seq AND d_year = 1999) z\nWHERE y.d_week_seq = z.d_week_seq - 53 ORDER BY d_week_seq1",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "union_cte_split",
            "nodes": {
              "year_1998_dates": "SELECT d_date_sk, d_week_seq, d_day_name FROM date_dim WHERE d_year = 1998",
              "year_1999_dates": "SELECT d_date_sk, d_week_seq, d_day_name FROM date_dim WHERE d_year = 1999",
              "wswscs_1998": "SELECT d_week_seq, SUM(CASE WHEN d_day_name='Sunday' THEN sales_price ELSE NULL END) AS sun_sales, SUM(CASE WHEN d_day_name='Monday' THEN sales_price ELSE NULL END) AS mon_sales, SUM(CASE WHEN d_day_name='Tuesday' THEN sales_price ELSE NULL END) AS tue_sales, SUM(CASE WHEN d_day_name='Wednesday' THEN sales_price ELSE NULL END) AS wed_sales, SUM(CASE WHEN d_day_name='Thursday' THEN sales_price ELSE NULL END) AS thu_sales, SUM(CASE WHEN d_day_name='Friday' THEN sales_price ELSE NULL END) AS fri_sales, SUM(CASE WHEN d_day_name='Saturday' THEN sales_price ELSE NULL END) AS sat_sales FROM (SELECT ws_sold_date_sk AS sold_date_sk, ws_ext_sales_price AS sales_price FROM web_sales UNION ALL SELECT cs_sold_date_sk AS sold_date_sk, cs_ext_sales_price AS sales_price FROM catalog_sales) wscs JOIN year_1998_dates ON d_date_sk = sold_date_sk GROUP BY d_week_seq",
              "wswscs_1999": "SELECT d_week_seq, SUM(CASE WHEN d_day_name='Sunday' THEN sales_price ELSE NULL END) AS sun_sales, SUM(CASE WHEN d_day_name='Monday' THEN sales_price ELSE NULL END) AS mon_sales, SUM(CASE WHEN d_day_name='Tuesday' THEN sales_price ELSE NULL END) AS tue_sales, SUM(CASE WHEN d_day_name='Wednesday' THEN sales_price ELSE NULL END) AS wed_sales, SUM(CASE WHEN d_day_name='Thursday' THEN sales_price ELSE NULL END) AS thu_sales, SUM(CASE WHEN d_day_name='Friday' THEN sales_price ELSE NULL END) AS fri_sales, SUM(CASE WHEN d_day_name='Saturday' THEN sales_price ELSE NULL END) AS sat_sales FROM (SELECT ws_sold_date_sk AS sold_date_sk, ws_ext_sales_price AS sales_price FROM web_sales UNION ALL SELECT cs_sold_date_sk AS sold_date_sk, cs_ext_sales_price AS sales_price FROM catalog_sales) wscs JOIN year_1999_dates ON d_date_sk = sold_date_sk GROUP BY d_week_seq",
              "main_query": "SELECT y.d_week_seq AS d_week_seq1, ROUND(y.sun_sales / NULLIF(z.sun_sales, 0), 2), ROUND(y.mon_sales / NULLIF(z.mon_sales, 0), 2), ROUND(y.tue_sales / NULLIF(z.tue_sales, 0), 2), ROUND(y.wed_sales / NULLIF(z.wed_sales, 0), 2), ROUND(y.thu_sales / NULLIF(z.thu_sales, 0), 2), ROUND(y.fri_sales / NULLIF(z.fri_sales, 0), 2), ROUND(y.sat_sales / NULLIF(z.sat_sales, 0), 2) FROM wswscs_1998 y JOIN wswscs_1999 z ON y.d_week_seq = z.d_week_seq - 53 ORDER BY y.d_week_seq"
            },
            "invariants_kept": [
              "same result rows",
              "same ordering",
              "same column output",
              "same aggregation semantics"
            ],
            "expected_speedup": "1.5x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Principle: CTE Specialization \u2014 when a generic CTE is scanned multiple times with different filters (e.g., by year), split it into specialized CTEs that embed the filter in their definition. Each specialized CTE processes only its relevant subset, eliminating redundant scans and post-hoc filtering. Here: generic wswscs CTE scanned twice with year filters becomes wswscs_1998 and wswscs_1999, each joining date_dim once during aggregation."
    },
    "original_sql": "with year_total as (\n select c_customer_id customer_id\n       ,c_first_name customer_first_name\n       ,c_last_name customer_last_name\n       ,d_year as year\n       ,stddev_samp(ss_net_paid) year_total\n       ,'s' sale_type\n from customer\n     ,store_sales\n     ,date_dim\n where c_customer_sk = ss_customer_sk\n   and ss_sold_date_sk = d_date_sk\n   and d_year in (1999,1999+1)\n group by c_customer_id\n         ,c_first_name\n         ,c_last_name\n         ,d_year\n union all\n select c_customer_id customer_id\n       ,c_first_name customer_first_name\n       ,c_last_name customer_last_name\n       ,d_year as year\n       ,stddev_samp(ws_net_paid) year_total\n       ,'w' sale_type\n from customer\n     ,web_sales\n     ,date_dim\n where c_customer_sk = ws_bill_customer_sk\n   and ws_sold_date_sk = d_date_sk\n   and d_year in (1999,1999+1)\n group by c_customer_id\n         ,c_first_name\n         ,c_last_name\n         ,d_year\n         )\n  select\n        t_s_secyear.customer_id, t_s_secyear.customer_first_name, t_s_secyear.customer_last_name\n from year_total t_s_firstyear\n     ,year_total t_s_secyear\n     ,year_total t_w_firstyear\n     ,year_total t_w_secyear\n where t_s_secyear.customer_id = t_s_firstyear.customer_id\n         and t_s_firstyear.customer_id = t_w_secyear.customer_id\n         and t_s_firstyear.customer_id = t_w_firstyear.customer_id\n         and t_s_firstyear.sale_type = 's'\n         and t_w_firstyear.sale_type = 'w'\n         and t_s_secyear.sale_type = 's'\n         and t_w_secyear.sale_type = 'w'\n         and t_s_firstyear.year = 1999\n         and t_s_secyear.year = 1999+1\n         and t_w_firstyear.year = 1999\n         and t_w_secyear.year = 1999+1\n         and t_s_firstyear.year_total > 0\n         and t_w_firstyear.year_total > 0\n         and case when t_w_firstyear.year_total > 0 then t_w_secyear.year_total / t_w_firstyear.year_total else null end\n           > case when t_s_firstyear.year_total > 0 then t_s_secyear.year_total / t_s_firstyear.year_total else null end\n order by 2,1,3\n LIMIT 100;",
    "optimized_sql": "WITH year_total AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, d_year AS year, STDDEV_SAMP(ss_net_paid) AS year_total, 's' AS sale_type FROM customer, store_sales, date_dim WHERE c_customer_sk = ss_customer_sk AND ss_sold_date_sk = d_date_sk AND d_year IN (1999, 1999 + 1) GROUP BY c_customer_id, c_first_name, c_last_name, d_year UNION ALL SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, d_year AS year, STDDEV_SAMP(ws_net_paid) AS year_total, 'w' AS sale_type FROM customer, web_sales, date_dim WHERE c_customer_sk = ws_bill_customer_sk AND ws_sold_date_sk = d_date_sk AND d_year IN (1999, 1999 + 1) GROUP BY c_customer_id, c_first_name, c_last_name, d_year), year_total_store AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, d_year AS year, STDDEV_SAMP(ss_net_paid) AS year_total FROM customer, store_sales, date_dim WHERE c_customer_sk = ss_customer_sk AND ss_sold_date_sk = d_date_sk AND d_year IN (1999, 1999 + 1) GROUP BY c_customer_id, c_first_name, c_last_name, d_year), year_total_web AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, d_year AS year, STDDEV_SAMP(ws_net_paid) AS year_total FROM customer, web_sales, date_dim WHERE c_customer_sk = ws_bill_customer_sk AND ws_sold_date_sk = d_date_sk AND d_year IN (1999, 1999 + 1) GROUP BY c_customer_id, c_first_name, c_last_name, d_year)\nSELECT t_s_secyear.customer_id, t_s_secyear.customer_first_name, t_s_secyear.customer_last_name FROM year_total_store AS t_s_firstyear, year_total_store AS t_s_secyear, year_total_web AS t_w_firstyear, year_total_web AS t_w_secyear WHERE t_s_secyear.customer_id = t_s_firstyear.customer_id AND t_s_firstyear.customer_id = t_w_secyear.customer_id AND t_s_firstyear.customer_id = t_w_firstyear.customer_id AND t_s_firstyear.year = 1999 AND t_s_secyear.year = 1999 + 1 AND t_w_firstyear.year = 1999 AND t_w_secyear.year = 1999 + 1 AND t_s_firstyear.year_total > 0 AND t_w_firstyear.year_total > 0 AND CASE WHEN t_w_firstyear.year_total > 0 THEN t_w_secyear.year_total / t_w_firstyear.year_total ELSE NULL END > CASE WHEN t_s_firstyear.year_total > 0 THEN t_s_secyear.year_total / t_s_firstyear.year_total ELSE NULL END ORDER BY 2, 1, 3 LIMIT 100;",
    "optimized_source": "kimi",
    "benchmark_query_num": 74,
    "sf10_baseline_ms": 1164.14,
    "sf10_speedup": 1.57,
    "sf10_rows_match": true
  },
  {
    "id": "regression_q16_semantic_rewrite",
    "type": "regression",
    "name": "Q16 regression: semantic_rewrite (0.14x)",
    "description": "Never materialize GROUP BY aggregates with HAVING clauses on fact tables before filtering those fact tables through dimension joins.",
    "verified_speedup": "0.14x",
    "query_id": "q16",
    "transform_attempted": "semantic_rewrite",
    "regression_mechanism": "Materialized a GROUP BY self-join (HAVING MIN() <> MAX()) on the entire fact table BEFORE applying date/address/call_center filters. The original query filters catalog_sales first via correlated EXISTS clauses, then checks warehouse conditions. Pre-materializing the unfiltered self-join creates a massive intermediate result the optimizer cannot cost-estimate correctly.",
    "original_sql": "-- start query 16 in stream 0 using template query16.tpl\nselect \n   count(distinct cs_order_number) as \"order count\"\n  ,sum(cs_ext_ship_cost) as \"total shipping cost\"\n  ,sum(cs_net_profit) as \"total net profit\"\nfrom\n   catalog_sales cs1\n  ,date_dim\n  ,customer_address\n  ,call_center\nwhere\n    d_date between '2002-4-01' and \n           (cast('2002-4-01' as date) + INTERVAL 60 DAY)\nand cs1.cs_ship_date_sk = d_date_sk\nand cs1.cs_ship_addr_sk = ca_address_sk\nand ca_state = 'WV'\nand cs1.cs_call_center_sk = cc_call_center_sk\nand cc_county in ('Ziebach County','Luce County','Richland County','Daviess County',\n                  'Barrow County'\n)\nand exists (select *\n            from catalog_sales cs2\n            where cs1.cs_order_number = cs2.cs_order_number\n              and cs1.cs_warehouse_sk <> cs2.cs_warehouse_sk)\nand not exists(select *\n               from catalog_returns cr1\n               where cs1.cs_order_number = cr1.cr_order_number)\norder by count(distinct cs_order_number)\n LIMIT 100;\n\n-- end query 16 in stream 0 using template query16.tpl",
    "example": {
      "before_sql": "-- start query 16 in stream 0 using template query16.tpl\nselect \n   count(distinct cs_order_number) as \"order count\"\n  ,sum(cs_ext_ship_cost) as \"total shipping cost\"\n  ,sum(cs_net_profit) as \"total net profit\"\nfrom\n   catalog_sales cs1\n  ,date_dim\n  ,customer_address\n  ,call_center\nwhere\n    d_date between '2002-4-01' and \n           (cast('2002-4-01' as date) + INTERVAL 60 DAY)\nand cs1.cs_ship_date_sk = d_date_sk\nand cs1.cs_ship_addr_sk = ca_address_sk\nand ca_state = 'WV'\nand cs1.cs_call_center_sk = cc_call_center_sk\nand cc_county in ('Ziebach County','Luce County','Richland County','Daviess County',\n                  'Barrow County'\n)\nand exists (select *\n            from catalog_sales cs2\n            where cs1.cs_order_number = cs2.cs_order_number\n              and cs1.cs_warehouse_sk <> cs2.cs_warehouse_sk)\nand not exists(select *\n               from catalog_returns cr1\n               where cs1.cs_order_number = cr1.cr_order_number)\norder by count(distinct cs_order_number)\n LIMIT 100;\n\n-- end query 16 in stream 0 using template query16.tpl",
      "after_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN '2002-4-01' AND (CAST('2002-4-01' AS DATE) + INTERVAL '60' DAY)), filtered_address AS (SELECT ca_address_sk FROM customer_address WHERE ca_state = 'WV'), filtered_call_center AS (SELECT cc_call_center_sk FROM call_center WHERE cc_county IN ('Ziebach County', 'Luce County', 'Richland County', 'Daviess County', 'Barrow County')), multi_warehouse_orders AS (SELECT DISTINCT cs_order_number FROM catalog_sales GROUP BY cs_order_number HAVING MIN(cs_warehouse_sk) <> MAX(cs_warehouse_sk)), returned_orders AS (SELECT DISTINCT cr_order_number FROM catalog_returns), filtered_sales AS (SELECT cs_order_number, cs_ext_ship_cost, cs_net_profit FROM catalog_sales AS cs1 JOIN filtered_dates ON cs1.cs_ship_date_sk = filtered_dates.d_date_sk JOIN filtered_address ON cs1.cs_ship_addr_sk = filtered_address.ca_address_sk JOIN filtered_call_center ON cs1.cs_call_center_sk = filtered_call_center.cc_call_center_sk)\nSELECT COUNT(DISTINCT fs.cs_order_number) AS \"order count\", SUM(fs.cs_ext_ship_cost) AS \"total shipping cost\", SUM(fs.cs_net_profit) AS \"total net profit\" FROM filtered_sales AS fs JOIN multi_warehouse_orders AS mwo ON fs.cs_order_number = mwo.cs_order_number LEFT JOIN returned_orders AS ro ON fs.cs_order_number = ro.cr_order_number WHERE ro.cr_order_number IS NULL ORDER BY COUNT(DISTINCT fs.cs_order_number) LIMIT 100",
      "key_insight": "Never materialize GROUP BY aggregates with HAVING clauses on fact tables before filtering those fact tables through dimension joins."
    }
  },
  {
    "id": "regression_q1_decorrelate",
    "type": "regression",
    "name": "Q1 regression: decorrelate (0.71x)",
    "description": "Do not pre-aggregate GROUP BY results into CTEs when the query uses them in a correlated comparison (e.g., customer return > 1.2x store average). The optimizer can compute aggregates incrementally with filter pushdown; materialization loses this.",
    "verified_speedup": "0.71x",
    "query_id": "q1",
    "transform_attempted": "decorrelate",
    "regression_mechanism": "Pre-computed customer_total_return (GROUP BY customer, store) and store_avg_return (GROUP BY store) as separate CTEs. The original correlated subquery computed the per-store average incrementally during the customer scan, filtering as it goes. Materializing forces full aggregation of ALL stores before any filtering.",
    "original_sql": "-- start query 1 in stream 0 using template query1.tpl\nwith customer_total_return as\n(select sr_customer_sk as ctr_customer_sk\n,sr_store_sk as ctr_store_sk\n,sum(SR_FEE) as ctr_total_return\nfrom store_returns\n,date_dim\nwhere sr_returned_date_sk = d_date_sk\nand d_year =2000\ngroup by sr_customer_sk\n,sr_store_sk)\n select c_customer_id\nfrom customer_total_return ctr1\n,store\n,customer\nwhere ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2\nfrom customer_total_return ctr2\nwhere ctr1.ctr_store_sk = ctr2.ctr_store_sk)\nand s_store_sk = ctr1.ctr_store_sk\nand s_state = 'SD'\nand ctr1.ctr_customer_sk = c_customer_sk\norder by c_customer_id\n LIMIT 100;\n\n-- end query 1 in stream 0 using template query1.tpl",
    "example": {
      "before_sql": "-- start query 1 in stream 0 using template query1.tpl\nwith customer_total_return as\n(select sr_customer_sk as ctr_customer_sk\n,sr_store_sk as ctr_store_sk\n,sum(SR_FEE) as ctr_total_return\nfrom store_returns\n,date_dim\nwhere sr_returned_date_sk = d_date_sk\nand d_year =2000\ngroup by sr_customer_sk\n,sr_store_sk)\n select c_customer_id\nfrom customer_total_return ctr1\n,store\n,customer\nwhere ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2\nfrom customer_total_return ctr2\nwhere ctr1.ctr_store_sk = ctr2.ctr_store_sk)\nand s_store_sk = ctr1.ctr_store_sk\nand s_state = 'SD'\nand ctr1.ctr_customer_sk = c_customer_sk\norder by c_customer_id\n LIMIT 100;\n\n-- end query 1 in stream 0 using template query1.tpl",
      "after_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2000), filtered_stores AS (SELECT s_store_sk FROM store WHERE s_state = 'SD'), filtered_returns AS (SELECT sr.sr_customer_sk, sr.sr_store_sk, sr.SR_FEE FROM store_returns AS sr JOIN filtered_dates ON sr.sr_returned_date_sk = d_date_sk JOIN filtered_stores ON sr.sr_store_sk = s_store_sk), customer_total_return AS (SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(SR_FEE) AS ctr_total_return FROM filtered_returns GROUP BY sr_customer_sk, sr_store_sk), store_avg_return AS (SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return_threshold FROM customer_total_return GROUP BY ctr_store_sk)\nSELECT c.c_customer_id FROM customer_total_return AS ctr1 JOIN store_avg_return AS sar ON ctr1.ctr_store_sk = sar.ctr_store_sk JOIN customer AS c ON ctr1.ctr_customer_sk = c.c_customer_sk WHERE ctr1.ctr_total_return > sar.avg_return_threshold ORDER BY c.c_customer_id LIMIT 100",
      "key_insight": "Do not pre-aggregate GROUP BY results into CTEs when the query uses them in a correlated comparison (e.g., customer return > 1.2x store average). The optimizer can compute aggregates incrementally with filter pushdown; materialization loses this."
    }
  },
  {
    "id": "regression_q25_date_cte_isolate",
    "type": "regression",
    "name": "Q25 regression: date_cte_isolate (0.5x)",
    "description": "Do not pre-filter and materialize fact tables when the query has 3+ fact table joins. The optimizer needs freedom to reorder multi-way fact joins and push filters across them.",
    "verified_speedup": "0.5x",
    "query_id": "q25",
    "transform_attempted": "date_cte_isolate",
    "regression_mechanism": "Pre-filtered and joined store_sales to date CTE BEFORE the 3-way fact table join (store_sales <- store_returns <- catalog_sales). By materializing the date-filtered store_sales early, the optimizer loses the ability to push filters across the multi-way fact join and reorder joins optimally.",
    "original_sql": "-- start query 25 in stream 0 using template query25.tpl\nselect \n i_item_id\n ,i_item_desc\n ,s_store_id\n ,s_store_name\n ,sum(ss_net_profit) as store_sales_profit\n ,sum(sr_net_loss) as store_returns_loss\n ,sum(cs_net_profit) as catalog_sales_profit\n from\n store_sales\n ,store_returns\n ,catalog_sales\n ,date_dim d1\n ,date_dim d2\n ,date_dim d3\n ,store\n ,item\n where\n d1.d_moy = 4\n and d1.d_year = 2000\n and d1.d_date_sk = ss_sold_date_sk\n and i_item_sk = ss_item_sk\n and s_store_sk = ss_store_sk\n and ss_customer_sk = sr_customer_sk\n and ss_item_sk = sr_item_sk\n and ss_ticket_number = sr_ticket_number\n and sr_returned_date_sk = d2.d_date_sk\n and d2.d_moy               between 4 and  10\n and d2.d_year              = 2000\n and sr_customer_sk = cs_bill_customer_sk\n and sr_item_sk = cs_item_sk\n and cs_sold_date_sk = d3.d_date_sk\n and d3.d_moy               between 4 and  10 \n and d3.d_year              = 2000\n group by\n i_item_id\n ,i_item_desc\n ,s_store_id\n ,s_store_name\n order by\n i_item_id\n ,i_item_desc\n ,s_store_id\n ,s_store_name\n LIMIT 100;\n\n-- end query 25 in stream 0 using template query25.tpl",
    "example": {
      "before_sql": "-- start query 25 in stream 0 using template query25.tpl\nselect \n i_item_id\n ,i_item_desc\n ,s_store_id\n ,s_store_name\n ,sum(ss_net_profit) as store_sales_profit\n ,sum(sr_net_loss) as store_returns_loss\n ,sum(cs_net_profit) as catalog_sales_profit\n from\n store_sales\n ,store_returns\n ,catalog_sales\n ,date_dim d1\n ,date_dim d2\n ,date_dim d3\n ,store\n ,item\n where\n d1.d_moy = 4\n and d1.d_year = 2000\n and d1.d_date_sk = ss_sold_date_sk\n and i_item_sk = ss_item_sk\n and s_store_sk = ss_store_sk\n and ss_customer_sk = sr_customer_sk\n and ss_item_sk = sr_item_sk\n and ss_ticket_number = sr_ticket_number\n and sr_returned_date_sk = d2.d_date_sk\n and d2.d_moy               between 4 and  10\n and d2.d_year              = 2000\n and sr_customer_sk = cs_bill_customer_sk\n and sr_item_sk = cs_item_sk\n and cs_sold_date_sk = d3.d_date_sk\n and d3.d_moy               between 4 and  10 \n and d3.d_year              = 2000\n group by\n i_item_id\n ,i_item_desc\n ,s_store_id\n ,s_store_name\n order by\n i_item_id\n ,i_item_desc\n ,s_store_id\n ,s_store_name\n LIMIT 100;\n\n-- end query 25 in stream 0 using template query25.tpl",
      "after_sql": "WITH d1_dates AS (SELECT d_date_sk FROM date_dim WHERE d_moy = 4 AND d_year = 2000), d2_dates AS (SELECT d_date_sk FROM date_dim WHERE d_moy BETWEEN 4 AND 10 AND d_year = 2000), filtered_store_sales AS (SELECT ss_item_sk, ss_customer_sk, ss_ticket_number, ss_store_sk, ss_net_profit FROM store_sales JOIN d1_dates ON store_sales.ss_sold_date_sk = d1_dates.d_date_sk), filtered_store_returns AS (SELECT sr_item_sk, sr_customer_sk, sr_ticket_number, sr_net_loss FROM store_returns JOIN d2_dates ON store_returns.sr_returned_date_sk = d2_dates.d_date_sk), filtered_catalog_sales AS (SELECT cs_item_sk, cs_bill_customer_sk, cs_net_profit FROM catalog_sales JOIN d2_dates ON catalog_sales.cs_sold_date_sk = d2_dates.d_date_sk)\nSELECT i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name, SUM(fss.ss_net_profit) AS store_sales_profit, SUM(fsr.sr_net_loss) AS store_returns_loss, SUM(fcs.cs_net_profit) AS catalog_sales_profit FROM filtered_store_sales AS fss JOIN filtered_store_returns AS fsr ON fss.ss_customer_sk = fsr.sr_customer_sk AND fss.ss_item_sk = fsr.sr_item_sk AND fss.ss_ticket_number = fsr.sr_ticket_number JOIN filtered_catalog_sales AS fcs ON fsr.sr_customer_sk = fcs.cs_bill_customer_sk AND fsr.sr_item_sk = fcs.cs_item_sk JOIN store AS s ON fss.ss_store_sk = s.s_store_sk JOIN item AS i ON fss.ss_item_sk = i.i_item_sk GROUP BY i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name ORDER BY i.i_item_id, i.i_item_desc, s.s_store_id, s.s_store_name LIMIT 100",
      "key_insight": "Do not pre-filter and materialize fact tables when the query has 3+ fact table joins. The optimizer needs freedom to reorder multi-way fact joins and push filters across them."
    }
  },
  {
    "id": "regression_q31_pushdown",
    "type": "regression",
    "name": "Q31 regression: pushdown (0.49x)",
    "description": "When creating filtered versions of existing CTEs, always REMOVE the original unfiltered CTEs. Keeping both causes redundant materialization and 1000x+ cardinality misestimates on self-joins.",
    "verified_speedup": "0.49x",
    "query_id": "q31",
    "transform_attempted": "pushdown",
    "regression_mechanism": "Created both filtered (store_sales_agg, web_sales_agg) AND original (ss, ws) versions of the same aggregations. The query does a 6-way self-join matching quarterly patterns (Q1->Q2->Q3). Duplicate CTEs doubled materialization and confused the optimizer's cardinality estimates for the multi-self-join.",
    "original_sql": "-- start query 31 in stream 0 using template query31.tpl\nwith ss as\n (select ca_county,d_qoy, d_year,sum(ss_ext_sales_price) as store_sales\n from store_sales,date_dim,customer_address\n where ss_sold_date_sk = d_date_sk\n  and ss_addr_sk=ca_address_sk\n group by ca_county,d_qoy, d_year),\n ws as\n (select ca_county,d_qoy, d_year,sum(ws_ext_sales_price) as web_sales\n from web_sales,date_dim,customer_address\n where ws_sold_date_sk = d_date_sk\n  and ws_bill_addr_sk=ca_address_sk\n group by ca_county,d_qoy, d_year)\n select \n        ss1.ca_county\n       ,ss1.d_year\n       ,ws2.web_sales/ws1.web_sales web_q1_q2_increase\n       ,ss2.store_sales/ss1.store_sales store_q1_q2_increase\n       ,ws3.web_sales/ws2.web_sales web_q2_q3_increase\n       ,ss3.store_sales/ss2.store_sales store_q2_q3_increase\n from\n        ss ss1\n       ,ss ss2\n       ,ss ss3\n       ,ws ws1\n       ,ws ws2\n       ,ws ws3\n where\n    ss1.d_qoy = 1\n    and ss1.d_year = 2000\n    and ss1.ca_county = ss2.ca_county\n    and ss2.d_qoy = 2\n    and ss2.d_year = 2000\n and ss2.ca_county = ss3.ca_county\n    and ss3.d_qoy = 3\n    and ss3.d_year = 2000\n    and ss1.ca_county = ws1.ca_county\n    and ws1.d_qoy = 1\n    and ws1.d_year = 2000\n    and ws1.ca_county = ws2.ca_county\n    and ws2.d_qoy = 2\n    and ws2.d_year = 2000\n    and ws1.ca_county = ws3.ca_county\n    and ws3.d_qoy = 3\n    and ws3.d_year =2000\n    and case when ws1.web_sales > 0 then ws2.web_sales/ws1.web_sales else null end \n       > case when ss1.store_sales > 0 then ss2.store_sales/ss1.store_sales else null end\n    and case when ws2.web_sales > 0 then ws3.web_sales/ws2.web_sales else null end\n       > case when ss2.store_sales > 0 then ss3.store_sales/ss2.store_sales else null end\n order by web_q1_q2_increase;\n\n-- end query 31 in stream 0 using template query31.tpl",
    "example": {
      "before_sql": "-- start query 31 in stream 0 using template query31.tpl\nwith ss as\n (select ca_county,d_qoy, d_year,sum(ss_ext_sales_price) as store_sales\n from store_sales,date_dim,customer_address\n where ss_sold_date_sk = d_date_sk\n  and ss_addr_sk=ca_address_sk\n group by ca_county,d_qoy, d_year),\n ws as\n (select ca_county,d_qoy, d_year,sum(ws_ext_sales_price) as web_sales\n from web_sales,date_dim,customer_address\n where ws_sold_date_sk = d_date_sk\n  and ws_bill_addr_sk=ca_address_sk\n group by ca_county,d_qoy, d_year)\n select \n        ss1.ca_county\n       ,ss1.d_year\n       ,ws2.web_sales/ws1.web_sales web_q1_q2_increase\n       ,ss2.store_sales/ss1.store_sales store_q1_q2_increase\n       ,ws3.web_sales/ws2.web_sales web_q2_q3_increase\n       ,ss3.store_sales/ss2.store_sales store_q2_q3_increase\n from\n        ss ss1\n       ,ss ss2\n       ,ss ss3\n       ,ws ws1\n       ,ws ws2\n       ,ws ws3\n where\n    ss1.d_qoy = 1\n    and ss1.d_year = 2000\n    and ss1.ca_county = ss2.ca_county\n    and ss2.d_qoy = 2\n    and ss2.d_year = 2000\n and ss2.ca_county = ss3.ca_county\n    and ss3.d_qoy = 3\n    and ss3.d_year = 2000\n    and ss1.ca_county = ws1.ca_county\n    and ws1.d_qoy = 1\n    and ws1.d_year = 2000\n    and ws1.ca_county = ws2.ca_county\n    and ws2.d_qoy = 2\n    and ws2.d_year = 2000\n    and ws1.ca_county = ws3.ca_county\n    and ws3.d_qoy = 3\n    and ws3.d_year =2000\n    and case when ws1.web_sales > 0 then ws2.web_sales/ws1.web_sales else null end \n       > case when ss1.store_sales > 0 then ss2.store_sales/ss1.store_sales else null end\n    and case when ws2.web_sales > 0 then ws3.web_sales/ws2.web_sales else null end\n       > case when ss2.store_sales > 0 then ss3.store_sales/ss2.store_sales else null end\n order by web_q1_q2_increase;\n\n-- end query 31 in stream 0 using template query31.tpl",
      "after_sql": "WITH filtered_dates AS (SELECT d_date_sk, d_qoy, d_year FROM date_dim WHERE d_year = 2000 AND d_qoy IN (1, 2, 3)), store_sales_agg AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk JOIN customer_address ON ss_addr_sk = ca_address_sk GROUP BY ca_county, d_qoy, d_year), web_sales_agg AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk JOIN customer_address ON ws_bill_addr_sk = ca_address_sk GROUP BY ca_county, d_qoy, d_year), ss AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk GROUP BY ca_county, d_qoy, d_year), ws AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk GROUP BY ca_county, d_qoy, d_year)\nSELECT ss1.ca_county, ss1.d_year, ws2.web_sales / ws1.web_sales AS web_q1_q2_increase, ss2.store_sales / ss1.store_sales AS store_q1_q2_increase, ws3.web_sales / ws2.web_sales AS web_q2_q3_increase, ss3.store_sales / ss2.store_sales AS store_q2_q3_increase FROM store_sales_agg AS ss1, store_sales_agg AS ss2, store_sales_agg AS ss3, web_sales_agg AS ws1, web_sales_agg AS ws2, web_sales_agg AS ws3 WHERE ss1.d_qoy = 1 AND ss1.d_year = 2000 AND ss1.ca_county = ss2.ca_county AND ss2.d_qoy = 2 AND ss2.d_year = 2000 AND ss2.ca_county = ss3.ca_county AND ss3.d_qoy = 3 AND ss3.d_year = 2000 AND ss1.ca_county = ws1.ca_county AND ws1.d_qoy = 1 AND ws1.d_year = 2000 AND ws1.ca_county = ws2.ca_county AND ws2.d_qoy = 2 AND ws2.d_year = 2000 AND ws1.ca_county = ws3.ca_county AND ws3.d_qoy = 3 AND ws3.d_year = 2000 AND CASE WHEN ws1.web_sales > 0 THEN ws2.web_sales / ws1.web_sales ELSE NULL END > CASE WHEN ss1.store_sales > 0 THEN ss2.store_sales / ss1.store_sales ELSE NULL END AND CASE WHEN ws2.web_sales > 0 THEN ws3.web_sales / ws2.web_sales ELSE NULL END > CASE WHEN ss2.store_sales > 0 THEN ss3.store_sales / ss2.store_sales ELSE NULL END ORDER BY web_q1_q2_increase",
      "key_insight": "When creating filtered versions of existing CTEs, always REMOVE the original unfiltered CTEs. Keeping both causes redundant materialization and 1000x+ cardinality misestimates on self-joins."
    }
  },
  {
    "id": "regression_q51_date_cte_isolate",
    "type": "regression",
    "name": "Q51 regression: date_cte_isolate (0.87x)",
    "description": "Do not materialize running/cumulative window aggregates into CTEs before joins that filter based on those aggregates. The optimizer can co-optimize window evaluation and join filtering together.",
    "verified_speedup": "0.87x",
    "query_id": "q51",
    "transform_attempted": "date_cte_isolate",
    "regression_mechanism": "Materialized cumulative window functions (SUM() OVER ORDER BY) into separate CTEs (web_v1, store_v1) before a FULL OUTER JOIN that filters on web_cumulative > store_cumulative. The original evaluates windows lazily during the join, co-optimizing window computation with the join filter. Materialization forces full window computation before filtering.",
    "original_sql": "-- start query 51 in stream 0 using template query51.tpl\nWITH web_v1 as (\nselect\n  ws_item_sk item_sk, d_date,\n  sum(sum(ws_sales_price))\n      over (partition by ws_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\nfrom web_sales\n    ,date_dim\nwhere ws_sold_date_sk=d_date_sk\n  and d_month_seq between 1216 and 1216+11\n  and ws_item_sk is not NULL\ngroup by ws_item_sk, d_date),\nstore_v1 as (\nselect\n  ss_item_sk item_sk, d_date,\n  sum(sum(ss_sales_price))\n      over (partition by ss_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\nfrom store_sales\n    ,date_dim\nwhere ss_sold_date_sk=d_date_sk\n  and d_month_seq between 1216 and 1216+11\n  and ss_item_sk is not NULL\ngroup by ss_item_sk, d_date)\n select *\nfrom (select item_sk\n     ,d_date\n     ,web_sales\n     ,store_sales\n     ,max(web_sales)\n         over (partition by item_sk order by d_date rows between unbounded preceding and current row) web_cumulative\n     ,max(store_sales)\n         over (partition by item_sk order by d_date rows between unbounded preceding and current row) store_cumulative\n     from (select case when web.item_sk is not null then web.item_sk else store.item_sk end item_sk\n                 ,case when web.d_date is not null then web.d_date else store.d_date end d_date\n                 ,web.cume_sales web_sales\n                 ,store.cume_sales store_sales\n           from web_v1 web full outer join store_v1 store on (web.item_sk = store.item_sk\n                                                          and web.d_date = store.d_date)\n          )x )y\nwhere web_cumulative > store_cumulative\norder by item_sk\n        ,d_date\n LIMIT 100;\n\n-- end query 51 in stream 0 using template query51.tpl",
    "example": {
      "before_sql": "-- start query 51 in stream 0 using template query51.tpl\nWITH web_v1 as (\nselect\n  ws_item_sk item_sk, d_date,\n  sum(sum(ws_sales_price))\n      over (partition by ws_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\nfrom web_sales\n    ,date_dim\nwhere ws_sold_date_sk=d_date_sk\n  and d_month_seq between 1216 and 1216+11\n  and ws_item_sk is not NULL\ngroup by ws_item_sk, d_date),\nstore_v1 as (\nselect\n  ss_item_sk item_sk, d_date,\n  sum(sum(ss_sales_price))\n      over (partition by ss_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\nfrom store_sales\n    ,date_dim\nwhere ss_sold_date_sk=d_date_sk\n  and d_month_seq between 1216 and 1216+11\n  and ss_item_sk is not NULL\ngroup by ss_item_sk, d_date)\n select *\nfrom (select item_sk\n     ,d_date\n     ,web_sales\n     ,store_sales\n     ,max(web_sales)\n         over (partition by item_sk order by d_date rows between unbounded preceding and current row) web_cumulative\n     ,max(store_sales)\n         over (partition by item_sk order by d_date rows between unbounded preceding and current row) store_cumulative\n     from (select case when web.item_sk is not null then web.item_sk else store.item_sk end item_sk\n                 ,case when web.d_date is not null then web.d_date else store.d_date end d_date\n                 ,web.cume_sales web_sales\n                 ,store.cume_sales store_sales\n           from web_v1 web full outer join store_v1 store on (web.item_sk = store.item_sk\n                                                          and web.d_date = store.d_date)\n          )x )y\nwhere web_cumulative > store_cumulative\norder by item_sk\n        ,d_date\n LIMIT 100;\n\n-- end query 51 in stream 0 using template query51.tpl",
      "after_sql": "WITH filtered_dates AS (SELECT d_date_sk, d_date FROM date_dim WHERE d_month_seq BETWEEN 1216 AND 1216 + 11), filtered_web_sales AS (SELECT ws_item_sk AS item_sk, d_date, ws_sales_price FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk WHERE NOT ws_item_sk IS NULL), filtered_store_sales AS (SELECT ss_item_sk AS item_sk, d_date, ss_sales_price FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk WHERE NOT ss_item_sk IS NULL), web_v1 AS (SELECT item_sk, d_date, SUM(SUM(ws_sales_price)) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS cume_sales FROM filtered_web_sales GROUP BY item_sk, d_date), store_v1 AS (SELECT item_sk, d_date, SUM(SUM(ss_sales_price)) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS cume_sales FROM filtered_store_sales GROUP BY item_sk, d_date)\nSELECT * FROM (SELECT item_sk, d_date, web_sales, store_sales, MAX(web_sales) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS web_cumulative, MAX(store_sales) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS store_cumulative FROM (SELECT CASE WHEN NOT web.item_sk IS NULL THEN web.item_sk ELSE store.item_sk END AS item_sk, CASE WHEN NOT web.d_date IS NULL THEN web.d_date ELSE store.d_date END AS d_date, web.cume_sales AS web_sales, store.cume_sales AS store_sales FROM web_v1 AS web FULL OUTER JOIN store_v1 AS store ON (web.item_sk = store.item_sk AND web.d_date = store.d_date)) AS x) AS y WHERE web_cumulative > store_cumulative ORDER BY item_sk, d_date LIMIT 100",
      "key_insight": "Do not materialize running/cumulative window aggregates into CTEs before joins that filter based on those aggregates. The optimizer can co-optimize window evaluation and join filtering together."
    }
  },
  {
    "id": "regression_q67_date_cte_isolate",
    "type": "regression",
    "name": "Q67 regression: date_cte_isolate (0.85x)",
    "description": "Do not materialize dimension filters into CTEs before complex aggregations (ROLLUP, CUBE, GROUPING SETS) with window functions. The optimizer needs to push aggregation through joins; CTEs create materialization barriers.",
    "verified_speedup": "0.85x",
    "query_id": "q67",
    "transform_attempted": "date_cte_isolate",
    "regression_mechanism": "Materialized date, store, and item dimension filters into CTEs before a ROLLUP aggregation with window functions (RANK() OVER). CTE materialization prevents the optimizer from pushing the ROLLUP and window computation down through the join tree, forcing a full materialized intermediate before the expensive aggregation.",
    "original_sql": "-- start query 67 in stream 0 using template query67.tpl\nselect *\nfrom (select i_category\n            ,i_class\n            ,i_brand\n            ,i_product_name\n            ,d_year\n            ,d_qoy\n            ,d_moy\n            ,s_store_id\n            ,sumsales\n            ,rank() over (partition by i_category order by sumsales desc) rk\n      from (select i_category\n                  ,i_class\n                  ,i_brand\n                  ,i_product_name\n                  ,d_year\n                  ,d_qoy\n                  ,d_moy\n                  ,s_store_id\n                  ,sum(coalesce(ss_sales_price*ss_quantity,0)) sumsales\n            from store_sales\n                ,date_dim\n                ,store\n                ,item\n       where  ss_sold_date_sk=d_date_sk\n          and ss_item_sk=i_item_sk\n          and ss_store_sk = s_store_sk\n          and d_month_seq between 1206 and 1206+11\n       group by  rollup(i_category, i_class, i_brand, i_product_name, d_year, d_qoy, d_moy,s_store_id))dw1) dw2\nwhere rk <= 100\norder by i_category\n        ,i_class\n        ,i_brand\n        ,i_product_name\n        ,d_year\n        ,d_qoy\n        ,d_moy\n        ,s_store_id\n        ,sumsales\n        ,rk\n LIMIT 100;\n\n-- end query 67 in stream 0 using template query67.tpl",
    "example": {
      "before_sql": "-- start query 67 in stream 0 using template query67.tpl\nselect *\nfrom (select i_category\n            ,i_class\n            ,i_brand\n            ,i_product_name\n            ,d_year\n            ,d_qoy\n            ,d_moy\n            ,s_store_id\n            ,sumsales\n            ,rank() over (partition by i_category order by sumsales desc) rk\n      from (select i_category\n                  ,i_class\n                  ,i_brand\n                  ,i_product_name\n                  ,d_year\n                  ,d_qoy\n                  ,d_moy\n                  ,s_store_id\n                  ,sum(coalesce(ss_sales_price*ss_quantity,0)) sumsales\n            from store_sales\n                ,date_dim\n                ,store\n                ,item\n       where  ss_sold_date_sk=d_date_sk\n          and ss_item_sk=i_item_sk\n          and ss_store_sk = s_store_sk\n          and d_month_seq between 1206 and 1206+11\n       group by  rollup(i_category, i_class, i_brand, i_product_name, d_year, d_qoy, d_moy,s_store_id))dw1) dw2\nwhere rk <= 100\norder by i_category\n        ,i_class\n        ,i_brand\n        ,i_product_name\n        ,d_year\n        ,d_qoy\n        ,d_moy\n        ,s_store_id\n        ,sumsales\n        ,rk\n LIMIT 100;\n\n-- end query 67 in stream 0 using template query67.tpl",
      "after_sql": "WITH filtered_dates AS (SELECT d_date_sk, d_year, d_qoy, d_moy FROM date_dim WHERE d_month_seq BETWEEN 1206 AND 1206 + 11), filtered_stores AS (SELECT s_store_sk, s_store_id FROM store), filtered_items AS (SELECT i_item_sk, i_category, i_class, i_brand, i_product_name FROM item)\nSELECT * FROM (SELECT i_category, i_class, i_brand, i_product_name, d_year, d_qoy, d_moy, s_store_id, sumsales, RANK() OVER (PARTITION BY i_category ORDER BY sumsales DESC) AS rk FROM (SELECT i_category, i_class, i_brand, i_product_name, d_year, d_qoy, d_moy, s_store_id, SUM(COALESCE(ss_sales_price * ss_quantity, 0)) AS sumsales FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk JOIN filtered_stores ON ss_store_sk = s_store_sk JOIN filtered_items ON ss_item_sk = i_item_sk GROUP BY ROLLUP (i_category, i_class, i_brand, i_product_name, d_year, d_qoy, d_moy, s_store_id)) AS dw1) AS dw2 WHERE rk <= 100 ORDER BY i_category, i_class, i_brand, i_product_name, d_year, d_qoy, d_moy, s_store_id, sumsales, rk LIMIT 100",
      "key_insight": "Do not materialize dimension filters into CTEs before complex aggregations (ROLLUP, CUBE, GROUPING SETS) with window functions. The optimizer needs to push aggregation through joins; CTEs create materialization barriers."
    }
  },
  {
    "id": "regression_q74_pushdown",
    "type": "regression",
    "name": "Q74 regression: pushdown (0.68x)",
    "description": "When splitting a UNION CTE by year, you MUST remove or replace the original UNION CTE. Keeping both the split and original versions causes redundant materialization and extreme cardinality misestimates.",
    "verified_speedup": "0.68x",
    "query_id": "q74",
    "transform_attempted": "pushdown",
    "regression_mechanism": "Created year-specific CTEs (store_sales_1999, store_sales_2000, etc.) but KEPT the original year_total union CTE alongside them. The optimizer materializes both the split versions and the original union, resulting in redundant computation. Projection cardinality estimates show 10^16x errors from the confused CTE graph.",
    "original_sql": "-- start query 74 in stream 0 using template query74.tpl\nwith year_total as (\n select c_customer_id customer_id\n       ,c_first_name customer_first_name\n       ,c_last_name customer_last_name\n       ,d_year as year\n       ,stddev_samp(ss_net_paid) year_total\n       ,'s' sale_type\n from customer\n     ,store_sales\n     ,date_dim\n where c_customer_sk = ss_customer_sk\n   and ss_sold_date_sk = d_date_sk\n   and d_year in (1999,1999+1)\n group by c_customer_id\n         ,c_first_name\n         ,c_last_name\n         ,d_year\n union all\n select c_customer_id customer_id\n       ,c_first_name customer_first_name\n       ,c_last_name customer_last_name\n       ,d_year as year\n       ,stddev_samp(ws_net_paid) year_total\n       ,'w' sale_type\n from customer\n     ,web_sales\n     ,date_dim\n where c_customer_sk = ws_bill_customer_sk\n   and ws_sold_date_sk = d_date_sk\n   and d_year in (1999,1999+1)\n group by c_customer_id\n         ,c_first_name\n         ,c_last_name\n         ,d_year\n         )\n  select\n        t_s_secyear.customer_id, t_s_secyear.customer_first_name, t_s_secyear.customer_last_name\n from year_total t_s_firstyear\n     ,year_total t_s_secyear\n     ,year_total t_w_firstyear\n     ,year_total t_w_secyear\n where t_s_secyear.customer_id = t_s_firstyear.customer_id\n         and t_s_firstyear.customer_id = t_w_secyear.customer_id\n         and t_s_firstyear.customer_id = t_w_firstyear.customer_id\n         and t_s_firstyear.sale_type = 's'\n         and t_w_firstyear.sale_type = 'w'\n         and t_s_secyear.sale_type = 's'\n         and t_w_secyear.sale_type = 'w'\n         and t_s_firstyear.year = 1999\n         and t_s_secyear.year = 1999+1\n         and t_w_firstyear.year = 1999\n         and t_w_secyear.year = 1999+1\n         and t_s_firstyear.year_total > 0\n         and t_w_firstyear.year_total > 0\n         and case when t_w_firstyear.year_total > 0 then t_w_secyear.year_total / t_w_firstyear.year_total else null end\n           > case when t_s_firstyear.year_total > 0 then t_s_secyear.year_total / t_s_firstyear.year_total else null end\n order by 2,1,3\n LIMIT 100;\n\n-- end query 74 in stream 0 using template query74.tpl",
    "example": {
      "before_sql": "-- start query 74 in stream 0 using template query74.tpl\nwith year_total as (\n select c_customer_id customer_id\n       ,c_first_name customer_first_name\n       ,c_last_name customer_last_name\n       ,d_year as year\n       ,stddev_samp(ss_net_paid) year_total\n       ,'s' sale_type\n from customer\n     ,store_sales\n     ,date_dim\n where c_customer_sk = ss_customer_sk\n   and ss_sold_date_sk = d_date_sk\n   and d_year in (1999,1999+1)\n group by c_customer_id\n         ,c_first_name\n         ,c_last_name\n         ,d_year\n union all\n select c_customer_id customer_id\n       ,c_first_name customer_first_name\n       ,c_last_name customer_last_name\n       ,d_year as year\n       ,stddev_samp(ws_net_paid) year_total\n       ,'w' sale_type\n from customer\n     ,web_sales\n     ,date_dim\n where c_customer_sk = ws_bill_customer_sk\n   and ws_sold_date_sk = d_date_sk\n   and d_year in (1999,1999+1)\n group by c_customer_id\n         ,c_first_name\n         ,c_last_name\n         ,d_year\n         )\n  select\n        t_s_secyear.customer_id, t_s_secyear.customer_first_name, t_s_secyear.customer_last_name\n from year_total t_s_firstyear\n     ,year_total t_s_secyear\n     ,year_total t_w_firstyear\n     ,year_total t_w_secyear\n where t_s_secyear.customer_id = t_s_firstyear.customer_id\n         and t_s_firstyear.customer_id = t_w_secyear.customer_id\n         and t_s_firstyear.customer_id = t_w_firstyear.customer_id\n         and t_s_firstyear.sale_type = 's'\n         and t_w_firstyear.sale_type = 'w'\n         and t_s_secyear.sale_type = 's'\n         and t_w_secyear.sale_type = 'w'\n         and t_s_firstyear.year = 1999\n         and t_s_secyear.year = 1999+1\n         and t_w_firstyear.year = 1999\n         and t_w_secyear.year = 1999+1\n         and t_s_firstyear.year_total > 0\n         and t_w_firstyear.year_total > 0\n         and case when t_w_firstyear.year_total > 0 then t_w_secyear.year_total / t_w_firstyear.year_total else null end\n           > case when t_s_firstyear.year_total > 0 then t_s_secyear.year_total / t_s_firstyear.year_total else null end\n order by 2,1,3\n LIMIT 100;\n\n-- end query 74 in stream 0 using template query74.tpl",
      "after_sql": "WITH year_1999_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year = 1999), year_2000_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2000), year_total AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, d_year AS year, STDDEV_SAMP(ss_net_paid) AS year_total, 's' AS sale_type FROM customer, store_sales, date_dim WHERE c_customer_sk = ss_customer_sk AND ss_sold_date_sk = d_date_sk AND d_year IN (1999, 1999 + 1) GROUP BY c_customer_id, c_first_name, c_last_name, d_year UNION ALL SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, d_year AS year, STDDEV_SAMP(ws_net_paid) AS year_total, 'w' AS sale_type FROM customer, web_sales, date_dim WHERE c_customer_sk = ws_bill_customer_sk AND ws_sold_date_sk = d_date_sk AND d_year IN (1999, 1999 + 1) GROUP BY c_customer_id, c_first_name, c_last_name, d_year), store_sales_1999 AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, 1999 AS year, STDDEV_SAMP(ss_net_paid) AS year_total FROM customer, store_sales, year_1999_dates WHERE c_customer_sk = ss_customer_sk AND ss_sold_date_sk = d_date_sk GROUP BY c_customer_id, c_first_name, c_last_name), store_sales_2000 AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, 2000 AS year, STDDEV_SAMP(ss_net_paid) AS year_total FROM customer, store_sales, year_2000_dates WHERE c_customer_sk = ss_customer_sk AND ss_sold_date_sk = d_date_sk GROUP BY c_customer_id, c_first_name, c_last_name), web_sales_1999 AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, 1999 AS year, STDDEV_SAMP(ws_net_paid) AS year_total FROM customer, web_sales, year_1999_dates WHERE c_customer_sk = ws_bill_customer_sk AND ws_sold_date_sk = d_date_sk GROUP BY c_customer_id, c_first_name, c_last_name), web_sales_2000 AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, 2000 AS year, STDDEV_SAMP(ws_net_paid) AS year_total FROM customer, web_sales, year_2000_dates WHERE c_customer_sk = ws_bill_customer_sk AND ws_sold_date_sk = d_date_sk GROUP BY c_customer_id, c_first_name, c_last_name), year_total_store AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, d_year AS year, STDDEV_SAMP(ss_net_paid) AS year_total FROM customer, store_sales, date_dim WHERE c_customer_sk = ss_customer_sk AND ss_sold_date_sk = d_date_sk AND d_year IN (1999, 1999 + 1) GROUP BY c_customer_id, c_first_name, c_last_name, d_year), year_total_web AS (SELECT c_customer_id AS customer_id, c_first_name AS customer_first_name, c_last_name AS customer_last_name, d_year AS year, STDDEV_SAMP(ws_net_paid) AS year_total FROM customer, web_sales, date_dim WHERE c_customer_sk = ws_bill_customer_sk AND ws_sold_date_sk = d_date_sk AND d_year IN (1999, 1999 + 1) GROUP BY c_customer_id, c_first_name, c_last_name, d_year)\nSELECT t_s_secyear.customer_id, t_s_secyear.customer_first_name, t_s_secyear.customer_last_name FROM store_sales_1999 AS t_s_firstyear, store_sales_2000 AS t_s_secyear, web_sales_1999 AS t_w_firstyear, web_sales_2000 AS t_w_secyear WHERE t_s_secyear.customer_id = t_s_firstyear.customer_id AND t_s_firstyear.customer_id = t_w_secyear.customer_id AND t_s_firstyear.customer_id = t_w_firstyear.customer_id AND t_s_firstyear.year_total > 0 AND t_w_firstyear.year_total > 0 AND CASE WHEN t_w_firstyear.year_total > 0 THEN t_w_secyear.year_total / t_w_firstyear.year_total ELSE NULL END > CASE WHEN t_s_firstyear.year_total > 0 THEN t_s_secyear.year_total / t_s_firstyear.year_total ELSE NULL END ORDER BY 2, 1, 3 LIMIT 100",
      "key_insight": "When splitting a UNION CTE by year, you MUST remove or replace the original UNION CTE. Keeping both the split and original versions causes redundant materialization and extreme cardinality misestimates."
    }
  },
  {
    "id": "regression_q90_materialize_cte",
    "type": "regression",
    "name": "Q90 regression: materialize_cte (0.59x)",
    "description": "Never convert OR conditions on the SAME column (e.g., range conditions on t_hour) into UNION ALL. The optimizer already handles same-column ORs as a single scan. UNION ALL only helps when branches access fundamentally different tables or columns.",
    "verified_speedup": "0.59x",
    "query_id": "q90",
    "transform_attempted": "materialize_cte",
    "regression_mechanism": "Split a simple OR condition (t_hour BETWEEN 10 AND 11 OR t_hour BETWEEN 16 AND 17) into UNION ALL of two separate web_sales scans. This doubles the fact table scan. DuckDB handles same-column OR ranges efficiently in a single scan \u2014 the UNION ALL adds materialization overhead with zero selectivity benefit.",
    "original_sql": "-- start query 90 in stream 0 using template query90.tpl\nselect cast(amc as decimal(15,4))/cast(pmc as decimal(15,4)) am_pm_ratio\n from ( select count(*) amc\n       from web_sales, household_demographics , time_dim, web_page\n       where ws_sold_time_sk = time_dim.t_time_sk\n         and ws_ship_hdemo_sk = household_demographics.hd_demo_sk\n         and ws_web_page_sk = web_page.wp_web_page_sk\n         and time_dim.t_hour between 10 and 10+1\n         and household_demographics.hd_dep_count = 2\n         and web_page.wp_char_count between 5000 and 5200) at_tbl,\n      ( select count(*) pmc\n       from web_sales, household_demographics , time_dim, web_page\n       where ws_sold_time_sk = time_dim.t_time_sk\n         and ws_ship_hdemo_sk = household_demographics.hd_demo_sk\n         and ws_web_page_sk = web_page.wp_web_page_sk\n         and time_dim.t_hour between 16 and 16+1\n         and household_demographics.hd_dep_count = 2\n         and web_page.wp_char_count between 5000 and 5200) pt\n order by am_pm_ratio\n LIMIT 100;\n\n-- end query 90 in stream 0 using template query90.tpl",
    "example": {
      "before_sql": "-- start query 90 in stream 0 using template query90.tpl\nselect cast(amc as decimal(15,4))/cast(pmc as decimal(15,4)) am_pm_ratio\n from ( select count(*) amc\n       from web_sales, household_demographics , time_dim, web_page\n       where ws_sold_time_sk = time_dim.t_time_sk\n         and ws_ship_hdemo_sk = household_demographics.hd_demo_sk\n         and ws_web_page_sk = web_page.wp_web_page_sk\n         and time_dim.t_hour between 10 and 10+1\n         and household_demographics.hd_dep_count = 2\n         and web_page.wp_char_count between 5000 and 5200) at_tbl,\n      ( select count(*) pmc\n       from web_sales, household_demographics , time_dim, web_page\n       where ws_sold_time_sk = time_dim.t_time_sk\n         and ws_ship_hdemo_sk = household_demographics.hd_demo_sk\n         and ws_web_page_sk = web_page.wp_web_page_sk\n         and time_dim.t_hour between 16 and 16+1\n         and household_demographics.hd_dep_count = 2\n         and web_page.wp_char_count between 5000 and 5200) pt\n order by am_pm_ratio\n LIMIT 100;\n\n-- end query 90 in stream 0 using template query90.tpl",
      "after_sql": "WITH filtered_household_demographics AS (SELECT hd_demo_sk FROM household_demographics WHERE hd_dep_count = 2), filtered_web_page AS (SELECT wp_web_page_sk FROM web_page WHERE wp_char_count BETWEEN 5000 AND 5200), filtered_time_am AS (SELECT t_time_sk FROM time_dim WHERE t_hour BETWEEN 10 AND 11), filtered_time_pm AS (SELECT t_time_sk FROM time_dim WHERE t_hour BETWEEN 16 AND 17), filtered_web_data AS (SELECT 1 AS am_flag, NULL AS pm_flag FROM web_sales AS ws JOIN filtered_household_demographics AS hd ON ws.ws_ship_hdemo_sk = hd.hd_demo_sk JOIN filtered_time_am AS t ON ws.ws_sold_time_sk = t.t_time_sk JOIN filtered_web_page AS wp ON ws.ws_web_page_sk = wp.wp_web_page_sk UNION ALL SELECT NULL AS am_flag, 1 AS pm_flag FROM web_sales AS ws JOIN filtered_household_demographics AS hd ON ws.ws_ship_hdemo_sk = hd.hd_demo_sk JOIN filtered_time_pm AS t ON ws.ws_sold_time_sk = t.t_time_sk JOIN filtered_web_page AS wp ON ws.ws_web_page_sk = wp.wp_web_page_sk), counts AS (SELECT COUNT(am_flag) AS amc, COUNT(pm_flag) AS pmc FROM filtered_web_data)\nSELECT CAST(amc AS DECIMAL(15, 4)) / CAST(pmc AS DECIMAL(15, 4)) AS am_pm_ratio FROM counts ORDER BY am_pm_ratio LIMIT 100",
      "key_insight": "Never convert OR conditions on the SAME column (e.g., range conditions on t_hour) into UNION ALL. The optimizer already handles same-column ORs as a single scan. UNION ALL only helps when branches access fundamentally different tables or columns."
    }
  },
  {
    "id": "regression_q93_decorrelate",
    "type": "regression",
    "name": "Q93 regression: decorrelate (0.34x)",
    "description": "Do not decorrelate correlated LEFT JOINs that the optimizer already executes as semi-joins. Materializing the correlated subquery into a CTE forces redundant scans.",
    "verified_speedup": "0.34x",
    "query_id": "q93",
    "transform_attempted": "decorrelate",
    "regression_mechanism": "Converted a correlated LEFT JOIN + filter into two materialized CTEs (sales_with_filtered_returns AND filtered_returns), both scanning store_returns. The original correlated LEFT JOIN was efficiently executed as a semi-join during the store_sales scan. Materializing both CTEs forces independent scans and loses the semi-join optimization.",
    "original_sql": "-- start query 93 in stream 0 using template query93.tpl\nselect ss_customer_sk\n            ,sum(act_sales) sumsales\n      from (select ss_item_sk\n                  ,ss_ticket_number\n                  ,ss_customer_sk\n                  ,case when sr_return_quantity is not null then (ss_quantity-sr_return_quantity)*ss_sales_price\n                                                            else (ss_quantity*ss_sales_price) end act_sales\n            from store_sales left outer join store_returns on (sr_item_sk = ss_item_sk\n                                                               and sr_ticket_number = ss_ticket_number)\n                ,reason\n            where sr_reason_sk = r_reason_sk\n              and r_reason_desc = 'duplicate purchase') t\n      group by ss_customer_sk\n      order by sumsales, ss_customer_sk\n LIMIT 100;\n\n-- end query 93 in stream 0 using template query93.tpl",
    "example": {
      "before_sql": "-- start query 93 in stream 0 using template query93.tpl\nselect ss_customer_sk\n            ,sum(act_sales) sumsales\n      from (select ss_item_sk\n                  ,ss_ticket_number\n                  ,ss_customer_sk\n                  ,case when sr_return_quantity is not null then (ss_quantity-sr_return_quantity)*ss_sales_price\n                                                            else (ss_quantity*ss_sales_price) end act_sales\n            from store_sales left outer join store_returns on (sr_item_sk = ss_item_sk\n                                                               and sr_ticket_number = ss_ticket_number)\n                ,reason\n            where sr_reason_sk = r_reason_sk\n              and r_reason_desc = 'duplicate purchase') t\n      group by ss_customer_sk\n      order by sumsales, ss_customer_sk\n LIMIT 100;\n\n-- end query 93 in stream 0 using template query93.tpl",
      "after_sql": "WITH filtered_reason AS (SELECT r_reason_sk FROM reason WHERE r_reason_desc = 'duplicate purchase'), sales_with_filtered_returns AS (SELECT ss.ss_customer_sk, ss.ss_item_sk, ss.ss_ticket_number, ss.ss_quantity, ss.ss_sales_price, sr.sr_return_quantity FROM store_sales AS ss LEFT JOIN (SELECT sr_item_sk, sr_ticket_number, sr_return_quantity FROM store_returns JOIN filtered_reason ON sr_reason_sk = r_reason_sk) AS sr ON (sr.sr_item_sk = ss.ss_item_sk AND sr.sr_ticket_number = ss.ss_ticket_number)), filtered_returns AS (SELECT sr_item_sk, sr_ticket_number, sr_return_quantity FROM store_returns JOIN filtered_reason ON sr_reason_sk = r_reason_sk)\nSELECT ss_customer_sk, SUM(CASE WHEN NOT sr_return_quantity IS NULL THEN (ss_quantity - sr_return_quantity) * ss_sales_price ELSE ss_quantity * ss_sales_price END) AS sumsales FROM sales_with_filtered_returns GROUP BY ss_customer_sk ORDER BY sumsales, ss_customer_sk LIMIT 100",
      "key_insight": "Do not decorrelate correlated LEFT JOINs that the optimizer already executes as semi-joins. Materializing the correlated subquery into a CTE forces redundant scans."
    }
  },
  {
    "id": "regression_q95_semantic_rewrite",
    "type": "regression",
    "name": "Q95 regression: semantic_rewrite (0.54x)",
    "description": "Do not decompose tightly-correlated EXISTS/NOT EXISTS clause pairs into independent CTEs. Their cardinality estimates depend on each other; materializing them independently causes severe join cost misestimates.",
    "verified_speedup": "0.54x",
    "query_id": "q95",
    "transform_attempted": "semantic_rewrite",
    "regression_mechanism": "Materialized complex correlated EXISTS/NOT EXISTS logic into independent CTEs (multi_warehouse_orders, returned_multi_warehouse_orders). The original EXISTS clauses were tightly correlated and evaluated together. Decoupling them into CTEs severed their cardinality relationship, causing 4x+ join estimate errors.",
    "original_sql": "-- start query 95 in stream 0 using template query95.tpl\nwith ws_wh as\n(select ws1.ws_order_number,ws1.ws_warehouse_sk wh1,ws2.ws_warehouse_sk wh2\n from web_sales ws1,web_sales ws2\n where ws1.ws_order_number = ws2.ws_order_number\n   and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)\n select \n   count(distinct ws_order_number) as \"order count\"\n  ,sum(ws_ext_ship_cost) as \"total shipping cost\"\n  ,sum(ws_net_profit) as \"total net profit\"\nfrom\n   web_sales ws1\n  ,date_dim\n  ,customer_address\n  ,web_site\nwhere\n    d_date between '1999-2-01' and \n           (cast('1999-2-01' as date) + INTERVAL 60 DAY)\nand ws1.ws_ship_date_sk = d_date_sk\nand ws1.ws_ship_addr_sk = ca_address_sk\nand ca_state = 'NC'\nand ws1.ws_web_site_sk = web_site_sk\nand web_company_name = 'pri'\nand ws1.ws_order_number in (select ws_order_number\n                            from ws_wh)\nand ws1.ws_order_number in (select wr_order_number\n                            from web_returns,ws_wh\n                            where wr_order_number = ws_wh.ws_order_number)\norder by count(distinct ws_order_number)\n LIMIT 100;\n\n-- end query 95 in stream 0 using template query95.tpl",
    "example": {
      "before_sql": "-- start query 95 in stream 0 using template query95.tpl\nwith ws_wh as\n(select ws1.ws_order_number,ws1.ws_warehouse_sk wh1,ws2.ws_warehouse_sk wh2\n from web_sales ws1,web_sales ws2\n where ws1.ws_order_number = ws2.ws_order_number\n   and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)\n select \n   count(distinct ws_order_number) as \"order count\"\n  ,sum(ws_ext_ship_cost) as \"total shipping cost\"\n  ,sum(ws_net_profit) as \"total net profit\"\nfrom\n   web_sales ws1\n  ,date_dim\n  ,customer_address\n  ,web_site\nwhere\n    d_date between '1999-2-01' and \n           (cast('1999-2-01' as date) + INTERVAL 60 DAY)\nand ws1.ws_ship_date_sk = d_date_sk\nand ws1.ws_ship_addr_sk = ca_address_sk\nand ca_state = 'NC'\nand ws1.ws_web_site_sk = web_site_sk\nand web_company_name = 'pri'\nand ws1.ws_order_number in (select ws_order_number\n                            from ws_wh)\nand ws1.ws_order_number in (select wr_order_number\n                            from web_returns,ws_wh\n                            where wr_order_number = ws_wh.ws_order_number)\norder by count(distinct ws_order_number)\n LIMIT 100;\n\n-- end query 95 in stream 0 using template query95.tpl",
      "after_sql": "WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN '1999-2-01' AND (CAST('1999-2-01' AS DATE) + INTERVAL '60' DAY)), ws_wh AS (SELECT ws1.ws_order_number, ws1.ws_warehouse_sk AS wh1, ws2.ws_warehouse_sk AS wh2 FROM web_sales AS ws1, web_sales AS ws2 WHERE ws1.ws_order_number = ws2.ws_order_number AND ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk), multi_warehouse_orders AS (SELECT DISTINCT ws_order_number FROM ws_wh), returned_multi_warehouse_orders AS (SELECT DISTINCT wr_order_number FROM web_returns AS wr JOIN ws_wh ON wr.wr_order_number = ws_wh.ws_order_number)\nSELECT COUNT(DISTINCT ws1.ws_order_number) AS \"order count\", SUM(ws1.ws_ext_ship_cost) AS \"total shipping cost\", SUM(ws1.ws_net_profit) AS \"total net profit\" FROM web_sales AS ws1 JOIN filtered_dates AS fd ON ws1.ws_ship_date_sk = fd.d_date_sk JOIN customer_address AS ca ON ws1.ws_ship_addr_sk = ca.ca_address_sk JOIN web_site AS ws ON ws1.ws_web_site_sk = ws.web_site_sk JOIN multi_warehouse_orders AS mwo ON ws1.ws_order_number = mwo.ws_order_number JOIN returned_multi_warehouse_orders AS rmwo ON ws1.ws_order_number = rmwo.wr_order_number WHERE ca.ca_state = 'NC' AND ws.web_company_name = 'pri' ORDER BY COUNT(DISTINCT ws1.ws_order_number) LIMIT 100",
      "key_insight": "Do not decompose tightly-correlated EXISTS/NOT EXISTS clause pairs into independent CTEs. Their cardinality estimates depend on each other; materializing them independently causes severe join cost misestimates."
    }
  }
]