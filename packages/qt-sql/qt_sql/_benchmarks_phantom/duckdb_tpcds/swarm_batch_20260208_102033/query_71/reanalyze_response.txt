FAILURE_ANALYSIS:
All attempts fell short because they focused solely on dimension filtering pushdown while missing the fundamental bottleneck: the massive UNION ALL of three large fact tables before any aggregation. DuckDB's optimizer can't push the item and time filters through the UNION ALL, forcing a full scan of all December 1998 sales data before filtering by manager_id=1 and meal_time. The CTE restructuring provided minor benefits (1.04x best) but didn't address the core scalability issue. Each worker essentially repackaged the same dimension-prefetching strategy without changing the join order or aggregate placement.

UNEXPLORED_OPPORTUNITIES:
1. **Aggregate pushdown before union**: Perform partial aggregation within each sales channel before UNION ALL, drastically reducing data volume.
2. **Time dimension pre-join in fact branches**: Join time_dim early in each sales channel to filter meal_time before union.
3. **Materialized view pattern**: Use CTEs to pre-aggregate sales by item and hour/minute before final brand grouping.
4. **Partition-aware restructuring**: Leverage potential physical partitioning by channel to enable parallel execution.
5. **Bloom filter application**: Use filtered_item CTE as a filter that can be pushed into each sales scan.

REFINED_STRATEGY:
Restructure to perform channel-level aggregation immediately after sales-date joins, incorporating both item and time filters at the channel level. This reduces the UNION ALL data volume by ~2-3 orders of magnitude. Specifically: 1) Filter date_dim once, 2) Join each sales table with filtered date, filtered item, AND filtered time_dim, 3) Perform partial aggregation (group by item_sk, hour, minute) within each channel, 4) UNION ALL the much smaller aggregated results, 5) Final join with item for brand details and final aggregation.

EXAMPLES: single_pass_aggregation, prefetch_fact_join, shared_dimension_multi_channel
HINT: Push aggregation into each sales channel CTE before union, ensuring time and item filters are applied at the earliest possible stage in each branch. Use the filtered dimension CTEs as broadcast hash tables for efficient joins within each channel.