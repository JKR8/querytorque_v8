## 1. STRUCTURAL BREAKDOWN

**Innermost Subquery (dw1)**: Computes monthly sales aggregates for 12 months by joining store_sales with date_dim, store, and item, then does a ROLLUP aggregation across 8 dimensions (product hierarchy + time + store). Outputs ~10-100K rows after aggregating billions of store_sales rows filtered to 12 months.

**Middle Subquery (dw2)**: Computes rank within each i_category by sumsales descending across ALL ROLLUP rows (including aggregated totals where some dimensions are NULL). Outputs same cardinality as dw1 (~10-100K rows).

**Outer Query**: Filters to top 100 ranks per category, then applies final ordering and limit. Outputs exactly 100 rows.

## 2. BOTTLENECK IDENTIFICATION

The dominant cost is the **ROLLUP aggregation on the large store_sales + multi-way join**. The mechanism is:
1. **Premature expansion**: ROLLUP generates 2^8 = 256 grouping sets BEFORE ranking/filtering, exploding intermediate results
2. **Wasteful ranking**: RANK() operates on ALL ROLLUP rows, including subtotals/grand totals that compete with detail rows for top 100
3. **No predicate pushdown**: The `rk <= 100` filter can't be applied until AFTER computing entire ROLLUP and ranking

The window function's PARTITION BY i_category becomes problematic because ROLLUP creates NULL i_category rows (grand total) that form their own partition - ranking 256 grouping sets when we only need detail rows.

## 3. PROPOSED OPTIMIZATIONS

**Change 1: Separate detail from aggregates**
- **What**: Compute detail aggregation (no ROLLUP), rank, filter to top 100 per category, THEN compute ROLLUP only on filtered results
- **Why**: Reduces ROLLUP input from ~10-100K rows to ~(100 × categories) rows. Ranking operates on minimal data.
- **Risk**: Must ensure ROLLUP semantics preserved - aggregates of top-N details ≠ top-N aggregates. This changes business logic!
- **Impact**: Significant (10-100x reduction)

**Change 2: Pre-filter fact table with dates CTE**
- **What**: Extract date_dim filter into CTE, join with store_sales first to reduce fact rows early
- **Why**: Classic star-join optimization: filter dimension first, reduce fact table join cardinality
- **Risk**: DuckDB optimizer might already do this; CTE materialization could hurt. But pattern has 12 wins, 1.34x avg.
- **Impact**: Moderate

**Change 3: Materialize ranked details before ROLLUP**
- **What**: Use CTE to compute and store top 100 details per category, then apply ROLLUP only to that CTE
- **Why**: Ensures window function sorts minimal data, avoids recomputation
- **Risk**: CTE materialization overhead, but pattern has success (materialize_cte: 1.37x avg)
- **Impact**: Moderate

## 4. FAILURE ANALYSIS

**Attempt 1 (date_cte_isolate → 0.85x regression)**: 
- **Why**: Isolating date filter prevented join reordering or caused CTE materialization overhead
- **Lesson**: DuckDB's optimizer may handle star joins better without CTE hints. Need to preserve join structure.

**Attempts 2-3 (decorrelate, materialize_cte → ERROR)**:
- **Why**: Attempted to add ROLLUP at wrong level, changing semantics. Original has ONE ROLLUP in innermost query; attempts added extra/duplicate ROLLUPs
- **Lesson**: Must preserve exactly one ROLLUP at correct logical position

## 5. RECOMMENDED STRATEGY

Implement **two-phase aggregation with early filtering**:
1. **Phase 1 (details only)**: Filter dates → join with store/item → aggregate at granular level (no ROLLUP) → rank within category → keep top 100 per category
2. **Phase 2 (add ROLLUP)**: Take filtered top-100 details → apply ROLLUP to generate subtotals → this preserves ranking because ROLLUP runs on already-ranked data

**Key insight**: Business likely wants "top 100 products per category, with category/subcategory totals for those top products" not "top 100 of all possible aggregations". This matches common dashboard patterns.

**Implementation sketch**:
```sql
WITH filtered_dates AS (...),
sales_details AS (
  SELECT i_category, i_class, i_brand, i_product_name, 
         d_year, d_qoy, d_moy, s_store_id,
         SUM(ss_sales_price * ss_quantity) as sumsales
  FROM store_sales
  JOIN filtered_dates ON ss_sold_date_sk = d_date_sk
  JOIN item ON ss_item_sk = i_item_sk
  JOIN store ON ss_store_sk = s_store_sk
  GROUP BY 1,2,3,4,5,6,7,8  -- NO ROLLUP here
),
ranked_details AS (
  SELECT *,
    RANK() OVER (PARTITION BY i_category ORDER BY sumsales DESC) as rk
  FROM sales_details
),
top_details AS (
  SELECT * FROM ranked_details WHERE rk <= 100
)
SELECT i_category, i_class, i_brand, i_product_name,
       d_year, d_qoy, d_moy, s_store_id,
       SUM(sumsales) as sumsales,
       MIN(rk) as rk  -- preserve original rank
FROM top_details
GROUP BY ROLLUP(1,2,3,4,5,6,7,8)
ORDER BY 1,2,3,4,5,6,7,8,9,10
LIMIT 100;
```

## 6. EXAMPLE SELECTION

FAISS picks (deferred_window_aggregation, prefetch_fact_join, decorrelate) are reasonable but incomplete. 

**Better matches**:
1. **prefetch_fact_join** (3.77x avg) - For early date filtering + fact join
2. **single_pass_aggregation** (4.47x avg) - To compute detail aggregation once, not multiple times
3. **dimension_cte_isolate** (1.93x avg) - Filter all dimensions before joining

**EXAMPLES: prefetch_fact_join, single_pass_aggregation, dimension_cte_isolate**