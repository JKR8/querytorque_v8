You are analyzing 5 failed optimization attempts to design a refined approach that reaches 2.0x speedup.

Your job: understand WHY each attempt fell short, identify unexplored optimization angles, and synthesize a NEW strategy that combines the best insights while avoiding repeated mistakes.

## Query: query040_agg
## Target: 2.0x speedup
## Dialect: postgres

```sql
select 
   w_state
  ,i_item_id
  ,sum(case when (cast(d_date as date) < cast ('1999-04-19' as date))
 		then cs_sales_price - coalesce(cr_refunded_cash,0) else 0 end) as sales_before
  ,sum(case when (cast(d_date as date) >= cast ('1999-04-19' as date))
 		then cs_sales_price - coalesce(cr_refunded_cash,0) else 0 end) as sales_after
 from
   catalog_sales left outer join catalog_returns on
       (cs_order_number = cr_order_number
        and cs_item_sk = cr_item_sk)
  ,warehouse
  ,item
  ,date_dim
 where
 i_item_sk          = cs_item_sk
 and cs_warehouse_sk    = w_warehouse_sk
 and cs_sold_date_sk    = d_date_sk
 and d_date between  (cast ('1999-04-19' as date) - interval '30 day')
                and (cast ('1999-04-19' as date) + interval '30 day') 
 and i_category  = 'Home'
 and i_manager_id between 25 and 64
 and cs_wholesale_cost between 17 and 36
 and cr_reason_sk = 16
 group by
    w_state,i_item_id
 order by w_state,i_item_id
limit 100;
```

## Previous Attempts

### Worker 1: early_filter_pushdown
- **Status**: pass (0.99x)
- **Transforms**: none
- **Examples used**: early_filter_decorrelate, pg_date_cte_explicit_join, pg_dimension_prefetch_star
- **Strategy hint**: Push filters on date, item, and catalog_sales early, and use explicit joins to control join order and reduce row counts.

```sql
WITH filtered_date AS (
    SELECT d_date_sk, d_date
    FROM date_dim
    WHERE d_date BETWEEN (CAST('1999-04-19' AS DATE) - INTERVAL '30 DAY')
                     AND (CAST('1999-04-19' AS DATE) + INTERVAL '30 DAY')
),
filtered_item AS (
    SELECT i_item_sk, i_item_id
    FROM item
    WHERE i_category = 'Home'
      AND i_manager_id BETWEEN 25 AND 64
),
filtered_catalog_returns AS (
    SELECT cr_order_number, cr_item_sk, cr_refunded_cash
    FROM catalog_returns
    WHERE cr_reason_sk = 16
)
SELECT
    w.w_state,
    i.i_item_id,
    SUM(
        CASE
            WHEN (CAST(d.d_date AS DATE) < CAST('1999-04-19' AS DATE))
            THEN cs.cs_sales_price - COALESCE(cr.cr_refunded_cash, 0)
            ELSE 0
        END
    ) AS sales_before,
    SUM(
        CASE
            WHEN (CAST(d.d_date AS DATE) >= CAST('1999-04-19' AS DATE))
-- ... (truncated)
```

### Worker 2: dimension_prefetch_cte
- **Status**: fail (0.90x)
- **Transforms**: none
- **Examples used**: pg_date_cte_explicit_join, pg_dimension_prefetch_star, pg_materialized_dimension_fact_prefilter
- **Strategy hint**: Pre-filter dimension tables (date_dim, item) and fact table (catalog_sales) into CTEs, then join with explicit JOIN syntax to minimize intermediate data.

```sql
WITH filtered_date AS (
    SELECT d_date_sk, d_date
    FROM date_dim
    WHERE d_date BETWEEN CAST('1999-04-19' AS DATE) - INTERVAL '30 DAY'
                     AND CAST('1999-04-19' AS DATE) + INTERVAL '30 DAY'
),
filtered_item AS (
    SELECT i_item_sk, i_item_id
    FROM item
    WHERE i_category = 'Home'
      AND i_manager_id BETWEEN 25 AND 64
),
filtered_catalog_sales AS (
    SELECT cs_item_sk,
           cs_warehouse_sk,
           cs_sold_date_sk,
           cs_sales_price,
           cs_order_number,
           cs_wholesale_cost
    FROM catalog_sales
    WHERE cs_wholesale_cost BETWEEN 17 AND 36
)
SELECT
    w.w_state,
    i.i_item_id,
    SUM(
        CASE
            WHEN d.d_date < CAST('1999-04-19' AS DATE)
            THEN cs.cs_sales_price - COALESCE(cr.cr_refunded_cash, 0)
            ELSE 0
-- ... (truncated)
```

### Worker 3: multi_cte_materialization
- **Status**: fail (0.87x)
- **Transforms**: none
- **Examples used**: pg_materialized_dimension_fact_prefilter, pg_self_join_decomposition, pg_dimension_prefetch_star
- **Strategy hint**: Materialize pre-filtered dimension and fact tables in CTEs, and restructure the query to avoid duplicate scans of the fact table.

```sql
WITH filtered_date AS (
    SELECT d_date_sk, d_date
    FROM date_dim
    WHERE d_date BETWEEN (CAST('1999-04-19' AS DATE) - INTERVAL '30 DAY')
                     AND (CAST('1999-04-19' AS DATE) + INTERVAL '30 DAY')
),
filtered_item AS (
    SELECT i_item_sk, i_item_id
    FROM item
    WHERE i_category = 'Home'
      AND i_manager_id BETWEEN 25 AND 64
),
filtered_catalog_sales AS (
    SELECT 
        cs_item_sk,
        cs_order_number,
        cs_sales_price,
        cs_warehouse_sk,
        cs_sold_date_sk
    FROM catalog_sales
    WHERE cs_wholesale_cost BETWEEN 17 AND 36
),
filtered_catalog_returns AS (
    SELECT 
        cr_order_number,
        cr_item_sk,
        cr_refunded_cash
    FROM catalog_returns
    WHERE cr_reason_sk = 16
)
-- ... (truncated)
```

### Worker 4: structural_transform_decomposition
- **Status**: fail (0.85x)
- **Transforms**: none
- **Examples used**: pg_self_join_decomposition, pg_materialized_dimension_fact_prefilter, early_filter_decorrelate
- **Strategy hint**: Apply structural transformations such as decomposing the outer join and using early filter decorrelation to enable novel access paths and reduce computation.

```sql
WITH filtered_date AS (
    SELECT d_date_sk, d_date
    FROM date_dim
    WHERE d_date BETWEEN (CAST('1999-04-19' AS DATE) - INTERVAL '30 DAY')
                     AND (CAST('1999-04-19' AS DATE) + INTERVAL '30 DAY')
),
filtered_item AS (
    SELECT i_item_sk, i_item_id
    FROM item
    WHERE i_category = 'Home'
      AND i_manager_id BETWEEN 25 AND 64
),
cs_filtered AS (
    SELECT 
        cs_item_sk,
        cs_order_number,
        cs_sales_price,
        cs_warehouse_sk,
        cs_sold_date_sk
    FROM catalog_sales
    WHERE cs_wholesale_cost BETWEEN 17 AND 36
),
joined_sales_returns AS (
    SELECT 
        cs.cs_item_sk,
        cs.cs_order_number,
        cs.cs_sales_price,
        cs.cs_warehouse_sk,
        cs.cs_sold_date_sk,
        cr.cr_refunded_cash,
-- ... (truncated)
```

### Worker 5: refined_snipe
- **Status**: fail (0.98x)
- **Transforms**: none
- **Examples used**: 
- **Strategy hint**: Snipe from iter 1

```sql
WITH filtered_date AS (
    SELECT d_date_sk, d_date
    FROM date_dim
    WHERE d_date BETWEEN CAST('1999-04-19' AS DATE) - INTERVAL '30 DAY'
                    AND CAST('1999-04-19' AS DATE) + INTERVAL '30 DAY'
),
filtered_item AS (
    SELECT i_item_sk, i_item_id
    FROM item
    WHERE i_category = 'Home'
      AND i_manager_id BETWEEN 25 AND 64
),
filtered_sales AS (
    SELECT 
        cs.cs_item_sk,
        cs.cs_order_number,
        cs.cs_sales_price,
        cs.cs_warehouse_sk,
        fd.d_date
    FROM catalog_sales cs
    JOIN filtered_date fd ON cs.cs_sold_date_sk = fd.d_date_sk
    JOIN filtered_item fi ON cs.cs_item_sk = fi.i_item_sk
    WHERE cs.cs_wholesale_cost BETWEEN 17 AND 36
)
SELECT
    w.w_state,
    fi.i_item_id,
    SUM(
        CASE
            WHEN fs.d_date < CAST('1999-04-19' AS DATE)
-- ... (truncated)
```

## DAG Structure & Bottlenecks

| Node | Role | Cost % |
|------|------|-------:|
| main_query |  | 0.0% |

## Available Examples (Full Catalog)

- **pg_date_cte_explicit_join** (2.28xx) — Isolate a selective date_dim filter into a CTE AND convert all comma-separated j
- **pg_dimension_prefetch_star** (3.32xx) — On multi-channel UNION queries with comma-separated implicit joins, pre-filter d
- **early_filter_decorrelate** (1.13xx) — 
- **pg_materialized_dimension_fact_prefilter** (2.68xx) — Pre-filter ALL dimension tables AND the fact table into MATERIALIZED CTEs, then 
- **pg_self_join_decomposition** (3.93xx) — Eliminate duplicate fact table scans in self-join patterns by computing the aggr

## Your Task

Analyze the failed attempts and design a refined approach:

1. **Failure Analysis**: Why did all attempts fall short? Be specific about mechanisms.
2. **Common Patterns**: What did multiple workers try unsuccessfully?
3. **Unexplored Space**: What optimization angles were missed entirely?
4. **Refined Strategy**: Synthesize a NEW approach combining best insights.

### Output Format (follow EXACTLY)

```
FAILURE_ANALYSIS:
<Why all workers fell short — be specific about mechanisms>

UNEXPLORED_OPPORTUNITIES:
<What optimization approaches haven't been tried>

REFINED_STRATEGY:
<Concrete optimization approach for next attempt>

EXAMPLES: <ex1>, <ex2>, <ex3>
HINT: <specific guidance for the refined attempt>
```