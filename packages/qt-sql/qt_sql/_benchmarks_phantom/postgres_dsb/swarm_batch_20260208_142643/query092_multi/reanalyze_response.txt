FAILURE_ANALYSIS:
All previous attempts fell short because they failed to address the core inefficiency: the correlated subquery performs a per-row re-evaluation of an aggregate against the same base table (web_sales) with similar filtering conditions. The implicit comma-join syntax hides join ordering opportunities, and attempts to pre-filter dimensions didn't eliminate the fundamental performance penalty of repeated subquery execution. Materialization attempts likely suffered from suboptimal join orders or missed the chance to compute the subquery aggregate once per item.

UNEXPLORED_OPPORTUNITIES:
1. **Subquery decorrelation via CTE/window function**: Precompute the average ws_ext_discount_amt per item for the specific conditions once, then join.
2. **Explicit join ordering with filtered aggregates**: Force date_dimâ†’web_sales join order to leverage date range selectivity early.
3. **Partial pre-aggregation**: Compute item-level averages before joining with the main fact scan.
4. **Predicate pushdown into CTEs**: Apply all selective filters (date, wholesale_cost, price ratio) in a single scan.

REFINED_STRATEGY:
Use a CTE to precompute per-item average discount amounts with all subquery conditions, then join this with the main query using explicit JOIN syntax. This eliminates correlation overhead by computing the threshold once per item. Additionally, pre-filter date_dim and web_sales in separate CTEs with explicit joins to ensure optimal join ordering and predicate pushdown.

EXAMPLES: pg_date_cte_explicit_join, early_filter_decorrelate, pg_self_join_decomposition
HINT: Create a CTE for date_dim filtered by the 90-day range, another CTE for web_sales filtered by wholesale_cost and date join, then compute the subquery's average per item in a third CTE with the price ratio condition. Finally, join all CTEs with the item table using explicit JOIN syntax and apply the threshold comparison.