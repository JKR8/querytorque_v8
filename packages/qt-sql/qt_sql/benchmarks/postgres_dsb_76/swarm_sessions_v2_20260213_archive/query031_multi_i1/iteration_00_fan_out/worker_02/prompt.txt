You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

This query compares quarter-over-quarter sales growth between store and web channels for counties in IA/IL in 1998, filtered by specific item colors and manager IDs. All joins are INNER (must match). Aggregates are SUM only, no statistical traps. The final ratios compare web vs store growth across quarters, requiring quarter-specific aggregates to be aligned by county and year. Any rewrite must preserve the quarter alignment and ratio comparisons.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
ss_pivoted -> ws_pivoted -> main_ratio
NODE_CONTRACTS:
  ss_pivoted:
    FROM: store_sales, date_dim, customer_address, item
    JOIN: ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk
    WHERE: i_color IN ('navajo','orchid') AND i_manager_id BETWEEN 8 AND 27 AND ss_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA','IL') AND d_year = 1998 AND d_qoy IN (1,2,3)
    GROUP BY: ca_county, d_year
    AGGREGATE: SUM(CASE WHEN d_qoy=1 THEN ss_ext_sales_price END) AS store_sales_q1,
               SUM(CASE WHEN d_qoy=2 THEN ss_ext_sales_price END) AS store_sales_q2,
               SUM(CASE WHEN d_qoy=3 THEN ss_ext_sales_price END) AS store_sales_q3
    OUTPUT: ca_county, d_year, store_sales_q1, store_sales_q2, store_sales_q3
    EXPECTED_ROWS: ~ (counties × 1 year)
    CONSUMERS: main_ratio
  ws_pivoted: [similar for web_sales]
  main_ratio:
    FROM: ss_pivoted, ws_pivoted
    WHERE: ws_pivoted.ca_county = ss_pivoted.ca_county AND ws_pivoted.d_year = ss_pivoted.d_year
          AND CASE WHEN ws_store_sales_q1 > 0 THEN ws_store_sales_q2/ws_store_sales_q1 ELSE NULL END
               > CASE WHEN store_sales_q1 > 0 THEN store_sales_q2/store_sales_q1 ELSE NULL END
          AND CASE WHEN ws_store_sales_q2 > 0 THEN ws_store_sales_q3/ws_store_sales_q2 ELSE NULL END
               > CASE WHEN store_sales_q2 > 0 THEN store_sales_q3/store_sales_q2 ELSE NULL END
    OUTPUT: ca_county, d_year, 
            ws_store_sales_q2/ws_store_sales_q1 AS web_q1_q2_increase,
            store_sales_q2/store_sales_q1 AS store_q1_q2_increase,
            ws_store_sales_q3/ws_store_sales_q2 AS web_q2_q3_increase,
            store_sales_q3/store_sales_q2 AS store_q2_q3_increase
    ORDER BY: d_year
    EXPECTED_ROWS: same as original
    CONSUMERS: final output

NODE_CONTRACTS:
ss_pivoted:
    FROM: store_sales, date_dim, customer_address, item
    JOIN: ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk
    WHERE: i_color IN ('navajo','orchid') AND i_manager_id BETWEEN 8 AND 27 AND ss_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA','IL') AND d_year = 1998 AND d_qoy IN (1,2,3)
    GROUP BY: ca_county, d_year
    AGGREGATE: SUM(CASE WHEN d_qoy=1 THEN ss_ext_sales_price END) AS store_sales_q1,
               SUM(CASE WHEN d_qoy=2 THEN ss_ext_sales_price END) AS store_sales_q2,
               SUM(CASE WHEN d_qoy=3 THEN ss_ext_sales_price END) AS store_sales_q3
    OUTPUT: ca_county, d_year, store_sales_q1, store_sales_q2, store_sales_q3
    EXPECTED_ROWS: ~ (counties × 1 year)
    CONSUMERS: main_ratio
  ws_pivoted: [similar for web_sales]
  main_ratio:
    FROM: ss_pivoted, ws_pivoted
    WHERE: ws_pivoted.ca_county = ss_pivoted.ca_county AND ws_pivoted.d_year = ss_pivoted.d_year
          AND CASE WHEN ws_store_sales_q1 > 0 THEN ws_store_sales_q2/ws_store_sales_q1 ELSE NULL END
               > CASE WHEN store_sales_q1 > 0 THEN store_sales_q2/store_sales_q1 ELSE NULL END
          AND CASE WHEN ws_store_sales_q2 > 0 THEN ws_store_sales_q3/ws_store_sales_q2 ELSE NULL END
               > CASE WHEN store_sales_q2 > 0 THEN store_sales_q3/store_sales_q2 ELSE NULL END
    OUTPUT: ca_county, d_year, 
            ws_store_sales_q2/ws_store_sales_q1 AS web_q1_q2_increase,
            store_sales_q2/store_sales_q1 AS store_q1_q2_increase,
            ws_store_sales_q3/ws_store_sales_q2 AS web_q2_q3_increase,
            store_sales_q3/store_sales_q2 AS store_q2_q3_increase
    ORDER BY: d_year
    EXPECTED_ROWS: same as original
    CONSUMERS: final output

## Hazard Flags (avoid these specific risks)

- Pivoting removes d_qoy grouping; must ensure quarters are correctly partitioned within (ca_county, d_year) groups.
- The ratio comparisons require all three quarterly values; NULL handling must match original (CASE WHEN sales>0 THEN ratio ELSE NULL).

## Regression Warnings (observed failures on similar queries)

1. CTE materialization blocking parallelism (observed regression in past queries):
   CAUSE: Materialized CTEs execute serially, preventing parallel scans of underlying tables.
   RULE: Avoid wrapping large fact table scans in CTEs if parallelism is needed; use subqueries instead.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Must output ca_county, d_year, web_q1_q2_increase, store_q1_q2_increase, web_q2_q3_increase, store_q2_q3_increase in same order.
- CTE_COLUMN_COMPLETENESS: CTEs must output ca_county, d_qoy, d_year, and sales aggregates for downstream quarter filtering and ratios.
- LITERAL_PRESERVATION: Must preserve literal values: i_color IN ('navajo','orchid'), i_manager_id BETWEEN 8 AND 27, list_price BETWEEN 86 AND 100, ca_state IN ('IA','IL'), d_year=1998, d_qoy IN (1,2,3).
- SEMANTIC_EQUIVALENCE: Must return same rows and ratios.
- COMMA_JOIN_WEAKNESS: CTEs use comma-separated joins (store_sales, date_dim, customer_address, item).
- CROSS_CTE_PREDICATE_BLINDNESS: Same CTE (`ss`) scanned 3 times with different quarter filters (d_qoy=1,2,3).

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- pg_self_join_decomposition: apply materialization of fact+dimension scan once and derive multiple aggregates; ignore the per-item/per-store split (we need per-quarter).
- single_pass_aggregation: use CASE inside SUM to compute quarterly aggregates in one scan; ignore the channel bitmap aspect (we have separate CTEs for store/web).

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

## Original SQL

```sql
with ss as
 (select ca_county,d_qoy, d_year,sum(ss_ext_sales_price) as store_sales
 from store_sales,date_dim,customer_address, item
 where ss_sold_date_sk = d_date_sk
  and ss_addr_sk=ca_address_sk
  and ss_item_sk = i_item_sk
  and i_color IN ('navajo', 'orchid')
  and i_manager_id BETWEEN 8 and 27
  and ss_list_price between 86 and 100
  and ca_state in ('IA','IL')
 group by ca_county,d_qoy, d_year),
 ws as
 (select ca_county,d_qoy, d_year,sum(ws_ext_sales_price) as web_sales
 from web_sales,date_dim,customer_address, item
 where ws_sold_date_sk = d_date_sk
  and ws_bill_addr_sk=ca_address_sk
  and ws_item_sk = i_item_sk
  and i_color IN ('navajo', 'orchid')
  and i_manager_id BETWEEN 8 and 27
  and ws_list_price between 86 and 100
  and ca_state in ('IA','IL')
group by ca_county,d_qoy, d_year)
 select
        ss1.ca_county
       ,ss1.d_year
       ,ws2.web_sales/ws1.web_sales web_q1_q2_increase
       ,ss2.store_sales/ss1.store_sales store_q1_q2_increase
       ,ws3.web_sales/ws2.web_sales web_q2_q3_increase
       ,ss3.store_sales/ss2.store_sales store_q2_q3_increase
 from
        ss ss1
       ,ss ss2
       ,ss ss3
       ,ws ws1
       ,ws ws2
       ,ws ws3
 where
    ss1.d_qoy = 1
    and ss1.d_year = 1998
    and ss1.ca_county = ss2.ca_county
    and ss2.d_qoy = 2
    and ss2.d_year = 1998
 and ss2.ca_county = ss3.ca_county
    and ss3.d_qoy = 3
    and ss3.d_year = 1998
    and ss1.ca_county = ws1.ca_county
    and ws1.d_qoy = 1
    and ws1.d_year = 1998
    and ws1.ca_county = ws2.ca_county
    and ws2.d_qoy = 2
    and ws2.d_year = 1998
    and ws1.ca_county = ws3.ca_county
    and ws3.d_qoy = 3
    and ws3.d_year =1998
    and case when ws1.web_sales > 0 then ws2.web_sales/ws1.web_sales else null end
       > case when ss1.store_sales > 0 then ss2.store_sales/ss1.store_sales else null end
    and case when ws2.web_sales > 0 then ws3.web_sales/ws2.web_sales else null end
       > case when ss2.store_sales > 0 then ss3.store_sales/ss2.store_sales else null end
 order by ss1.d_year;
```

## Per-Rewrite Configuration (SET LOCAL)

You have two optimization levers: SQL rewrite AND per-query configuration.
After writing your rewrite, analyze its execution profile and emit SET LOCAL
commands that fix planner-level bottlenecks specific to YOUR rewrite.

Memory budget: shared_buffers=128MB, effective_cache_size=4GB
Global work_mem: 4MB (per-operation)
Active connections: ~1 (work_mem headroom: safe up to 16MB per-op)
Storage: HDD (random_page_cost=4.0)
Parallel capacity: max_parallel_workers=8, per_gather=2

SET LOCAL permissions:
  user-level (always available): effective_cache_size, enable_hashjoin, enable_mergejoin, enable_nestloop, enable_seqscan, from_collapse_limit, geqo_threshold, hash_mem_multiplier, jit, jit_above_cost, join_collapse_limit, max_parallel_workers_per_gather, parallel_setup_cost, parallel_tuple_cost, random_page_cost, work_mem

### Tunable Parameters (whitelist — only these are allowed)

- **effective_cache_size** (1024MB–65536MB): Advisory: how much OS cache to expect (MB). Safe to set aggressively.
- **enable_hashjoin** (on | off): Enable hash join plan type.
- **enable_mergejoin** (on | off): Enable merge join plan type.
- **enable_nestloop** (on | off): Enable nested-loop join plan type.
- **enable_seqscan** (on | off): Enable sequential scan plan type.
- **from_collapse_limit** (1–20): Max FROM items before subqueries stop being flattened.
- **geqo_threshold** (2–20): Number of FROM items that triggers genetic query optimizer.
- **hash_mem_multiplier** (1.0–10.0): Multiplier applied to work_mem for hash-based operations.
- **jit** (on | off): Enable JIT compilation.
- **jit_above_cost** (0.0–1000000.0): Query cost above which JIT is activated.
- **join_collapse_limit** (1–20): Max FROM items before planner stops trying all join orders.
- **max_parallel_workers_per_gather** (0–8): Max parallel workers per Gather node.
- **parallel_setup_cost** (0.0–10000.0): Planner estimate of cost to launch parallel workers.
- **parallel_tuple_cost** (0.0–1.0): Planner estimate of cost to transfer a tuple to parallel worker.
- **random_page_cost** (1.0–10.0): Planner estimate of cost of a random page fetch (1.0 = SSD, 4.0 = HDD).
- **work_mem** (64MB–2048MB): Memory for sorts/hashes per operation (MB). Allocated PER-OPERATION, not per-query. Count hash/sort ops in EXPLAIN before sizing.

### Rules
- Every SET LOCAL MUST cite a specific EXPLAIN node your rewrite creates/changes
- work_mem is PER-OPERATION: count hash/sort ops in your rewrite before sizing
- random_page_cost: ONLY change if your rewrite creates index-favorable access patterns
- Empty is valid: if your rewrite has no planner bottleneck, emit no SET LOCAL
- Stay within the resource envelope bounds above

### SET LOCAL Syntax
Include SET LOCAL commands in the `runtime_config` array field of your JSON output.
If no config changes help, omit the field or use an empty array.

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

### Column Completeness Contract

Your `main_query` component MUST produce **exactly** these output columns (same names, same order):

  1. `ca_county`
  2. `d_year`
  3. `web_q1_q2_increase`
  4. `store_q1_q2_increase`
  5. `web_q2_q3_increase`
  6. `store_q2_q3_increase`

Do NOT add, remove, or rename any output columns. The result set schema must be identical to the original query.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
├── [CTE] ss  [=]  Cost: 47%  Rows: ~3K
│   ├── SCAN (store_sales, date_dim (join), customer_address (join), item (join))
│   ├── JOIN (ss_sold_date_sk = d_date_sk)
│   ├── JOIN (ss_addr_sk = ca_address_sk)
│   ├── JOIN (+1 more)
│   ├── FILTER (i_color IN ('navajo', 'orchid'))
│   ├── FILTER (i_manager_id BETWEEN 8 AND 27)
│   ├── FILTER (+2 more)
│   ├── AGG (GROUP BY)
│   └── OUTPUT (ca_county, d_qoy, d_year, store_sales)
├── [CTE] ws  [=]  Cost: 22%  Rows: ~3K
│   ├── SCAN (web_sales, date_dim (join), customer_address (join), item (join))
│   ├── JOIN (ws_sold_date_sk = d_date_sk)
│   ├── JOIN (ws_bill_addr_sk = ca_address_sk)
│   ├── JOIN (+1 more)
│   ├── FILTER (i_color IN ('navajo', 'orchid'))
│   ├── FILTER (i_manager_id BETWEEN 8 AND 27)
│   ├── FILTER (+2 more)
│   ├── AGG (GROUP BY)
│   └── OUTPUT (ca_county, d_qoy, d_year, web_sales)
└── [MAIN] main_query  [=]  Cost: 32%  Rows: ~36K
    ├── SCAN (ss AS ss1 (join), ss AS ss2 (join), ss AS ss3 (join), ws AS ws1 (join), ws AS ws2 (join), ws AS ws3 (join))
    ├── JOIN (ss1.ca_county = ss2.ca_county)
    ├── JOIN (ss2.ca_county = ss3.ca_county)
    ├── JOIN (+3 more)
    ├── FILTER (ss1.d_qoy = 1)
    ├── FILTER (ss1.d_year = 1998)
    ├── FILTER (+12 more)
    ├── AGG (GROUP BY)
    ├── SORT (ss1.d_year ASC)
    └── OUTPUT (ca_county, d_year, web_q1_q2_increase, store_q1_q2_increase, web_q2_q3_increase, store_q2_q3_increase)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: