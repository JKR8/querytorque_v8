You are a senior SQL optimization architect for PostgreSQL v16.11-0ubuntu0.24.04.1). You have FULL FREEDOM to design your own approach — you are NOT constrained to any specific logical tree topology or CTE structure. Your job: diagnose WHY previous workers failed to reach 2.0x, identify unexplored optimization angles, and produce an optimized SQL rewrite that reaches the target.

Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — guards prevent silent breakage. Strip benchmark comments (-- start query, -- end query) from output.

## Target: >=2.0x speedup

Your target is >=2.0x speedup on this query. This is the bar. Anything below 2.0x is a miss.

## Previous Optimization Attempts
Target: **>=2.0x** | 4 workers tried | none reached target

### W1: star_join_prefetch → 0.254263504611182x ★ BEST [REGRESSION (0.254263504611182x)]
- **Examples**: pg_dimension_prefetch_star, pg_date_cte_explicit_join
- **Transforms**: multi_dimension_prefetch
- **Approach**: - pg_dimension_prefetch_star: apply pre-filtering of item and customer_address i
- **Optimized SQL:**
```sql
WITH filtered_item AS (SELECT i_item_sk FROM item WHERE i_color IN ('navajo', 'orchid') AND i_manager_id BETWEEN 8 AND 27), filtered_ca AS (SELECT ca_address_sk, ca_county FROM customer_address WHERE ca_state IN ('IA', 'IL')), prefactored_store_sales AS (SELECT ca_county, d_qoy, d_year, ss_ext_sales_price FROM store_sales INNER JOIN filtered_item ON ss_item_sk = filtered_item.i_item_sk INNER JOIN filtered_ca ON ss_addr_sk = filtered_ca.ca_address_sk INNER JOIN date_dim ON ss_sold_date_sk = date_dim.d_date_sk WHERE ss_list_price BETWEEN 86 AND 100 AND date_dim.d_year = 1998 AND date_dim.d_qoy IN (1, 2, 3)), ss_agg AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM prefactored_store_sales GROUP BY ca_county, d_qoy, d_year), prefactored_web_sales AS (SELECT ca_county, d_qoy, d_year, ws_ext_sales_price FROM web_sales INNER JOIN filtered_item ON ws_item_sk = filtered_item.i_item_sk INNER JOIN filtered_ca ON ws_bill_addr_sk = filtered_ca.ca_address_sk INNER JOIN date_dim ON ws_sold_date_sk = date_dim.d_date_sk WHERE ws_list_price BETWEEN 86 AND 100 AND date_dim.d_year = 1998 AND date_dim.d_qoy IN (1, 2, 3)), ws_agg AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM prefactored_web_sales GROUP BY ca_county, d_qoy, d_year) SELECT ss1.ca_county, ss1.d_year, ws2.web_sales / ws1.web_sales AS web_q1_q2_increase, ss2.store_sales / ss1.store_sales AS store_q1_q2_increase, ws3.web_sales / ws2.web_sales AS web_q2_q3_increase, ss3.store_sales / ss2.store_sales AS store_q2_q3_increase FROM ss_agg AS ss1, ss_agg AS ss2, ss_agg AS ss3, ws_agg AS ws1, ws_agg AS ws2, ws_agg AS ws3 WHERE ss1.d_qoy = 1 AND ss1.d_year = 1998 AND ss1.ca_county = ss2.ca_county AND ss2.d_qoy = 2 AND ss2.d_year = 1998 AND ss2.ca_county = ss3.ca_county AND ss3.d_qoy = 3 AND ss3.d_year = 1998 AND ss1.ca_county = ws1.ca_county AND ws1.d_qoy = 1 AND ws1.d_year = 1998 AND ws1.ca_county = ws2.ca_county AND ws2.d_qoy = 2 AND ws2.d_year = 1998 AND ws1.ca_county = ws3.ca_county AND ws3.d_qoy = 3 AND ws3.d_year = 1998 AND CASE WHEN ws1.web_sales > 0 THEN ws2.web_sales / ws1.web_sales ELSE NULL END > CASE WHEN ss1.store_sales > 0 THEN ss2.store_sales / ss1.store_sales ELSE NULL END AND CASE WHEN ws2.web_sales > 0 THEN ws3.web_sales / ws2.web_sales ELSE NULL END > CASE WHEN ss2.store_sales > 0 THEN ss3.store_sales / ss2.store_sales ELSE NULL END ORDER BY ss1.d_year
```
- **Execution Plan (EXPLAIN ANALYZE):**
```
Nested Loop  (rows=0, time=330.837)
  Bitmap Heap Scan on item  (rows=268, time=6.017)
    Bitmap Index Scan  (rows=1386, time=0.142)
  Seq Scan on customer_address  (rows=15493, time=23.709)
  Aggregate  (rows=21, time=330.804)
    Sort  (rows=24, time=330.785)
      Hash Join  (rows=24, time=330.696)
        Hash Join  (rows=431, time=302.04)
          Gather  (rows=303025, time=282.477)
            Nested Loop  (rows=151512, time=266.167)
              Seq Scan on date_dim  (rows=137, time=3.626)
              Index Only Scan on store_sales  (rows=1106, time=1.864)
          Hash  (rows=268, time=6.113)
            CTE Scan (filtered_item)  (rows=268, time=6.065)
        Hash  (rows=15493, time=28.206)
          CTE Scan (filtered_ca)  (rows=15493, time=26.255)
  Aggregate  (rows=0, time=0.0)
    Sort  (rows=0, time=0.0)
      Hash Join  (rows=0, time=0.0)
        Hash Join  (rows=0, time=0.0)
          Gather  (rows=0, time=0.0)
            Nested Loop  (rows=0, time=0.0)
              Seq Scan on date_dim (date_dim_1)  (rows=0, time=0.0)
              Index Scan on web_sales  (rows=0, time=0.0)
          Hash  (rows=0, time=0.0)
            CTE Scan (filtered_item_1)  (rows=0, time=0.0)
        Hash  (rows=0, time=0.0)
          CTE Scan (filtered_ca_1)  (rows=0, time=0.0)
  Nested Loop  (rows=0, time=330.763)
    Nested Loop  (rows=0, time=330.762)
      Nested Loop  (rows=0, time=330.761)
        Nested Loop  (rows=0, time=330.759)
          CTE Scan (ss1)  (rows=10, time=330.739)
          CTE Scan (ss2)  (rows=9, time=0.002)
        CTE Scan (ss3)  (rows=0, time=0.0)
      CTE Scan (ws1)  (rows=0, time=0.0)
    CTE Scan (ws2)  (rows=0, time=0.0)
  CTE Scan (ws3)  (rows=0, time=0.0)
```

### W4: compound_prefetch_pivot_latebinding → 0.1800201558946866x [REGRESSION (0.1800201558946866x)]
- **Examples**: pg_materialized_dimension_fact_prefilter, pg_dimension_prefetch_star
- **Transforms**: single_pass_aggregation
- **Approach**: - pg_materialized_dimension_fact_prefilter: stage reduction by pre-filtering dim
- **Optimized SQL:**
```sql
WITH filtered_item AS (SELECT i_item_sk FROM item WHERE i_color IN ('navajo', 'orchid') AND i_manager_id BETWEEN 8 AND 27), filtered_ca AS (SELECT ca_address_sk, ca_county FROM customer_address WHERE ca_state IN ('IA', 'IL')), store_sales_joined AS (SELECT ss_addr_sk, d_qoy, ss_ext_sales_price FROM store_sales INNER JOIN filtered_item ON ss_item_sk = i_item_sk INNER JOIN date_dim ON ss_sold_date_sk = d_date_sk WHERE ss_list_price BETWEEN 86 AND 100 AND d_year = 1998 AND d_qoy IN (1, 2, 3)), ss_pivoted AS (SELECT ca_county, 1998 AS d_year, SUM(CASE WHEN d_qoy = 1 THEN ss_ext_sales_price END) AS store_sales_q1, SUM(CASE WHEN d_qoy = 2 THEN ss_ext_sales_price END) AS store_sales_q2, SUM(CASE WHEN d_qoy = 3 THEN ss_ext_sales_price END) AS store_sales_q3 FROM store_sales_joined INNER JOIN filtered_ca ON ss_addr_sk = ca_address_sk GROUP BY ca_county), web_sales_joined AS (SELECT ws_bill_addr_sk, d_qoy, ws_ext_sales_price FROM web_sales INNER JOIN filtered_item ON ws_item_sk = i_item_sk INNER JOIN date_dim ON ws_sold_date_sk = d_date_sk WHERE ws_list_price BETWEEN 86 AND 100 AND d_year = 1998 AND d_qoy IN (1, 2, 3)), ws_pivoted AS (SELECT ca_county, 1998 AS d_year, SUM(CASE WHEN d_qoy = 1 THEN ws_ext_sales_price END) AS web_sales_q1, SUM(CASE WHEN d_qoy = 2 THEN ws_ext_sales_price END) AS web_sales_q2, SUM(CASE WHEN d_qoy = 3 THEN ws_ext_sales_price END) AS web_sales_q3 FROM web_sales_joined INNER JOIN filtered_ca ON ws_bill_addr_sk = ca_address_sk GROUP BY ca_county) SELECT ss.ca_county, ss.d_year, CASE WHEN ws.web_sales_q1 > 0 THEN ws.web_sales_q2 / ws.web_sales_q1 ELSE NULL END AS web_q1_q2_increase, CASE WHEN ss.store_sales_q1 > 0 THEN ss.store_sales_q2 / ss.store_sales_q1 ELSE NULL END AS store_q1_q2_increase, CASE WHEN ws.web_sales_q2 > 0 THEN ws.web_sales_q3 / ws.web_sales_q2 ELSE NULL END AS web_q2_q3_increase, CASE WHEN ss.store_sales_q2 > 0 THEN ss.store_sales_q3 / ss.store_sales_q2 ELSE NULL END AS store_q2_q3_increase FROM ss_pivoted ss INNER JOIN ws_pivoted ws ON ss.ca_county = ws.ca_county AND ss.d_year = ws.d_year WHERE (CASE WHEN ws.web_sales_q1 > 0 THEN ws.web_sales_q2 / ws.web_sales_q1 ELSE NULL END) > (CASE WHEN ss.store_sales_q1 > 0 THEN ss.store_sales_q2 / ss.store_sales_q1 ELSE NULL END) AND (CASE WHEN ws.web_sales_q2 > 0 THEN ws.web_sales_q3 / ws.web_sales_q2 ELSE NULL END) > (CASE WHEN ss.store_sales_q2 > 0 THEN ss.store_sales_q3 / ss.store_sales_q2 ELSE NULL END) ORDER BY ss.d_year
```
- **Execution Plan (EXPLAIN ANALYZE):**
```
Merge Join  (rows=0, time=466.76)
  Bitmap Heap Scan on item  (rows=268, time=4.897)
    Bitmap Index Scan  (rows=1386, time=0.124)
  Seq Scan on customer_address  (rows=15493, time=22.345)
  Sort  (rows=21, time=347.979)
    Aggregate  (rows=21, time=347.96)
      Sort  (rows=24, time=347.936)
        Hash Join  (rows=24, time=347.866)
          Hash Join  (rows=431, time=320.898)
            Gather  (rows=303025, time=302.454)
              Nested Loop  (rows=151512, time=266.566)
                Seq Scan on date_dim  (rows=137, time=3.512)
                Index Only Scan on store_sales  (rows=1106, time=1.866)
            Hash  (rows=268, time=5.04)
              CTE Scan (filtered_item)  (rows=268, time=5.008)
          Hash  (rows=15493, time=26.579)
            CTE Scan (filtered_ca)  (rows=15493, time=24.872)
  Sort  (rows=5, time=118.768)
    Subquery Scan (ws)  (rows=5, time=118.739)
      Aggregate  (rows=5, time=118.737)
        Sort  (rows=5, time=118.721)
          Hash Join  (rows=5, time=118.7)
            Hash Join  (rows=67, time=116.661)
              Gather  (rows=50696, time=113.719)
                Nested Loop  (rows=25348, time=85.06)
                  Seq Scan on date_dim (date_dim_1)  (rows=137, time=2.835)
                  Index Scan on web_sales  (rows=185, time=0.587)
              Hash  (rows=268, time=0.022)
                CTE Scan (filtered_item_1)  (rows=268, time=0.009)
            Hash  (rows=15493, time=1.903)
              CTE Scan (filtered_ca_1)  (rows=15493, time=0.689)
```

### W3: comma_join_explicit_with_quarter_split → 0.16781736310034642x [REGRESSION (0.16781736310034642x)]
- **Examples**: pg_date_cte_explicit_join, early_filter_decorrelate
- **Transforms**: prefetch_fact_join
- **Approach**: - pg_date_cte_explicit_join: convert comma joins to explicit JOINs; pre-filter d
- **Optimized SQL:**
```sql
WITH ss_q1 AS (SELECT ca_county, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales INNER JOIN date_dim ON ss_sold_date_sk = d_date_sk INNER JOIN customer_address ON ss_addr_sk = ca_address_sk INNER JOIN item ON ss_item_sk = i_item_sk WHERE i_color IN ('navajo','orchid') AND i_manager_id BETWEEN 8 AND 27 AND ss_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA','IL') AND d_qoy = 1 AND d_year = 1998 GROUP BY ca_county, d_year), ss_q2 AS (SELECT ca_county, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales INNER JOIN date_dim ON ss_sold_date_sk = d_date_sk INNER JOIN customer_address ON ss_addr_sk = ca_address_sk INNER JOIN item ON ss_item_sk = i_item_sk WHERE i_color IN ('navajo','orchid') AND i_manager_id BETWEEN 8 AND 27 AND ss_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA','IL') AND d_qoy = 2 AND d_year = 1998 GROUP BY ca_county, d_year), ss_q3 AS (SELECT ca_county, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales INNER JOIN date_dim ON ss_sold_date_sk = d_date_sk INNER JOIN customer_address ON ss_addr_sk = ca_address_sk INNER JOIN item ON ss_item_sk = i_item_sk WHERE i_color IN ('navajo','orchid') AND i_manager_id BETWEEN 8 AND 27 AND ss_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA','IL') AND d_qoy = 3 AND d_year = 1998 GROUP BY ca_county, d_year), ws_q1 AS (SELECT ca_county, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales INNER JOIN date_dim ON ws_sold_date_sk = d_date_sk INNER JOIN customer_address ON ws_bill_addr_sk = ca_address_sk INNER JOIN item ON ws_item_sk = i_item_sk WHERE i_color IN ('navajo','orchid') AND i_manager_id BETWEEN 8 AND 27 AND ws_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA','IL') AND d_qoy = 1 AND d_year = 1998 GROUP BY ca_county, d_year), ws_q2 AS (SELECT ca_county, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales INNER JOIN date_dim ON ws_sold_date_sk = d_date_sk INNER JOIN customer_address ON ws_bill_addr_sk = ca_address_sk INNER JOIN item ON ws_item_sk = i_item_sk WHERE i_color IN ('navajo','orchid') AND i_manager_id BETWEEN 8 AND 27 AND ws_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA','IL') AND d_qoy = 2 AND d_year = 1998 GROUP BY ca_county, d_year), ws_q3 AS (SELECT ca_county, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales INNER JOIN date_dim ON ws_sold_date_sk = d_date_sk INNER JOIN customer_address ON ws_bill_addr_sk = ca_address_sk INNER JOIN item ON ws_item_sk = i_item_sk WHERE i_color IN ('navajo','orchid') AND i_manager_id BETWEEN 8 AND 27 AND ws_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA','IL') AND d_qoy = 3 AND d_year = 1998 GROUP BY ca_county, d_year) SELECT ss_q1.ca_county, ss_q1.d_year, ws_q2.web_sales / ws_q1.web_sales AS web_q1_q2_increase, ss_q2.store_sales / ss_q1.store_sales AS store_q1_q2_increase, ws_q3.web_sales / ws_q2.web_sales AS web_q2_q3_increase, ss_q3.store_sales / ss_q2.store_sales AS store_q2_q3_increase FROM ss_q1, ss_q2, ss_q3, ws_q1, ws_q2, ws_q3 WHERE ss_q1.ca_county = ss_q2.ca_county AND ss_q2.ca_county = ss_q3.ca_county AND ss_q1.ca_county = ws_q1.ca_county AND ws_q1.ca_county = ws_q2.ca_county AND ws_q1.ca_county = ws_q3.ca_county AND CASE WHEN ws_q1.web_sales > 0 THEN ws_q2.web_sales / ws_q1.web_sales ELSE NULL END > CASE WHEN ss_q1.store_sales > 0 THEN ss_q2.store_sales / ss_q1.store_sales ELSE NULL END AND CASE WHEN ws_q2.web_sales > 0 THEN ws_q3.web_sales / ws_q2.web_sales ELSE NULL END > CASE WHEN ss_q2.store_sales > 0 THEN ss_q3.store_sales / ss_q2.store_sales ELSE NULL END ORDER BY ss_q1.d_year
```
- **Execution Plan (EXPLAIN ANALYZE):**
```
Sort  (rows=0, time=500.089)
  Nested Loop  (rows=0, time=500.069)
    Nested Loop  (rows=0, time=500.066)
      Nested Loop  (rows=0, time=500.063)
        Nested Loop  (rows=0, time=500.06)
          Nested Loop  (rows=0, time=500.056)
            Aggregate  (rows=10, time=222.0)
              Sort  (rows=11, time=221.986)
                Gather  (rows=11, time=221.951)
                  Nested Loop  (rows=6, time=217.653)
                    Nested Loop  (rows=89, time=216.737)
                      Nested Loop  (rows=59498, time=112.004)
                        Seq Scan on date_dim  (rows=46, time=3.422)
                        Index Only Scan on store_sales  (rows=1308, time=2.311)
                      Index Scan on item  (rows=0, time=0.002)
                    Index Scan on customer_address  (rows=0, time=0.009)
            Aggregate  (rows=9, time=27.805)
              Sort  (rows=10, time=27.801)
                Gather  (rows=10, time=277.969)
                  Nested Loop  (rows=5, time=187.107)
                    Nested Loop  (rows=84, time=186.371)
                      Nested Loop  (rows=54368, time=97.296)
                        Seq Scan on date_dim (date_dim_1)  (rows=46, time=2.896)
                        Index Only Scan on store_sales (store_sales_1)  (rows=1195, time=2.011)
                      Index Scan on item (item_1)  (rows=0, time=0.002)
                    Index Scan on customer_address (customer_address_1)  (rows=0, time=0.008)
          Aggregate  (rows=0, time=0.0)
            Sort  (rows=0, time=0.0)
              Gather  (rows=0, time=0.0)
                Nested Loop  (rows=0, time=0.0)
                  Nested Loop  (rows=0, time=0.0)
                    Nested Loop  (rows=0, time=0.0)
                      Seq Scan on date_dim (date_dim_2)  (rows=0, time=0.0)
                      Index Only Scan on store_sales (store_sales_2)  (rows=0, time=0.0)
                    Index Scan on item (item_2)  (rows=0, time=0.0)
                  Index Scan on customer_address (customer_address_2)  (rows=0, time=0.0)
        Aggregate  (rows=0, time=0.0)
          Sort  (rows=0, time=0.0)
            Nested Loop  (rows=0, time=0.0)
              Gather  (rows=0, time=0.0)
                Nested Loop  (rows=0, time=0.0)
                  Nested Loop  (rows=0, time=0.0)
                    Seq Scan on date_dim (date_dim_3)  (rows=0, time=0.0)
                    Index Scan on web_sales  (rows=0, time=0.0)
                  Index Scan on item (item_3)  (rows=0, time=0.0)
              Index Scan on customer_address (customer_address_3)  (rows=0, time=0.0)
      Aggregate  (rows=0, time=0.0)
        Sort  (rows=0, time=0.0)
          Nested Loop  (rows=0, time=0.0)
            Gather  (rows=0, time=0.0)
              Nested Loop  (rows=0, time=0.0)
                Nested Loop  (rows=0, time=0.0)
                  Seq Scan on date_dim (date_dim_4)  (rows=0, time=0.0)
                  Index Scan on web_sales (web_sales_1)  (rows=0, time=0.0)
                Index Scan on item (item_4)  (rows=0, time=0.0)
            Index Scan on customer_address (customer_address_4)  (rows=0, time=0.0)
    Aggregate  (rows=0, time=0.0)
      Sort  (rows=0, time=0.0)
        Nested Loop  (rows=0, time=0.0)
          Gather  (rows=0, time=0.0)
            Nested Loop  (rows=0, time=0.0)
              Nested Loop  (rows=0, time=0.0)
                Seq Scan on date_dim (date_dim_5)  (rows=0, time=0.0)
                Index Scan on web_sales (web_sales_2)  (rows=0, time=0.0)
              Index Scan on item (item_5)  (rows=0, time=0.0)
          Index Scan on customer_address (customer_address_5)  (rows=0, time=0.0)
```

### W2: scan_consolidation_pivot → 0.11797590996230259x [REGRESSION (0.11797590996230259x)]
- **Examples**: pg_self_join_decomposition, single_pass_aggregation
- **Transforms**: single_pass_aggregation
- **Approach**: - pg_self_join_decomposition: apply materialization of fact+dimension scan once 
- **Optimized SQL:**
```sql
WITH ss_pivoted AS (SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ss_ext_sales_price END) AS store_sales_q1, SUM(CASE WHEN d_qoy = 2 THEN ss_ext_sales_price END) AS store_sales_q2, SUM(CASE WHEN d_qoy = 3 THEN ss_ext_sales_price END) AS store_sales_q3 FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('navajo', 'orchid') AND i_manager_id BETWEEN 8 AND 27 AND ss_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA', 'IL') AND d_year = 1998 AND d_qoy IN (1, 2, 3) GROUP BY ca_county, d_year), ws_pivoted AS (SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ws_ext_sales_price END) AS ws_store_sales_q1, SUM(CASE WHEN d_qoy = 2 THEN ws_ext_sales_price END) AS ws_store_sales_q2, SUM(CASE WHEN d_qoy = 3 THEN ws_ext_sales_price END) AS ws_store_sales_q3 FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('navajo', 'orchid') AND i_manager_id BETWEEN 8 AND 27 AND ws_list_price BETWEEN 86 AND 100 AND ca_state IN ('IA', 'IL') AND d_year = 1998 AND d_qoy IN (1, 2, 3) GROUP BY ca_county, d_year) SELECT ss.ca_county, ss.d_year, CASE WHEN ws.ws_store_sales_q1 > 0 THEN ws.ws_store_sales_q2 / ws.ws_store_sales_q1 ELSE NULL END AS web_q1_q2_increase, CASE WHEN ss.store_sales_q1 > 0 THEN ss.store_sales_q2 / ss.store_sales_q1 ELSE NULL END AS store_q1_q2_increase, CASE WHEN ws.ws_store_sales_q2 > 0 THEN ws.ws_store_sales_q3 / ws.ws_store_sales_q2 ELSE NULL END AS web_q2_q3_increase, CASE WHEN ss.store_sales_q2 > 0 THEN ss.store_sales_q3 / ss.store_sales_q2 ELSE NULL END AS store_q2_q3_increase FROM ss_pivoted ss, ws_pivoted ws WHERE ws.ca_county = ss.ca_county AND ws.d_year = ss.d_year AND CASE WHEN ws.ws_store_sales_q1 > 0 THEN ws.ws_store_sales_q2 / ws.ws_store_sales_q1 ELSE NULL END > CASE WHEN ss.store_sales_q1 > 0 THEN ss.store_sales_q2 / ss.store_sales_q1 ELSE NULL END AND CASE WHEN ws.ws_store_sales_q2 > 0 THEN ws.ws_store_sales_q3 / ws.ws_store_sales_q2 ELSE NULL END > CASE WHEN ss.store_sales_q2 > 0 THEN ss.store_sales_q3 / ss.store_sales_q2 ELSE NULL END ORDER BY ss.d_year
```
- **Execution Plan (EXPLAIN ANALYZE):**
```
Merge Join  (rows=0, time=674.243)
  Sort  (rows=21, time=519.939)
    Aggregate  (rows=21, time=519.925)
      Sort  (rows=24, time=519.903)
        Gather  (rows=24, time=519.848)
          Nested Loop  (rows=12, time=515.479)
            Nested Loop  (rows=216, time=513.319)
              Nested Loop  (rows=151512, time=265.467)
                Seq Scan on date_dim  (rows=137, time=3.54)
                Index Only Scan on store_sales  (rows=1106, time=1.853)
              Index Scan on item  (rows=0, time=0.002)
            Index Scan on customer_address  (rows=0, time=0.009)
  Sort  (rows=5, time=154.286)
    Subquery Scan (ws)  (rows=5, time=154.238)
      Aggregate  (rows=5, time=154.235)
        Sort  (rows=5, time=154.21)
          Gather  (rows=5, time=154.183)
            Nested Loop  (rows=2, time=132.859)
              Nested Loop  (rows=34, time=132.504)
                Nested Loop  (rows=25348, time=83.883)
                  Seq Scan on date_dim (date_dim_1)  (rows=137, time=2.911)
                  Index Scan on web_sales  (rows=185, time=0.577)
                Index Scan on item (item_1)  (rows=0, time=0.002)
              Index Scan on customer_address (customer_address_1)  (rows=0, time=0.009)
```


## Original Execution Plan (EXPLAIN ANALYZE)

Compare each candidate's plan (above) against this baseline.

```
Total execution time: 99.9ms
Planning time: 2.0ms

-> Nested Loop Inner  (rows=0 loops=1 time=99.9ms)
   Join Filter: (((ss1.ca_county)::text = (ws3.ca_county)::text) AND (CASE WHEN (ws2.web_sales > '0'::numeric) TH...
  -> Aggregate  (rows=173 loops=1 time=99.7ms)
    -> Gather Merge  (rows=180 loops=1 time=99.6ms)
       Workers: 2/2 launched
      -> Aggregate  (rows=60 loops=3 time=90.8ms)
        -> Sort  (rows=62 loops=3 time=90.8ms)
           Sort Method: quicksort  Space: 31kB (Memory)
          -> Nested Loop Inner  (rows=62 loops=3 time=90.6ms)
            -> Nested Loop Inner  (rows=63 loops=3 time=90.1ms)
              -> Nested Loop Inner  (rows=1,048 loops=3 time=81.4ms)
                -> Index Scan on item  (rows=89 loops=3 time=18.1ms)
                   Filter: ((i_color = ANY ('{navajo,orchid}'::bpchar[])) AND (i_manager_id >= 8) AND (i_manager_id <= 27))
                   Rows Removed by Filter: 34K
                -> Bitmap Heap Scan on store_sales  (rows=12 loops=268 time=0.7ms)
                   Filter: ((ss_list_price >= '86'::numeric) AND (ss_list_price <= '100'::numeric))
                   Recheck Cond: (ss_item_sk = item.i_item_sk)
                   Rows Removed by Filter: 123
                  -> Bitmap Index Scan on store_sales_pkey  (rows=135 loops=268 time=0.1ms)
                     Index Cond: (ss_item_sk = item.i_item_sk)
              -> Index Scan on customer_address  (rows=0 loops=3143 time=0.0ms)
                 Filter: (ca_state = ANY ('{IA,IL}'::bpchar[]))
                 Index Cond: (ca_address_sk = store_sales.ss_addr_sk)
                 Rows Removed by Filter: 1
            -> Index Scan on date_dim  (rows=1 loops=188 time=0.0ms)
               Index Cond: (d_date_sk = store_sales.ss_sold_date_sk)
  -> Aggregate  (rows=0 loops=1 time=0.0ms)
    -> Gather Merge  (rows=0 loops=1 time=0.0ms)
       Workers: 0/2 launched
      -> Aggregate  (rows=0 loops=1 time=0.0ms)
        -> Sort  (rows=0 loops=1 time=0.0ms)
          -> Nested Loop Inner  (rows=0 loops=1 time=0.0ms)
            -> Nested Loop Inner  (rows=0 loops=1 time=0.0ms)
              -> Nested Loop Inner  (rows=0 loops=1 time=0.0ms)
                -> Index Scan on item item_1  (rows=0 loops=1 time=0.0ms)
                   Filter: ((i_color = ANY ('{navajo,orchid}'::bpchar[])) AND (i_manager_id >= 8) AND (i_manager_id <= 27))
                -> Bitmap Heap Scan on web_sales  (rows=0 loops=1 time=0.0ms)
                   Filter: ((ws_list_price >= '86'::numeric) AND (ws_list_price <= '100'::numeric))
                   Recheck Cond: (ws_item_sk = item_1.i_item_sk)
                  -> Bitmap Index Scan on web_sales_pkey  (rows=0 loops=1 time=0.0ms)
                     Index Cond: (ws_item_sk = item_1.i_item_sk)
              -> Index Scan on customer_address customer_address_1  (rows=0 loops=1 time=0.0ms)
                 Filter: (ca_state = ANY ('{IA,IL}'::bpchar[]))
                 Index Cond: (ca_address_sk = web_sales.ws_bill_addr_sk)
            -> Index Scan on date_dim date_dim_1  (rows=0 loops=1 time=0.0ms)
               Index Cond: (d_date_sk = web_sales.ws_sold_date_sk)
  -> Nested Loop Inner  (rows=0 loops=1 time=96.6ms)
     Join Filter: (((ss1.ca_county)::text = (ws2.ca_county)::text) AND (CASE WHEN (ws1.web_sales > '0'::numeric) TH...
    -> Nested Loop Inner  (rows=0 loops=1 time=96.6ms)
       Join Filter: ((ss1.ca_county)::text = (ws1.ca_county)::text)
      -> Nested Loop Inner  (rows=0 loops=1 time=96.6ms)
         Join Filter: ((ss1.ca_county)::text = (ss3.ca_county)::text)
        -> Nested Loop Inner  (rows=0 loops=1 time=96.6ms)
           Join Filter: ((ss1.ca_county)::text = (ss2.ca_county)::text)
          -> CTE Scan ss1 (CTE: ss)  (rows=10 loops=1 time=96.3ms)
             Filter: ((d_qoy = 1) AND (d_year = 1998))
             Rows Removed by Filter: 163
          -> CTE Scan ss2 (CTE: ss)  (rows=9 loops=10 time=0.0ms)
             Filter: ((d_year = 1998) AND (d_qoy = 2))
             Rows Removed by Filter: 164
        -> CTE Scan ss3 (CTE: ss)  (rows=0 loops=1 time=0.0ms)
           Filter: ((d_year = 1998) AND (d_qoy = 3))
      -> CTE Scan ws1 (CTE: ws)  (rows=0 loops=1 time=0.0ms)
         Filter: ((d_qoy = 1) AND (d_year = 1998))
    -> CTE Scan ws2 (CTE: ws)  (rows=0 loops=1 time=0.0ms)
       Filter: ((d_year = 1998) AND (d_qoy = 2))
  -> CTE Scan ws3 (CTE: ws)  (rows=0 loops=1 time=0.0ms)
     Filter: ((d_year = 1998) AND (d_qoy = 3))
```

## Semantic Contract (MUST preserve)

This query compares quarter-over-quarter sales growth between store and web channels for counties in IA/IL in 1998, filtered by specific item colors and manager IDs. All joins are INNER (must match). Aggregates are SUM only, no statistical traps. The final ratios compare web vs store growth across quarters, requiring quarter-specific aggregates to be aligned by county and year. Any rewrite must preserve the quarter alignment and ratio comparisons.

## Bottleneck Diagnosis

The dominant cost (99.7ms) is computing the store_sales CTE (`ss`), which joins store_sales with item, customer_address, and date_dim. The plan is scan-bound on item and store_sales, with parallel aggregation. The optimizer already materializes CTEs and pushes item/customer filters, but does NOT push quarter/year filters into CTEs—they're applied post-materialization. Cardinality flow: item scan → 89 rows, store_sales → ~12 rows per item, aggregated to ~173 rows. The web_sales CTE returns 0 rows in this data. Logical-tree cost percentages are misleading: ss shows 47% but consumes ~99% of runtime.

## Engine Profile

*This is field intelligence gathered from 53 DSB queries at SF5-SF10. PostgreSQL is a fundamentally different optimizer than DuckDB — it has bitmap index scans, JIT compilation, and aggressive CTE materialization. Techniques that work on DuckDB often regress here. Use this to guide your analysis but apply your own judgment — every query is different. Add to this knowledge if you observe something new.*

### Optimizer Strengths (DO NOT fight these)
- **BITMAP_OR_SCAN**: Multi-branch OR conditions on indexed columns are handled via BitmapOr — a single fact table scan with bitmap combination. Extremely efficient.
- **SEMI_JOIN_EXISTS**: EXISTS/NOT EXISTS uses semi-join with early termination. Stops scanning after the first match per outer row.
- **INNER_JOIN_REORDERING**: PostgreSQL freely reorders INNER JOINs based on estimated selectivity. The cost model works well for explicit JOIN...ON syntax.
- **INDEX_ONLY_SCAN**: When an index covers all requested columns, PostgreSQL reads only the index without touching the heap.
- **PARALLEL_QUERY_EXECUTION**: PostgreSQL parallelizes large scans and aggregations across worker processes with partial aggregation finalization.
- **JIT_COMPILATION**: PostgreSQL JIT-compiles complex expressions and tuple deforming for long-running queries.

### Optimizer Gaps (opportunities)
- **COMMA_JOIN_WEAKNESS**: Implicit comma-separated FROM tables (FROM t1, t2, t3 WHERE t1.id = t2.id) are treated as cross products initially. The cost model is significantly weaker on comma-joins than on explicit JOIN...ON syntax.
  Opportunity: Convert comma-joins to explicit JOIN...ON syntax. This alone can unlock 2-3x improvements. Best when combined with date_cte_isolate.
    + Q080: 3.32x — comma-joins to explicit JOINs + date CTE on multi-channel UNION query
    + Q099: 2.28x — same pattern on star schema
    + Q054: 1.14x — JOIN conversion alone
- **CORRELATED_SUBQUERY_PARALYSIS**: Cannot automatically decorrelate complex correlated subqueries. Correlated scalar subqueries with aggregates are executed as nested-loop with repeated evaluation.
  Opportunity: Convert correlated WHERE to explicit CTE with GROUP BY + JOIN.
    + Q092: 4428x — timeout recovery. Unbounded correlated subquery converted to explicit JOIN.
    + Q032: 391x — same pattern, timeout to sub-second.
- **NON_EQUI_JOIN_INPUT_BLINDNESS**: Cannot pre-filter fact tables before non-equi join operations (date arithmetic, range comparisons, quantity < quantity). Non-equi joins fall back to nested-loop, which is O(N*M).
  Opportunity: Reduce fact table input size via filtered CTE before the non-equi join.
    + Q072: 2.68x — pre-filtered catalog_sales by wholesale_cost range before non-equi quantity comparison with inventory. Reduced nested-loop input by ~70%.
- **CTE_MATERIALIZATION_FENCE**: PostgreSQL materializes CTEs by default (multi-referenced) or by choice (AS MATERIALIZED). This creates a hard optimization fence — no predicate pushdown from outer query into CTE. This makes CTE-based strategies a double-edged sword on PG.
  Opportunity: Use materialization STRATEGICALLY: materialize when the CTE is expensive and reused multiple times. Avoid CTEs that fence off predicate pushdown for single-use cases.
    + Q065: 1.95x — strategic materialization prevented redundant fact table scan multiplication
- **CROSS_CTE_PREDICATE_BLINDNESS**: Same gap as DuckDB but WORSE on PostgreSQL because CTE materialization fence makes it more impactful. Predicates in the outer WHERE cannot propagate into materialized CTEs.
  Opportunity: Same as DuckDB: pre-filter into CTE definition. But be more cautious — only when the CTE is clearly suboptimal.
    + Q080: 3.32x — date filter + comma-join conversion (the combo is key)
    + Q099: 2.28x — date CTE with explicit JOIN

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_dimension_prefetch_star (3.32x)

**Principle:** Multi-Dimension Prefetch (PG): pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax. PostgreSQL's optimizer gets better cardinality estimates from pre-materialized small dimension results.

**BEFORE (slow):**
```sql
with ssr as
 (select  s_store_id as store_id,
          sum(ss_ext_sales_price) as sales,
          sum(coalesce(sr_return_amt, 0)) as returns,
          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit
  from store_sales left outer join store_returns on
         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),
     date_dim,
     store,
     item,
     promotion
 where ss_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
       and ss_store_sk = s_store_sk
       and ss_item_sk = i_item_sk
       and i_current_price > 50
       and ss_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ss_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
 group by s_store_id)
 ,
 csr as
 (select  cp_catalog_page_id as catalog_page_id,
          sum(cs_ext_sales_price) as sales,
          sum(coalesce(cr_return_amount, 0)) as returns,
          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit
  from catalog_sales left outer join catalog_returns on
         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),
     date_dim,
     catalog_page,
     item,
     promotion
 where cs_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and cs_catalog_page_sk = cp_catalog_page_sk
       and cs_item_sk = i_item_sk
       and i_current_price > 50
       and cs_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and cs_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by cp_catalog_page_id)
 ,
 wsr as
 (select  web_site_id,
          sum(ws_ext_sales_price) as sales,
          sum(coalesce(wr_return_amt, 0)) as returns,
          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit
  from web_sales left outer join web_returns on
         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),
     date_dim,
     web_site,
     item,
     promotion
 where ws_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and ws_web_site_sk = web_site_sk
       and ws_item_sk = i_item_sk
       and i_current_price > 50
       and ws_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ws_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by web_site_id)
  select  channel
        , id
        , sum(sales) as sales
        , sum(returns) as returns
        , sum(profit) as profit
 from
 (select 'store channel' as channel
        , 'store' || store_id as id
        , sales
        , returns
        , profit
 from   ssr
 union all
 select 'catalog channel' as channel
        , 'catalog_page' || catalog_page_id as id
        , sales
        , returns
        , profit
 from  csr
 union all
 select 'web channel' as channel
        , 'web_site' || web_site_id as id
        , sales
        , returns
        , profit
 from   wsr
 ) x
 group by rollup (channel, id)
 order by channel
         ,id
 limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-23' AS DATE) AND CAST('1998-08-23' AS DATE) + INTERVAL '30 DAY'
```
[filtered_item]:
```sql
SELECT i_item_sk FROM item WHERE i_current_price > 50 AND i_category IN ('Jewelry', 'Music')
```
[filtered_promotion]:
```sql
SELECT p_promo_sk FROM promotion WHERE p_channel_email = 'Y' AND p_channel_tv = 'Y' AND p_channel_radio = 'N' AND p_channel_press = 'N' AND p_channel_event = 'Y'
```
[ssr]:
```sql
SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS returns, SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) INNER JOIN filtered_date ON ss_sold_date_sk = filtered_date.d_date_sk INNER JOIN store ON ss_store_sk = s_store_sk INNER JOIN filtered_item ON ss_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ss_promo_sk = filtered_promotion.p_promo_sk WHERE ss_wholesale_cost BETWEEN 63 AND 78 GROUP BY s_store_id
```
[csr]:
```sql
SELECT cp_catalog_page_id AS catalog_page_id, SUM(cs_ext_sales_price) AS sales, SUM(COALESCE(cr_return_amount, 0)) AS returns, SUM(cs_net_profit - COALESCE(cr_net_loss, 0)) AS profit FROM catalog_sales LEFT OUTER JOIN catalog_returns ON (cs_item_sk = cr_item_sk AND cs_order_number = cr_order_number) INNER JOIN filtered_date ON cs_sold_date_sk = filtered_date.d_date_sk INNER JOIN catalog_page ON cs_catalog_page_sk = cp_catalog_page_sk INNER JOIN filtered_item ON cs_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON cs_promo_sk = filtered_promotion.p_promo_sk WHERE cs_wholesale_cost BETWEEN 63 AND 78 GROUP BY cp_catalog_page_id
```
[wsr]:
```sql
SELECT web_site_id, SUM(ws_ext_sales_price) AS sales, SUM(COALESCE(wr_return_amt, 0)) AS returns, SUM(ws_net_profit - COALESCE(wr_net_loss, 0)) AS profit FROM web_sales LEFT OUTER JOIN web_returns ON (ws_item_sk = wr_item_sk AND ws_order_number = wr_order_number) INNER JOIN filtered_date ON ws_sold_date_sk = filtered_date.d_date_sk INNER JOIN web_site ON ws_web_site_sk = web_site_sk INNER JOIN filtered_item ON ws_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ws_promo_sk = filtered_promotion.p_promo_sk WHERE ws_wholesale_cost BETWEEN 63 AND 78 GROUP BY web_site_id
```
[main_query]:
```sql
SELECT channel, id, SUM(sales) AS sales, SUM(returns) AS returns, SUM(profit) AS profit FROM (SELECT 'store channel' AS channel, 'store' || store_id AS id, sales, returns, profit FROM ssr UNION ALL SELECT 'catalog channel' AS channel, 'catalog_page' || catalog_page_id AS id, sales, returns, profit FROM csr UNION ALL SELECT 'web channel' AS channel, 'web_site' || web_site_id AS id, sales, returns, profit FROM wsr) AS x GROUP BY ROLLUP (channel, id) ORDER BY channel, id LIMIT 100
```

### 2. pg_materialized_dimension_fact_prefilter (2.68x)

**Principle:** Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.

**BEFORE (slow):**
```sql
select  i_item_desc
      ,w_warehouse_name
      ,d1.d_week_seq
      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo
      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo
      ,count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity
  and d3.d_date > d1.d_date + interval '3 day'
  and hd_buy_potential = '501-1000'
  and d1.d_year = 1998
  and cd_marital_status = 'M'
  and cd_dep_count between 9 and 11
  and i_category IN ('Home', 'Men', 'Music')
  and cs_wholesale_cost BETWEEN 34 AND 54
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk, d_date, d_week_seq FROM date_dim WHERE d_year = 1998
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc FROM item WHERE i_category IN ('Home', 'Men', 'Music')
```
[filtered_cd]:
```sql
SELECT cd_demo_sk FROM customer_demographics WHERE cd_marital_status = 'M' AND cd_dep_count BETWEEN 9 AND 11
```
[filtered_hd]:
```sql
SELECT hd_demo_sk FROM household_demographics WHERE hd_buy_potential = '501-1000'
```
[cs_filtered]:
```sql
SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk, cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost, cs_order_number FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 34 AND 54
```
[main_query]:
```sql
SELECT i.i_item_desc, w.w_warehouse_name, d1.d_week_seq, SUM(CASE WHEN p.p_promo_sk IS NULL THEN 1 ELSE 0 END) AS no_promo, SUM(CASE WHEN p.p_promo_sk IS NOT NULL THEN 1 ELSE 0 END) AS promo, COUNT(*) AS total_cnt FROM cs_filtered cs JOIN inventory inv ON cs.cs_item_sk = inv.inv_item_sk JOIN warehouse w ON w.w_warehouse_sk = inv.inv_warehouse_sk JOIN filtered_item i ON i.i_item_sk = cs.cs_item_sk JOIN filtered_cd cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk JOIN filtered_hd hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk JOIN filtered_date d1 ON cs.cs_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON inv.inv_date_sk = d2.d_date_sk JOIN date_dim d3 ON cs.cs_ship_date_sk = d3.d_date_sk LEFT OUTER JOIN promotion p ON cs.cs_promo_sk = p.p_promo_sk LEFT OUTER JOIN catalog_returns cr ON cr.cr_item_sk = cs.cs_item_sk AND cr.cr_order_number = cs.cs_order_number WHERE d1.d_week_seq = d2.d_week_seq AND inv.inv_quantity_on_hand < cs.cs_quantity AND d3.d_date > d1.d_date + INTERVAL '3 day' GROUP BY i.i_item_desc, w.w_warehouse_name, d1.d_week_seq ORDER BY total_cnt DESC, i.i_item_desc, w.w_warehouse_name, d1.d_week_seq LIMIT 100
```

### 3. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

### 4. early_filter_decorrelate (1.13x)

**Principle:** Early Selection + Decorrelation: push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN.

**BEFORE (slow):**
```sql
WITH customer_total_return AS (
  SELECT sr_customer_sk AS ctr_customer_sk,
         sr_store_sk AS ctr_store_sk,
         sr_reason_sk AS ctr_reason_sk,
         SUM(SR_REFUNDED_CASH) AS ctr_total_return
  FROM store_returns, date_dim
  WHERE sr_returned_date_sk = d_date_sk
    AND d_year = 2001
    AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295
  GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1, store, customer, customer_demographics
WHERE ctr1.ctr_total_return > (
    SELECT AVG(ctr_total_return) * 1.2
    FROM customer_total_return ctr2
    WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk
  )
  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31
  AND s_store_sk = ctr1.ctr_store_sk
  AND s_state IN ('MI', 'NC', 'WI')
  AND ctr1.ctr_customer_sk = c_customer_sk
  AND c_current_cdemo_sk = cd_demo_sk
  AND cd_marital_status IN ('W', 'W')
  AND cd_education_status IN ('4 yr Degree', 'College')
  AND cd_gender = 'M'
  AND c_birth_month = 5
  AND c_birth_year BETWEEN 1950 AND 1956
ORDER BY c_customer_id
LIMIT 100
```

**AFTER (fast):**
```sql
WITH customer_total_return AS (
    SELECT sr_customer_sk AS ctr_customer_sk,
           sr_store_sk AS ctr_store_sk,
           sr_reason_sk AS ctr_reason_sk,
           SUM(SR_REFUNDED_CASH) AS ctr_total_return
    FROM store_returns
    JOIN date_dim ON sr_returned_date_sk = d_date_sk
    JOIN store ON sr_store_sk = s_store_sk
    WHERE d_year = 2001
      AND s_state IN ('MI', 'NC', 'WI')
      AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295
    GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
),
store_thresholds AS (
    SELECT ctr_store_sk,
           AVG(ctr_total_return) * 1.2 AS avg_limit
    FROM customer_total_return
    GROUP BY ctr_store_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1
JOIN store_thresholds st ON ctr1.ctr_store_sk = st.ctr_store_sk
JOIN customer ON ctr1.ctr_customer_sk = c_customer_sk
JOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk
JOIN store s ON ctr1.ctr_store_sk = s.s_store_sk
WHERE ctr1.ctr_total_return > st.avg_limit
  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31
  AND s.s_state IN ('MI', 'NC', 'WI')
  AND cd_marital_status = 'W'
  AND cd_education_status IN ('4 yr Degree', 'College')
  AND cd_gender = 'M'
  AND c_birth_month = 5
  AND c_birth_year BETWEEN 1950 AND 1956
ORDER BY c_customer_id
LIMIT 100
```

### 5. inline_decorrelate_materialized (timeout_rescue)

**Principle:** Inline Decorrelation with MATERIALIZED CTEs: When a WHERE clause contains a correlated scalar subquery (e.g., col > (SELECT 1.3 * avg(col) FROM ... WHERE correlated_key = outer.key)), PostgreSQL re-executes the subquery per outer row. Fix: decompose into 3 MATERIALIZED CTEs — (1) pre-filter dimension table, (2) pre-filter fact table by date range, (3) compute per-key aggregate threshold from filtered data — then JOIN the threshold CTE in the final query. MATERIALIZED keyword prevents PG from inlining the CTEs back into correlated form.

**BEFORE (slow):**
```sql
select  sum(cs_ext_discount_amt)  as "excess discount amount"
from
   catalog_sales
   ,item
   ,date_dim
where
(i_manufact_id in (1, 78, 97, 516, 521)
or i_manager_id BETWEEN 25 and 54)
and i_item_sk = cs_item_sk
and d_date between '1999-03-07' and
        cast('1999-03-07' as date) + interval '90 day'
and d_date_sk = cs_sold_date_sk
and cs_ext_discount_amt
     > (
         select
            1.3 * avg(cs_ext_discount_amt)
         from
            catalog_sales
           ,date_dim
         where
              cs_item_sk = i_item_sk
          and d_date between '1999-03-07' and
                             cast('1999-03-07' as date) + interval '90 day'
          and d_date_sk = cs_sold_date_sk
          and cs_list_price between 16 and 45
          and cs_sales_price / cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01
      )
order by sum(cs_ext_discount_amt)
limit 100;
```

**AFTER (fast):**
```sql
WITH filtered_items AS MATERIALIZED (
    SELECT i_item_sk
    FROM item
    WHERE i_manufact_id IN (1, 78, 97, 516, 521)
       OR i_manager_id BETWEEN 25 AND 54
),
date_filtered_sales AS MATERIALIZED (
    SELECT cs.cs_item_sk, cs.cs_ext_discount_amt,
           cs.cs_list_price, cs.cs_sales_price
    FROM catalog_sales cs
    JOIN date_dim d ON d.d_date_sk = cs.cs_sold_date_sk
    WHERE d.d_date BETWEEN '1999-03-07' AND cast('1999-03-07' as date) + interval '90 day'
),
item_avg_discount AS MATERIALIZED (
    SELECT dfs.cs_item_sk,
           1.3 * avg(dfs.cs_ext_discount_amt) AS threshold
    FROM date_filtered_sales dfs
    JOIN filtered_items fi ON fi.i_item_sk = dfs.cs_item_sk
    WHERE dfs.cs_list_price BETWEEN 16 AND 45
      AND dfs.cs_sales_price / dfs.cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01
    GROUP BY dfs.cs_item_sk
)
SELECT sum(dfs.cs_ext_discount_amt) AS "excess discount amount"
FROM date_filtered_sales dfs
JOIN item_avg_discount iad ON iad.cs_item_sk = dfs.cs_item_sk
WHERE dfs.cs_ext_discount_amt > iad.threshold
ORDER BY 1
LIMIT 100;
```

### 6. pg_date_cte_explicit_join (2.28x)

**Principle:** Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.

**BEFORE (slow):**
```sql
select 
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   catalog_sales
  ,warehouse
  ,ship_mode
  ,call_center
  ,date_dim
where
d_month_seq between 1193 and 1193 + 23
and cs_ship_date_sk   = d_date_sk
and cs_warehouse_sk   = w_warehouse_sk
and cs_ship_mode_sk   = sm_ship_mode_sk
and cs_call_center_sk = cc_call_center_sk
and cs_list_price between 271 and 300
and sm_type = 'REGULAR'
and cc_class = 'small'
and w_gmt_offset = -5
group by
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
order by substring(w_warehouse_name,1,20)
        ,sm_type
        ,cc_name
limit 100;
```

**AFTER (fast):**
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1193 AND 1216
```
[main_query]:
```sql
SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", ... FROM catalog_sales JOIN filtered_dates ON cs_ship_date_sk = d_date_sk JOIN warehouse ON cs_warehouse_sk = w_warehouse_sk JOIN ship_mode ON cs_ship_mode_sk = sm_ship_mode_sk JOIN call_center ON cs_call_center_sk = cc_call_center_sk WHERE cs_list_price BETWEEN 271 AND 300 AND sm_type = 'REGULAR' AND cc_class = 'small' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY 1, 2, 3 LIMIT 100
```

## Correctness Invariants (HARD STOPS — non-negotiable)

These 4 constraints are absolute. Even with full creative freedom, you may NEVER violate these:

- **COMPLETE_OUTPUT**: The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original.
- **CTE_COLUMN_COMPLETENESS**: CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.
- **LITERAL_PRESERVATION**: CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.
- **SEMANTIC_EQUIVALENCE**: The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set — even by one row, one column, or a different sort order — is WRONG and will be REJECTED.

## Aggregation Semantics Check (HARD STOP)

- STDDEV_SAMP/VARIANCE are grouping-sensitive — changing group membership changes the result.
- AVG and STDDEV are NOT duplicate-safe.
- FILTER over a combined group != separate per-group computation.
- Verify aggregation equivalence for ANY proposed restructuring.

## Original SQL

```sql
with ss as
 (select ca_county,d_qoy, d_year,sum(ss_ext_sales_price) as store_sales
 from store_sales,date_dim,customer_address, item
 where ss_sold_date_sk = d_date_sk
  and ss_addr_sk=ca_address_sk
  and ss_item_sk = i_item_sk
  and i_color IN ('navajo', 'orchid')
  and i_manager_id BETWEEN 8 and 27
  and ss_list_price between 86 and 100
  and ca_state in ('IA','IL')
 group by ca_county,d_qoy, d_year),
 ws as
 (select ca_county,d_qoy, d_year,sum(ws_ext_sales_price) as web_sales
 from web_sales,date_dim,customer_address, item
 where ws_sold_date_sk = d_date_sk
  and ws_bill_addr_sk=ca_address_sk
  and ws_item_sk = i_item_sk
  and i_color IN ('navajo', 'orchid')
  and i_manager_id BETWEEN 8 and 27
  and ws_list_price between 86 and 100
  and ca_state in ('IA','IL')
group by ca_county,d_qoy, d_year)
 select
        ss1.ca_county
       ,ss1.d_year
       ,ws2.web_sales/ws1.web_sales web_q1_q2_increase
       ,ss2.store_sales/ss1.store_sales store_q1_q2_increase
       ,ws3.web_sales/ws2.web_sales web_q2_q3_increase
       ,ss3.store_sales/ss2.store_sales store_q2_q3_increase
 from
        ss ss1
       ,ss ss2
       ,ss ss3
       ,ws ws1
       ,ws ws2
       ,ws ws3
 where
    ss1.d_qoy = 1
    and ss1.d_year = 1998
    and ss1.ca_county = ss2.ca_county
    and ss2.d_qoy = 2
    and ss2.d_year = 1998
 and ss2.ca_county = ss3.ca_county
    and ss3.d_qoy = 3
    and ss3.d_year = 1998
    and ss1.ca_county = ws1.ca_county
    and ws1.d_qoy = 1
    and ws1.d_year = 1998
    and ws1.ca_county = ws2.ca_county
    and ws2.d_qoy = 2
    and ws2.d_year = 1998
    and ws1.ca_county = ws3.ca_county
    and ws3.d_qoy = 3
    and ws3.d_year =1998
    and case when ws1.web_sales > 0 then ws2.web_sales/ws1.web_sales else null end
       > case when ss1.store_sales > 0 then ss2.store_sales/ss1.store_sales else null end
    and case when ws2.web_sales > 0 then ws3.web_sales/ws2.web_sales else null end
       > case when ss2.store_sales > 0 then ss3.store_sales/ss2.store_sales else null end
 order by ss1.d_year;
```

## Per-Rewrite Configuration (SET LOCAL)

You have two optimization levers: SQL rewrite AND per-query configuration.
After writing your rewrite, analyze its execution profile and emit SET LOCAL
commands that fix planner-level bottlenecks specific to YOUR rewrite.

Memory budget: shared_buffers=128MB, effective_cache_size=4GB
Global work_mem: 4MB (per-operation)
Active connections: ~1 (work_mem headroom: safe up to 16MB per-op)
Storage: HDD (random_page_cost=4.0)
Parallel capacity: max_parallel_workers=8, per_gather=2

SET LOCAL permissions:
  user-level (always available): effective_cache_size, enable_hashjoin, enable_mergejoin, enable_nestloop, enable_seqscan, from_collapse_limit, geqo_threshold, hash_mem_multiplier, jit, jit_above_cost, join_collapse_limit, max_parallel_workers_per_gather, parallel_setup_cost, parallel_tuple_cost, random_page_cost, work_mem

### Tunable Parameters (whitelist — only these are allowed)

- **effective_cache_size** (1024MB–65536MB): Advisory: how much OS cache to expect (MB). Safe to set aggressively.
- **enable_hashjoin** (on | off): Enable hash join plan type.
- **enable_mergejoin** (on | off): Enable merge join plan type.
- **enable_nestloop** (on | off): Enable nested-loop join plan type.
- **enable_seqscan** (on | off): Enable sequential scan plan type.
- **from_collapse_limit** (1–20): Max FROM items before subqueries stop being flattened.
- **geqo_threshold** (2–20): Number of FROM items that triggers genetic query optimizer.
- **hash_mem_multiplier** (1.0–10.0): Multiplier applied to work_mem for hash-based operations.
- **jit** (on | off): Enable JIT compilation.
- **jit_above_cost** (0.0–1000000.0): Query cost above which JIT is activated.
- **join_collapse_limit** (1–20): Max FROM items before planner stops trying all join orders.
- **max_parallel_workers_per_gather** (0–8): Max parallel workers per Gather node.
- **parallel_setup_cost** (0.0–10000.0): Planner estimate of cost to launch parallel workers.
- **parallel_tuple_cost** (0.0–1.0): Planner estimate of cost to transfer a tuple to parallel worker.
- **random_page_cost** (1.0–10.0): Planner estimate of cost of a random page fetch (1.0 = SSD, 4.0 = HDD).
- **work_mem** (64MB–2048MB): Memory for sorts/hashes per operation (MB). Allocated PER-OPERATION, not per-query. Count hash/sort ops in EXPLAIN before sizing.

### Rules
- Every SET LOCAL MUST cite a specific EXPLAIN node your rewrite creates/changes
- work_mem is PER-OPERATION: count hash/sort ops in your rewrite before sizing
- random_page_cost: ONLY change if your rewrite creates index-favorable access patterns
- Empty is valid: if your rewrite has no planner bottleneck, emit no SET LOCAL
- Stay within the resource envelope bounds above

### SET LOCAL Syntax
Include SET LOCAL commands in the `runtime_config` array field of your JSON output.
If no config changes help, omit the field or use an empty array.

## Your Task — Self-Directed Retry

Work through these 3 steps in a `<reasoning>` block, then output your optimized SQL:

1. **DIAGNOSE**: Why did the best worker achieve 0.254263504611182x instead of the 2.0x target? What do the EXPLAIN plans reveal about the actual execution bottleneck?
2. **IDENTIFY**: What optimization angles are still unexplored? What did the empirical results reveal that couldn't have been known before seeing the execution plans?
3. **REWRITE**: Produce optimized SQL that exploits the angles you identified. You may build on the best foundation or start fresh.

## Rewrite Checklist (must pass before final SQL)

- Verify output schema matches the Column Completeness Contract (same columns, same names, same order).
- Keep all semantic invariants from `Correctness Invariants` (including join/null behavior).
- Verify aggregation equivalence: same rows participate in each group, same aggregate semantics.
- Preserve all literals exactly (numbers, strings, date values).
- Apply `Hazard Flags` as hard guards against known failure modes.

### Column Completeness Contract

Your `main_query` component MUST produce **exactly** these output columns (same names, same order):

  1. `ca_county`
  2. `d_year`
  3. `web_q1_q2_increase`
  4. `store_q1_q2_increase`
  5. `web_q2_q3_increase`
  6. `store_q2_q3_increase`

Do NOT add, remove, or rename any output columns. The result set schema must be identical to the original query.

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: