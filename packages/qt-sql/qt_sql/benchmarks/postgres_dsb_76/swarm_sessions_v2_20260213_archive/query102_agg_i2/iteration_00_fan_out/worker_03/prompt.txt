You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

Compare customer demographics for items sold through both store and web channels within 30 days, where inventory stock meets sales quantity. All joins are INNER (must match all sides). Aggregation is simple COUNT(*) with GROUP BY on 4 demographic columns - no sensitive aggregates. Filter dependencies: d2 date range depends on d1 date; inventory quantity check depends on store_sales quantity; state filter applies to customer_address.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
base_sales -> web_sales_part -> store_sales_part -> joined -> final_aggregation
NODE_CONTRACTS:
  base_sales:
    FROM: (SELECT ws_item_sk, ws_bill_customer_sk, ws_sold_date_sk, ws_warehouse_sk, ws_wholesale_cost FROM web_sales WHERE ws_wholesale_cost BETWEEN 76 AND 96
           UNION ALL
           SELECT ss_item_sk, ss_customer_sk, ss_sold_date_sk, NULL, NULL FROM store_sales) sales
          JOIN item ON sales.item_sk = i_item_sk AND i_category IN ('Men', 'Shoes', 'Sports') AND i_manager_id IN (6, 11, 16, 17, 19, 28, 47, 82, 88, 98)
          JOIN customer ON sales.customer_sk = c_customer_sk
          JOIN customer_address ON c_current_addr_sk = ca_address_sk AND ca_state IN ('AR', 'CA', 'KS', 'NY', 'VA')
          JOIN household_demographics ON c_current_hdemo_sk = hd_demo_sk
          JOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk
    OUTPUT: sales.item_sk, sales.customer_sk, sales.sold_date_sk, sales.warehouse_sk, sales.wholesale_cost, 
            cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count,
            CASE WHEN sales.wholesale_cost IS NOT NULL THEN 'web' ELSE 'store' END as channel
    EXPECTED_ROWS: web_sales 43K + store_sales unknown
    CONSUMERS: web_sales_part, store_sales_part
  web_sales_part:
    FROM: base_sales
    WHERE: channel = 'web'
    OUTPUT: item_sk, customer_sk, sold_date_sk, warehouse_sk, cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: ~43K
    CONSUMERS: joined
  store_sales_part:
    FROM: base_sales
    WHERE: channel = 'store'
    OUTPUT: item_sk, customer_sk, sold_date_sk, cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: unknown
    CONSUMERS: joined
  joined:
    FROM: web_sales_part ws JOIN store_sales_part ss ON ws.item_sk = ss.item_sk AND ws.customer_sk = ss.customer_sk
                            JOIN date_dim d1 ON ss.sold_date_sk = d1.d_date_sk AND d1.d_year = 1998
                            JOIN date_dim d2 ON ws.sold_date_sk = d2.d_date_sk
                            JOIN warehouse ON ws.warehouse_sk = w_warehouse_sk
                            JOIN store ON s_state = w_state
                            JOIN inventory ON inv_warehouse_sk = ws.warehouse_sk AND inv_item_sk = ss.item_sk AND inv_date_sk = ss.sold_date_sk
    WHERE: d2.d_date BETWEEN d1.d_date AND (d1.d_date + interval '30 day')
      AND inv_quantity_on_hand >= (SELECT ss_quantity FROM store_sales WHERE ss_item_sk = ss.item_sk AND ss_customer_sk = ss.customer_sk AND ss_sold_date_sk = ss.sold_date_sk)
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: small
    CONSUMERS: final_aggregation
  final_aggregation:
    FROM: joined
    GROUP BY: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    AGGREGATE: COUNT(*) as cnt
    ORDER BY: cnt
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt
    EXPECTED_ROWS: 0
    CONSUMERS: output

NODE_CONTRACTS:
base_sales:
    FROM: (SELECT ws_item_sk, ws_bill_customer_sk, ws_sold_date_sk, ws_warehouse_sk, ws_wholesale_cost FROM web_sales WHERE ws_wholesale_cost BETWEEN 76 AND 96
           UNION ALL
           SELECT ss_item_sk, ss_customer_sk, ss_sold_date_sk, NULL, NULL FROM store_sales) sales
          JOIN item ON sales.item_sk = i_item_sk AND i_category IN ('Men', 'Shoes', 'Sports') AND i_manager_id IN (6, 11, 16, 17, 19, 28, 47, 82, 88, 98)
          JOIN customer ON sales.customer_sk = c_customer_sk
          JOIN customer_address ON c_current_addr_sk = ca_address_sk AND ca_state IN ('AR', 'CA', 'KS', 'NY', 'VA')
          JOIN household_demographics ON c_current_hdemo_sk = hd_demo_sk
          JOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk
    OUTPUT: sales.item_sk, sales.customer_sk, sales.sold_date_sk, sales.warehouse_sk, sales.wholesale_cost, 
            cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count,
            CASE WHEN sales.wholesale_cost IS NOT NULL THEN 'web' ELSE 'store' END as channel
    EXPECTED_ROWS: web_sales 43K + store_sales unknown
    CONSUMERS: web_sales_part, store_sales_part
  web_sales_part:
    FROM: base_sales
    WHERE: channel = 'web'
    OUTPUT: item_sk, customer_sk, sold_date_sk, warehouse_sk, cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: ~43K
    CONSUMERS: joined
  store_sales_part:
    FROM: base_sales
    WHERE: channel = 'store'
    OUTPUT: item_sk, customer_sk, sold_date_sk, cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: unknown
    CONSUMERS: joined
  joined:
    FROM: web_sales_part ws JOIN store_sales_part ss ON ws.item_sk = ss.item_sk AND ws.customer_sk = ss.customer_sk
                            JOIN date_dim d1 ON ss.sold_date_sk = d1.d_date_sk AND d1.d_year = 1998
                            JOIN date_dim d2 ON ws.sold_date_sk = d2.d_date_sk
                            JOIN warehouse ON ws.warehouse_sk = w_warehouse_sk
                            JOIN store ON s_state = w_state
                            JOIN inventory ON inv_warehouse_sk = ws.warehouse_sk AND inv_item_sk = ss.item_sk AND inv_date_sk = ss.sold_date_sk
    WHERE: d2.d_date BETWEEN d1.d_date AND (d1.d_date + interval '30 day')
      AND inv_quantity_on_hand >= (SELECT ss_quantity FROM store_sales WHERE ss_item_sk = ss.item_sk AND ss_customer_sk = ss.customer_sk AND ss_sold_date_sk = ss.sold_date_sk)
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: small
    CONSUMERS: final_aggregation
  final_aggregation:
    FROM: joined
    GROUP BY: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    AGGREGATE: COUNT(*) as cnt
    ORDER BY: cnt
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt
    EXPECTED_ROWS: 0
    CONSUMERS: output

## Hazard Flags (avoid these specific risks)

- UNION ALL in base_sales may duplicate rows if same sale appears in both channels (unlikely but possible).
- Subquery for ss_quantity in joined may re-introduce nested loops; consider including ss_quantity in store_sales_part output.

## Regression Warnings (observed failures on similar queries)

1. CTE blocking parallelism (observed regression in heavy aggregation queries):
   CAUSE: Materialized CTEs execute single-threaded, preventing parallel scans of large fact tables.
   RULE: For web_sales/store_sales scans, avoid wrapping entire fact tables in CTEs if they benefit from parallel scans.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Must output cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt exactly.
- CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream (ss_item_sk, ss_customer_sk, ss_quantity, ws_item_sk, ws_bill_customer_sk, etc.).
- LITERAL_PRESERVATION: Must preserve all filter values (1998, AR/CA/KS/NY/VA, 76-96, etc.).
- SEMANTIC_EQUIVALENCE: Must return same rows and ordering.
- COMMA_JOIN_WEAKNESS: Query uses comma-separated implicit joins (EXPLAIN shows optimizer using hash/nested loops but may misestimate).
- NON_EQUI_JOIN_INPUT_BLINDNESS: inv_quantity_on_hand >= ss_quantity applied late after joins (EXPLAIN shows Filter on inventory scan).
- CROSS_CTE_PREDICATE_BLINDNESS: store_sales scanned repeatedly via nested loop (EXPLAIN shows 4,148 loops × 3 workers).

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

Apply the shared materialization pattern: create a base CTE that scans both fact tables once with shared dimension joins, then split into web/store parts. Ignore that example Q65 aggregated differently - the principle of single fact+dimension scan applies.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

## Original SQL

```sql
select 
    cd_gender,
    cd_marital_status,
    cd_education_status,
    hd_vehicle_count,
    count(*) as cnt
from
    store_sales,
    web_sales,
    date_dim d1,
    date_dim d2,
    customer,
    inventory,
    store,
    warehouse,
    item,
    customer_demographics,
    household_demographics,
    customer_address
    where
      ss_item_sk = i_item_sk
      and ws_item_sk = ss_item_sk
      and ss_sold_date_sk = d1.d_date_sk
      and ws_sold_date_sk = d2.d_date_sk
			and d2.d_date between d1.d_date and (d1.d_date + interval '30 day')
      and ss_customer_sk = c_customer_sk
      and ws_bill_customer_sk = c_customer_sk
      and ws_warehouse_sk = inv_warehouse_sk
      and ws_warehouse_sk = w_warehouse_sk
      and inv_item_sk = ss_item_sk
      and inv_date_sk = ss_sold_date_sk
      and inv_quantity_on_hand >= ss_quantity
      and s_state = w_state
      AND i_category IN ('Men', 'Shoes', 'Sports')
      and i_manager_id IN (6, 11, 16, 17, 19, 28, 47, 82, 88, 98)
      and c_current_cdemo_sk = cd_demo_sk
      and c_current_hdemo_sk = hd_demo_sk
      and c_current_addr_sk = ca_address_sk
      and ca_state in ('AR', 'CA', 'KS', 'NY', 'VA')
      and d1.d_year = 1998
      and ws_wholesale_cost BETWEEN 76 AND 96
    group by cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    order by cnt
    ;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 99%  Rows: ~1.4M
    ├── SCAN (store_sales, web_sales (join), date_dim AS d1 (join), date_dim AS d2 (join), customer (join), inventory (join), store (join), warehouse (join), item (join), customer_demographics (join), household_demographics (join), customer_address (join))
    ├── JOIN (ss_item_sk = i_item_sk)
    ├── JOIN (ws_item_sk = ss_item_sk)
    ├── JOIN (+12 more)
    ├── FILTER (d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '30 DAY'))
    ├── FILTER (inv_quantity_on_hand >= ss_quantity)
    ├── FILTER (+5 more)
    ├── AGG (GROUP BY)
    ├── SORT (cnt ASC)
    └── OUTPUT (cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: