You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

Find shipping metrics for web orders within a 60-day window where: (a) the order ships to one of six US states, (b) the website is in timezone GMT-5 or later, (c) list price is between $253-$282, (d) the order was fulfilled from at least two different warehouses, and (e) the order was not returned for any of five specific reasons. All joins are INNER (must match), and COUNT(DISTINCT) requires preserving exact order set. The NOT EXISTS with wr_reason_sk IN list must reject orders with ANY matching reason.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
CTE_multi_warehouse_orders -> CTE_bad_returns -> JOIN with filtered web_sales+dimensions -> Aggregate
NODE_CONTRACTS:
  multi_warehouse_orders:
    FROM: web_sales
    GROUP BY: ws_order_number
    HAVING: COUNT(DISTINCT ws_warehouse_sk) >= 2
    OUTPUT: ws_order_number
    EXPECTED_ROWS: unknown but ≤ total orders
    CONSUMERS: qualified_sales
  bad_returns:
    FROM: web_returns
    WHERE: wr_reason_sk IN (8,18,20,23,41)
    GROUP BY: wr_order_number
    OUTPUT: wr_order_number
    EXPECTED_ROWS: ≤77K (one per bad order)
    CONSUMERS: qualified_sales
  qualified_sales:
    FROM: web_sales ws1, date_dim, customer_address, web_site, multi_warehouse_orders mwo
    WHERE: d_date BETWEEN '1999-10-01' AND CAST('1999-10-01' AS DATE) + INTERVAL '60 DAY'
           AND ws1.ws_ship_date_sk = d_date_sk
           AND ws1.ws_ship_addr_sk = ca_address_sk
           AND ca_state IN ('MO','MT','OK','SC','TX','WI')
           AND ws1.ws_web_site_sk = web_site_sk
           AND web_gmt_offset >= -5
           AND ws1.ws_list_price BETWEEN 253 AND 282
           AND ws1.ws_order_number = mwo.ws_order_number
           AND NOT EXISTS (SELECT 1 FROM bad_returns br WHERE br.wr_order_number = ws1.ws_order_number)
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit
    EXPECTED_ROWS: same as final result set
    CONSUMERS: final_agg
  final_agg:
    FROM: qualified_sales
    AGGREGATE: COUNT(DISTINCT ws_order_number), SUM(ws_ext_ship_cost), SUM(ws_net_profit)
    OUTPUT: order count, total shipping cost, total net profit
    EXPECTED_ROWS: 1
    CONSUMERS: final

NODE_CONTRACTS:
multi_warehouse_orders:
    FROM: web_sales
    GROUP BY: ws_order_number
    HAVING: COUNT(DISTINCT ws_warehouse_sk) >= 2
    OUTPUT: ws_order_number
    EXPECTED_ROWS: unknown but ≤ total orders
    CONSUMERS: qualified_sales
  bad_returns:
    FROM: web_returns
    WHERE: wr_reason_sk IN (8,18,20,23,41)
    GROUP BY: wr_order_number
    OUTPUT: wr_order_number
    EXPECTED_ROWS: ≤77K (one per bad order)
    CONSUMERS: qualified_sales
  qualified_sales:
    FROM: web_sales ws1, date_dim, customer_address, web_site, multi_warehouse_orders mwo
    WHERE: d_date BETWEEN '1999-10-01' AND CAST('1999-10-01' AS DATE) + INTERVAL '60 DAY'
           AND ws1.ws_ship_date_sk = d_date_sk
           AND ws1.ws_ship_addr_sk = ca_address_sk
           AND ca_state IN ('MO','MT','OK','SC','TX','WI')
           AND ws1.ws_web_site_sk = web_site_sk
           AND web_gmt_offset >= -5
           AND ws1.ws_list_price BETWEEN 253 AND 282
           AND ws1.ws_order_number = mwo.ws_order_number
           AND NOT EXISTS (SELECT 1 FROM bad_returns br WHERE br.wr_order_number = ws1.ws_order_number)
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit
    EXPECTED_ROWS: same as final result set
    CONSUMERS: final_agg
  final_agg:
    FROM: qualified_sales
    AGGREGATE: COUNT(DISTINCT ws_order_number), SUM(ws_ext_ship_cost), SUM(ws_net_profit)
    OUTPUT: order count, total shipping cost, total net profit
    EXPECTED_ROWS: 1
    CONSUMERS: final

## Hazard Flags (avoid these specific risks)

- bad_returns CTE may be large (77K rows) - could hurt performance if not selective
- Must preserve NOT EXISTS semantics exactly (anti-join, not LEFT JOIN WHERE NULL)

## Regression Warnings (observed failures on similar queries)

1. EXISTS to IN/NOT IN (observed 0.50x regression):
   CAUSE: Converting EXISTS to IN with large result set forces materialization and loses semi-join early termination
   RULE: Preserve EXISTS structure; if decorrelating, use JOIN with DISTINCT or GROUP BY instead of IN
2. CTE blocking parallelism (observed 0.8x regression):
   CAUSE: MATERIALIZED CTEs execute single-threaded, preventing parallel scan of large fact tables
   RULE: Avoid wrapping large fact table scans in CTEs; keep them in main query for parallel execution

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Must output exactly three columns: order count, total shipping cost, total net profit
- CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream (ws_order_number, ws_ext_ship_cost, ws_net_profit, join keys)
- LITERAL_PRESERVATION: Must preserve exact date '1999-10-01', interval '60 day', state list, price range 253-282, reason_sk values 8,18,20,23,41
- SEMANTIC_EQUIVALENCE: Must return same rows and aggregation values
- COMMA_JOIN_WEAKNESS: Query uses implicit comma joins (lines 6-9), causing poor cardinality estimation
- CROSS_CTE_PREDICATE_BLINDNESS: web_sales scanned twice (ws1 for main, ws2 for EXISTS) - opportunity for shared materialization

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

inline_decorrelate_materialized: Apply decorrelation of EXISTS by pre-computing multi_warehouse_orders in a CTE; use MATERIALIZED to prevent re-inlining; ignore the 3-CTE structure (we only need 2 CTEs).
  early_filter_decorrelate: Push dimension filters early; pre-compute bad_returns in separate CTE; ignore the threshold computation aspect.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. inline_decorrelate_materialized (timeout_rescue)

**Principle:** Inline Decorrelation with MATERIALIZED CTEs: When a WHERE clause contains a correlated scalar subquery (e.g., col > (SELECT 1.3 * avg(col) FROM ... WHERE correlated_key = outer.key)), PostgreSQL re-executes the subquery per outer row. Fix: decompose into 3 MATERIALIZED CTEs — (1) pre-filter dimension table, (2) pre-filter fact table by date range, (3) compute per-key aggregate threshold from filtered data — then JOIN the threshold CTE in the final query. MATERIALIZED keyword prevents PG from inlining the CTEs back into correlated form.

**BEFORE (slow):**
```sql
select  sum(cs_ext_discount_amt)  as "excess discount amount"
from
   catalog_sales
   ,item
   ,date_dim
where
(i_manufact_id in (1, 78, 97, 516, 521)
or i_manager_id BETWEEN 25 and 54)
and i_item_sk = cs_item_sk
and d_date between '1999-03-07' and
        cast('1999-03-07' as date) + interval '90 day'
and d_date_sk = cs_sold_date_sk
and cs_ext_discount_amt
     > (
         select
            1.3 * avg(cs_ext_discount_amt)
         from
            catalog_sales
           ,date_dim
         where
              cs_item_sk = i_item_sk
          and d_date between '1999-03-07' and
                             cast('1999-03-07' as date) + interval '90 day'
          and d_date_sk = cs_sold_date_sk
          and cs_list_price between 16 and 45
          and cs_sales_price / cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01
      )
order by sum(cs_ext_discount_amt)
limit 100;
```

**AFTER (fast):**
```sql
WITH filtered_items AS MATERIALIZED (
    SELECT i_item_sk
    FROM item
    WHERE i_manufact_id IN (1, 78, 97, 516, 521)
       OR i_manager_id BETWEEN 25 AND 54
),
date_filtered_sales AS MATERIALIZED (
    SELECT cs.cs_item_sk, cs.cs_ext_discount_amt,
           cs.cs_list_price, cs.cs_sales_price
    FROM catalog_sales cs
    JOIN date_dim d ON d.d_date_sk = cs.cs_sold_date_sk
    WHERE d.d_date BETWEEN '1999-03-07' AND cast('1999-03-07' as date) + interval '90 day'
),
item_avg_discount AS MATERIALIZED (
    SELECT dfs.cs_item_sk,
           1.3 * avg(dfs.cs_ext_discount_amt) AS threshold
    FROM date_filtered_sales dfs
    JOIN filtered_items fi ON fi.i_item_sk = dfs.cs_item_sk
    WHERE dfs.cs_list_price BETWEEN 16 AND 45
      AND dfs.cs_sales_price / dfs.cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01
    GROUP BY dfs.cs_item_sk
)
SELECT sum(dfs.cs_ext_discount_amt) AS "excess discount amount"
FROM date_filtered_sales dfs
JOIN item_avg_discount iad ON iad.cs_item_sk = dfs.cs_item_sk
WHERE dfs.cs_ext_discount_amt > iad.threshold
ORDER BY 1
LIMIT 100;
```

### 2. early_filter_decorrelate (1.13x)

**Principle:** Early Selection + Decorrelation: push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN.

**BEFORE (slow):**
```sql
WITH customer_total_return AS (
  SELECT sr_customer_sk AS ctr_customer_sk,
         sr_store_sk AS ctr_store_sk,
         sr_reason_sk AS ctr_reason_sk,
         SUM(SR_REFUNDED_CASH) AS ctr_total_return
  FROM store_returns, date_dim
  WHERE sr_returned_date_sk = d_date_sk
    AND d_year = 2001
    AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295
  GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1, store, customer, customer_demographics
WHERE ctr1.ctr_total_return > (
    SELECT AVG(ctr_total_return) * 1.2
    FROM customer_total_return ctr2
    WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk
  )
  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31
  AND s_store_sk = ctr1.ctr_store_sk
  AND s_state IN ('MI', 'NC', 'WI')
  AND ctr1.ctr_customer_sk = c_customer_sk
  AND c_current_cdemo_sk = cd_demo_sk
  AND cd_marital_status IN ('W', 'W')
  AND cd_education_status IN ('4 yr Degree', 'College')
  AND cd_gender = 'M'
  AND c_birth_month = 5
  AND c_birth_year BETWEEN 1950 AND 1956
ORDER BY c_customer_id
LIMIT 100
```

**AFTER (fast):**
```sql
WITH customer_total_return AS (
    SELECT sr_customer_sk AS ctr_customer_sk,
           sr_store_sk AS ctr_store_sk,
           sr_reason_sk AS ctr_reason_sk,
           SUM(SR_REFUNDED_CASH) AS ctr_total_return
    FROM store_returns
    JOIN date_dim ON sr_returned_date_sk = d_date_sk
    JOIN store ON sr_store_sk = s_store_sk
    WHERE d_year = 2001
      AND s_state IN ('MI', 'NC', 'WI')
      AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295
    GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
),
store_thresholds AS (
    SELECT ctr_store_sk,
           AVG(ctr_total_return) * 1.2 AS avg_limit
    FROM customer_total_return
    GROUP BY ctr_store_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1
JOIN store_thresholds st ON ctr1.ctr_store_sk = st.ctr_store_sk
JOIN customer ON ctr1.ctr_customer_sk = c_customer_sk
JOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk
JOIN store s ON ctr1.ctr_store_sk = s.s_store_sk
WHERE ctr1.ctr_total_return > st.avg_limit
  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31
  AND s.s_state IN ('MI', 'NC', 'WI')
  AND cd_marital_status = 'W'
  AND cd_education_status IN ('4 yr Degree', 'College')
  AND cd_gender = 'M'
  AND c_birth_month = 5
  AND c_birth_year BETWEEN 1950 AND 1956
ORDER BY c_customer_id
LIMIT 100
```

## Original SQL

```sql
select 
   count(distinct ws_order_number) as "order count"
  ,sum(ws_ext_ship_cost) as "total shipping cost"
  ,sum(ws_net_profit) as "total net profit"
from
   web_sales ws1
  ,date_dim
  ,customer_address
  ,web_site
where
    d_date between '1999-10-01' and
           cast('1999-10-01' as date) + interval '60 day'
and ws1.ws_ship_date_sk = d_date_sk
and ws1.ws_ship_addr_sk = ca_address_sk
and ca_state in ('MO','MT','OK'
            ,'SC' ,'TX' ,'WI')
and ws1.ws_web_site_sk = web_site_sk
and web_gmt_offset >= -5
and ws1.ws_list_price between 253 and 282
and exists (select *
            from web_sales ws2
            where ws1.ws_order_number = ws2.ws_order_number
              and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)
and not exists(select *
               from web_returns wr1
               where ws1.ws_order_number = wr1.wr_order_number
               and wr1.wr_reason_sk in (8, 18, 20, 23, 41)
               )
order by count(distinct ws_order_number)
limit 100;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~154K
    ├── SCAN (web_sales AS ws1 (join), date_dim (join), customer_address (join), web_site (join))
    ├── JOIN (ws1.ws_ship_date_sk = d_date_sk)
    ├── JOIN (ws1.ws_ship_addr_sk = ca_address_sk)
    ├── JOIN (+1 more)
    ├── FILTER (d_date BETWEEN '1999-10-01' AND CAST('1999-10-01' AS DATE) + INTERVAL '60 DAY')
    ├── FILTER (ca_state IN ('MO', 'MT', 'OK', 'SC', 'TX', 'WI'))
    ├── FILTER (+4 more)
    ├── SORT (COUNT(DISTINCT ws_order_number) ASC)
    └── OUTPUT (order count, total shipping cost, total net profit)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: