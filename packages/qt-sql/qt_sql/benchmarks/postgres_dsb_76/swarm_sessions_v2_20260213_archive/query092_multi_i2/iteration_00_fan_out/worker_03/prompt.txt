You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

Compute total excess discount amount where web sales discount exceeds 1.3x the average discount for that same item during the same 90-day period, for items meeting manufacturer or category criteria. INNER JOIN semantics require all three tables to match. The AVG in the correlated subquery groups implicitly by item and date (via join correlation). Filter dependencies: the subquery's additional ws_sales_price/ws_list_price ratio filter (76-91%) does NOT apply to the outer query rows, only to the average calculation.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
common_scan -> threshold_computation -> outer_rows -> join_filter -> aggregate
NODE_CONTRACTS:
  common_scan:
    FROM: web_sales
    JOIN: INNER JOIN date_dim ON d_date_sk = ws_sold_date_sk
    WHERE: d_date BETWEEN '1999-01-29' AND CAST('1999-01-29' AS DATE) + INTERVAL '90 DAY'
      AND ws_wholesale_cost BETWEEN 35 AND 55
    OUTPUT: ws_item_sk, ws_sold_date_sk, ws_ext_discount_amt, ws_wholesale_cost, ws_sales_price, ws_list_price, d_date_sk
    EXPECTED_ROWS: web_sales rows within date range and wholesale_cost range
    CONSUMERS: threshold_computation, outer_rows
  threshold_computation:
    FROM: common_scan
    WHERE: ws_sales_price / ws_list_price BETWEEN 76 * 0.01 AND 91 * 0.01
    GROUP BY: ws_item_sk
    AGGREGATE: 1.3 * AVG(ws_ext_discount_amt) AS threshold
    OUTPUT: ws_item_sk, threshold
    EXPECTED_ROWS: distinct ws_item_sk values meeting ratio filter
    CONSUMERS: join_filter
  outer_rows:
    FROM: common_scan
    JOIN: INNER JOIN item ON i_item_sk = ws_item_sk
    WHERE: (i_manufact_id BETWEEN 797 AND 996 OR i_category IN ('Men', 'Shoes', 'Sports'))
    OUTPUT: ws_item_sk, ws_ext_discount_amt
    EXPECTED_ROWS: common_scan rows meeting item criteria
    CONSUMERS: join_filter
  join_filter:
    FROM: outer_rows
    JOIN: INNER JOIN threshold_computation ON outer_rows.ws_item_sk = threshold_computation.ws_item_sk
    WHERE: outer_rows.ws_ext_discount_amt > threshold_computation.threshold
    OUTPUT: ws_ext_discount_amt
    EXPECTED_ROWS: outer_rows where discount exceeds threshold
    CONSUMERS: final_aggregate
  final_aggregate:
    FROM: join_filter
    AGGREGATE: SUM(ws_ext_discount_amt) AS "Excess Discount Amount"
    ORDER BY: SUM(ws_ext_discount_amt) ASC
    LIMIT: 100
    OUTPUT: "Excess Discount Amount"
    EXPECTED_ROWS: 1
    CONSUMERS: output

NODE_CONTRACTS:
common_scan:
    FROM: web_sales
    JOIN: INNER JOIN date_dim ON d_date_sk = ws_sold_date_sk
    WHERE: d_date BETWEEN '1999-01-29' AND CAST('1999-01-29' AS DATE) + INTERVAL '90 DAY'
      AND ws_wholesale_cost BETWEEN 35 AND 55
    OUTPUT: ws_item_sk, ws_sold_date_sk, ws_ext_discount_amt, ws_wholesale_cost, ws_sales_price, ws_list_price, d_date_sk
    EXPECTED_ROWS: web_sales rows within date range and wholesale_cost range
    CONSUMERS: threshold_computation, outer_rows
  threshold_computation:
    FROM: common_scan
    WHERE: ws_sales_price / ws_list_price BETWEEN 76 * 0.01 AND 91 * 0.01
    GROUP BY: ws_item_sk
    AGGREGATE: 1.3 * AVG(ws_ext_discount_amt) AS threshold
    OUTPUT: ws_item_sk, threshold
    EXPECTED_ROWS: distinct ws_item_sk values meeting ratio filter
    CONSUMERS: join_filter
  outer_rows:
    FROM: common_scan
    JOIN: INNER JOIN item ON i_item_sk = ws_item_sk
    WHERE: (i_manufact_id BETWEEN 797 AND 996 OR i_category IN ('Men', 'Shoes', 'Sports'))
    OUTPUT: ws_item_sk, ws_ext_discount_amt
    EXPECTED_ROWS: common_scan rows meeting item criteria
    CONSUMERS: join_filter
  join_filter:
    FROM: outer_rows
    JOIN: INNER JOIN threshold_computation ON outer_rows.ws_item_sk = threshold_computation.ws_item_sk
    WHERE: outer_rows.ws_ext_discount_amt > threshold_computation.threshold
    OUTPUT: ws_ext_discount_amt
    EXPECTED_ROWS: outer_rows where discount exceeds threshold
    CONSUMERS: final_aggregate
  final_aggregate:
    FROM: join_filter
    AGGREGATE: SUM(ws_ext_discount_amt) AS "Excess Discount Amount"
    ORDER BY: SUM(ws_ext_discount_amt) ASC
    LIMIT: 100
    OUTPUT: "Excess Discount Amount"
    EXPECTED_ROWS: 1
    CONSUMERS: output

## Hazard Flags (avoid these specific risks)

- Common_scan must include all columns needed by both branches (ws_sales_price, ws_list_price for threshold, ws_ext_discount_amt for both)
- Threshold computation groups only by ws_item_sk (not ws_sold_date_sk) since original correlation is by item only

## Regression Warnings (observed failures on similar queries)

None applicable.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Query outputs single column "Excess Discount Amount" as SUM(ws_ext_discount_amt)
- CTE_COLUMN_COMPLETENESS: Any CTE must include ws_item_sk, ws_sold_date_sk, ws_ext_discount_amt, ws_wholesale_cost, plus item/dim join keys
- LITERAL_PRESERVATION: All date literals ('1999-01-29'), intervals ('90 day'), numeric ranges (797-996, 35-55, 1.3, 76*0.01, 91*0.01), categories ('Men','Shoes','Sports') must be preserved
- SEMANTIC_EQUIVALENCE: Must return same sum of ws_ext_discount_amt for rows where discount exceeds 1.3x per-item average
- COMMA_JOIN_WEAKNESS: Query uses comma-separated joins (web_sales, item, date_dim) which confuses PostgreSQL cardinality estimation
- CORRELATED_SUBQUERY_PARALYSIS: Scalar subquery correlated via i_item_sk re-executes per outer row
- CROSS_CTE_PREDICATE_BLINDNESS: Same web_sales+date_dim scan appears in outer query and subquery with same date/wholesale_cost filters

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

Apply the shared materialization pattern: common_scan CTE contains the expensive web_sales+date_dim join with date/wholesale_cost filters, reused for both threshold computation and outer rows. This eliminates duplicate fact table scan. Ignore any store_sales vs web_sales differences - pattern applies to any fact table.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

## Original SQL

```sql
select 
   sum(ws_ext_discount_amt)  as "Excess Discount Amount"
from
    web_sales
   ,item
   ,date_dim
where
(i_manufact_id BETWEEN 797 and 996
or i_category IN ('Men', 'Shoes', 'Sports'))
and i_item_sk = ws_item_sk
and d_date between '1999-01-29' and
        cast('1999-01-29' as date) + interval '90 day'
and d_date_sk = ws_sold_date_sk
and ws_wholesale_cost BETWEEN 35 AND 55
and ws_ext_discount_amt
     > (
         SELECT
            1.3 * avg(ws_ext_discount_amt)
         FROM
            web_sales
           ,date_dim
         WHERE
              ws_item_sk = i_item_sk
          and d_date between '1999-01-29' and
                             cast('1999-01-29' as date) + interval '90 day'
          and d_date_sk = ws_sold_date_sk
          and ws_wholesale_cost BETWEEN 35 AND 55
          and ws_sales_price / ws_list_price BETWEEN 76 * 0.01 AND 91 * 0.01
  )
order by sum(ws_ext_discount_amt)
limit 100;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~1K
    ├── SCAN (web_sales, item (join), date_dim (join))
    ├── JOIN (i_item_sk = ws_item_sk)
    ├── JOIN (d_date_sk = ws_sold_date_sk)
    ├── FILTER ((i_manufact_id BETWEEN 797 AND 996 OR i_category IN ('Men', 'Shoes', 'Sports')))
    ├── FILTER (d_date BETWEEN '1999-01-29' AND CAST('1999-01-29' AS DATE) + INTERVAL '90 DAY')
    ├── FILTER (+2 more)
    ├── SORT (SUM(ws_ext_discount_amt) ASC)
    └── OUTPUT (Excess Discount Amount)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: