You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

Business intent: Count sales events where web sales occur within 30 days of store sales for the same item and customer, with filters on item category, manager, customer state, and wholesale cost. JOIN semantics: All joins are INNER (implicit intersection) - all tables must match. Aggregation trap: Only COUNT(*), safe. Filter dependencies: The date range condition (d2 between d1 and d1+30) correlates two date dimensions; moving this before joins could change semantics if either date side is filtered out prematurely.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
date_range_cte -> filtered_dims -> fact_join -> aggregation -> sort
NODE_CONTRACTS:
  date_range_cte:
    FROM: date_dim d1
      JOIN date_dim d2 ON d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '30 DAY')
    WHERE: d1.d_year = 2001
    OUTPUT: d1.d_date_sk, d2.d_date_sk
    EXPECTED_ROWS: ~365 * 30
    CONSUMERS: fact_join
  filtered_item:
    FROM: item
    WHERE: i_category IN ('Children', 'Jewelry', 'Men') AND i_manager_id IN (21, 22, 38, 39, 46, 47, 66, 67, 74, 93)
    OUTPUT: i_item_sk
    EXPECTED_ROWS: 786
    CONSUMERS: fact_join
  filtered_customer:
    FROM: customer
      JOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk
      JOIN household_demographics ON c_current_hdemo_sk = hd_demo_sk
      JOIN customer_address ON c_current_addr_sk = ca_address_sk
    WHERE: ca_state IN ('AZ', 'KS', 'OH', 'TX', 'WA')
    OUTPUT: c_customer_sk, cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: 25K
    CONSUMERS: fact_join
  fact_join:
    FROM: web_sales
      JOIN filtered_item ON ws_item_sk = i_item_sk
      JOIN filtered_customer ON ws_bill_customer_sk = c_customer_sk
      JOIN date_range_cte ON ws_sold_date_sk = d2.d_date_sk
      JOIN store_sales ON ss_item_sk = i_item_sk AND ss_customer_sk = c_customer_sk AND ss_sold_date_sk = d1.d_date_sk
      JOIN inventory ON inv_item_sk = ss_item_sk AND inv_date_sk = ss_sold_date_sk AND inv_warehouse_sk = ws_warehouse_sk
      JOIN warehouse ON ws_warehouse_sk = w_warehouse_sk
      JOIN store ON s_state = w_state
    WHERE: ws_wholesale_cost BETWEEN 35 AND 55 AND inv_quantity_on_hand >= ss_quantity
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: ~660K
    CONSUMERS: aggregation
  aggregation:
    FROM: fact_join
    GROUP BY: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    AGGREGATE: COUNT(*) AS cnt
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt
    EXPECTED_ROWS: group count
    CONSUMERS: sort
  sort:
    FROM: aggregation
    ORDER BY: cnt
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt
    EXPECTED_ROWS: group count
    CONSUMERS: final

NODE_CONTRACTS:
date_range_cte:
    FROM: date_dim d1
      JOIN date_dim d2 ON d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '30 DAY')
    WHERE: d1.d_year = 2001
    OUTPUT: d1.d_date_sk, d2.d_date_sk
    EXPECTED_ROWS: ~365 * 30
    CONSUMERS: fact_join
  filtered_item:
    FROM: item
    WHERE: i_category IN ('Children', 'Jewelry', 'Men') AND i_manager_id IN (21, 22, 38, 39, 46, 47, 66, 67, 74, 93)
    OUTPUT: i_item_sk
    EXPECTED_ROWS: 786
    CONSUMERS: fact_join
  filtered_customer:
    FROM: customer
      JOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk
      JOIN household_demographics ON c_current_hdemo_sk = hd_demo_sk
      JOIN customer_address ON c_current_addr_sk = ca_address_sk
    WHERE: ca_state IN ('AZ', 'KS', 'OH', 'TX', 'WA')
    OUTPUT: c_customer_sk, cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: 25K
    CONSUMERS: fact_join
  fact_join:
    FROM: web_sales
      JOIN filtered_item ON ws_item_sk = i_item_sk
      JOIN filtered_customer ON ws_bill_customer_sk = c_customer_sk
      JOIN date_range_cte ON ws_sold_date_sk = d2.d_date_sk
      JOIN store_sales ON ss_item_sk = i_item_sk AND ss_customer_sk = c_customer_sk AND ss_sold_date_sk = d1.d_date_sk
      JOIN inventory ON inv_item_sk = ss_item_sk AND inv_date_sk = ss_sold_date_sk AND inv_warehouse_sk = ws_warehouse_sk
      JOIN warehouse ON ws_warehouse_sk = w_warehouse_sk
      JOIN store ON s_state = w_state
    WHERE: ws_wholesale_cost BETWEEN 35 AND 55 AND inv_quantity_on_hand >= ss_quantity
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    EXPECTED_ROWS: ~660K
    CONSUMERS: aggregation
  aggregation:
    FROM: fact_join
    GROUP BY: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    AGGREGATE: COUNT(*) AS cnt
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt
    EXPECTED_ROWS: group count
    CONSUMERS: sort
  sort:
    FROM: aggregation
    ORDER BY: cnt
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt
    EXPECTED_ROWS: group count
    CONSUMERS: final

## Hazard Flags (avoid these specific risks)

- Date range CTE may produce many rows; ensure it's materialized efficiently.
- Parallelism may be blocked by CTEs; use SET max_parallel_workers_per_gather = 4.
CONSTRAINT_OVERRIDE: None
OVERRIDE_REASONING: N/A
EXPLORATION_TYPE: compound_strategy (combines date_range CTE with explicit joins and parallelism tuning)

## Regression Warnings (observed failures on similar queries)

1. OR to UNION ALL (0.21x regression on Q085):
   CAUSE: Splitting OR conditions into UNION ALL branches disabled bitmap index scans.
   RULE: Do NOT convert OR conditions (none in this query) to UNION ALL.
2. EXISTS to IN materialization (0.50x regression on Q069):
   CAUSE: Converting EXISTS to IN with materialized CTEs blocked semi-join optimization.
   RULE: Do NOT convert EXISTS/IN subqueries (none present).

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Must output cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt exactly.
- CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream (e.g., join keys, filter columns, grouping columns).
- LITERAL_PRESERVATION: All filter values (2001, 'AZ','KS','OH','TX','WA', 35,55, etc.) must be preserved exactly.
- SEMANTIC_EQUIVALENCE: Result rows and order must match original.
- COMMA_JOIN_WEAKNESS: Query uses comma-separated joins; EXPLAIN shows hash joins but comma joins may hinder estimation.
- NON_EQUI_JOIN_INPUT_BLINDNESS: Non-equi date range join uses nested loop filter; could benefit from staged reduction.

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- pg_date_cte_explicit_join: Apply date_dim filtering into a CTE and explicit JOIN syntax. Use the non-equi join condition inside the CTE.
- pg_dimension_prefetch_star: Also pre-filter other dimensions (item, customer) into CTEs. Ignore the UNION aspect.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_date_cte_explicit_join (2.28x)

**Principle:** Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.

**BEFORE (slow):**
```sql
select 
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   catalog_sales
  ,warehouse
  ,ship_mode
  ,call_center
  ,date_dim
where
d_month_seq between 1193 and 1193 + 23
and cs_ship_date_sk   = d_date_sk
and cs_warehouse_sk   = w_warehouse_sk
and cs_ship_mode_sk   = sm_ship_mode_sk
and cs_call_center_sk = cc_call_center_sk
and cs_list_price between 271 and 300
and sm_type = 'REGULAR'
and cc_class = 'small'
and w_gmt_offset = -5
group by
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
order by substring(w_warehouse_name,1,20)
        ,sm_type
        ,cc_name
limit 100;
```

**AFTER (fast):**
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1193 AND 1216
```
[main_query]:
```sql
SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", ... FROM catalog_sales JOIN filtered_dates ON cs_ship_date_sk = d_date_sk JOIN warehouse ON cs_warehouse_sk = w_warehouse_sk JOIN ship_mode ON cs_ship_mode_sk = sm_ship_mode_sk JOIN call_center ON cs_call_center_sk = cc_call_center_sk WHERE cs_list_price BETWEEN 271 AND 300 AND sm_type = 'REGULAR' AND cc_class = 'small' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY 1, 2, 3 LIMIT 100
```

### 2. pg_dimension_prefetch_star (3.32x)

**Principle:** Multi-Dimension Prefetch (PG): pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax. PostgreSQL's optimizer gets better cardinality estimates from pre-materialized small dimension results.

**BEFORE (slow):**
```sql
with ssr as
 (select  s_store_id as store_id,
          sum(ss_ext_sales_price) as sales,
          sum(coalesce(sr_return_amt, 0)) as returns,
          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit
  from store_sales left outer join store_returns on
         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),
     date_dim,
     store,
     item,
     promotion
 where ss_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
       and ss_store_sk = s_store_sk
       and ss_item_sk = i_item_sk
       and i_current_price > 50
       and ss_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ss_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
 group by s_store_id)
 ,
 csr as
 (select  cp_catalog_page_id as catalog_page_id,
          sum(cs_ext_sales_price) as sales,
          sum(coalesce(cr_return_amount, 0)) as returns,
          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit
  from catalog_sales left outer join catalog_returns on
         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),
     date_dim,
     catalog_page,
     item,
     promotion
 where cs_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and cs_catalog_page_sk = cp_catalog_page_sk
       and cs_item_sk = i_item_sk
       and i_current_price > 50
       and cs_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and cs_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by cp_catalog_page_id)
 ,
 wsr as
 (select  web_site_id,
          sum(ws_ext_sales_price) as sales,
          sum(coalesce(wr_return_amt, 0)) as returns,
          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit
  from web_sales left outer join web_returns on
         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),
     date_dim,
     web_site,
     item,
     promotion
 where ws_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and ws_web_site_sk = web_site_sk
       and ws_item_sk = i_item_sk
       and i_current_price > 50
       and ws_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ws_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by web_site_id)
  select  channel
        , id
        , sum(sales) as sales
        , sum(returns) as returns
        , sum(profit) as profit
 from
 (select 'store channel' as channel
        , 'store' || store_id as id
        , sales
        , returns
        , profit
 from   ssr
 union all
 select 'catalog channel' as channel
        , 'catalog_page' || catalog_page_id as id
        , sales
        , returns
        , profit
 from  csr
 union all
 select 'web channel' as channel
        , 'web_site' || web_site_id as id
        , sales
        , returns
        , profit
 from   wsr
 ) x
 group by rollup (channel, id)
 order by channel
         ,id
 limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-23' AS DATE) AND CAST('1998-08-23' AS DATE) + INTERVAL '30 DAY'
```
[filtered_item]:
```sql
SELECT i_item_sk FROM item WHERE i_current_price > 50 AND i_category IN ('Jewelry', 'Music')
```
[filtered_promotion]:
```sql
SELECT p_promo_sk FROM promotion WHERE p_channel_email = 'Y' AND p_channel_tv = 'Y' AND p_channel_radio = 'N' AND p_channel_press = 'N' AND p_channel_event = 'Y'
```
[ssr]:
```sql
SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS returns, SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) INNER JOIN filtered_date ON ss_sold_date_sk = filtered_date.d_date_sk INNER JOIN store ON ss_store_sk = s_store_sk INNER JOIN filtered_item ON ss_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ss_promo_sk = filtered_promotion.p_promo_sk WHERE ss_wholesale_cost BETWEEN 63 AND 78 GROUP BY s_store_id
```
[csr]:
```sql
SELECT cp_catalog_page_id AS catalog_page_id, SUM(cs_ext_sales_price) AS sales, SUM(COALESCE(cr_return_amount, 0)) AS returns, SUM(cs_net_profit - COALESCE(cr_net_loss, 0)) AS profit FROM catalog_sales LEFT OUTER JOIN catalog_returns ON (cs_item_sk = cr_item_sk AND cs_order_number = cr_order_number) INNER JOIN filtered_date ON cs_sold_date_sk = filtered_date.d_date_sk INNER JOIN catalog_page ON cs_catalog_page_sk = cp_catalog_page_sk INNER JOIN filtered_item ON cs_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON cs_promo_sk = filtered_promotion.p_promo_sk WHERE cs_wholesale_cost BETWEEN 63 AND 78 GROUP BY cp_catalog_page_id
```
[wsr]:
```sql
SELECT web_site_id, SUM(ws_ext_sales_price) AS sales, SUM(COALESCE(wr_return_amt, 0)) AS returns, SUM(ws_net_profit - COALESCE(wr_net_loss, 0)) AS profit FROM web_sales LEFT OUTER JOIN web_returns ON (ws_item_sk = wr_item_sk AND ws_order_number = wr_order_number) INNER JOIN filtered_date ON ws_sold_date_sk = filtered_date.d_date_sk INNER JOIN web_site ON ws_web_site_sk = web_site_sk INNER JOIN filtered_item ON ws_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ws_promo_sk = filtered_promotion.p_promo_sk WHERE ws_wholesale_cost BETWEEN 63 AND 78 GROUP BY web_site_id
```
[main_query]:
```sql
SELECT channel, id, SUM(sales) AS sales, SUM(returns) AS returns, SUM(profit) AS profit FROM (SELECT 'store channel' AS channel, 'store' || store_id AS id, sales, returns, profit FROM ssr UNION ALL SELECT 'catalog channel' AS channel, 'catalog_page' || catalog_page_id AS id, sales, returns, profit FROM csr UNION ALL SELECT 'web channel' AS channel, 'web_site' || web_site_id AS id, sales, returns, profit FROM wsr) AS x GROUP BY ROLLUP (channel, id) ORDER BY channel, id LIMIT 100
```

## Original SQL

```sql
select 
    cd_gender,
    cd_marital_status,
    cd_education_status,
    hd_vehicle_count,
    count(*) as cnt
from
    store_sales,
    web_sales,
    date_dim d1,
    date_dim d2,
    customer,
    inventory,
    store,
    warehouse,
    item,
    customer_demographics,
    household_demographics,
    customer_address
    where
      ss_item_sk = i_item_sk
      and ws_item_sk = ss_item_sk
      and ss_sold_date_sk = d1.d_date_sk
      and ws_sold_date_sk = d2.d_date_sk
			and d2.d_date between d1.d_date and (d1.d_date + interval '30 day')
      and ss_customer_sk = c_customer_sk
      and ws_bill_customer_sk = c_customer_sk
      and ws_warehouse_sk = inv_warehouse_sk
      and ws_warehouse_sk = w_warehouse_sk
      and inv_item_sk = ss_item_sk
      and inv_date_sk = ss_sold_date_sk
      and inv_quantity_on_hand >= ss_quantity
      and s_state = w_state
      AND i_category IN ('Children', 'Jewelry', 'Men')
      and i_manager_id IN (21, 22, 38, 39, 46, 47, 66, 67, 74, 93)
      and c_current_cdemo_sk = cd_demo_sk
      and c_current_hdemo_sk = hd_demo_sk
      and c_current_addr_sk = ca_address_sk
      and ca_state in ('AZ', 'KS', 'OH', 'TX', 'WA')
      and d1.d_year = 2001
      and ws_wholesale_cost BETWEEN 35 AND 55
    group by cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count
    order by cnt
    ;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~660K
    ├── SCAN (store_sales, web_sales (join), date_dim AS d1 (join), date_dim AS d2 (join), customer (join), inventory (join), store (join), warehouse (join), item (join), customer_demographics (join), household_demographics (join), customer_address (join))
    ├── JOIN (ss_item_sk = i_item_sk)
    ├── JOIN (ws_item_sk = ss_item_sk)
    ├── JOIN (+12 more)
    ├── FILTER (d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '30 DAY'))
    ├── FILTER (inv_quantity_on_hand >= ss_quantity)
    ├── FILTER (+5 more)
    ├── AGG (GROUP BY)
    ├── SORT (cnt ASC)
    └── OUTPUT (cd_gender, cd_marital_status, cd_education_status, hd_vehicle_count, cnt)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: