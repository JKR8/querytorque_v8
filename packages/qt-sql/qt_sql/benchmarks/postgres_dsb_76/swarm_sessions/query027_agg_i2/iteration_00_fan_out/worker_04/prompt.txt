You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

This query computes average sales metrics for Music items sold in Ohio stores in 1999 to male, widowed, secondary‑educated customers, grouped by item and state with a rollup. All joins are INNER (each fact row must match all dimension filters). The aggregates are AVG, which are sensitive to row duplication—joins must preserve one‑to‑many cardinality from fact to dimensions. Filters on dimension columns (cd_gender, cd_marital_status, cd_education_status, d_year, s_state, i_category) are interdependent only through the fact table; pushing them earlier is safe.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
fact_join_explicit -> aggregation -> sort -> limit
NODE_CONTRACTS:
  fact_join_explicit:
    FROM: store_sales
      INNER JOIN date_dim ON ss_sold_date_sk = date_dim.d_date_sk
      INNER JOIN store ON ss_store_sk = store.s_store_sk
      INNER JOIN item ON ss_item_sk = item.i_item_sk
      INNER JOIN customer_demographics ON ss_cdemo_sk = customer_demographics.cd_demo_sk
    WHERE: date_dim.d_year = 1999
      AND store.s_state = 'OH'
      AND item.i_category = 'Music'
      AND customer_demographics.cd_gender = 'M'
      AND customer_demographics.cd_marital_status = 'W'
      AND customer_demographics.cd_education_status = 'Secondary'
    OUTPUT: i_item_id, s_state, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price
    EXPECTED_ROWS: unknown (small)
    CONSUMERS: aggregation
  aggregation:
    GROUP BY: ROLLUP (i_item_id, s_state)
    AGGREGATE: AVG(ss_quantity) AS agg1, AVG(ss_list_price) AS agg2, AVG(ss_coupon_amt) AS agg3, AVG(ss_sales_price) AS agg4
    OUTPUT: i_item_id, s_state, GROUPING(s_state) AS g_state, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: ~366
    CONSUMERS: sort
  sort:
    ORDER BY: i_item_id, s_state
    CONSUMERS: limit
  limit:
    LIMIT: 100
    CONSUMERS: final output

NODE_CONTRACTS:
fact_join_explicit:
    FROM: store_sales
      INNER JOIN date_dim ON ss_sold_date_sk = date_dim.d_date_sk
      INNER JOIN store ON ss_store_sk = store.s_store_sk
      INNER JOIN item ON ss_item_sk = item.i_item_sk
      INNER JOIN customer_demographics ON ss_cdemo_sk = customer_demographics.cd_demo_sk
    WHERE: date_dim.d_year = 1999
      AND store.s_state = 'OH'
      AND item.i_category = 'Music'
      AND customer_demographics.cd_gender = 'M'
      AND customer_demographics.cd_marital_status = 'W'
      AND customer_demographics.cd_education_status = 'Secondary'
    OUTPUT: i_item_id, s_state, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price
    EXPECTED_ROWS: unknown (small)
    CONSUMERS: aggregation
  aggregation:
    GROUP BY: ROLLUP (i_item_id, s_state)
    AGGREGATE: AVG(ss_quantity) AS agg1, AVG(ss_list_price) AS agg2, AVG(ss_coupon_amt) AS agg3, AVG(ss_sales_price) AS agg4
    OUTPUT: i_item_id, s_state, GROUPING(s_state) AS g_state, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: ~366
    CONSUMERS: sort
  sort:
    ORDER BY: i_item_id, s_state
    CONSUMERS: limit
  limit:
    LIMIT: 100
    CONSUMERS: final output

## Hazard Flags (avoid these specific risks)

- Increasing parallelism may not help if data is already small.
- Explicit JOINs without CTEs may not improve cardinality estimation significantly.
CONSTRAINT_OVERRIDE: None
OVERRIDE_REASONING: N/A
EXPLORATION_TYPE: compound_strategy (explicit JOINs + parallelism boost)

## Regression Warnings (observed failures on similar queries)

1. Nestloop off regression (observed 184x regression):
   CAUSE: Disabling nested loops on lookup‑style joins forces hash/merge joins that may be slower.
   RULE: Only set enable_nestloop = off if you pre‑filter dimensions into tiny CTEs, making hash join build side small.
2. CTE inlining (observed regression in some plans):
   CAUSE: PostgreSQL may inline CTEs, defeating materialization benefits.
   RULE: Use AS MATERIALIZED on CTEs when early reduction is critical.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Output columns i_item_id, s_state, g_state, agg1, agg2, agg3, agg4 must be preserved.
- CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream (join keys, i_item_id, s_state, and fact aggregates).
- LITERAL_PRESERVATION: Literals 'M', 'W', 'Secondary', 1999, 'OH', 'Music' must be copied exactly.
- SEMANTIC_EQUIVALENCE: Result set must match original row‑for‑row, including ROLLUP rows and ordering.
- COMMA_JOIN_WEAKNESS: Query uses comma‑separated joins; EXPLAIN shows optimizer reorders them, but explicit JOINs may improve cardinality estimation.

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- pg_date_cte_explicit_join: Apply explicit JOIN syntax only, without CTEs. Additionally, increase parallel workers.
- early_filter_decorrelate: Apply explicit JOINs and push filters into JOIN conditions. Ignore CTE creation.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_date_cte_explicit_join (2.28x)

**Principle:** Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.

**BEFORE (slow):**
```sql
select 
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   catalog_sales
  ,warehouse
  ,ship_mode
  ,call_center
  ,date_dim
where
d_month_seq between 1193 and 1193 + 23
and cs_ship_date_sk   = d_date_sk
and cs_warehouse_sk   = w_warehouse_sk
and cs_ship_mode_sk   = sm_ship_mode_sk
and cs_call_center_sk = cc_call_center_sk
and cs_list_price between 271 and 300
and sm_type = 'REGULAR'
and cc_class = 'small'
and w_gmt_offset = -5
group by
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
order by substring(w_warehouse_name,1,20)
        ,sm_type
        ,cc_name
limit 100;
```

**AFTER (fast):**
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1193 AND 1216
```
[main_query]:
```sql
SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", ... FROM catalog_sales JOIN filtered_dates ON cs_ship_date_sk = d_date_sk JOIN warehouse ON cs_warehouse_sk = w_warehouse_sk JOIN ship_mode ON cs_ship_mode_sk = sm_ship_mode_sk JOIN call_center ON cs_call_center_sk = cc_call_center_sk WHERE cs_list_price BETWEEN 271 AND 300 AND sm_type = 'REGULAR' AND cc_class = 'small' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY 1, 2, 3 LIMIT 100
```

### 2. early_filter_decorrelate (1.13x)

**Principle:** Early Selection + Decorrelation: push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN.

**BEFORE (slow):**
```sql
WITH customer_total_return AS (
  SELECT sr_customer_sk AS ctr_customer_sk,
         sr_store_sk AS ctr_store_sk,
         sr_reason_sk AS ctr_reason_sk,
         SUM(SR_REFUNDED_CASH) AS ctr_total_return
  FROM store_returns, date_dim
  WHERE sr_returned_date_sk = d_date_sk
    AND d_year = 2001
    AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295
  GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1, store, customer, customer_demographics
WHERE ctr1.ctr_total_return > (
    SELECT AVG(ctr_total_return) * 1.2
    FROM customer_total_return ctr2
    WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk
  )
  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31
  AND s_store_sk = ctr1.ctr_store_sk
  AND s_state IN ('MI', 'NC', 'WI')
  AND ctr1.ctr_customer_sk = c_customer_sk
  AND c_current_cdemo_sk = cd_demo_sk
  AND cd_marital_status IN ('W', 'W')
  AND cd_education_status IN ('4 yr Degree', 'College')
  AND cd_gender = 'M'
  AND c_birth_month = 5
  AND c_birth_year BETWEEN 1950 AND 1956
ORDER BY c_customer_id
LIMIT 100
```

**AFTER (fast):**
```sql
WITH customer_total_return AS (
    SELECT sr_customer_sk AS ctr_customer_sk,
           sr_store_sk AS ctr_store_sk,
           sr_reason_sk AS ctr_reason_sk,
           SUM(SR_REFUNDED_CASH) AS ctr_total_return
    FROM store_returns
    JOIN date_dim ON sr_returned_date_sk = d_date_sk
    JOIN store ON sr_store_sk = s_store_sk
    WHERE d_year = 2001
      AND s_state IN ('MI', 'NC', 'WI')
      AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295
    GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
),
store_thresholds AS (
    SELECT ctr_store_sk,
           AVG(ctr_total_return) * 1.2 AS avg_limit
    FROM customer_total_return
    GROUP BY ctr_store_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1
JOIN store_thresholds st ON ctr1.ctr_store_sk = st.ctr_store_sk
JOIN customer ON ctr1.ctr_customer_sk = c_customer_sk
JOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk
JOIN store s ON ctr1.ctr_store_sk = s.s_store_sk
WHERE ctr1.ctr_total_return > st.avg_limit
  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31
  AND s.s_state IN ('MI', 'NC', 'WI')
  AND cd_marital_status = 'W'
  AND cd_education_status IN ('4 yr Degree', 'College')
  AND cd_gender = 'M'
  AND c_birth_month = 5
  AND c_birth_year BETWEEN 1950 AND 1956
ORDER BY c_customer_id
LIMIT 100
```

## Original SQL

```sql
select  i_item_id,
        s_state, grouping(s_state) g_state,
        avg(ss_quantity) agg1,
        avg(ss_list_price) agg2,
        avg(ss_coupon_amt) agg3,
        avg(ss_sales_price) agg4
from store_sales, customer_demographics, date_dim, store, item
where ss_sold_date_sk = d_date_sk and
      ss_item_sk = i_item_sk and
      ss_store_sk = s_store_sk and
      ss_cdemo_sk = cd_demo_sk and
      cd_gender = 'M' and
      cd_marital_status = 'W' and
      cd_education_status = 'Secondary' and
      d_year = 1999 and
      s_state = 'OH' and
     i_category  = 'Music'
 group by rollup (i_item_id, s_state)
 order by i_item_id
         ,s_state
 limit 100;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~366
    ├── SCAN (store_sales, customer_demographics (join), date_dim (join), store (join), item (join))
    ├── JOIN (ss_sold_date_sk = d_date_sk)
    ├── JOIN (ss_item_sk = i_item_sk)
    ├── JOIN (+2 more)
    ├── FILTER (cd_gender = 'M')
    ├── FILTER (cd_marital_status = 'W')
    ├── FILTER (+4 more)
    ├── AGG (GROUP BY)
    ├── SORT (i_item_id ASC, s_state ASC)
    └── OUTPUT (i_item_id, s_state, g_state, agg1, agg2, agg3, agg4)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: