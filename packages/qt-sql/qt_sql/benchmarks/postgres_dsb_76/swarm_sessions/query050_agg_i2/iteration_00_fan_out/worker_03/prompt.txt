You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

This query computes for each store in July 1999 the distribution of return delays (in days) for items sold and returned within 120 days. All joins are INNER joins requiring matches across store_sales, store_returns, store, and two date_dim instances. Aggregation uses conditional sums of 1/0 values (grouping-insensitive). The d1.d_date filter depends on d2.d_date (correlated range: d1.d_date between d2.d_date - 120 days and d2.d_date) - any rewrite must preserve this temporal relationship.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
d2_filtered -> store_returns_filtered -> sales_returns_joined -> d1_joined -> pre_aggregated -> store_joined -> sorted -> limited
NODE_CONTRACTS:
  d2_filtered:
    FROM: date_dim d2
    WHERE: d_year = 1999 AND d_moy = 7
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 16
    CONSUMERS: store_returns_filtered, d1_joined
  store_returns_filtered:
    FROM: store_returns, d2_filtered
    JOIN: sr_returned_date_sk = d2_filtered.d_date_sk
    OUTPUT: sr_item_sk, sr_ticket_number, sr_customer_sk, sr_returned_date_sk, d2_filtered.d_date
    EXPECTED_ROWS: 56K
    CONSUMERS: sales_returns_joined
  sales_returns_joined:
    FROM: store_sales, store_returns_filtered
    JOIN: ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number AND ss_customer_sk = sr_customer_sk
    OUTPUT: ss_store_sk, ss_sold_date_sk, sr_returned_date_sk, d2_filtered.d_date
    EXPECTED_ROWS: 42K
    CONSUMERS: d1_joined
  d1_joined:
    FROM: sales_returns_joined, date_dim d1
    JOIN: ss_sold_date_sk = d1.d_date_sk
    WHERE: d1.d_date BETWEEN (d2_filtered.d_date - INTERVAL '120 DAY') AND d2_filtered.d_date
    OUTPUT: ss_store_sk, sr_returned_date_sk, ss_sold_date_sk
    EXPECTED_ROWS: 39K
    CONSUMERS: pre_aggregated
  pre_aggregated:
    FROM: d1_joined
    GROUP BY: ss_store_sk
    AGGREGATE: SUM(CASE WHEN (sr_returned_date_sk - ss_sold_date_sk <= 30) THEN 1 ELSE 0 END) as "30 days", [other buckets], COUNT(*) as cnt
    OUTPUT: ss_store_sk, "30 days", "31-60 days", "61-90 days", "91-120 days", ">120 days"
    EXPECTED_ROWS: ~number of stores
    CONSUMERS: store_joined
  store_joined:
    FROM: pre_aggregated, store
    JOIN: ss_store_sk = s_store_sk
    OUTPUT: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip, "30 days", "31-60 days", "61-90 days", "91-120 days", ">120 days"
    EXPECTED_ROWS: ~30
    CONSUMERS: sorted

NODE_CONTRACTS:
d2_filtered:
    FROM: date_dim d2
    WHERE: d_year = 1999 AND d_moy = 7
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 16
    CONSUMERS: store_returns_filtered, d1_joined
  store_returns_filtered:
    FROM: store_returns, d2_filtered
    JOIN: sr_returned_date_sk = d2_filtered.d_date_sk
    OUTPUT: sr_item_sk, sr_ticket_number, sr_customer_sk, sr_returned_date_sk, d2_filtered.d_date
    EXPECTED_ROWS: 56K
    CONSUMERS: sales_returns_joined
  sales_returns_joined:
    FROM: store_sales, store_returns_filtered
    JOIN: ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number AND ss_customer_sk = sr_customer_sk
    OUTPUT: ss_store_sk, ss_sold_date_sk, sr_returned_date_sk, d2_filtered.d_date
    EXPECTED_ROWS: 42K
    CONSUMERS: d1_joined
  d1_joined:
    FROM: sales_returns_joined, date_dim d1
    JOIN: ss_sold_date_sk = d1.d_date_sk
    WHERE: d1.d_date BETWEEN (d2_filtered.d_date - INTERVAL '120 DAY') AND d2_filtered.d_date
    OUTPUT: ss_store_sk, sr_returned_date_sk, ss_sold_date_sk
    EXPECTED_ROWS: 39K
    CONSUMERS: pre_aggregated
  pre_aggregated:
    FROM: d1_joined
    GROUP BY: ss_store_sk
    AGGREGATE: SUM(CASE WHEN (sr_returned_date_sk - ss_sold_date_sk <= 30) THEN 1 ELSE 0 END) as "30 days", [other buckets], COUNT(*) as cnt
    OUTPUT: ss_store_sk, "30 days", "31-60 days", "61-90 days", "91-120 days", ">120 days"
    EXPECTED_ROWS: ~number of stores
    CONSUMERS: store_joined
  store_joined:
    FROM: pre_aggregated, store
    JOIN: ss_store_sk = s_store_sk
    OUTPUT: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip, "30 days", "31-60 days", "61-90 days", "91-120 days", ">120 days"
    EXPECTED_ROWS: ~30
    CONSUMERS: sorted

## Hazard Flags (avoid these specific risks)

- Aggregation pushdown changes group membership (grouping by ss_store_sk only vs 10 store columns). Must ensure store join is one-to-one (ss_store_sk → store columns) to preserve semantics.
  - Pre-aggregation loses store columns needed for final ORDER BY.

## Regression Warnings (observed failures on similar queries)

1. Never set enable_nestloop=off (observed 184x regression):
   CAUSE: Disabling nested loops forces hash/merge joins that spill to disk for large tables.
   RULE: Avoid SET enable_nestloop=off; nested loops are efficient for indexed lookups on d1.
2. CTEs blocking parallelism (observed 0.50x on Q069):
   CAUSE: Materialized CTEs execute single-threaded, preventing parallel table scans.
   RULE: Use non-materialized CTEs (WITHOUT MATERIALIZED) or inline subqueries for large fact joins.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Query outputs 10 store columns and 5 aggregated bucket counts.
- CTE_COLUMN_COMPLETENESS: Any CTE must include ss_sold_date_sk, sr_returned_date_sk, and all store columns used in GROUP BY.
- LITERAL_PRESERVATION: Literal values 1999, 7, 30, 60, 90, 120 must be preserved exactly.
- SEMANTIC_EQUIVALENCE: Must return same rows and ordering (store attributes).
- COMMA_JOIN_WEAKNESS: Query uses comma-separated implicit joins (lines 21-25).
- CORRELATED_SUBQUERY_PARALYSIS: d1.d_date BETWEEN condition correlates with d2.d_date (lines 35-36).

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

pg_self_join_decomposition: Apply materialization of fact joins before aggregation, but ignore self-join aspect (no repeated scans).
  late_attribute_binding: Defer store join until after aggregation (store columns not used in filters or aggregates). Ignore the need to preserve all grouping columns in pre_aggregated.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

## Original SQL

```sql
select 
   s_store_name
  ,s_company_id
  ,s_street_number
  ,s_street_name
  ,s_street_type
  ,s_suite_number
  ,s_city
  ,s_county
  ,s_state
  ,s_zip
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 30) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 60) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 90) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   store_sales
  ,store_returns
  ,store
  ,date_dim d1
  ,date_dim d2
where
    d2.d_year = 1999
and d2.d_moy  = 7
and ss_ticket_number = sr_ticket_number
and ss_item_sk = sr_item_sk
and ss_sold_date_sk   = d1.d_date_sk
and sr_returned_date_sk   = d2.d_date_sk
and ss_customer_sk = sr_customer_sk
and ss_store_sk = s_store_sk
and d1.d_date between (d2.d_date - interval '120 day')
               and d2.d_date
group by
   s_store_name
  ,s_company_id
  ,s_street_number
  ,s_street_name
  ,s_street_type
  ,s_suite_number
  ,s_city
  ,s_county
  ,s_state
  ,s_zip
order by s_store_name
        ,s_company_id
        ,s_street_number
        ,s_street_name
        ,s_street_type
        ,s_suite_number
        ,s_city
        ,s_county
        ,s_state
        ,s_zip
limit 100;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~112K
    ├── SCAN (store_sales, store_returns (join), store (join), date_dim AS d1 (join), date_dim AS d2 (join))
    ├── JOIN (ss_ticket_number = sr_ticket_number)
    ├── JOIN (ss_item_sk = sr_item_sk)
    ├── JOIN (+4 more)
    ├── FILTER (d2.d_year = 1999)
    ├── FILTER (d2.d_moy = 7)
    ├── FILTER (+1 more)
    ├── AGG (GROUP BY)
    ├── SORT (s_store_name ASC, s_company_id ASC, s_street_number ASC, s_street_name ASC, s_street_type ASC, s_suite_number ASC, s_city ASC, s_county ASC, s_state ASC, s_zip ASC)
    └── OUTPUT (s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, ...)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: