You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

This query computes for each store in July 1999 the distribution of return delays (in days) for items sold and returned within 120 days. All joins are INNER joins requiring matches across store_sales, store_returns, store, and two date_dim instances. Aggregation uses conditional sums of 1/0 values (grouping-insensitive). The d1.d_date filter depends on d2.d_date (correlated range: d1.d_date between d2.d_date - 120 days and d2.d_date) - any rewrite must preserve this temporal relationship.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
d2_filtered -> store_returns_filtered -> sales_returns_store_joined -> d1_joined -> aggregated -> sorted -> limited
NODE_CONTRACTS:
  d2_filtered:
    FROM: date_dim d2
    WHERE: d_year = 1999 AND d_moy = 7
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 16
    CONSUMERS: store_returns_filtered, d1_joined
  store_returns_filtered:
    FROM: store_returns, d2_filtered
    JOIN: sr_returned_date_sk = d2_filtered.d_date_sk
    OUTPUT: sr_item_sk, sr_ticket_number, sr_customer_sk, sr_returned_date_sk, d2_filtered.d_date
    EXPECTED_ROWS: 56K
    CONSUMERS: sales_returns_store_joined
  sales_returns_store_joined:
    FROM: store_sales, store_returns_filtered, store
    JOIN: ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number AND ss_customer_sk = sr_customer_sk AND ss_store_sk = s_store_sk
    OUTPUT: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip, ss_sold_date_sk, sr_returned_date_sk, d2_filtered.d_date
    EXPECTED_ROWS: 39K
    CONSUMERS: d1_joined
  d1_joined:
    FROM: sales_returns_store_joined, date_dim d1
    JOIN: ss_sold_date_sk = d1.d_date_sk
    WHERE: d1.d_date BETWEEN (d2_filtered.d_date - INTERVAL '120 DAY') AND d2_filtered.d_date
    OUTPUT: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip, ss_sold_date_sk, sr_returned_date_sk
    EXPECTED_ROWS: 39K
    CONSUMERS: aggregated
  aggregated:
    FROM: d1_joined
    GROUP BY: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip
    AGGREGATE: same conditional sums
    OUTPUT: store columns + 5 bucket aggregates
    EXPECTED_ROWS: ~30
    CONSUMERS: sorted

NODE_CONTRACTS:
d2_filtered:
    FROM: date_dim d2
    WHERE: d_year = 1999 AND d_moy = 7
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 16
    CONSUMERS: store_returns_filtered, d1_joined
  store_returns_filtered:
    FROM: store_returns, d2_filtered
    JOIN: sr_returned_date_sk = d2_filtered.d_date_sk
    OUTPUT: sr_item_sk, sr_ticket_number, sr_customer_sk, sr_returned_date_sk, d2_filtered.d_date
    EXPECTED_ROWS: 56K
    CONSUMERS: sales_returns_store_joined
  sales_returns_store_joined:
    FROM: store_sales, store_returns_filtered, store
    JOIN: ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number AND ss_customer_sk = sr_customer_sk AND ss_store_sk = s_store_sk
    OUTPUT: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip, ss_sold_date_sk, sr_returned_date_sk, d2_filtered.d_date
    EXPECTED_ROWS: 39K
    CONSUMERS: d1_joined
  d1_joined:
    FROM: sales_returns_store_joined, date_dim d1
    JOIN: ss_sold_date_sk = d1.d_date_sk
    WHERE: d1.d_date BETWEEN (d2_filtered.d_date - INTERVAL '120 DAY') AND d2_filtered.d_date
    OUTPUT: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip, ss_sold_date_sk, sr_returned_date_sk
    EXPECTED_ROWS: 39K
    CONSUMERS: aggregated
  aggregated:
    FROM: d1_joined
    GROUP BY: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip
    AGGREGATE: same conditional sums
    OUTPUT: store columns + 5 bucket aggregates
    EXPECTED_ROWS: ~30
    CONSUMERS: sorted

## Hazard Flags (avoid these specific risks)

- The d1 join still has correlated range condition, may still cause nested loops.
  - Explicit JOIN order may differ from original comma join order.

## Regression Warnings (observed failures on similar queries)

1. Never set enable_nestloop=off (observed 184x regression):
   CAUSE: Disabling nested loops forces hash/merge joins that spill to disk for large tables.
   RULE: Avoid SET enable_nestloop=off; nested loops are efficient for indexed lookups on d1.
2. CTEs blocking parallelism (observed 0.50x on Q069):
   CAUSE: Materialized CTEs execute single-threaded, preventing parallel table scans.
   RULE: Use non-materialized CTEs (WITHOUT MATERIALIZED) or inline subqueries for large fact joins.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Query outputs 10 store columns and 5 aggregated bucket counts.
- CTE_COLUMN_COMPLETENESS: Any CTE must include ss_sold_date_sk, sr_returned_date_sk, and all store columns used in GROUP BY.
- LITERAL_PRESERVATION: Literal values 1999, 7, 30, 60, 90, 120 must be preserved exactly.
- SEMANTIC_EQUIVALENCE: Must return same rows and ordering (store attributes).
- COMMA_JOIN_WEAKNESS: Query uses comma-separated implicit joins (lines 21-25).
- CORRELATED_SUBQUERY_PARALYSIS: d1.d_date BETWEEN condition correlates with d2.d_date (lines 35-36).

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

pg_date_cte_explicit_join: Apply isolation of d2 filter into CTE and convert all comma joins to explicit JOIN syntax. Ignore the need for d1 CTE.
  pushdown: Push d2.d_date predicate into the d1 join condition via transitive propagation (d1.d_date between (d2_filtered.d_date - 120 days) and d2_filtered.d_date). Ignore other predicate pushdowns.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_date_cte_explicit_join (2.28x)

**Principle:** Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.

**BEFORE (slow):**
```sql
select 
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   catalog_sales
  ,warehouse
  ,ship_mode
  ,call_center
  ,date_dim
where
d_month_seq between 1193 and 1193 + 23
and cs_ship_date_sk   = d_date_sk
and cs_warehouse_sk   = w_warehouse_sk
and cs_ship_mode_sk   = sm_ship_mode_sk
and cs_call_center_sk = cc_call_center_sk
and cs_list_price between 271 and 300
and sm_type = 'REGULAR'
and cc_class = 'small'
and w_gmt_offset = -5
group by
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
order by substring(w_warehouse_name,1,20)
        ,sm_type
        ,cc_name
limit 100;
```

**AFTER (fast):**
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1193 AND 1216
```
[main_query]:
```sql
SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", ... FROM catalog_sales JOIN filtered_dates ON cs_ship_date_sk = d_date_sk JOIN warehouse ON cs_warehouse_sk = w_warehouse_sk JOIN ship_mode ON cs_ship_mode_sk = sm_ship_mode_sk JOIN call_center ON cs_call_center_sk = cc_call_center_sk WHERE cs_list_price BETWEEN 271 AND 300 AND sm_type = 'REGULAR' AND cc_class = 'small' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY 1, 2, 3 LIMIT 100
```

## Original SQL

```sql
select 
   s_store_name
  ,s_company_id
  ,s_street_number
  ,s_street_name
  ,s_street_type
  ,s_suite_number
  ,s_city
  ,s_county
  ,s_state
  ,s_zip
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 30) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 60) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 90) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   store_sales
  ,store_returns
  ,store
  ,date_dim d1
  ,date_dim d2
where
    d2.d_year = 1999
and d2.d_moy  = 7
and ss_ticket_number = sr_ticket_number
and ss_item_sk = sr_item_sk
and ss_sold_date_sk   = d1.d_date_sk
and sr_returned_date_sk   = d2.d_date_sk
and ss_customer_sk = sr_customer_sk
and ss_store_sk = s_store_sk
and d1.d_date between (d2.d_date - interval '120 day')
               and d2.d_date
group by
   s_store_name
  ,s_company_id
  ,s_street_number
  ,s_street_name
  ,s_street_type
  ,s_suite_number
  ,s_city
  ,s_county
  ,s_state
  ,s_zip
order by s_store_name
        ,s_company_id
        ,s_street_number
        ,s_street_name
        ,s_street_type
        ,s_suite_number
        ,s_city
        ,s_county
        ,s_state
        ,s_zip
limit 100;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~112K
    ├── SCAN (store_sales, store_returns (join), store (join), date_dim AS d1 (join), date_dim AS d2 (join))
    ├── JOIN (ss_ticket_number = sr_ticket_number)
    ├── JOIN (ss_item_sk = sr_item_sk)
    ├── JOIN (+4 more)
    ├── FILTER (d2.d_year = 1999)
    ├── FILTER (d2.d_moy = 7)
    ├── FILTER (+1 more)
    ├── AGG (GROUP BY)
    ├── SORT (s_store_name ASC, s_company_id ASC, s_street_number ASC, s_street_name ASC, s_street_type ASC, s_suite_number ASC, s_city ASC, s_county ASC, s_state ASC, s_zip ASC)
    └── OUTPUT (s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, ...)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: