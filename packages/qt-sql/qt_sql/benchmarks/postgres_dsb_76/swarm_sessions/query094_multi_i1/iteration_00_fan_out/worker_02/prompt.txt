You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

This query computes shipping cost and net profit for web sales orders within a 60-day period that ship to 6 US states, from websites in GMT offset >= -5, with list price between 237 and 266, where the same order was fulfilled from multiple warehouses and was not returned for 5 specific reasons. JOIN semantics are INNER: all dimension tables must match, and the EXISTS/NOT EXISTS are semi/anti-joins. Aggregation traps: COUNT(DISTINCT ws_order_number) is sensitive to duplicate order numbers from joins; the current plan uses semi/anti-joins so no duplication. Filter dependencies: The date filter on date_dim must apply before joining to web_sales; the state filter on customer_address and GMT offset on web_site are independent.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
multi_warehouse_orders_cte -> filtered_ws1 -> anti_join -> join_multi -> aggregate
NODE_CONTRACTS:
  multi_warehouse_orders_cte:
    FROM: web_sales
    GROUP BY: ws_order_number
    HAVING: COUNT(DISTINCT ws_warehouse_sk) > 1
    OUTPUT: ws_order_number
    EXPECTED_ROWS: unknown (but subset of orders)
    CONSUMERS: join_multi
  filtered_ws1:
    FROM: web_sales ws1, date_dim, customer_address, web_site
    WHERE: d_date BETWEEN '2002-9-01' AND CAST('2002-9-01' AS DATE) + INTERVAL '60 DAY'
      AND ws1.ws_ship_date_sk = d_date_sk
      AND ws1.ws_ship_addr_sk = ca_address_sk
      AND ca_state IN ('CA','MI','OH','SD','TX','VA')
      AND ws1.ws_web_site_sk = web_site_sk
      AND web_gmt_offset >= -5
      AND ws1.ws_list_price BETWEEN 237 AND 266
      AND NOT EXISTS (SELECT 1 FROM web_returns wr1 WHERE wr1.wr_order_number = ws1.ws_order_number AND wr1.wr_reason_sk IN (7,25,26,52,69))
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit
    EXPECTED_ROWS: 753
    CONSUMERS: join_multi
  join_multi:
    FROM: filtered_ws1
    JOIN: INNER JOIN multi_warehouse_orders_cte ON filtered_ws1.ws_order_number = multi_warehouse_orders_cte.ws_order_number
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit
    EXPECTED_ROWS: 753 (all filtered_ws1 rows satisfy the multi-warehouse condition)
    CONSUMERS: aggregate
  aggregate:
    FROM: join_multi
    AGGREGATE: COUNT(DISTINCT ws_order_number) AS "order count", SUM(ws_ext_ship_cost) AS "total shipping cost", SUM(ws_net_profit) AS "total net profit"
    OUTPUT: "order count", "total shipping cost", "total net profit"
    EXPECTED_ROWS: 1
    CONSUMERS: final output

NODE_CONTRACTS:
multi_warehouse_orders_cte:
    FROM: web_sales
    GROUP BY: ws_order_number
    HAVING: COUNT(DISTINCT ws_warehouse_sk) > 1
    OUTPUT: ws_order_number
    EXPECTED_ROWS: unknown (but subset of orders)
    CONSUMERS: join_multi
  filtered_ws1:
    FROM: web_sales ws1, date_dim, customer_address, web_site
    WHERE: d_date BETWEEN '2002-9-01' AND CAST('2002-9-01' AS DATE) + INTERVAL '60 DAY'
      AND ws1.ws_ship_date_sk = d_date_sk
      AND ws1.ws_ship_addr_sk = ca_address_sk
      AND ca_state IN ('CA','MI','OH','SD','TX','VA')
      AND ws1.ws_web_site_sk = web_site_sk
      AND web_gmt_offset >= -5
      AND ws1.ws_list_price BETWEEN 237 AND 266
      AND NOT EXISTS (SELECT 1 FROM web_returns wr1 WHERE wr1.wr_order_number = ws1.ws_order_number AND wr1.wr_reason_sk IN (7,25,26,52,69))
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit
    EXPECTED_ROWS: 753
    CONSUMERS: join_multi
  join_multi:
    FROM: filtered_ws1
    JOIN: INNER JOIN multi_warehouse_orders_cte ON filtered_ws1.ws_order_number = multi_warehouse_orders_cte.ws_order_number
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit
    EXPECTED_ROWS: 753 (all filtered_ws1 rows satisfy the multi-warehouse condition)
    CONSUMERS: aggregate
  aggregate:
    FROM: join_multi
    AGGREGATE: COUNT(DISTINCT ws_order_number) AS "order count", SUM(ws_ext_ship_cost) AS "total shipping cost", SUM(ws_net_profit) AS "total net profit"
    OUTPUT: "order count", "total shipping cost", "total net profit"
    EXPECTED_ROWS: 1
    CONSUMERS: final output

## Hazard Flags (avoid these specific risks)

- The multi_warehouse_orders_cte may be large; ensure it is efficient (use aggregation on web_sales with index on ws_order_number, ws_warehouse_sk).
- Must preserve the NOT EXISTS condition; do not lose the anti-join.

## Regression Warnings (observed failures on similar queries)

1. Never split OR conditions into UNION ALL (observed regression 0.21x):
   CAUSE: Query has no OR conditions over different dimension keys; splitting would add overhead.
   RULE: Do not apply OR-to-UNION to this query.
2. Never convert EXISTS to IN/NOT IN (observed regression 0.50x):
   CAUSE: Optimizer already converts EXISTS to efficient semi-joins; manual conversion may block optimizations.
   RULE: Keep EXISTS as semi-join; do not convert to IN.

## Constraints (analyst-filtered for this query)

- CORRECTNESS_CONSTRAINT_ID: COMPLETE_OUTPUT: Must output three columns: order count, total shipping cost, total net profit.
- CORRECTNESS_CONSTRAINT_ID: CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream: ws_order_number, ws_ext_ship_cost, ws_net_profit, ws_warehouse_sk, ws_ship_date_sk, ws_ship_addr_sk, ws_web_site_sk, ws_list_price, and dimension keys.
- CORRECTNESS_CONSTRAINT_ID: LITERAL_PRESERVATION: Must preserve literal values for date range, state list, reason_sk list, list price range, GMT offset.
- CORRECTNESS_CONSTRAINT_ID: SEMANTIC_EQUIVALENCE: Must return same rows and ordering (ORDER BY count distinct, LIMIT 100).
- ENGINE_GAP_ID: COMMA_JOIN_WEAKNESS: Query uses comma-separated implicit joins; EXPLAIN shows optimizer reordered joins but may have suboptimal cardinality estimates.
- ENGINE_GAP_ID: SELF_JOIN_ELIMINATION: EXISTS subquery is a self-join on web_sales; optimizer uses index-only scan but per-row correlation remains.

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- pg_self_join_decomposition: Apply the idea of materializing the multi-warehouse condition once as a CTE, then join with filtered fact rows. Ignore the fact that the example uses multiple aggregates; here we just need the order numbers.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

## Original SQL

```sql
select 
   count(distinct ws_order_number) as "order count"
  ,sum(ws_ext_ship_cost) as "total shipping cost"
  ,sum(ws_net_profit) as "total net profit"
from
   web_sales ws1
  ,date_dim
  ,customer_address
  ,web_site
where
    d_date between '2002-9-01' and
           cast('2002-9-01' as date) + interval '60 day'
and ws1.ws_ship_date_sk = d_date_sk
and ws1.ws_ship_addr_sk = ca_address_sk
and ca_state in ('CA','MI','OH'
            ,'SD' ,'TX' ,'VA')
and ws1.ws_web_site_sk = web_site_sk
and web_gmt_offset >= -5
and ws1.ws_list_price between 237 and 266
and exists (select *
            from web_sales ws2
            where ws1.ws_order_number = ws2.ws_order_number
              and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)
and not exists(select *
               from web_returns wr1
               where ws1.ws_order_number = wr1.wr_order_number
               and wr1.wr_reason_sk in (7, 25, 26, 52, 69)
               )
order by count(distinct ws_order_number)
limit 100;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~101K
    ├── SCAN (web_sales AS ws1 (join), date_dim (join), customer_address (join), web_site (join))
    ├── JOIN (ws1.ws_ship_date_sk = d_date_sk)
    ├── JOIN (ws1.ws_ship_addr_sk = ca_address_sk)
    ├── JOIN (+1 more)
    ├── FILTER (d_date BETWEEN '2002-9-01' AND CAST('2002-9-01' AS DATE) + INTERVAL '60 DAY')
    ├── FILTER (ca_state IN ('CA', 'MI', 'OH', 'SD', 'TX', 'VA'))
    ├── FILTER (+4 more)
    ├── SORT (COUNT(DISTINCT ws_order_number) ASC)
    └── OUTPUT (order count, total shipping cost, total net profit)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: