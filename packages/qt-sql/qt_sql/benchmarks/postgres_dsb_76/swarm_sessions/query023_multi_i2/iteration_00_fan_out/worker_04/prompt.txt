You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

This query computes total sales from catalog and web channels for May 1999, filtered to items that were frequently sold in stores during 1999 (with manager and category constraints) and customers whose store sales exceed 95% of the maximum per-customer store sales in 1999 (with wholesale cost and birth year constraints). All joins are INNER (intersection) except the HAVING subquery which is a scalar correlated threshold. Aggregates are SUM and COUNT, which are duplicate-insensitive, allowing safe restructure. The query depends on multiple filters on date_dim (year, month), item (manager_id, category), customer (birth_year), and wholesale_cost ranges; any rewrite must preserve these exact literal values.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
date_filtered, item_filtered, customer_filtered -> store_sales_unified -> max_store_sales, best_ss_customer_joined -> frequent_ss_items -> main_union
NODE_CONTRACTS:
  date_filtered:
    FROM: date_dim
    WHERE: d_year = 1999
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 365
    CONSUMERS: store_sales_unified
  item_filtered:
    FROM: item
    WHERE: i_manager_id BETWEEN 44 AND 63 AND i_category IN ('Men', 'Music', 'Sports')
    OUTPUT: i_item_sk, i_item_desc
    EXPECTED_ROWS: 1389
    CONSUMERS: store_sales_unified, frequent_ss_items
  customer_filtered:
    FROM: customer
    WHERE: c_birth_year BETWEEN 1987 AND 1993
    OUTPUT: c_customer_sk
    EXPECTED_ROWS: 13K
    CONSUMERS: store_sales_unified
  store_sales_unified:
    FROM: store_sales
      INNER JOIN date_filtered ON ss_sold_date_sk = d_date_sk
      LEFT JOIN item_filtered ON ss_item_sk = i_item_sk
      LEFT JOIN customer_filtered ON ss_customer_sk = c_customer_sk
    OUTPUT: ss_item_sk, ss_sold_date_sk, d_date, i_item_desc, ss_customer_sk, c_customer_sk, ss_quantity, ss_sales_price, ss_wholesale_cost
    EXPECTED_ROWS: ~300K
    CONSUMERS: max_store_sales, best_ss_customer_joined
  max_store_sales:
    FROM: store_sales_unified
    WHERE: ss_wholesale_cost BETWEEN 26 AND 36
    GROUP BY: ss_customer_sk
    AGGREGATE: SUM(ss_quantity * ss_sales_price) as csales
    OUTPUT: ss_customer_sk, csales
    EXPECTED_ROWS: ~1K (per-customer sums)
    CONSUMERS: best_ss_customer_joined
  best_ss_customer_joined:
    FROM: store_sales_unified
      INNER JOIN max_store_sales ON store_sales_unified.ss_customer_sk = max_store_sales.ss_customer_sk
    WHERE: store_sales_unified.c_customer_sk IS NOT NULL
    GROUP BY: store_sales_unified.ss_customer_sk, max_store_sales.csales
    AGGREGATE: SUM(store_sales_unified.ss_quantity * store_sales_unified.ss_sales_price) as ssales
    HAVING: SUM(store_sales_unified.ss_quantity * store_sales_unified.ss_sales_price) > (95/100.0) * max_store_sales.csales
    OUTPUT: store_sales_unified.ss_customer_sk as c_customer_sk, ssales
    EXPECTED_ROWS: 5504
    CONSUMERS: main_union
  frequent_ss_items:
    FROM: store_sales_unified
      INNER JOIN item_filtered ON ss_item_sk = i_item_sk
    GROUP BY: SUBSTRING(i_item_desc FROM 1 FOR 30), ss_item_sk, d_date
    AGGREGATE: COUNT(*) as cnt
    HAVING: COUNT(*) > 4
    OUTPUT: SUBSTRING(i_item_desc FROM 1 FOR 30) as itemdesc, ss_item_sk as item_sk, d_date as solddate, cnt
    EXPECTED_ROWS: 2
    CONSUMERS: main_union

NODE_CONTRACTS:
date_filtered:
    FROM: date_dim
    WHERE: d_year = 1999
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 365
    CONSUMERS: store_sales_unified
  item_filtered:
    FROM: item
    WHERE: i_manager_id BETWEEN 44 AND 63 AND i_category IN ('Men', 'Music', 'Sports')
    OUTPUT: i_item_sk, i_item_desc
    EXPECTED_ROWS: 1389
    CONSUMERS: store_sales_unified, frequent_ss_items
  customer_filtered:
    FROM: customer
    WHERE: c_birth_year BETWEEN 1987 AND 1993
    OUTPUT: c_customer_sk
    EXPECTED_ROWS: 13K
    CONSUMERS: store_sales_unified
  store_sales_unified:
    FROM: store_sales
      INNER JOIN date_filtered ON ss_sold_date_sk = d_date_sk
      LEFT JOIN item_filtered ON ss_item_sk = i_item_sk
      LEFT JOIN customer_filtered ON ss_customer_sk = c_customer_sk
    OUTPUT: ss_item_sk, ss_sold_date_sk, d_date, i_item_desc, ss_customer_sk, c_customer_sk, ss_quantity, ss_sales_price, ss_wholesale_cost
    EXPECTED_ROWS: ~300K
    CONSUMERS: max_store_sales, best_ss_customer_joined
  max_store_sales:
    FROM: store_sales_unified
    WHERE: ss_wholesale_cost BETWEEN 26 AND 36
    GROUP BY: ss_customer_sk
    AGGREGATE: SUM(ss_quantity * ss_sales_price) as csales
    OUTPUT: ss_customer_sk, csales
    EXPECTED_ROWS: ~1K (per-customer sums)
    CONSUMERS: best_ss_customer_joined
  best_ss_customer_joined:
    FROM: store_sales_unified
      INNER JOIN max_store_sales ON store_sales_unified.ss_customer_sk = max_store_sales.ss_customer_sk
    WHERE: store_sales_unified.c_customer_sk IS NOT NULL
    GROUP BY: store_sales_unified.ss_customer_sk, max_store_sales.csales
    AGGREGATE: SUM(store_sales_unified.ss_quantity * store_sales_unified.ss_sales_price) as ssales
    HAVING: SUM(store_sales_unified.ss_quantity * store_sales_unified.ss_sales_price) > (95/100.0) * max_store_sales.csales
    OUTPUT: store_sales_unified.ss_customer_sk as c_customer_sk, ssales
    EXPECTED_ROWS: 5504
    CONSUMERS: main_union
  frequent_ss_items:
    FROM: store_sales_unified
      INNER JOIN item_filtered ON ss_item_sk = i_item_sk
    GROUP BY: SUBSTRING(i_item_desc FROM 1 FOR 30), ss_item_sk, d_date
    AGGREGATE: COUNT(*) as cnt
    HAVING: COUNT(*) > 4
    OUTPUT: SUBSTRING(i_item_desc FROM 1 FOR 30) as itemdesc, ss_item_sk as item_sk, d_date as solddate, cnt
    EXPECTED_ROWS: 2
    CONSUMERS: main_union

## Hazard Flags (avoid these specific risks)

- The HAVING clause now joins max_store_sales per customer, which may change semantics if multiple customers share the same csales threshold (unlikely).
- This restructure changes the scalar subquery to a per-customer JOIN, which could increase row counts if csales are not unique per customer.
CONSTRAINT_OVERRIDE: None
OVERRIDE_REASONING: This exploration does not violate any correctness constraints; it preserves all literals and semantic equivalence by restructuring the HAVING clause as a JOIN with the same threshold logic.
EXPLORATION_TYPE: novel_combination

## Regression Warnings (observed failures on similar queries)

1. OR to UNION ALL (observed regression 0.21x):
   CAUSE: Splitting OR conditions into UNION ALL branches prevented bitmap index combination.
   RULE: Do not split OR conditions; this query has no OR conditions.
2. EXISTS to IN/NOT IN (observed regression 0.50x):
   CAUSE: Converting EXISTS to IN blocked semi-join short-circuit.
   RULE: Do not convert EXISTS; this query uses IN subqueries, not EXISTS.
3. CTE blocking parallelism (observed regression 0.67x):
   CAUSE: Materialized CTEs prevented parallel table scans.
   RULE: Avoid materializing CTEs that scan large fact tables if parallelism is needed; store_sales scans are already parallelized in EXPLAIN.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: The final output is a single SUM(sales) column; must preserve exactly.
- CTE_COLUMN_COMPLETENESS: Each CTE must output all columns referenced by downstream nodes (item_sk, c_customer_sk, etc.).
- LITERAL_PRESERVATION: Must keep all filter literals (1999, 5, 44, 63, 'Men','Music','Sports', 26, 36, 1987, 1993, 95/100.0).
- SEMANTIC_EQUIVALENCE: Must return same sum of sales across catalog and web channels.
- COMMA_JOIN_WEAKNESS: Query uses comma-separated joins (FROM store_sales, date_dim, item). EXPLAIN shows hash joins but cardinality estimation may suffer.
- CROSS_CTE_PREDICATE_BLINDNESS: store_sales scanned 3 times with overlapping filters; EXPLAIN shows separate scans for frequent_ss_items, max_store_sales, and best_ss_customer.

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- inline_decorrelate_materialized: apply the pattern of decomposing correlated subquery into JOIN via CTEs; ignore the 3-CTE structure (we use unified CTE).
- pg_materialized_dimension_fact_prefilter: apply staged reduction via dimension CTEs; ignore the non-equi join aspect.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. inline_decorrelate_materialized (timeout_rescue)

**Principle:** Inline Decorrelation with MATERIALIZED CTEs: When a WHERE clause contains a correlated scalar subquery (e.g., col > (SELECT 1.3 * avg(col) FROM ... WHERE correlated_key = outer.key)), PostgreSQL re-executes the subquery per outer row. Fix: decompose into 3 MATERIALIZED CTEs — (1) pre-filter dimension table, (2) pre-filter fact table by date range, (3) compute per-key aggregate threshold from filtered data — then JOIN the threshold CTE in the final query. MATERIALIZED keyword prevents PG from inlining the CTEs back into correlated form.

**BEFORE (slow):**
```sql
select  sum(cs_ext_discount_amt)  as "excess discount amount"
from
   catalog_sales
   ,item
   ,date_dim
where
(i_manufact_id in (1, 78, 97, 516, 521)
or i_manager_id BETWEEN 25 and 54)
and i_item_sk = cs_item_sk
and d_date between '1999-03-07' and
        cast('1999-03-07' as date) + interval '90 day'
and d_date_sk = cs_sold_date_sk
and cs_ext_discount_amt
     > (
         select
            1.3 * avg(cs_ext_discount_amt)
         from
            catalog_sales
           ,date_dim
         where
              cs_item_sk = i_item_sk
          and d_date between '1999-03-07' and
                             cast('1999-03-07' as date) + interval '90 day'
          and d_date_sk = cs_sold_date_sk
          and cs_list_price between 16 and 45
          and cs_sales_price / cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01
      )
order by sum(cs_ext_discount_amt)
limit 100;
```

**AFTER (fast):**
```sql
WITH filtered_items AS MATERIALIZED (
    SELECT i_item_sk
    FROM item
    WHERE i_manufact_id IN (1, 78, 97, 516, 521)
       OR i_manager_id BETWEEN 25 AND 54
),
date_filtered_sales AS MATERIALIZED (
    SELECT cs.cs_item_sk, cs.cs_ext_discount_amt,
           cs.cs_list_price, cs.cs_sales_price
    FROM catalog_sales cs
    JOIN date_dim d ON d.d_date_sk = cs.cs_sold_date_sk
    WHERE d.d_date BETWEEN '1999-03-07' AND cast('1999-03-07' as date) + interval '90 day'
),
item_avg_discount AS MATERIALIZED (
    SELECT dfs.cs_item_sk,
           1.3 * avg(dfs.cs_ext_discount_amt) AS threshold
    FROM date_filtered_sales dfs
    JOIN filtered_items fi ON fi.i_item_sk = dfs.cs_item_sk
    WHERE dfs.cs_list_price BETWEEN 16 AND 45
      AND dfs.cs_sales_price / dfs.cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01
    GROUP BY dfs.cs_item_sk
)
SELECT sum(dfs.cs_ext_discount_amt) AS "excess discount amount"
FROM date_filtered_sales dfs
JOIN item_avg_discount iad ON iad.cs_item_sk = dfs.cs_item_sk
WHERE dfs.cs_ext_discount_amt > iad.threshold
ORDER BY 1
LIMIT 100;
```

### 2. pg_materialized_dimension_fact_prefilter (2.68x)

**Principle:** Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.

**BEFORE (slow):**
```sql
select  i_item_desc
      ,w_warehouse_name
      ,d1.d_week_seq
      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo
      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo
      ,count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity
  and d3.d_date > d1.d_date + interval '3 day'
  and hd_buy_potential = '501-1000'
  and d1.d_year = 1998
  and cd_marital_status = 'M'
  and cd_dep_count between 9 and 11
  and i_category IN ('Home', 'Men', 'Music')
  and cs_wholesale_cost BETWEEN 34 AND 54
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk, d_date, d_week_seq FROM date_dim WHERE d_year = 1998
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc FROM item WHERE i_category IN ('Home', 'Men', 'Music')
```
[filtered_cd]:
```sql
SELECT cd_demo_sk FROM customer_demographics WHERE cd_marital_status = 'M' AND cd_dep_count BETWEEN 9 AND 11
```
[filtered_hd]:
```sql
SELECT hd_demo_sk FROM household_demographics WHERE hd_buy_potential = '501-1000'
```
[cs_filtered]:
```sql
SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk, cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost, cs_order_number FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 34 AND 54
```
[main_query]:
```sql
SELECT i.i_item_desc, w.w_warehouse_name, d1.d_week_seq, SUM(CASE WHEN p.p_promo_sk IS NULL THEN 1 ELSE 0 END) AS no_promo, SUM(CASE WHEN p.p_promo_sk IS NOT NULL THEN 1 ELSE 0 END) AS promo, COUNT(*) AS total_cnt FROM cs_filtered cs JOIN inventory inv ON cs.cs_item_sk = inv.inv_item_sk JOIN warehouse w ON w.w_warehouse_sk = inv.inv_warehouse_sk JOIN filtered_item i ON i.i_item_sk = cs.cs_item_sk JOIN filtered_cd cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk JOIN filtered_hd hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk JOIN filtered_date d1 ON cs.cs_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON inv.inv_date_sk = d2.d_date_sk JOIN date_dim d3 ON cs.cs_ship_date_sk = d3.d_date_sk LEFT OUTER JOIN promotion p ON cs.cs_promo_sk = p.p_promo_sk LEFT OUTER JOIN catalog_returns cr ON cr.cr_item_sk = cs.cs_item_sk AND cr.cr_order_number = cs.cs_order_number WHERE d1.d_week_seq = d2.d_week_seq AND inv.inv_quantity_on_hand < cs.cs_quantity AND d3.d_date > d1.d_date + INTERVAL '3 day' GROUP BY i.i_item_desc, w.w_warehouse_name, d1.d_week_seq ORDER BY total_cnt DESC, i.i_item_desc, w.w_warehouse_name, d1.d_week_seq LIMIT 100
```

## Original SQL

```sql
with frequent_ss_items as
 (select substring(i_item_desc,1,30) itemdesc,i_item_sk item_sk,d_date solddate,count(*) cnt
  from store_sales
      ,date_dim
      ,item
  where ss_sold_date_sk = d_date_sk
    and ss_item_sk = i_item_sk
    and d_year = 1999
    and i_manager_id BETWEEN 44 and 63
     AND i_category IN ('Men', 'Music', 'Sports')
  group by substring(i_item_desc,1,30),i_item_sk,d_date
  having count(*) >4),
 max_store_sales as
 (select max(csales) tpcds_cmax
  from (select c_customer_sk,sum(ss_quantity*ss_sales_price) csales
        from store_sales
            ,customer
            ,date_dim
        where ss_customer_sk = c_customer_sk
         and ss_sold_date_sk = d_date_sk
         and d_year = 1999
         and ss_wholesale_cost BETWEEN 26 AND 36
        group by c_customer_sk) tmp1),
 best_ss_customer as
 (select c_customer_sk,sum(ss_quantity*ss_sales_price) ssales
  from store_sales
      ,customer
  where ss_customer_sk = c_customer_sk
  and c_birth_year BETWEEN 1987 AND 1993
  group by c_customer_sk
  having sum(ss_quantity*ss_sales_price) > (95/100.0) * (select
  *
from
 max_store_sales))
  select  sum(sales)
 from (select cs_quantity*cs_list_price sales
       from catalog_sales
           ,date_dim
       where d_year = 1999
         and d_moy = 5
         and cs_sold_date_sk = d_date_sk
         and cs_item_sk in (select item_sk from frequent_ss_items)
         and cs_bill_customer_sk in (select c_customer_sk from best_ss_customer)
         and cs_wholesale_cost BETWEEN 26 AND 36
      union all
      select ws_quantity*ws_list_price sales
       from web_sales
           ,date_dim
       where d_year = 1999
         and d_moy = 5
         and ws_sold_date_sk = d_date_sk
         and ws_item_sk in (select item_sk from frequent_ss_items)
         and ws_bill_customer_sk in (select c_customer_sk from best_ss_customer)
         and ws_wholesale_cost BETWEEN 26 AND 36) tmp2
 limit 100;
```

## Per-Rewrite Configuration (SET LOCAL)

You have two optimization levers: SQL rewrite AND per-query configuration.
After writing your rewrite, analyze its execution profile and emit SET LOCAL
commands that fix planner-level bottlenecks specific to YOUR rewrite.

Memory budget: shared_buffers=128MB, effective_cache_size=4GB
Global work_mem: 4MB (per-operation)
Active connections: ~1 (work_mem headroom: safe up to 16MB per-op)
Storage: HDD (random_page_cost=4.0)
Parallel capacity: max_parallel_workers=8, per_gather=2

SET LOCAL permissions:
  user-level (always available): effective_cache_size, enable_hashjoin, enable_mergejoin, enable_nestloop, enable_seqscan, from_collapse_limit, geqo_threshold, hash_mem_multiplier, jit, jit_above_cost, join_collapse_limit, max_parallel_workers_per_gather, parallel_setup_cost, parallel_tuple_cost, random_page_cost, work_mem

### Tunable Parameters (whitelist — only these are allowed)

- **effective_cache_size** (1024MB–65536MB): Advisory: how much OS cache to expect (MB). Safe to set aggressively.
- **enable_hashjoin** (on | off): Enable hash join plan type.
- **enable_mergejoin** (on | off): Enable merge join plan type.
- **enable_nestloop** (on | off): Enable nested-loop join plan type.
- **enable_seqscan** (on | off): Enable sequential scan plan type.
- **from_collapse_limit** (1–20): Max FROM items before subqueries stop being flattened.
- **geqo_threshold** (2–20): Number of FROM items that triggers genetic query optimizer.
- **hash_mem_multiplier** (1.0–10.0): Multiplier applied to work_mem for hash-based operations.
- **jit** (on | off): Enable JIT compilation.
- **jit_above_cost** (0.0–1000000.0): Query cost above which JIT is activated.
- **join_collapse_limit** (1–20): Max FROM items before planner stops trying all join orders.
- **max_parallel_workers_per_gather** (0–8): Max parallel workers per Gather node.
- **parallel_setup_cost** (0.0–10000.0): Planner estimate of cost to launch parallel workers.
- **parallel_tuple_cost** (0.0–1.0): Planner estimate of cost to transfer a tuple to parallel worker.
- **random_page_cost** (1.0–10.0): Planner estimate of cost of a random page fetch (1.0 = SSD, 4.0 = HDD).
- **work_mem** (64MB–2048MB): Memory for sorts/hashes per operation (MB). Allocated PER-OPERATION, not per-query. Count hash/sort ops in EXPLAIN before sizing.

### Rules
- Every SET LOCAL MUST cite a specific EXPLAIN node your rewrite creates/changes
- work_mem is PER-OPERATION: count hash/sort ops in your rewrite before sizing
- random_page_cost: ONLY change if your rewrite creates index-favorable access patterns
- Empty is valid: if your rewrite has no planner bottleneck, emit no SET LOCAL
- Stay within the resource envelope bounds above

### SET LOCAL Syntax
Include SET LOCAL commands in the `runtime_config` array field of your JSON output.
If no config changes help, omit the field or use an empty array.

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

### Column Completeness Contract

Your `main_query` component MUST produce **exactly** these output columns (same names, same order):

  1. `SUM(sales)`

Do NOT add, remove, or rename any output columns. The result set schema must be identical to the original query.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
├── [CTE] frequent_ss_items  [=]  Cost: 0%  Rows: ~4K
│   ├── SCAN (store_sales, date_dim (join), item (join))
│   ├── JOIN (ss_sold_date_sk = d_date_sk)
│   ├── JOIN (ss_item_sk = i_item_sk)
│   ├── FILTER (d_year = 1999)
│   ├── FILTER (i_manager_id BETWEEN 44 AND 63)
│   ├── FILTER (+1 more)
│   ├── AGG (GROUP BY)
│   └── OUTPUT (itemdesc, item_sk, solddate, cnt)
├── [CTE] max_store_sales  [=]  Cost: 0%  Rows: ~1K
│   ├── SCAN (store_sales, customer, date_dim)
│   ├── JOIN (ss_customer_sk = c_customer_sk)
│   ├── JOIN (ss_sold_date_sk = d_date_sk)
│   ├── FILTER (d_year = 1999)
│   ├── FILTER (ss_wholesale_cost BETWEEN 26 AND 36)
│   ├── AGG (GROUP BY)
│   └── OUTPUT (tpcds_cmax)
├── [CTE] best_ss_customer  [=]  Cost: 53%  Rows: ~2.2M
│   ├── SCAN (store_sales, customer (join), max_store_sales (correlated subquery))
│   ├── JOIN (ss_customer_sk = c_customer_sk)
│   ├── FILTER (c_birth_year BETWEEN 1987 AND 1993)
│   ├── AGG (GROUP BY)
│   └── OUTPUT (c_customer_sk, ssales)
└── [MAIN] main_query  [=]  Cost: 41%  Rows: ~10K
    ├── SCAN (catalog_sales, date_dim, web_sales, best_ss_customer, frequent_ss_items)
    ├── JOIN (cs_sold_date_sk = d_date_sk)
    ├── FILTER (d_year = 1999)
    ├── FILTER (d_moy = 5)
    ├── FILTER (+3 more)
    ├── AGG (GROUP BY)
    └── OUTPUT (SUM(sales))
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: