You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

This query finds customers who made store purchases and returns, then web purchases within 90 days, for items in specific categories, with specific discount ranges, living in certain states and demographic bands. It counts qualifying transaction combinations per customer. All joins are INNER (must match all sides). Aggregation uses COUNT(*) which is sensitive to row duplication from joins. The date range filter (d2 between d1 and d1+90) creates a temporal dependency between store returns and web sales.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
filtered_dates -> filtered_item -> filtered_ca_hd -> fact_joins -> aggregation -> sort
NODE_CONTRACTS:
  filtered_d1:
    FROM: date_dim d1
    WHERE: d1.d_year = 2000
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 122
    CONSUMERS: fact_joins
  filtered_d2:
    FROM: date_dim d2
    WHERE: EXISTS (SELECT 1 FROM filtered_d1 WHERE d2.d_date BETWEEN d1.d_date AND (d1.d_date + interval '90 day'))
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: ~365 (90 days * 4 years approx)
    CONSUMERS: fact_joins
  filtered_item:
    FROM: item
    WHERE: i_category IN ('Children', 'Home', 'Women')
    OUTPUT: i_item_sk
    EXPECTED_ROWS: 9203
    CONSUMERS: fact_joins
  filtered_ca:
    FROM: customer_address
    WHERE: ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA')
    OUTPUT: ca_address_sk
    EXPECTED_ROWS: ~5 states / 50 = 10% of table
    CONSUMERS: customer_prefilter
  filtered_hd:
    FROM: household_demographics
    WHERE: hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000'
    OUTPUT: hd_demo_sk
    EXPECTED_ROWS: selective
    CONSUMERS: customer_prefilter
  customer_prefilter:
    FROM: customer
    JOIN: INNER JOIN filtered_ca ON c_current_addr_sk = ca_address_sk
          INNER JOIN filtered_hd ON c_current_hdemo_sk = hd_demo_sk
    OUTPUT: c_customer_sk, c_first_name, c_last_name, c_current_addr_sk, c_current_hdemo_sk
    EXPECTED_ROWS: reduced by state and demographic filters
    CONSUMERS: fact_joins
  fact_joins:
    FROM: store_sales
    JOIN: INNER JOIN store_returns ON ss_ticket_number = sr_ticket_number AND ss_item_sk = sr_item_sk
          INNER JOIN filtered_item ON ss_item_sk = i_item_sk
          INNER JOIN filtered_d1 ON sr_returned_date_sk = d1.d_date_sk
          INNER JOIN web_sales ON sr_item_sk = ws_item_sk AND ss_customer_sk = ws_bill_customer_sk
          INNER JOIN filtered_d2 ON ws_sold_date_sk = d2.d_date_sk
          INNER JOIN customer_prefilter ON ss_customer_sk = c_customer_sk
    WHERE: ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01
    OUTPUT: c_customer_sk, c_first_name, c_last_name
    EXPECTED_ROWS: same as original output
    CONSUMERS: aggregation
  aggregation:
    FROM: fact_joins
    GROUP BY: c_customer_sk, c_first_name, c_last_name
    AGGREGATE: COUNT(*) as cnt
    OUTPUT: c_customer_sk, c_first_name, c_last_name, cnt
    EXPECTED_ROWS: same as original
    CONSUMERS: sort
  sort:
    FROM: aggregation
    ORDER BY: cnt
    OUTPUT: c_customer_sk, c_first_name, c_last_name, cnt
    EXPECTED_ROWS: same as original
    CONSUMERS: final output

NODE_CONTRACTS:
filtered_d1:
    FROM: date_dim d1
    WHERE: d1.d_year = 2000
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 122
    CONSUMERS: fact_joins
  filtered_d2:
    FROM: date_dim d2
    WHERE: EXISTS (SELECT 1 FROM filtered_d1 WHERE d2.d_date BETWEEN d1.d_date AND (d1.d_date + interval '90 day'))
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: ~365 (90 days * 4 years approx)
    CONSUMERS: fact_joins
  filtered_item:
    FROM: item
    WHERE: i_category IN ('Children', 'Home', 'Women')
    OUTPUT: i_item_sk
    EXPECTED_ROWS: 9203
    CONSUMERS: fact_joins
  filtered_ca:
    FROM: customer_address
    WHERE: ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA')
    OUTPUT: ca_address_sk
    EXPECTED_ROWS: ~5 states / 50 = 10% of table
    CONSUMERS: customer_prefilter
  filtered_hd:
    FROM: household_demographics
    WHERE: hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000'
    OUTPUT: hd_demo_sk
    EXPECTED_ROWS: selective
    CONSUMERS: customer_prefilter
  customer_prefilter:
    FROM: customer
    JOIN: INNER JOIN filtered_ca ON c_current_addr_sk = ca_address_sk
          INNER JOIN filtered_hd ON c_current_hdemo_sk = hd_demo_sk
    OUTPUT: c_customer_sk, c_first_name, c_last_name, c_current_addr_sk, c_current_hdemo_sk
    EXPECTED_ROWS: reduced by state and demographic filters
    CONSUMERS: fact_joins
  fact_joins:
    FROM: store_sales
    JOIN: INNER JOIN store_returns ON ss_ticket_number = sr_ticket_number AND ss_item_sk = sr_item_sk
          INNER JOIN filtered_item ON ss_item_sk = i_item_sk
          INNER JOIN filtered_d1 ON sr_returned_date_sk = d1.d_date_sk
          INNER JOIN web_sales ON sr_item_sk = ws_item_sk AND ss_customer_sk = ws_bill_customer_sk
          INNER JOIN filtered_d2 ON ws_sold_date_sk = d2.d_date_sk
          INNER JOIN customer_prefilter ON ss_customer_sk = c_customer_sk
    WHERE: ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01
    OUTPUT: c_customer_sk, c_first_name, c_last_name
    EXPECTED_ROWS: same as original output
    CONSUMERS: aggregation
  aggregation:
    FROM: fact_joins
    GROUP BY: c_customer_sk, c_first_name, c_last_name
    AGGREGATE: COUNT(*) as cnt
    OUTPUT: c_customer_sk, c_first_name, c_last_name, cnt
    EXPECTED_ROWS: same as original
    CONSUMERS: sort
  sort:
    FROM: aggregation
    ORDER BY: cnt
    OUTPUT: c_customer_sk, c_first_name, c_last_name, cnt
    EXPECTED_ROWS: same as original
    CONSUMERS: final output

## Hazard Flags (avoid these specific risks)

- May lose parallel execution if CTEs are materialized
- Explicit JOIN syntax may constrain join order optimization

## Regression Warnings (observed failures on similar queries)

1. CTE blocking parallelism (observed regression: 0.50x on Q069):
   CAUSE: MATERIALIZED CTEs executed single-threaded prevent parallel table scans
   RULE: Use non-materialized CTEs or inline subqueries for large fact tables when parallel scans are beneficial
2. Nestloop disable on lookups (observed regression: 184x):
   CAUSE: SET enable_nestloop=off forces hash/merge joins on selective index lookups
   RULE: Never disable nestloop globally; allow optimizer to choose for point lookups

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Query outputs c_customer_sk, c_first_name, c_last_name, cnt
- CTE_COLUMN_COMPLETENESS: All CTEs must include columns referenced downstream: ss_customer_sk, ss_item_sk, ss_ticket_number, sr_item_sk, sr_ticket_number, ws_bill_customer_sk, ws_item_sk, plus dimension keys
- LITERAL_PRESERVATION: Must preserve exact filter values: i_category IN ('Children','Home','Women'), ca_state IN ('AR','GA','IN','KY','VA'), d_year=2000, etc.
- SEMANTIC_EQUIVALENCE: Must return same rows, columns, ordering
- COMMA_JOIN_WEAKNESS: Query uses comma-separated implicit joins (evidence from original SQL)
- NON_EQUI_JOIN_INPUT_BLINDNESS: Range join d2.d_date BETWEEN d1.d_date AND (d1.d_date + interval '90 day')

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- pg_dimension_prefetch_star: Apply pre-filtering of all selective dimensions (date, item, customer_address, household_demographics) into CTEs; convert comma joins to explicit JOIN syntax. Ignore promotion table references.
- pg_date_cte_explicit_join: Apply date_dim isolation for both d1 and d2 with explicit JOINs. Ignore single-date focus; adapt for two date dimensions with range condition.
- pg_materialized_dimension_fact_prefilter: Apply staged reduction via CTEs but avoid MATERIALIZED keyword to preserve parallelism; focus on dimension pre-filtering.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_dimension_prefetch_star (3.32x)

**Principle:** Multi-Dimension Prefetch (PG): pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax. PostgreSQL's optimizer gets better cardinality estimates from pre-materialized small dimension results.

**BEFORE (slow):**
```sql
with ssr as
 (select  s_store_id as store_id,
          sum(ss_ext_sales_price) as sales,
          sum(coalesce(sr_return_amt, 0)) as returns,
          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit
  from store_sales left outer join store_returns on
         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),
     date_dim,
     store,
     item,
     promotion
 where ss_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
       and ss_store_sk = s_store_sk
       and ss_item_sk = i_item_sk
       and i_current_price > 50
       and ss_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ss_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
 group by s_store_id)
 ,
 csr as
 (select  cp_catalog_page_id as catalog_page_id,
          sum(cs_ext_sales_price) as sales,
          sum(coalesce(cr_return_amount, 0)) as returns,
          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit
  from catalog_sales left outer join catalog_returns on
         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),
     date_dim,
     catalog_page,
     item,
     promotion
 where cs_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and cs_catalog_page_sk = cp_catalog_page_sk
       and cs_item_sk = i_item_sk
       and i_current_price > 50
       and cs_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and cs_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by cp_catalog_page_id)
 ,
 wsr as
 (select  web_site_id,
          sum(ws_ext_sales_price) as sales,
          sum(coalesce(wr_return_amt, 0)) as returns,
          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit
  from web_sales left outer join web_returns on
         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),
     date_dim,
     web_site,
     item,
     promotion
 where ws_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and ws_web_site_sk = web_site_sk
       and ws_item_sk = i_item_sk
       and i_current_price > 50
       and ws_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ws_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by web_site_id)
  select  channel
        , id
        , sum(sales) as sales
        , sum(returns) as returns
        , sum(profit) as profit
 from
 (select 'store channel' as channel
        , 'store' || store_id as id
        , sales
        , returns
        , profit
 from   ssr
 union all
 select 'catalog channel' as channel
        , 'catalog_page' || catalog_page_id as id
        , sales
        , returns
        , profit
 from  csr
 union all
 select 'web channel' as channel
        , 'web_site' || web_site_id as id
        , sales
        , returns
        , profit
 from   wsr
 ) x
 group by rollup (channel, id)
 order by channel
         ,id
 limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-23' AS DATE) AND CAST('1998-08-23' AS DATE) + INTERVAL '30 DAY'
```
[filtered_item]:
```sql
SELECT i_item_sk FROM item WHERE i_current_price > 50 AND i_category IN ('Jewelry', 'Music')
```
[filtered_promotion]:
```sql
SELECT p_promo_sk FROM promotion WHERE p_channel_email = 'Y' AND p_channel_tv = 'Y' AND p_channel_radio = 'N' AND p_channel_press = 'N' AND p_channel_event = 'Y'
```
[ssr]:
```sql
SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS returns, SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) INNER JOIN filtered_date ON ss_sold_date_sk = filtered_date.d_date_sk INNER JOIN store ON ss_store_sk = s_store_sk INNER JOIN filtered_item ON ss_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ss_promo_sk = filtered_promotion.p_promo_sk WHERE ss_wholesale_cost BETWEEN 63 AND 78 GROUP BY s_store_id
```
[csr]:
```sql
SELECT cp_catalog_page_id AS catalog_page_id, SUM(cs_ext_sales_price) AS sales, SUM(COALESCE(cr_return_amount, 0)) AS returns, SUM(cs_net_profit - COALESCE(cr_net_loss, 0)) AS profit FROM catalog_sales LEFT OUTER JOIN catalog_returns ON (cs_item_sk = cr_item_sk AND cs_order_number = cr_order_number) INNER JOIN filtered_date ON cs_sold_date_sk = filtered_date.d_date_sk INNER JOIN catalog_page ON cs_catalog_page_sk = cp_catalog_page_sk INNER JOIN filtered_item ON cs_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON cs_promo_sk = filtered_promotion.p_promo_sk WHERE cs_wholesale_cost BETWEEN 63 AND 78 GROUP BY cp_catalog_page_id
```
[wsr]:
```sql
SELECT web_site_id, SUM(ws_ext_sales_price) AS sales, SUM(COALESCE(wr_return_amt, 0)) AS returns, SUM(ws_net_profit - COALESCE(wr_net_loss, 0)) AS profit FROM web_sales LEFT OUTER JOIN web_returns ON (ws_item_sk = wr_item_sk AND ws_order_number = wr_order_number) INNER JOIN filtered_date ON ws_sold_date_sk = filtered_date.d_date_sk INNER JOIN web_site ON ws_web_site_sk = web_site_sk INNER JOIN filtered_item ON ws_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ws_promo_sk = filtered_promotion.p_promo_sk WHERE ws_wholesale_cost BETWEEN 63 AND 78 GROUP BY web_site_id
```
[main_query]:
```sql
SELECT channel, id, SUM(sales) AS sales, SUM(returns) AS returns, SUM(profit) AS profit FROM (SELECT 'store channel' AS channel, 'store' || store_id AS id, sales, returns, profit FROM ssr UNION ALL SELECT 'catalog channel' AS channel, 'catalog_page' || catalog_page_id AS id, sales, returns, profit FROM csr UNION ALL SELECT 'web channel' AS channel, 'web_site' || web_site_id AS id, sales, returns, profit FROM wsr) AS x GROUP BY ROLLUP (channel, id) ORDER BY channel, id LIMIT 100
```

### 2. pg_date_cte_explicit_join (2.28x)

**Principle:** Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.

**BEFORE (slow):**
```sql
select 
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   catalog_sales
  ,warehouse
  ,ship_mode
  ,call_center
  ,date_dim
where
d_month_seq between 1193 and 1193 + 23
and cs_ship_date_sk   = d_date_sk
and cs_warehouse_sk   = w_warehouse_sk
and cs_ship_mode_sk   = sm_ship_mode_sk
and cs_call_center_sk = cc_call_center_sk
and cs_list_price between 271 and 300
and sm_type = 'REGULAR'
and cc_class = 'small'
and w_gmt_offset = -5
group by
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
order by substring(w_warehouse_name,1,20)
        ,sm_type
        ,cc_name
limit 100;
```

**AFTER (fast):**
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1193 AND 1216
```
[main_query]:
```sql
SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", ... FROM catalog_sales JOIN filtered_dates ON cs_ship_date_sk = d_date_sk JOIN warehouse ON cs_warehouse_sk = w_warehouse_sk JOIN ship_mode ON cs_ship_mode_sk = sm_ship_mode_sk JOIN call_center ON cs_call_center_sk = cc_call_center_sk WHERE cs_list_price BETWEEN 271 AND 300 AND sm_type = 'REGULAR' AND cc_class = 'small' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY 1, 2, 3 LIMIT 100
```

### 3. pg_materialized_dimension_fact_prefilter (2.68x)

**Principle:** Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.

**BEFORE (slow):**
```sql
select  i_item_desc
      ,w_warehouse_name
      ,d1.d_week_seq
      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo
      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo
      ,count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity
  and d3.d_date > d1.d_date + interval '3 day'
  and hd_buy_potential = '501-1000'
  and d1.d_year = 1998
  and cd_marital_status = 'M'
  and cd_dep_count between 9 and 11
  and i_category IN ('Home', 'Men', 'Music')
  and cs_wholesale_cost BETWEEN 34 AND 54
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk, d_date, d_week_seq FROM date_dim WHERE d_year = 1998
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc FROM item WHERE i_category IN ('Home', 'Men', 'Music')
```
[filtered_cd]:
```sql
SELECT cd_demo_sk FROM customer_demographics WHERE cd_marital_status = 'M' AND cd_dep_count BETWEEN 9 AND 11
```
[filtered_hd]:
```sql
SELECT hd_demo_sk FROM household_demographics WHERE hd_buy_potential = '501-1000'
```
[cs_filtered]:
```sql
SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk, cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost, cs_order_number FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 34 AND 54
```
[main_query]:
```sql
SELECT i.i_item_desc, w.w_warehouse_name, d1.d_week_seq, SUM(CASE WHEN p.p_promo_sk IS NULL THEN 1 ELSE 0 END) AS no_promo, SUM(CASE WHEN p.p_promo_sk IS NOT NULL THEN 1 ELSE 0 END) AS promo, COUNT(*) AS total_cnt FROM cs_filtered cs JOIN inventory inv ON cs.cs_item_sk = inv.inv_item_sk JOIN warehouse w ON w.w_warehouse_sk = inv.inv_warehouse_sk JOIN filtered_item i ON i.i_item_sk = cs.cs_item_sk JOIN filtered_cd cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk JOIN filtered_hd hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk JOIN filtered_date d1 ON cs.cs_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON inv.inv_date_sk = d2.d_date_sk JOIN date_dim d3 ON cs.cs_ship_date_sk = d3.d_date_sk LEFT OUTER JOIN promotion p ON cs.cs_promo_sk = p.p_promo_sk LEFT OUTER JOIN catalog_returns cr ON cr.cr_item_sk = cs.cs_item_sk AND cr.cr_order_number = cs.cs_order_number WHERE d1.d_week_seq = d2.d_week_seq AND inv.inv_quantity_on_hand < cs.cs_quantity AND d3.d_date > d1.d_date + INTERVAL '3 day' GROUP BY i.i_item_desc, w.w_warehouse_name, d1.d_week_seq ORDER BY total_cnt DESC, i.i_item_desc, w.w_warehouse_name, d1.d_week_seq LIMIT 100
```

## Original SQL

```sql
select  c_customer_sk, c_first_name, c_last_name, count(*) as cnt
FROM
store_sales,
store_returns,
web_sales,
date_dim d1,
date_dim d2,
item,
customer,
customer_address,
household_demographics
WHERE
ss_ticket_number = sr_ticket_number
AND ss_customer_sk = ws_bill_customer_sk
AND ss_customer_sk = c_customer_sk
AND c_current_addr_sk = ca_address_sk
AND c_current_hdemo_sk = hd_demo_sk
AND ss_item_sk = sr_item_sk
AND sr_item_sk = ws_item_sk
AND i_item_sk = ss_item_sk
AND i_category IN ('Children', 'Home', 'Women')
AND sr_returned_date_sk = d1.d_date_sk
AND ws_sold_date_sk = d2.d_date_sk
AND d2.d_date between d1.d_date AND (d1.d_date + interval '90 day')
AND ca_state in ('AR', 'GA', 'IN', 'KY', 'VA')
AND d1.d_year = 2000
AND hd_income_band_sk BETWEEN 8 AND 14
AND hd_buy_potential = '501-1000'
AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01
GROUP BY c_customer_sk, c_first_name, c_last_name
ORDER BY cnt
;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 99%  Rows: ~1.2M
    ├── SCAN (store_sales, store_returns (join), web_sales (join), date_dim AS d1 (join), date_dim AS d2 (join), item (join), customer (join), customer_address (join), household_demographics (join))
    ├── JOIN (ss_ticket_number = sr_ticket_number)
    ├── JOIN (ss_customer_sk = ws_bill_customer_sk)
    ├── JOIN (+8 more)
    ├── FILTER (i_category IN ('Children', 'Home', 'Women'))
    ├── FILTER (d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY'))
    ├── FILTER (+5 more)
    ├── AGG (GROUP BY)
    ├── SORT (cnt ASC)
    └── OUTPUT (c_customer_sk, c_first_name, c_last_name, cnt)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: