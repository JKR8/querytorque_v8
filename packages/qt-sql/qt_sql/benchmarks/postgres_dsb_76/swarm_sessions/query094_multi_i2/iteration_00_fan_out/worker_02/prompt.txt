You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

Find shipping metrics for web orders within a 60-day window where: (a) the order ships to one of six US states, (b) the website is in timezone GMT-5 or later, (c) list price is between $253-$282, (d) the order was fulfilled from at least two different warehouses, and (e) the order was not returned for any of five specific reasons. All joins are INNER (must match), and COUNT(DISTINCT) requires preserving exact order set. The NOT EXISTS with wr_reason_sk IN list must reject orders with ANY matching reason.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
CTE_base_sales -> CTE_warehouse_counts -> Filter multi-warehouse -> Anti-join web_returns -> Aggregate
NODE_CONTRACTS:
  base_sales:
    FROM: web_sales ws1, date_dim, customer_address, web_site
    WHERE: d_date BETWEEN '1999-10-01' AND CAST('1999-10-01' AS DATE) + INTERVAL '60 DAY'
           AND ws1.ws_ship_date_sk = d_date_sk
           AND ws1.ws_ship_addr_sk = ca_address_sk
           AND ca_state IN ('MO','MT','OK','SC','TX','WI')
           AND ws1.ws_web_site_sk = web_site_sk
           AND web_gmt_offset >= -5
           AND ws1.ws_list_price BETWEEN 253 AND 282
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit, ws_warehouse_sk
    EXPECTED_ROWS: ~1,185
    CONSUMERS: warehouse_counts
  warehouse_counts:
    FROM: base_sales
    GROUP BY: ws_order_number, ws_ext_ship_cost, ws_net_profit
    AGGREGATE: COUNT(DISTINCT ws_warehouse_sk) as warehouse_count
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit, warehouse_count
    EXPECTED_ROWS: ≤1,185 (one per order)
    CONSUMERS: multi_warehouse_orders
  multi_warehouse_orders:
    FROM: warehouse_counts
    WHERE: warehouse_count >= 2
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit
    EXPECTED_ROWS: same as final output (orders with multiple warehouses)
    CONSUMERS: final_agg
  final_agg:
    FROM: multi_warehouse_orders mwo
    WHERE: NOT EXISTS (SELECT 1 FROM web_returns wr1 WHERE wr1.wr_order_number = mwo.ws_order_number AND wr1.wr_reason_sk IN (8,18,20,23,41))
    AGGREGATE: COUNT(DISTINCT ws_order_number), SUM(ws_ext_ship_cost), SUM(ws_net_profit)
    OUTPUT: order count, total shipping cost, total net profit
    EXPECTED_ROWS: 1
    CONSUMERS: final

NODE_CONTRACTS:
base_sales:
    FROM: web_sales ws1, date_dim, customer_address, web_site
    WHERE: d_date BETWEEN '1999-10-01' AND CAST('1999-10-01' AS DATE) + INTERVAL '60 DAY'
           AND ws1.ws_ship_date_sk = d_date_sk
           AND ws1.ws_ship_addr_sk = ca_address_sk
           AND ca_state IN ('MO','MT','OK','SC','TX','WI')
           AND ws1.ws_web_site_sk = web_site_sk
           AND web_gmt_offset >= -5
           AND ws1.ws_list_price BETWEEN 253 AND 282
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit, ws_warehouse_sk
    EXPECTED_ROWS: ~1,185
    CONSUMERS: warehouse_counts
  warehouse_counts:
    FROM: base_sales
    GROUP BY: ws_order_number, ws_ext_ship_cost, ws_net_profit
    AGGREGATE: COUNT(DISTINCT ws_warehouse_sk) as warehouse_count
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit, warehouse_count
    EXPECTED_ROWS: ≤1,185 (one per order)
    CONSUMERS: multi_warehouse_orders
  multi_warehouse_orders:
    FROM: warehouse_counts
    WHERE: warehouse_count >= 2
    OUTPUT: ws_order_number, ws_ext_ship_cost, ws_net_profit
    EXPECTED_ROWS: same as final output (orders with multiple warehouses)
    CONSUMERS: final_agg
  final_agg:
    FROM: multi_warehouse_orders mwo
    WHERE: NOT EXISTS (SELECT 1 FROM web_returns wr1 WHERE wr1.wr_order_number = mwo.ws_order_number AND wr1.wr_reason_sk IN (8,18,20,23,41))
    AGGREGATE: COUNT(DISTINCT ws_order_number), SUM(ws_ext_ship_cost), SUM(ws_net_profit)
    OUTPUT: order count, total shipping cost, total net profit
    EXPECTED_ROWS: 1
    CONSUMERS: final

## Hazard Flags (avoid these specific risks)

- Changing EXISTS to COUNT(DISTINCT ws_warehouse_sk) >= 2 must be semantically equivalent
- Must ensure web_returns anti-join preserves NOT EXISTS semantics exactly

## Regression Warnings (observed failures on similar queries)

1. EXISTS to IN/NOT IN (observed 0.50x regression):
   CAUSE: Converting EXISTS to IN with large result set forces materialization and loses semi-join early termination
   RULE: Preserve EXISTS structure; if decorrelating, use JOIN with DISTINCT or GROUP BY instead of IN
2. CTE blocking parallelism (observed 0.8x regression):
   CAUSE: MATERIALIZED CTEs execute single-threaded, preventing parallel scan of large fact tables
   RULE: Avoid wrapping large fact table scans in CTEs; keep them in main query for parallel execution

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Must output exactly three columns: order count, total shipping cost, total net profit
- CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream (ws_order_number, ws_ext_ship_cost, ws_net_profit, join keys)
- LITERAL_PRESERVATION: Must preserve exact date '1999-10-01', interval '60 day', state list, price range 253-282, reason_sk values 8,18,20,23,41
- SEMANTIC_EQUIVALENCE: Must return same rows and aggregation values
- COMMA_JOIN_WEAKNESS: Query uses implicit comma joins (lines 6-9), causing poor cardinality estimation
- CROSS_CTE_PREDICATE_BLINDNESS: web_sales scanned twice (ws1 for main, ws2 for EXISTS) - opportunity for shared materialization

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

pg_self_join_decomposition: Apply the core idea - compute warehouse counts via GROUP BY instead of correlated EXISTS; materialize base_sales once; ignore the multi-channel aspect (we have single channel).

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

## Original SQL

```sql
select 
   count(distinct ws_order_number) as "order count"
  ,sum(ws_ext_ship_cost) as "total shipping cost"
  ,sum(ws_net_profit) as "total net profit"
from
   web_sales ws1
  ,date_dim
  ,customer_address
  ,web_site
where
    d_date between '1999-10-01' and
           cast('1999-10-01' as date) + interval '60 day'
and ws1.ws_ship_date_sk = d_date_sk
and ws1.ws_ship_addr_sk = ca_address_sk
and ca_state in ('MO','MT','OK'
            ,'SC' ,'TX' ,'WI')
and ws1.ws_web_site_sk = web_site_sk
and web_gmt_offset >= -5
and ws1.ws_list_price between 253 and 282
and exists (select *
            from web_sales ws2
            where ws1.ws_order_number = ws2.ws_order_number
              and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)
and not exists(select *
               from web_returns wr1
               where ws1.ws_order_number = wr1.wr_order_number
               and wr1.wr_reason_sk in (8, 18, 20, 23, 41)
               )
order by count(distinct ws_order_number)
limit 100;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~154K
    ├── SCAN (web_sales AS ws1 (join), date_dim (join), customer_address (join), web_site (join))
    ├── JOIN (ws1.ws_ship_date_sk = d_date_sk)
    ├── JOIN (ws1.ws_ship_addr_sk = ca_address_sk)
    ├── JOIN (+1 more)
    ├── FILTER (d_date BETWEEN '1999-10-01' AND CAST('1999-10-01' AS DATE) + INTERVAL '60 DAY')
    ├── FILTER (ca_state IN ('MO', 'MT', 'OK', 'SC', 'TX', 'WI'))
    ├── FILTER (+4 more)
    ├── SORT (COUNT(DISTINCT ws_order_number) ASC)
    └── OUTPUT (order count, total shipping cost, total net profit)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: