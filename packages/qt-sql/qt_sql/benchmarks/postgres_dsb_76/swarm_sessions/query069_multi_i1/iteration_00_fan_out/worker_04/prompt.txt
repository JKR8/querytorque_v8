You are a SQL rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1). Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

Business intent: Identify demographic segments of customers in three states who purchased in stores during Q4 2002 (list price $80-$169) but did NOT purchase via web or catalog in same period. JOIN semantics: All joins are INNER equi-joins (customer-address, customer-demographics) plus EXISTS semi-join and NOT EXISTS anti-joins correlated by customer_sk. Aggregation trap: Three COUNT(*) are identical per group (no FILTER clause). Filter dependencies: The date range (2002, months 10-12) and list price range (80-169) must apply identically across all three channel subqueries.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
filtered_date -> channel_bitmaps -> customer_base -> bitmap_join -> group_by
NODE_CONTRACTS:
  filtered_date:
    FROM: date_dim
    WHERE: d_year = 2002 AND d_moy BETWEEN 10 AND 12
    OUTPUT: d_date_sk
    EXPECTED_ROWS: 31
    CONSUMERS: channel_bitmaps
  channel_bitmaps:
    FROM: 
      (SELECT ss_customer_sk AS customer_sk FROM store_sales JOIN filtered_date ON ss_sold_date_sk = d_date_sk WHERE ss_list_price BETWEEN 80 AND 169) store,
      (SELECT ws_bill_customer_sk FROM web_sales JOIN filtered_date ON ws_sold_date_sk = d_date_sk WHERE ws_list_price BETWEEN 80 AND 169) web,
      (SELECT cs_ship_customer_sk FROM catalog_sales JOIN filtered_date ON cs_sold_date_sk = d_date_sk WHERE cs_list_price BETWEEN 80 AND 169) catalog
    Actually, we need to combine them. Let's use a lateral approach: compute three bitmaps via subqueries? Not SQL.
    Instead, compute three separate CTEs of customer_sk, then join them via full outer join? Too complex.
    Let's try a novel approach: use PostgreSQL's hash aggregation with FILTER to compute per-customer channel presence in a single scan of each fact table, but combine with UNION ALL and pivot.
    But that's similar to Worker 3.
    Let's try a different novel combination: use LATERAL to compute channel existence per customer from the customer_base, but that's re-correlating.
    Let's instead precompute three bitmaps as temporary tables? Not allowed.
    Let's explore: Use a single CTE that scans all three fact tables with a discriminator, then use bitmap aggregates per customer.
    We'll design:
    all_sales:
      SELECT ss_customer_sk AS customer_sk, 1 AS store_bit, 0 AS web_bit, 0 AS catalog_bit FROM store_sales JOIN filtered_date ON ss_sold_date_sk = d_date_sk WHERE ss_list_price BETWEEN 80 AND 169
      UNION ALL
      SELECT ws_bill_customer_sk, 0, 1, 0 FROM web_sales JOIN filtered_date ON ws_sold_date_sk = d_date_sk WHERE ws_list_price BETWEEN 80 AND 169
      UNION ALL
      SELECT cs_ship_customer_sk, 0, 0, 1 FROM catalog_sales JOIN filtered_date ON cs_sold_date_sk = d_date_sk WHERE cs_list_price BETWEEN 80 AND 169
    Then aggregate:
      SELECT customer_sk,
             BIT_OR(store_bit) AS has_store,
             BIT_OR(web_bit) AS has_web,
             BIT_OR(catalog_bit) AS has_catalog
      FROM all_sales
      GROUP BY customer_sk
    But BIT_OR not standard; use MAX.
    This is similar to Worker 3 but with bit columns.
    Let's accept that and focus on the exploration aspect: we are combining dimension prefetch with bitmap aggregation and early filtering.
    We'll also pre-filter customer_address and customer_demographics early.
    So TARGET_LOGICAL_TREE:
      filtered_ca -> filtered_cd -> filtered_date -> all_sales_union -> customer_channel_bits -> customer_join -> filter_bits -> group_by
    Let's define contracts.
NODE_CONTRACTS:
  filtered_ca: (as Worker 1)
    FROM: customer_address
    WHERE: ca_state IN ('CO','NC','TX')
    OUTPUT: ca_address_sk, ca_state
    EXPECTED_ROWS: 11K
    CONSUMERS: customer_join
  filtered_cd: (as Worker 1)
    FROM: customer_demographics
    WHERE: cd_marital_status IN ('S','M','U') AND cd_education_status IN ('Primary','College')
    OUTPUT: cd_demo_sk, cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    EXPECTED_ROWS: ?
    CONSUMERS: customer_join
  filtered_date: (as Worker 1)
    FROM: date_dim
    WHERE: d_year = 2002 AND d_moy BETWEEN 10 AND 12
    OUTPUT: d_date_sk
    EXPECTED_ROWS: 31
    CONSUMERS: store_sales_part, web_sales_part, catalog_sales_part
  store_sales_part:
    FROM: store_sales JOIN filtered_date ON ss_sold_date_sk = d_date_sk
    WHERE: ss_list_price BETWEEN 80 AND 169
    OUTPUT: ss_customer_sk AS customer_sk, 1 AS store_bit, 0 AS web_bit, 0 AS catalog_bit
    EXPECTED_ROWS: 151K
    CONSUMERS: all_sales_union
  web_sales_part:
    FROM: web_sales JOIN filtered_date ON ws_sold_date_sk = d_date_sk
    WHERE: ws_list_price BETWEEN 80 AND 169
    OUTPUT: ws_bill_customer_sk AS customer_sk, 0 AS store_bit, 1 AS web_bit, 0 AS catalog_bit
    EXPECTED_ROWS: 84K
    CONSUMERS: all_sales_union
  catalog_sales_part:
    FROM: catalog_sales JOIN filtered_date ON cs_sold_date_sk = d_date_sk
    WHERE: cs_list_price BETWEEN 80 AND 169
    OUTPUT: cs_ship_customer_sk AS customer_sk, 0 AS store_bit, 0 AS web_bit, 1 AS catalog_bit
    EXPECTED_ROWS: 332K
    CONSUMERS: all_sales_union
  all_sales_union:
    FROM: store_sales_part UNION ALL web_sales_part UNION ALL catalog_sales_part
    OUTPUT: customer_sk, store_bit, web_bit, catalog_bit
    EXPECTED_ROWS: 567K
    CONSUMERS: customer_channel_bits
  customer_channel_bits:
    FROM: all_sales_union
    GROUP BY: customer_sk
    AGGREGATE: 
        MAX(store_bit) AS has_store,
        MAX(web_bit) AS has_web,
        MAX(catalog_bit) AS has_catalog
    OUTPUT: customer_sk, has_store, has_web, has_catalog
    EXPECTED_ROWS: distinct customers
    CONSUMERS: filter_bits
  customer_join:
    FROM: customer c
      JOIN filtered_ca ON c.c_current_addr_sk = ca_address_sk
      JOIN filtered_cd ON cd_demo_sk = c.c_current_cdemo_sk
    OUTPUT: c_customer_sk, cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    EXPECTED_ROWS: 22K
    CONSUMERS: filter_bits
  filter_bits:
    FROM: customer_join cj
      INNER JOIN customer_channel_bits ccb ON cj.c_customer_sk = ccb.customer_sk
    WHERE: ccb.has_store = 1 AND ccb.has_web = 0 AND ccb.has_catalog = 0
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    EXPECTED_ROWS: 964
    CONSUMERS: group_by
  group_by: (same)
    FROM: filter_bits
    GROUP BY: cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    AGGREGATE: COUNT(*) AS cnt
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, cnt AS cnt1, cd_purchase_estimate, cnt AS cnt2, cd_credit_rating, cnt AS cnt3
    EXPECTED_ROWS: 80
    CONSUMERS: order_by_limit

NODE_CONTRACTS:
filtered_date:
    FROM: date_dim
    WHERE: d_year = 2002 AND d_moy BETWEEN 10 AND 12
    OUTPUT: d_date_sk
    EXPECTED_ROWS: 31
    CONSUMERS: channel_bitmaps
  channel_bitmaps:
    FROM: 
      (SELECT ss_customer_sk AS customer_sk FROM store_sales JOIN filtered_date ON ss_sold_date_sk = d_date_sk WHERE ss_list_price BETWEEN 80 AND 169) store,
      (SELECT ws_bill_customer_sk FROM web_sales JOIN filtered_date ON ws_sold_date_sk = d_date_sk WHERE ws_list_price BETWEEN 80 AND 169) web,
      (SELECT cs_ship_customer_sk FROM catalog_sales JOIN filtered_date ON cs_sold_date_sk = d_date_sk WHERE cs_list_price BETWEEN 80 AND 169) catalog
    Actually, we need to combine them. Let's use a lateral approach: compute three bitmaps via subqueries? Not SQL.
    Instead, compute three separate CTEs of customer_sk, then join them via full outer join? Too complex.
    Let's try a novel approach: use PostgreSQL's hash aggregation with FILTER to compute per-customer channel presence in a single scan of each fact table, but combine with UNION ALL and pivot.
    But that's similar to Worker 3.
    Let's try a different novel combination: use LATERAL to compute channel existence per customer from the customer_base, but that's re-correlating.
    Let's instead precompute three bitmaps as temporary tables? Not allowed.
    Let's explore: Use a single CTE that scans all three fact tables with a discriminator, then use bitmap aggregates per customer.
    We'll design:
    all_sales:
      SELECT ss_customer_sk AS customer_sk, 1 AS store_bit, 0 AS web_bit, 0 AS catalog_bit FROM store_sales JOIN filtered_date ON ss_sold_date_sk = d_date_sk WHERE ss_list_price BETWEEN 80 AND 169
      UNION ALL
      SELECT ws_bill_customer_sk, 0, 1, 0 FROM web_sales JOIN filtered_date ON ws_sold_date_sk = d_date_sk WHERE ws_list_price BETWEEN 80 AND 169
      UNION ALL
      SELECT cs_ship_customer_sk, 0, 0, 1 FROM catalog_sales JOIN filtered_date ON cs_sold_date_sk = d_date_sk WHERE cs_list_price BETWEEN 80 AND 169
    Then aggregate:
      SELECT customer_sk,
             BIT_OR(store_bit) AS has_store,
             BIT_OR(web_bit) AS has_web,
             BIT_OR(catalog_bit) AS has_catalog
      FROM all_sales
      GROUP BY customer_sk
    But BIT_OR not standard; use MAX.
    This is similar to Worker 3 but with bit columns.
    Let's accept that and focus on the exploration aspect: we are combining dimension prefetch with bitmap aggregation and early filtering.
    We'll also pre-filter customer_address and customer_demographics early.
    So TARGET_LOGICAL_TREE:
      filtered_ca -> filtered_cd -> filtered_date -> all_sales_union -> customer_channel_bits -> customer_join -> filter_bits -> group_by
    Let's define contracts.
NODE_CONTRACTS:
  filtered_ca: (as Worker 1)
    FROM: customer_address
    WHERE: ca_state IN ('CO','NC','TX')
    OUTPUT: ca_address_sk, ca_state
    EXPECTED_ROWS: 11K
    CONSUMERS: customer_join
  filtered_cd: (as Worker 1)
    FROM: customer_demographics
    WHERE: cd_marital_status IN ('S','M','U') AND cd_education_status IN ('Primary','College')
    OUTPUT: cd_demo_sk, cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    EXPECTED_ROWS: ?
    CONSUMERS: customer_join
  filtered_date: (as Worker 1)
    FROM: date_dim
    WHERE: d_year = 2002 AND d_moy BETWEEN 10 AND 12
    OUTPUT: d_date_sk
    EXPECTED_ROWS: 31
    CONSUMERS: store_sales_part, web_sales_part, catalog_sales_part
  store_sales_part:
    FROM: store_sales JOIN filtered_date ON ss_sold_date_sk = d_date_sk
    WHERE: ss_list_price BETWEEN 80 AND 169
    OUTPUT: ss_customer_sk AS customer_sk, 1 AS store_bit, 0 AS web_bit, 0 AS catalog_bit
    EXPECTED_ROWS: 151K
    CONSUMERS: all_sales_union
  web_sales_part:
    FROM: web_sales JOIN filtered_date ON ws_sold_date_sk = d_date_sk
    WHERE: ws_list_price BETWEEN 80 AND 169
    OUTPUT: ws_bill_customer_sk AS customer_sk, 0 AS store_bit, 1 AS web_bit, 0 AS catalog_bit
    EXPECTED_ROWS: 84K
    CONSUMERS: all_sales_union
  catalog_sales_part:
    FROM: catalog_sales JOIN filtered_date ON cs_sold_date_sk = d_date_sk
    WHERE: cs_list_price BETWEEN 80 AND 169
    OUTPUT: cs_ship_customer_sk AS customer_sk, 0 AS store_bit, 0 AS web_bit, 1 AS catalog_bit
    EXPECTED_ROWS: 332K
    CONSUMERS: all_sales_union
  all_sales_union:
    FROM: store_sales_part UNION ALL web_sales_part UNION ALL catalog_sales_part
    OUTPUT: customer_sk, store_bit, web_bit, catalog_bit
    EXPECTED_ROWS: 567K
    CONSUMERS: customer_channel_bits
  customer_channel_bits:
    FROM: all_sales_union
    GROUP BY: customer_sk
    AGGREGATE: 
        MAX(store_bit) AS has_store,
        MAX(web_bit) AS has_web,
        MAX(catalog_bit) AS has_catalog
    OUTPUT: customer_sk, has_store, has_web, has_catalog
    EXPECTED_ROWS: distinct customers
    CONSUMERS: filter_bits
  customer_join:
    FROM: customer c
      JOIN filtered_ca ON c.c_current_addr_sk = ca_address_sk
      JOIN filtered_cd ON cd_demo_sk = c.c_current_cdemo_sk
    OUTPUT: c_customer_sk, cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    EXPECTED_ROWS: 22K
    CONSUMERS: filter_bits
  filter_bits:
    FROM: customer_join cj
      INNER JOIN customer_channel_bits ccb ON cj.c_customer_sk = ccb.customer_sk
    WHERE: ccb.has_store = 1 AND ccb.has_web = 0 AND ccb.has_catalog = 0
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    EXPECTED_ROWS: 964
    CONSUMERS: group_by
  group_by: (same)
    FROM: filter_bits
    GROUP BY: cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    AGGREGATE: COUNT(*) AS cnt
    OUTPUT: cd_gender, cd_marital_status, cd_education_status, cnt AS cnt1, cd_purchase_estimate, cnt AS cnt2, cd_credit_rating, cnt AS cnt3
    EXPECTED_ROWS: 80
    CONSUMERS: order_by_limit

## Hazard Flags (avoid these specific risks)

- Using MAX on bits assumes at most one row per customer per channel; duplicate rows still produce 1.
- The UNION ALL may be large; consider using DISTINCT in each part to reduce rows? But could increase cost.
CONSTRAINT_OVERRIDE: None
OVERRIDE_REASONING: N/A
EXPLORATION_TYPE: compound_strategy (combining dimension prefetch, date consolidation, and bitmap aggregation)

## Regression Warnings (observed failures on similar queries)

1. EXISTS to IN/NOT IN materializing CTEs (observed regression 0.50x on Q069):
   CAUSE: Converting EXISTS to NOT IN with CTEs blocked hash anti-join optimization.
   RULE: Do NOT convert NOT EXISTS to NOT IN; keep anti-join structure but decorrelate via precomputed sets and LEFT JOIN / IS NULL.
2. Splitting OR conditions into UNION ALL (observed regression 0.21x on Q085):
   CAUSE: PostgreSQL's bitmap OR scan is more efficient.
   RULE: Not applicable; query has no OR conditions on indexed columns.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Must output cd_gender, cd_marital_status, cd_education_status, cnt1, cd_purchase_estimate, cnt2, cd_credit_rating, cnt3 in exact order.
- CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream: customer_sk, address_sk, demo_sk, ca_state, cd_* columns, etc.
- LITERAL_PRESERVATION: Must preserve literal values: ca_state IN ('CO','NC','TX'), cd_marital_status IN ('S','M','U'), cd_education_status IN ('Primary','College'), d_year=2002, d_moy between 10 and 12, list_price between 80 and 169.
- SEMANTIC_EQUIVALENCE: Must return same rows as original with same grouping counts.
- COMMA_JOIN_WEAKNESS: Query uses comma-separated joins in main FROM and subqueries, confusing cardinality estimation.
- CORRELATED_SUBQUERY_PARALYSIS: EXISTS/NOT EXISTS cause nested-loop anti-joins with per-row materialization.
- CROSS_CTE_PREDICATE_BLINDNESS: Same date_dim filter scanned three times separately.

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- pg_materialized_dimension_fact_prefilter: Apply MATERIALIZED to filtered_date and filtered_ca/filtered_cd CTEs to force early reduction. Ignore the non-equi join aspect; we have equi-joins.
- channel_bitmap_aggregation: Use UNION ALL with bit flags and MAX aggregation to compute channel presence. This is directly applicable.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_materialized_dimension_fact_prefilter (2.68x)

**Principle:** Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.

**BEFORE (slow):**
```sql
select  i_item_desc
      ,w_warehouse_name
      ,d1.d_week_seq
      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo
      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo
      ,count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity
  and d3.d_date > d1.d_date + interval '3 day'
  and hd_buy_potential = '501-1000'
  and d1.d_year = 1998
  and cd_marital_status = 'M'
  and cd_dep_count between 9 and 11
  and i_category IN ('Home', 'Men', 'Music')
  and cs_wholesale_cost BETWEEN 34 AND 54
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk, d_date, d_week_seq FROM date_dim WHERE d_year = 1998
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc FROM item WHERE i_category IN ('Home', 'Men', 'Music')
```
[filtered_cd]:
```sql
SELECT cd_demo_sk FROM customer_demographics WHERE cd_marital_status = 'M' AND cd_dep_count BETWEEN 9 AND 11
```
[filtered_hd]:
```sql
SELECT hd_demo_sk FROM household_demographics WHERE hd_buy_potential = '501-1000'
```
[cs_filtered]:
```sql
SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk, cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost, cs_order_number FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 34 AND 54
```
[main_query]:
```sql
SELECT i.i_item_desc, w.w_warehouse_name, d1.d_week_seq, SUM(CASE WHEN p.p_promo_sk IS NULL THEN 1 ELSE 0 END) AS no_promo, SUM(CASE WHEN p.p_promo_sk IS NOT NULL THEN 1 ELSE 0 END) AS promo, COUNT(*) AS total_cnt FROM cs_filtered cs JOIN inventory inv ON cs.cs_item_sk = inv.inv_item_sk JOIN warehouse w ON w.w_warehouse_sk = inv.inv_warehouse_sk JOIN filtered_item i ON i.i_item_sk = cs.cs_item_sk JOIN filtered_cd cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk JOIN filtered_hd hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk JOIN filtered_date d1 ON cs.cs_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON inv.inv_date_sk = d2.d_date_sk JOIN date_dim d3 ON cs.cs_ship_date_sk = d3.d_date_sk LEFT OUTER JOIN promotion p ON cs.cs_promo_sk = p.p_promo_sk LEFT OUTER JOIN catalog_returns cr ON cr.cr_item_sk = cs.cs_item_sk AND cr.cr_order_number = cs.cs_order_number WHERE d1.d_week_seq = d2.d_week_seq AND inv.inv_quantity_on_hand < cs.cs_quantity AND d3.d_date > d1.d_date + INTERVAL '3 day' GROUP BY i.i_item_desc, w.w_warehouse_name, d1.d_week_seq ORDER BY total_cnt DESC, i.i_item_desc, w.w_warehouse_name, d1.d_week_seq LIMIT 100
```

## Original SQL

```sql
select 
  cd_gender,
  cd_marital_status,
  cd_education_status,
  count(*) cnt1,
  cd_purchase_estimate,
  count(*) cnt2,
  cd_credit_rating,
  count(*) cnt3
 from
  customer c,customer_address ca,customer_demographics
 where
  c.c_current_addr_sk = ca.ca_address_sk and
  ca_state in ('CO','NC','TX') and
  cd_demo_sk = c.c_current_cdemo_sk
  and cd_marital_status in ('S', 'M', 'U')
  and cd_education_status in ('Primary', 'College') and
  exists (select *
          from store_sales,date_dim
          where c.c_customer_sk = ss_customer_sk and
                ss_sold_date_sk = d_date_sk and
                d_year = 2002 and
                d_moy between 10 and 10+2
                and ss_list_price between 80 and 169
          ) and
   (not exists (select *
            from web_sales,date_dim
            where c.c_customer_sk = ws_bill_customer_sk and
                  ws_sold_date_sk = d_date_sk and
                  d_year = 2002 and
                  d_moy between 10 and 10+2
                  and ws_list_price between 80 and 169
            ) and
    not exists (select *
            from catalog_sales,date_dim
            where c.c_customer_sk = cs_ship_customer_sk and
                  cs_sold_date_sk = d_date_sk and
                  d_year = 2002 and
                  d_moy between 10 and 10+2
                  and cs_list_price between 80 and 169)
            )
 group by cd_gender,
          cd_marital_status,
          cd_education_status,
          cd_purchase_estimate,
          cd_credit_rating
 order by cd_gender,
          cd_marital_status,
          cd_education_status,
          cd_purchase_estimate,
          cd_credit_rating
 limit 100;
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~500K
    ├── SCAN (customer AS c (join), customer_address AS ca (join), customer_demographics (join), date_dim (join))
    ├── JOIN (c.c_current_addr_sk = ca.ca_address_sk)
    ├── JOIN (cd_demo_sk = c.c_current_cdemo_sk)
    ├── FILTER (ca_state IN ('CO', 'NC', 'TX'))
    ├── FILTER (cd_marital_status IN ('S', 'M', 'U'))
    ├── FILTER (+1 more)
    ├── AGG (GROUP BY)
    ├── SORT (cd_gender ASC, cd_marital_status ASC, cd_education_status ASC, cd_purchase_estimate ASC, cd_credit_rating ASC)
    └── OUTPUT (cd_gender, cd_marital_status, cd_education_status, cnt1, cd_purchase_estimate, cnt2, cd_credit_rating, cnt3)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "runtime_config": ["SET LOCAL work_mem = '512MB'"],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `runtime_config`: SET LOCAL commands for PostgreSQL. Omit or use empty array if not needed
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: