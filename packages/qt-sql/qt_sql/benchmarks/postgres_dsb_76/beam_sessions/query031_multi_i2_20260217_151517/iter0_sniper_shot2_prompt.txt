## Role

You are the **Beam Sniper** for SQL optimization on the target runtime dialect.

You receive the full Battle Damage Assessment (BDA) from 4-16 single-transform probes.
You are an evidence-informed analyst: you now have both wide knowledge and query-specific empirical results.

Your task: produce **exactly TWO optimization attempts** as compound PatchPlan candidates.

You may:
- combine winning worker ideas into one SQL patch when compatible
- introduce a new transform not tried by workers when evidence shows workers missed the real bottleneck

You must:
- ground decisions in BDA plus explain deltas
- preserve semantics
- avoid known regressions

---

## Prompt Map (cache friendly)

### Phase A - Cached Context (static)
A1. Dialect reminders plus regression registry
A2. Combination hazards (duplication, multiplicity, CTE fences)
A3. Evidence-first decision procedure (mechanical)
A4. Sniper output contract (strict JSON array)

### Phase B - Query-Specific Input (dynamic; after cache boundary)
B1. Importance star rating (1-3)
B2. Original SQL plus original plan
B3. IR structure plus anchor hashes
B4. BDA table (ALL probes: status, speedup, explain delta, failure reasons)
B5. Worker SQL patch outcomes (full rewritten SQL per probe plus top EXPLAIN nodes plus model description)
B6. Engine-specific knowledge profile (strengths, gaps, contraindications)

---

## Dialect reminders

Use runtime-injected **Engine-Specific Knowledge** as authoritative.
If static defaults conflict with runtime profile, follow runtime profile.

---

## Regression Registry (hard bans)

Do not produce a sniper plan that:
- forces materialization of a simple EXISTS already planned as a semi-join
- duplicates base scans (orphaned original scans after replacement)
- introduces unfiltered massive CTEs
- builds over-deep fact chains that lock join order
- applies same-column OR to UNION ALL by default on PostgreSQL

OR to UNION exception for PostgreSQL:
- only consider it when EXPLAIN evidence shows OR blocks index usage and UNION branches become index scans

---

## Combination hazards (what to watch)

- **Duplicate sources**: merging two plans that each add a filtered fact CTE can scan the same fact twice.
- **Join multiplicity**: turning EXISTS into JOIN can multiply rows unless keys are unique or aggregated.
- **CTE fences**: materialized CTEs can block pushdown and join reorder.
- **Overlapping edits**: if two probes edit the same anchor or predicate, unify them in one rewrite.

---

## Evidence-first decision procedure (mechanical)

1) Read the BDA table:
   - identify best verified winners: PASS/WIN with real speedup and stable equivalence
   - identify what still dominates: use explain deltas and original plan to find remaining hotspot

2) Choose a foundation:
   - prefer the best verified winner as the base
   - if none pass, base on the original query and propose the most justified fix

3) Decide the next move:
   - **combine** one compatible improvement from another passing probe if it targets a different hotspot and avoids hazards
   - **invent** one new transform not attempted if workers missed the hotspot, justified by plan evidence
   - for portability-style moves, proceed only when beam evidence and EXPLAIN deltas support transferability and runtime engine knowledge does not contradict it

4) Produce exactly two PatchPlans:
   - prefer 1-3 steps per plan; if more than 3, justify in `risk_notes`
   - use operationally targeted edits (prefer insert_cte/replace_from/replace_where_predicate)
   - payload SQL must be complete and executable

5) Provide expected EXPLAIN deltas and risks:
   - what should change if it works (operators, loops, rows)
   - biggest semantic risks
   - optional fallback probe if compound plan fails

---

## Sniper Output Contract (MUST follow)

Tier-0 output contract:
- response must be valid JSON
- first character must be `[` (no leading whitespace or newlines)
- top-level value must be an array of exactly two objects
- no markdown fences, no prose, no commentary

Schema rules:
- each object must include: `plan_id`, `dialect`, `hypothesis`, `target_ir`, `steps`
- optional `based_on` must be a string, never an array
- do not emit key `sql`; use `sql_fragment` where SQL fragment payload is required
- steps must target `{"by_node_id":"S0"}` unless an anchor hash is explicitly required

Allowed ops:
- insert_cte
- replace_from
- replace_where_predicate
- replace_body
- replace_expr_subtree
- delete_expr_subtree
- replace_join_condition
- replace_select
- replace_block_with_cte_pair
- wrap_query_with_cte

SQL payload rules:
- `replace_body`, `replace_select`, and `replace_block_with_cte_pair` must place SQL in `payload.sql_fragment`
- payload SQL must be complete and executable

Output JSON shape:
[
  {
    "plan_id": "snipe_p1",
    "dialect": "<target_dialect>",
    "confidence": 0.81,
    "based_on": "p03,p11",
    "strategy": "Foundation plus one compatible add-on",
    "hypothesis": "Plan evidence and expected win mechanism",
    "target_ir": "Short structural description of final query shape",
    "steps": [
      {
        "step_id": "s1",
        "op": "replace_body",
        "target": {"by_node_id": "S0"},
        "payload": {"sql_fragment": "SELECT c_customer_sk FROM customer"}
      }
    ]
  },
  {
    "plan_id": "snipe_p2",
    "dialect": "<target_dialect>",
    "confidence": 0.73,
    "based_on": "p07",
    "strategy": "Alternative independent pathway",
    "hypothesis": "Plan evidence for second pathway",
    "target_ir": "Alternative structural description",
    "steps": [
      {
        "step_id": "s1",
        "op": "insert_cte",
        "target": {"by_node_id": "S0"},
        "payload": {
          "cte_name": "filtered_sales",
          "cte_query_sql": "SELECT ss_customer_sk FROM store_sales WHERE ss_quantity > 0"
        }
      }
    ]
  }
]

---

## Cache Boundary
Everything below is query-specific input.

## Query ID
query031_multi_i2

## Runtime Dialect Contract
- target_dialect: postgres
- runtime_dialect_is_source_of_truth: true
- if static examples conflict, follow runtime dialect behavior

## Importance
- importance_stars: 3
- importance_label: ***

## Original SQL
```sql
with ss as
 (select ca_county,d_qoy, d_year,sum(ss_ext_sales_price) as store_sales
 from store_sales,date_dim,customer_address, item
 where ss_sold_date_sk = d_date_sk
  and ss_addr_sk=ca_address_sk
  and ss_item_sk = i_item_sk
  and i_color IN ('dark', 'puff')
  and i_manager_id BETWEEN 15 and 34
  and ss_list_price between 244 and 258
  and ca_state in ('KS','OH')
 group by ca_county,d_qoy, d_year),
 ws as
 (select ca_county,d_qoy, d_year,sum(ws_ext_sales_price) as web_sales
 from web_sales,date_dim,customer_address, item
 where ws_sold_date_sk = d_date_sk
  and ws_bill_addr_sk=ca_address_sk
  and ws_item_sk = i_item_sk
  and i_color IN ('dark', 'puff')
  and i_manager_id BETWEEN 15 and 34
  and ws_list_price between 244 and 258
  and ca_state in ('KS','OH')
group by ca_county,d_qoy, d_year)
 select
        ss1.ca_county
       ,ss1.d_year
       ,ws2.web_sales/ws1.web_sales web_q1_q2_increase
       ,ss2.store_sales/ss1.store_sales store_q1_q2_increase
       ,ws3.web_sales/ws2.web_sales web_q2_q3_increase
       ,ss3.store_sales/ss2.store_sales store_q2_q3_increase
 from
        ss ss1
       ,ss ss2
       ,ss ss3
       ,ws ws1
       ,ws ws2
       ,ws ws3
 where
    ss1.d_qoy = 1
    and ss1.d_year = 1999
    and ss1.ca_county = ss2.ca_county
    and ss2.d_qoy = 2
    and ss2.d_year = 1999
 and ss2.ca_county = ss3.ca_county
    and ss3.d_qoy = 3
    and ss3.d_year = 1999
    and ss1.ca_county = ws1.ca_county
    and ws1.d_qoy = 1
    and ws1.d_year = 1999
    and ws1.ca_county = ws2.ca_county
    and ws2.d_qoy = 2
    and ws2.d_year = 1999
    and ws1.ca_county = ws3.ca_county
    and ws3.d_qoy = 3
    and ws3.d_year =1999
    and case when ws1.web_sales > 0 then ws2.web_sales/ws1.web_sales else null end
       > case when ss1.store_sales > 0 then ss2.store_sales/ss1.store_sales else null end
    and case when ws2.web_sales > 0 then ws3.web_sales/ws2.web_sales else null end
       > case when ss2.store_sales > 0 then ss3.store_sales/ss2.store_sales else null end
 order by ss1.d_year;
```

## Original Plan
```
Nested Loop  (rows=0, time=253411.57)
  Aggregate  (rows=98, time=253411.489)
    Gather Merge  (rows=98, time=253411.447)
      Aggregate  (rows=98, time=253410.448)
        Sort  (rows=100, time=253410.377)
          Nested Loop  (rows=100, time=253410.22)
            Nested Loop  (rows=102, time=253403.082)
              Hash Join  (rows=1674, time=252594.201)
                Seq Scan on store_sales  (rows=415237, time=249309.424)
                Hash  (rows=815, time=3066.801)
                  Bitmap Heap Scan on item  (rows=815, time=3066.053)
                    Bitmap Index Scan  (rows=4248, time=3.337)
              Index Scan on customer_address  (rows=0, time=0.481)
            Index Scan on date_dim  (rows=1, time=0.067)
  Aggregate  (rows=0, time=0.0)
    Gather Merge  (rows=0, time=0.0)
      Aggregate  (rows=0, time=0.0)
        Sort  (rows=0, time=0.0)
          Nested Loop  (rows=0, time=0.0)
            Nested Loop  (rows=0, time=0.0)
              Hash Join  (rows=0, time=0.0)
                Seq Scan on web_sales  (rows=0, time=0.0)
                Hash  (rows=0, time=0.0)
                  Bitmap Heap Scan on item (item_1)  (rows=0, time=0.0)
                    Bitmap Index Scan  (rows=0, time=0.0)
              Index Scan on customer_address (customer_address_1)  (rows=0, time=0.0)
            Index Scan on date_dim (date_dim_1)  (rows=0, time=0.0)
  Nested Loop  (rows=0, time=253411.274)
    Nested Loop  (rows=0, time=253411.273)
      Nested Loop  (rows=0, time=253411.272)
        Nested Loop  (rows=0, time=253411.27)
          CTE Scan (ss1)  (rows=8, time=253411.144)
          CTE Scan (ss2)  (rows=4, time=0.015)
        CTE Scan (ss3)  (rows=0, time=0.0)
      CTE Scan (ws1)  (rows=0, time=0.0)
    CTE Scan (ws2)  (rows=0, time=0.0)
  CTE Scan (ws3)  (rows=0, time=0.0)
```

## IR Structure + Anchor Hashes
```
S0 [SELECT]
  CTE: ss  (via CTE_Q_S0_ss)
    FROM: store_sales, date_dim, customer_address, item
    WHERE [f55d9959a55a5f8c]: ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color...
    GROUP BY: ca_county, d_qoy, d_year
  CTE: ws  (via CTE_Q_S0_ws)
    FROM: web_sales, date_dim, customer_address, item
    WHERE [3c884b73784f3399]: ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_...
    GROUP BY: ca_county, d_qoy, d_year
  MAIN QUERY (via Q_S0)
    FROM: ss ss1, ss ss2, ss ss3, ws ws1, ws ws2, ws ws3
    WHERE [e3d013ee216110fe]: ss1.d_qoy = 1 AND ss1.d_year = 1999 AND ss1.ca_county = ss2.ca_county AND ss2.d_qoy = 2 AND ss2.d...
    ORDER BY: ss1.d_year

Patch operations (core+advanced): insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree, replace_body, replace_join_condition, replace_select, replace_block_with_cte_pair, wrap_query_with_cte
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Schema / Index / Stats Context
- source: postgres
- referenced_tables: 5

| Table | Rows(est) | PK | Indexes |
|-------|-----------|----|---------|
| customer_address | 250000 | ca_address_sk | customer_address_pkey |
| date_dim | 73049 | d_date_sk | date_dim_pkey, _dta_index_date_dim_6_661577395__k7_k4_k9_k1, _dta_index_date_dim_6_661577395__k7_k9_k1, _dta_index_date_dim_6_661577395__k1_k7_k9, _dta_index_date_dim_6_661577395__k7_k11_k1, _dta_index_date_dim_6_661577395__k9_k7_k1 |
| item | 102000 | i_item_sk | item_pkey, _dta_index_item_6_853578079__k1_2_5, _dta_index_item_6_853578079__k13_k11_k1, _dta_index_item_6_853578079__k18, _dta_index_item_6_853578079__k2_k1 |
| store_sales | 28806628 | ss_item_sk, ss_ticket_number | store_sales_pkey, _dta_index_store_sales_6_1333579789__k1_k23_k14_k6_k8_k5_k7_3_4, _dta_index_store_sales_6_1333579789__k1_k5_k8_k3_11_13_14_20, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_9_16_23, _dta_index_store_sales_6_1333579789__k4_1_3_10_11_14, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_23 |
| web_sales | 7197533 | ws_item_sk, ws_order_number | web_sales_pkey, _dta_index_web_sales_6_1269579561__k3_k18_k12_k14_16_29_34, _dta_index_web_sales_6_1269579561__k1_k4_k5_18, _dta_index_web_sales_6_1269579561__k1_8_24, _dta_index_web_sales_6_1269579561__k18_16, _dta_index_web_sales_6_1269579561__k1_k5 |

## Engine-Specific Knowledge
## Dialect Profile (POSTGRES)

**Combined Intelligence Baseline**: Combined intelligence baseline from 53 validated DSB queries at SF5-SF10, plus regression registry outcomes. PostgreSQL has bitmap index scans, JIT compilation, and aggressive CTE materialization. Techniques that work on DuckDB often regress here.

### Optimizer Strengths (don't fight these)
- `BITMAP_OR_SCAN`: Avoid splitting OR conditions into UNION ALL by default. Only consider OR→UNION when EXPLAIN shows OR blocks index usage and UNION branches become index scans. 0.21x and 0.26x reg…
- `SEMI_JOIN_EXISTS`: NEVER convert EXISTS to IN/NOT IN or materialized CTEs. 0.50x, 0.75x observed. Note: NOT EXISTS anti-join decorrelation can still be valid when replacing large correlated anti patterns.
- `INNER_JOIN_REORDERING`: Don't restructure INNER JOIN orders. Focus on LEFT JOIN blocking or comma-join confusion.
- `INDEX_ONLY_SCAN`: Small dimension lookups (<10K rows) may not need CTEs.

### Known Gaps (exploit these)
- `COMMA_JOIN_WEAKNESS` [HIGH] detect: FROM t1, t2, t3 WHERE t1.key = t2.key (comma joins, no explicit JOIN). Poor row estimates in EXPLAIN. | action: Convert comma-joins to explicit JOIN...ON syntax. Best when combined with date_cte_isolate.
- `CORRELATED_SUBQUERY_PARALYSIS` [HIGH] detect: Nested loop in EXPLAIN, inner re-executes aggregate per outer row. SQL: WHERE col > (SELECT AGG FROM ... WHERE outer.key = inner.key). Hash… | action: Convert correlated WHERE to explicit CTE with GROUP BY + JOIN.
- `NON_EQUI_JOIN_INPUT_BLINDNESS` [HIGH] detect: Expensive non-equi join (BETWEEN, <, >) with large inputs on both sides. Neither side filtered. | action: Reduce fact table input size via filtered CTE before the non-equi join.
- `CTE_MATERIALIZATION_FENCE` [MEDIUM] detect: Large CTE + small post-filter. Multi-referenced CTE that blocks predicate pushdown. | action: Materialize STRATEGICALLY: only when CTE is expensive and reused. Avoid fencing single-use cases.
- `CROSS_CTE_PREDICATE_BLINDNESS` [MEDIUM] detect: Sequential scan on dimension table without index condition. Late filter after large scan/join. | action: Pre-filter into CTE definition. But be more cautious than on DuckDB.

## Dispatcher Hypothesis
The execution plan shows a dominant bottleneck in sequential scans on store_sales (249s) and web_sales due to late predicate application and comma-join inefficiencies. Key issues include full fact table scans before dimension filters, comma-join cardinality misestimation, and redundant CTE rescans. Transform families A (Early Filtering) and F (Join Topology) should reduce scan amplification through dimension isolation and explicit joins.

## Dispatcher Reasoning Trace
- Cost spine: Seq Scan on store_sales (249s) → Hash Join (253s) → Nested Loop (253s)
- Amplification: 415k rows scanned in store_sales before dimension filters
- Late selectivity: Dimension filters (item/customer_address) applied after fact table scan
- Comma-join weakness: Poor cardinality estimates in FROM clause joins

## Equivalence Tier
- exact

## Additional Intelligence
### AST Feature Detection

- **date_cte_explicit_join**: 100% match (AGG_SUM, BETWEEN, CASE_EXPR, DATE_DIM) (gap: COMMA_JOIN_WEAKNESS)  [SUPPORT: native_or_universal]
- **multi_dimension_prefetch**: 100% match (AGG_SUM, CASE_EXPR, DATE_DIM, GROUP_BY) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [SUPPORT: portability_candidate; engines=duckdb]
- **prefetch_fact_join**: 100% match (AGG_SUM, DATE_DIM, GROUP_BY, STAR_JOIN) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: MAX_2_CHAINS] [SUPPORT: portability_candidate; engines=duckdb]
- **dimension_cte_isolate**: 100% match (DATE_DIM, GROUP_BY, MULTI_TABLE_5+) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: CROSS_JOIN_3_DIMS, UNFILTERED_CTE] [SUPPORT: portability_candidate; engines=duckdb]
- **sf_sk_pushdown_multi_fact**: 100% match (DATE_DIM, MULTI_TABLE_5+) (gap: PREDICATE_TRANSITIVITY_FAILURE) [SUPPORT: portability_candidate; engines=snowflake]


## Probe Summary
12 probes fired, 0 passed validation, 0 showed speedup.

## BDA Table (all probes)

| Probe | Transform | Family | Status | Speedup | Top EXPLAIN Nodes | Model Description | SQL Patch | Error/Notes |
|-------|-----------|--------|--------|---------|-------------------|-------------------|-----------|-------------|
| p11 | inner_join_conversion | F | FAIL | - | - | Convert comma joins to explicit INNER JOIN syntax in ws CTE | - | Failed to parse/apply PatchPlan |
| p01 | date_cte_explicit_join | F | FAIL | - | - | Replace comma joins in ss CTE with explicit INNER JOINs. Isolate date_dim filter via CTE materialization. | - | Failed to parse/apply PatchPlan |
| p06 | aggregate_pushdown | C | FAIL | - | - | Pre-aggregate store_sales by ss_item_sk/ss_addr_sk before joining dimensions | p06 | Tier-1: COLUMN REF MISMATCH: Original columns missing from rewrite — ['ss_sold_date_sk']. The rewrite references different table columns. |
| p10 | early_filter | A | ERROR | - | - | Push d_year=1999 filter into ss/ws CTE definitions (not just main query) | p10 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p02 | dimension_cte_isolate | A | FAIL | - | - | Pre-filter item/customer_address into CTEs before ss CTE join. Preserve i_manager_id and ca_state filters. | - | Failed to parse/apply PatchPlan |
| p05 | pg_self_join_decomposition | E | ERROR | - | - | Materialize ss CTE once and derive all quarters via CASE aggregation to avoid self-joins | p05 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p07 | shared_dimension_multi_channel | A | FAIL | - | - | Create shared CTE for filtered item/customer_address reused in ss and ws CTEs | - | Failed to parse/apply PatchPlan |
| p09 | materialized_dimension_fact_prefilter | F | FAIL | - | - | Materialize pre-join filtered fact tables (store_sales/web_sales) before main query ratios | - | Failed to parse/apply PatchPlan |
| p08 | prefetch_fact_join | A | ERROR | - | - | Staged reduction: Filter customer_address → join with store_sales → join with item | p08 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p03 | multi_dimension_prefetch | A | FAIL | - | - | Create CTEs for all filtered dimensions (item, customer_address, date_dim) before joining with store_sales | - | Failed to parse/apply PatchPlan |
| p12 | single_pass_aggregation | C | FAIL | - | - | Consolidate ss1/ss2/ss3 into single CTE using CASE for quarterly aggregates | p12 | Tier-1: COLUMN REF MISMATCH: Original columns missing from rewrite — ['store_sales', 'web_sales']. The rewrite references different table columns. |
| p04 | sf_sk_pushdown_multi_fact | A | FAIL | - | - | Add d_date_sk BETWEEN filter to store_sales using date_dim CTE surrogate keys | - | Failed to parse/apply PatchPlan |

## Worker SQL Patches

### p06: aggregate_pushdown (FAIL, n/a)
```sql
WITH ss AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address, item WHERE dd.d_date_sk = sa.ss_item_sk AND ca.ca_address_sk = sa.ss_addr_sk AND i.i_item_sk = sa.ss_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ws AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ss_agg AS (SELECT ss_item_sk, ss_addr_sk, SUM(ss_ext_sales_price) AS sum_ss_ext_sales_price FROM store_sales WHERE ss_list_price BETWEEN 244 AND 258 GROUP BY ss_item_sk, ss_addr_sk) SELECT ss1.ca_county, ss1.d_year, ws2.web_sales / ws1.web_sales AS web_q1_q2_increase, ss2.store_sales / ss1.store_sales AS store_q1_q2_increase, ws3.web_sales / ws2.web_sales AS web_q2_q3_increase, ss3.store_sales / ss2.store_sales AS store_q2_q3_increase FROM ss_agg AS sa JOIN date_dim AS dd ON sa.ss_item_sk = dd.d_date_sk JOIN customer_address AS ca ON sa.ss_addr_sk = ca.ca_address_sk JOIN item AS i ON sa.ss_item_sk = i.i_item_sk WHERE ss1.d_qoy = 1 AND ss1.d_year = 1999 AND ss1.ca_county = ss2.ca_county AND ss2.d_qoy = 2 AND ss2.d_year = 1999 AND ss2.ca_county = ss3.ca_county AND ss3.d_qoy = 3 AND ss3.d_year = 1999 AND ss1.ca_county = ws1.ca_county AND ws1.d_qoy = 1 AND ws1.d_year = 1999 AND ws1.ca_county = ws2.ca_county AND ws2.d_qoy = 2 AND ws2.d_year = 1999 AND ws1.ca_county = ws3.ca_county AND ws3.d_qoy = 3 AND ws3.d_year = 1999 AND CASE WHEN ws1.web_sales > 0 THEN ws2.web_sales / ws1.web_sales ELSE NULL END > CASE WHEN ss1.store_sales > 0 THEN ss2.store_sales / ss1.store_sales ELSE NULL END AND CASE WHEN ws2.web_sales > 0 THEN ws3.web_sales / ws2.web_sales ELSE NULL END > CASE WHEN ss2.store_sales > 0 THEN ss3.store_sales / ss2.store_sales ELSE NULL END ORDER BY ss1.d_year;
```

### p10: early_filter (ERROR, n/a)
```sql
WITH ss AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') AND d_year = 1999 GROUP BY ca_county, d_qoy, d_year), ws AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') AND d_year = 1999 GROUP BY ca_county, d_qoy, d_year) SELECT ss1.ca_county, ss1.d_year, ws2.web_sales / ws1.web_sales AS web_q1_q2_increase, ss2.store_sales / ss1.store_sales AS store_q1_q2_increase, ws3.web_sales / ws2.web_sales AS web_q2_q3_increase, ss3.store_sales / ss2.store_sales AS store_q2_q3_increase FROM ss AS ss1, ss AS ss2, ss AS ss3, ws AS ws1, ws AS ws2, ws AS ws3 WHERE ss1.d_qoy = 1 AND ss1.d_year = 1999 AND ss1.ca_county = ss2.ca_county AND ss2.d_qoy = 2 AND ss2.d_year = 1999 AND ss2.ca_county = ss3.ca_county AND ss3.d_qoy = 3 AND ss3.d_year = 1999 AND ss1.ca_county = ws1.ca_county AND ws1.d_qoy = 1 AND ws1.d_year = 1999 AND ws1.ca_county = ws2.ca_county AND ws2.d_qoy = 2 AND ws2.d_year = 1999 AND ws1.ca_county = ws3.ca_county AND ws3.d_qoy = 3 AND ws3.d_year = 1999 AND CASE WHEN ws1.web_sales > 0 THEN ws2.web_sales / ws1.web_sales ELSE NULL END > CASE WHEN ss1.store_sales > 0 THEN ss2.store_sales / ss1.store_sales ELSE NULL END AND CASE WHEN ws2.web_sales > 0 THEN ws3.web_sales / ws2.web_sales ELSE NULL END > CASE WHEN ss2.store_sales > 0 THEN ss3.store_sales / ss2.store_sales ELSE NULL END ORDER BY ss1.d_year;
```

### p05: pg_self_join_decomposition (ERROR, n/a)
```sql
WITH ss AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ws AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ss_quarterly AS (SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ss_ext_sales_price ELSE 0 END) AS q1_sales, SUM(CASE WHEN d_qoy = 2 THEN ss_ext_sales_price ELSE 0 END) AS q2_sales, SUM(CASE WHEN d_qoy = 3 THEN ss_ext_sales_price ELSE 0 END) AS q3_sales FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_year) SELECT ss1.ca_county, ss1.d_year, ws2.web_sales / ws1.web_sales AS web_q1_q2_increase, ss2.store_sales / ss1.store_sales AS store_q1_q2_increase, ws3.web_sales / ws2.web_sales AS web_q2_q3_increase, ss3.store_sales / ss2.store_sales AS store_q2_q3_increase FROM ss_quarterly AS ssq, ws AS ws1, ws AS ws2, ws AS ws3 WHERE ssq.d_year = 1999 AND ws1.d_qoy = 1 AND ws1.d_year = 1999 AND ws1.ca_county = ws2.ca_county AND ws2.d_qoy = 2 AND ws2.d_year = 1999 AND ws1.ca_county = ws3.ca_county AND ws3.d_qoy = 3 AND ws3.d_year = 1999 AND CASE WHEN ws1.web_sales > 0 THEN ws2.web_sales / ws1.web_sales ELSE NULL END > CASE WHEN ssq.q1_sales > 0 THEN ssq.q2_sales / ssq.q1_sales ELSE NULL END AND CASE WHEN ws2.web_sales > 0 THEN ws3.web_sales / ws2.web_sales ELSE NULL END > CASE WHEN ssq.q2_sales > 0 THEN ssq.q3_sales / ssq.q2_sales ELSE NULL END ORDER BY ss1.d_year;
```

### p08: prefetch_fact_join (ERROR, n/a)
```sql
WITH ss AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ws AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), filtered_ca AS (SELECT ca_address_sk FROM customer_address WHERE ca_state IN ('KS', 'OH')) SELECT ss1.ca_county, ss1.d_year, ws2.web_sales / ws1.web_sales AS web_q1_q2_increase, ss2.store_sales / ss1.store_sales AS store_q1_q2_increase, ws3.web_sales / ws2.web_sales AS web_q2_q3_increase, ss3.store_sales / ss2.store_sales AS store_q2_q3_increase FROM store_sales AS ss JOIN date_dim AS dd ON ss.ss_sold_date_sk = dd.d_date_sk JOIN filtered_ca AS fca ON ss.ss_addr_sk = fca.ca_address_sk JOIN item AS i ON ss.ss_item_sk = i.i_item_sk WHERE ss1.d_qoy = 1 AND ss1.d_year = 1999 AND ss1.ca_county = ss2.ca_county AND ss2.d_qoy = 2 AND ss2.d_year = 1999 AND ss2.ca_county = ss3.ca_county AND ss3.d_qoy = 3 AND ss3.d_year = 1999 AND ss1.ca_county = ws1.ca_county AND ws1.d_qoy = 1 AND ws1.d_year = 1999 AND ws1.ca_county = ws2.ca_county AND ws2.d_qoy = 2 AND ws2.d_year = 1999 AND ws1.ca_county = ws3.ca_county AND ws3.d_qoy = 3 AND ws3.d_year = 1999 AND CASE WHEN ws1.web_sales > 0 THEN ws2.web_sales / ws1.web_sales ELSE NULL END > CASE WHEN ss1.store_sales > 0 THEN ss2.store_sales / ss1.store_sales ELSE NULL END AND CASE WHEN ws2.web_sales > 0 THEN ws3.web_sales / ws2.web_sales ELSE NULL END > CASE WHEN ss2.store_sales > 0 THEN ss3.store_sales / ss2.store_sales ELSE NULL END ORDER BY ss1.d_year;
```

### p12: single_pass_aggregation (FAIL, n/a)
```sql
WITH ss AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ws AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ss_all_quarters AS (SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ss_ext_sales_price ELSE 0 END) AS store_sales_q1, SUM(CASE WHEN d_qoy = 2 THEN ss_ext_sales_price ELSE 0 END) AS store_sales_q2, SUM(CASE WHEN d_qoy = 3 THEN ss_ext_sales_price ELSE 0 END) AS store_sales_q3 FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') AND d_qoy IN (1, 2, 3) GROUP BY ca_county, d_year), ws_all_quarters AS (SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ws_ext_sales_price ELSE 0 END) AS web_sales_q1, SUM(CASE WHEN d_qoy = 2 THEN ws_ext_sales_price ELSE 0 END) AS web_sales_q2, SUM(CASE WHEN d_qoy = 3 THEN ws_ext_sales_price ELSE 0 END) AS web_sales_q3 FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') AND d_qoy IN (1, 2, 3) GROUP BY ca_county, d_year) SELECT ss.ca_county, ss.d_year, CASE WHEN ws.web_sales_q1 > 0 THEN CAST(ws.web_sales_q2 AS DOUBLE PRECISION) / ws.web_sales_q1 ELSE NULL END AS web_q1_q2_increase, CASE WHEN ss.store_sales_q1 > 0 THEN CAST(ss.store_sales_q2 AS DOUBLE PRECISION) / ss.store_sales_q1 ELSE NULL END AS store_q1_q2_increase, CASE WHEN ws.web_sales_q2 > 0 THEN CAST(ws.web_sales_q3 AS DOUBLE PRECISION) / ws.web_sales_q2 ELSE NULL END AS web_q2_q3_increase, CASE WHEN ss.store_sales_q2 > 0 THEN CAST(ss.store_sales_q3 AS DOUBLE PRECISION) / ss.store_sales_q2 ELSE NULL END AS store_q2_q3_increase FROM ss_all_quarters AS ss, ws_all_quarters AS ws WHERE ss.ca_county = ws.ca_county AND ss.d_year = 1999 AND ws.d_year = 1999 AND CASE WHEN ws.web_sales_q1 > 0 THEN CAST(ws.web_sales_q2 AS DOUBLE PRECISION) / ws.web_sales_q1 ELSE NULL END > CASE WHEN ss.store_sales_q1 > 0 THEN CAST(ss.store_sales_q2 AS DOUBLE PRECISION) / ss.store_sales_q1 ELSE NULL END AND CASE WHEN ws.web_sales_q2 > 0 THEN CAST(ws.web_sales_q3 AS DOUBLE PRECISION) / ws.web_sales_q2 ELSE NULL END > CASE WHEN ss.store_sales_q2 > 0 THEN CAST(ss.store_sales_q3 AS DOUBLE PRECISION) / ss.store_sales_q2 ELSE NULL END ORDER BY ss1.d_year;
```


## Shot 1 Results

| # | Family | Transform | Speedup | Status | Error |
|---|--------|-----------|---------|--------|-------|
| snipe_p1 | ? | unknown | - | ERROR | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| snipe_p2 | ? | unknown | - | ERROR | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |

### snipe_p1 Error:
Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context'

### snipe_p2 Error:
Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context'

## Shot 2 — Design 2 More Patch Plans

Build on shot 1 results:
1. Your first plan should refine or extend the best winner (or fix its remaining bottleneck)
2. Your second should try a different approach not yet attempted

If all shot 1 plans failed, diagnose why and try fundamentally different strategies.

Output exactly **2 patch plans** as a JSON array.

Tier-0 Output Contract (hard fail):
- response must be valid JSON
- first character must be `[` (no leading whitespace/newlines)
- top-level value must be an array of exactly 2 objects
- no markdown fences, prose, or commentary
- never emit key `sql`; use `sql_fragment` for SQL fragments

Required per plan:
- `plan_id`, `family`, `transform`, `hypothesis`, `target_ir`, `dialect`, `steps`
- optional: `based_on` as a string (use comma-separated IDs for multiple sources; never an array)
- `steps[]` item: `step_id`, `op`, `target`, optional `payload`
- `target.by_node_id` MUST be `"S0"` (use `by_anchor_hash` only when needed)

Allowed `op` values:
- `insert_cte`
- `replace_from`
- `replace_where_predicate`
- `replace_body`
- `replace_expr_subtree`
- `delete_expr_subtree`
- `replace_join_condition`
- `replace_select`
- `replace_block_with_cte_pair`
- `wrap_query_with_cte`

Semantic guards (MUST preserve):
- all WHERE/HAVING/ON logic
- all literals exactly
- columns/aliases/ORDER BY/LIMIT
- row count and semantics
- no orphaned CTEs or duplicated source scans after replacement

Rules:
- output exactly 2 plans
- each plan must use a different strategy (`family` + `transform`)
- payload SQL fragments must be complete/executable (no ellipsis)
- `replace_body`, `replace_select`, and `replace_block_with_cte_pair` must put SQL in `payload.sql_fragment`
- cite EXPLAIN evidence in `hypothesis`

Output ONLY JSON array.