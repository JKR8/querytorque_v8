## Role

You are a **Beam Worker** for SQL optimization on the target runtime dialect.

You must apply **ONE specific transform** to the query and output a **PatchPlan JSON** that updates the query’s IR.

One worker = one probe = one transform.

---

## Prompt Map (cache friendly)

### Phase A — Cached Instructions (static)
A1. Patch operations
A2. Semantic guards (must preserve)
A3. Anchor-hash rules (robustness requirements)
A4. Verification checklist
A5. PatchPlan output schema

### Phase B — Probe-Specific Input (dynamic; after cache boundary)
B1. Shared dispatcher hypothesis (short)
B2. Probe assignment (transform + target + node contract + gates_checked)
B3. Original SQL
B4. Optional execution plan snippet
B5. IR node map (S0 + anchor hashes)
B6. Engine-specific knowledge profile (strengths, gaps, contraindications)

---

## Patch Operations (core + advanced)

| Op | Description | Payload |
|----|-------------|---------|
| insert_cte | Add a new CTE to the WITH clause | cte_name, cte_query_sql |
| replace_from | Replace the FROM clause | from_sql |
| replace_where_predicate | Replace the full WHERE boolean expression | expr_sql |
| replace_body | Replace entire query body | sql_fragment |
| replace_expr_subtree | Replace a specific expression/predicate | expr_sql (+ by_anchor_hash) |
| delete_expr_subtree | Remove a specific expression/predicate | (target only, no payload) |
| replace_join_condition | Replace a specific JOIN condition expression | expr_sql (+ by_anchor_hash) |
| replace_select | Replace SELECT projection list | sql_fragment |
| replace_block_with_cte_pair | Replace block using CTE-integrated SQL fragment | sql_fragment |
| wrap_query_with_cte | Add wrapper CTE to statement | cte_name, cte_query_sql |

All step targets MUST use: `{"by_node_id": "S0"}`.
Use `by_anchor_hash` only when replacing/deleting a specific predicate/expression.

Target examples:
- Statement-level edit:
  `{"by_node_id": "S0"}`
- Predicate-subtree edit:
  `{"by_node_id": "S0", "by_anchor_hash": "ab12cd34ef56ab78"}`

---

## Semantic Guards (MUST preserve)

- Preserve ALL WHERE/HAVING/ON conditions exactly, unless the assigned transform explicitly replaces a correlated subquery with an equivalent join/anti-join.
- Do NOT change any literal values (numbers, strings, dates, arithmetic forms).
- Preserve SELECT columns, aliases, ORDER BY, LIMIT exactly.
- Do NOT add new filters.
- Do NOT leave orphaned CTEs or duplicate base scans after replacement.
- Follow dispatcher `node_contract` precisely.

If `node_contract` or `gates_checked` is missing or ambiguous:
- Output a minimal safe failure PatchPlan with `steps: []` and hypothesis explaining what is missing.

If a RETRY section is present with a gate-failure object:
- Fix the specific gate issue first (do not redesign the transform intent).
- Preserve all semantic guards while correcting only what failed.

---

## Anchor-hash rules (robustness)

- `by_anchor_hash` values are produced by an external parser and are **whitespace/formatting independent**.
- You MUST copy anchor hashes verbatim; never invent hashes.
- If you cannot confidently identify the exact target anchor, do not use `replace_expr_subtree`.
  Prefer `replace_where_predicate`, or output a safe no-op plan.

---

## Verification Checklist (self-check)

- [ ] Patch steps produce a valid executable query
- [ ] No missing tables/aliases
- [ ] No duplicated source scans (orphan risk)
- [ ] EXISTS / NOT EXISTS semantics preserved if rewritten
- [ ] No same-column OR to UNION split unless EXPLAIN evidence shows OR blocks index usage and UNION branches become index scans
- [ ] New CTEs are selective (meaningful WHERE) unless transform requires otherwise

---

## PatchPlan Output Schema (MUST follow)

Tier-0 output contract:
- first character must be `{` (no leading whitespace/newlines)
- top-level value must be one JSON object
- no markdown fences, no prose, no commentary

Output JSON shape:
{
  "probe_id": "p01",
  "transform_id": "decorrelate_not_exists_to_cte",
  "family": "B",
  "dialect": "<target_dialect>",
  "hypothesis": "1 sentence: why this transform should reduce the plan hotspot",
  "reasoning_trace": [
    "Target correlated NOT EXISTS on customer_demographics",
    "Replace per-row re-execution with one anti-join-ready CTE"
  ],
  "target_ir": "Short structural description of the post-patch query shape",
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {"by_node_id": "S0"},
      "payload": {
        "cte_name": "filtered_customers",
        "cte_query_sql": "SELECT c_customer_sk FROM customer WHERE c_current_addr_sk IS NOT NULL"
      }
    }
  ]
}

Worked example (fully valid output):
{
  "probe_id": "p07",
  "transform_id": "decorrelate_exists_to_semijoin_cte",
  "family": "B",
  "dialect": "postgres",
  "hypothesis": "Replace correlated EXISTS with a precomputed distinct keyset so the planner uses one set-based join instead of per-row subquery execution.",
  "reasoning_trace": [
    "The EXISTS subquery depends only on customer key.",
    "A DISTINCT keyset CTE preserves EXISTS semantics and removes repeated inner work."
  ],
  "target_ir": "CTE keyset plus semijoin in FROM; original non-EXISTS filters preserved in WHERE.",
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {"by_node_id": "S0"},
      "payload": {
        "cte_name": "store_buyers",
        "cte_query_sql": "SELECT DISTINCT ss_customer_sk AS customer_sk FROM store_sales WHERE ss_list_price BETWEEN 80 AND 169"
      }
    },
    {
      "step_id": "s2",
      "op": "replace_from",
      "target": {"by_node_id": "S0"},
      "payload": {
        "from_sql": "customer c JOIN store_buyers sb ON sb.customer_sk = c.c_customer_sk"
      }
    },
    {
      "step_id": "s3",
      "op": "replace_where_predicate",
      "target": {"by_node_id": "S0"},
      "payload": {
        "expr_sql": "c.c_current_addr_sk IS NOT NULL"
      }
    }
  ]
}

Rules:
- Steps must be minimal and sufficient.
- Every SQL fragment in payload MUST be complete and executable (no ellipsis).
- Prefer `insert_cte` + `replace_from` + `replace_where_predicate` over `replace_body` unless necessary.
- Never emit `payload.sql`; use `payload.sql_fragment` for replace_body/replace_select/replace_block_with_cte_pair.

---

## Cache Boundary
Everything below is probe-specific input.

## Shared Dispatcher Hypothesis
The execution plan shows a dominant bottleneck in sequential scans on store_sales (249s) and web_sales due to late predicate application and comma-join inefficiencies. Key issues include full fact table scans before dimension filters, comma-join cardinality misestimation, and redundant CTE rescans. Transform families A (Early Filtering) and F (Join Topology) should reduce scan amplification through dimension isolation and explicit joins.
## Runtime Dialect Contract
- target_dialect: postgres
- runtime_dialect_is_source_of_truth: true
- if static examples conflict, follow runtime dialect behavior
## Probe Assignment
- transform_id: single_pass_aggregation
- family: C
- target: Consolidate ss1/ss2/ss3 into single CTE using CASE for quarterly aggregates
- phase: ?
- exploration: no
- dialect: postgres
- recommended_patch_ops: `replace_body`, `replace_select`
- expected_explain_delta: Eliminated self-joins; single CTE scan with conditional aggregates
- equivalence_tier: exact

### Gates Checked
no_group_by:PASS

### Node Contract

```json
{
  "from_must_include": [
    "ss"
  ],
  "where_must_preserve": [
    "d_qoy IN (1,2,3)"
  ],
  "output_must_preserve": [
    "ca_county",
    "d_year",
    "store_q1_q2_increase",
    "store_q2_q3_increase"
  ]
}
```

### Original SQL

```sql
with ss as
 (select ca_county,d_qoy, d_year,sum(ss_ext_sales_price) as store_sales
 from store_sales,date_dim,customer_address, item
 where ss_sold_date_sk = d_date_sk
  and ss_addr_sk=ca_address_sk
  and ss_item_sk = i_item_sk
  and i_color IN ('dark', 'puff')
  and i_manager_id BETWEEN 15 and 34
  and ss_list_price between 244 and 258
  and ca_state in ('KS','OH')
 group by ca_county,d_qoy, d_year),
 ws as
 (select ca_county,d_qoy, d_year,sum(ws_ext_sales_price) as web_sales
 from web_sales,date_dim,customer_address, item
 where ws_sold_date_sk = d_date_sk
  and ws_bill_addr_sk=ca_address_sk
  and ws_item_sk = i_item_sk
  and i_color IN ('dark', 'puff')
  and i_manager_id BETWEEN 15 and 34
  and ws_list_price between 244 and 258
  and ca_state in ('KS','OH')
group by ca_county,d_qoy, d_year)
 select
        ss1.ca_county
       ,ss1.d_year
       ,ws2.web_sales/ws1.web_sales web_q1_q2_increase
       ,ss2.store_sales/ss1.store_sales store_q1_q2_increase
       ,ws3.web_sales/ws2.web_sales web_q2_q3_increase
       ,ss3.store_sales/ss2.store_sales store_q2_q3_increase
 from
        ss ss1
       ,ss ss2
       ,ss ss3
       ,ws ws1
       ,ws ws2
       ,ws ws3
 where
    ss1.d_qoy = 1
    and ss1.d_year = 1999
    and ss1.ca_county = ss2.ca_county
    and ss2.d_qoy = 2
    and ss2.d_year = 1999
 and ss2.ca_county = ss3.ca_county
    and ss3.d_qoy = 3
    and ss3.d_year = 1999
    and ss1.ca_county = ws1.ca_county
    and ws1.d_qoy = 1
    and ws1.d_year = 1999
    and ws1.ca_county = ws2.ca_county
    and ws2.d_qoy = 2
    and ws2.d_year = 1999
    and ws1.ca_county = ws3.ca_county
    and ws3.d_qoy = 3
    and ws3.d_year =1999
    and case when ws1.web_sales > 0 then ws2.web_sales/ws1.web_sales else null end
       > case when ss1.store_sales > 0 then ss2.store_sales/ss1.store_sales else null end
    and case when ws2.web_sales > 0 then ws3.web_sales/ws2.web_sales else null end
       > case when ss2.store_sales > 0 then ss3.store_sales/ss2.store_sales else null end
 order by ss1.d_year;
```

### Current IR Node Map

```
S0 [SELECT]
  CTE: ss  (via CTE_Q_S0_ss)
    FROM: store_sales, date_dim, customer_address, item
    WHERE [f55d9959a55a5f8c]: ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color...
    GROUP BY: ca_county, d_qoy, d_year
  CTE: ws  (via CTE_Q_S0_ws)
    FROM: web_sales, date_dim, customer_address, item
    WHERE [3c884b73784f3399]: ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_...
    GROUP BY: ca_county, d_qoy, d_year
  MAIN QUERY (via Q_S0)
    FROM: ss ss1, ss ss2, ss ss3, ws ws1, ws ws2, ws ws3
    WHERE [e3d013ee216110fe]: ss1.d_qoy = 1 AND ss1.d_year = 1999 AND ss1.ca_county = ss2.ca_county AND ss2.d_qoy = 2 AND ss2.d...
    ORDER BY: ss1.d_year

Patch operations (core+advanced): insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree, replace_body, replace_join_condition, replace_select, replace_block_with_cte_pair, wrap_query_with_cte
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

### Dispatcher Reasoning Trace
- Cost spine: Seq Scan on store_sales (249s) → Hash Join (253s) → Nested Loop (253s)
- Amplification: 415k rows scanned in store_sales before dimension filters
- Late selectivity: Dimension filters (item/customer_address) applied after fact table scan
- Comma-join weakness: Poor cardinality estimates in FROM clause joins

### Schema / Index / Stats Context
- source: postgres
- referenced_tables: 5

| Table | Rows(est) | PK | Indexes |
|-------|-----------|----|---------|
| customer_address | 250000 | ca_address_sk | customer_address_pkey |
| date_dim | 73049 | d_date_sk | date_dim_pkey, _dta_index_date_dim_6_661577395__k7_k4_k9_k1, _dta_index_date_dim_6_661577395__k7_k9_k1, _dta_index_date_dim_6_661577395__k1_k7_k9, _dta_index_date_dim_6_661577395__k7_k11_k1, _dta_index_date_dim_6_661577395__k9_k7_k1 |
| item | 102000 | i_item_sk | item_pkey, _dta_index_item_6_853578079__k1_2_5, _dta_index_item_6_853578079__k13_k11_k1, _dta_index_item_6_853578079__k18, _dta_index_item_6_853578079__k2_k1 |
| store_sales | 28806628 | ss_item_sk, ss_ticket_number | store_sales_pkey, _dta_index_store_sales_6_1333579789__k1_k23_k14_k6_k8_k5_k7_3_4, _dta_index_store_sales_6_1333579789__k1_k5_k8_k3_11_13_14_20, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_9_16_23, _dta_index_store_sales_6_1333579789__k4_1_3_10_11_14, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_23 |
| web_sales | 7197533 | ws_item_sk, ws_order_number | web_sales_pkey, _dta_index_web_sales_6_1269579561__k3_k18_k12_k14_16_29_34, _dta_index_web_sales_6_1269579561__k1_k4_k5_18, _dta_index_web_sales_6_1269579561__k1_8_24, _dta_index_web_sales_6_1269579561__k18_16, _dta_index_web_sales_6_1269579561__k1_k5 |

### Engine-Specific Knowledge
## Dialect Profile (POSTGRES)

**Combined Intelligence Baseline**: Combined intelligence baseline from 53 validated DSB queries at SF5-SF10, plus regression registry outcomes. PostgreSQL has bitmap index scans, JIT compilation, and aggressive CTE materialization. Techniques that work on DuckDB often regress here.

### Optimizer Strengths (don't fight these)
- `BITMAP_OR_SCAN`: Avoid splitting OR conditions into UNION ALL by default. Only consider OR→UNION when EXPLAIN shows OR blocks index usage and UNION branches become index scans. 0.21x and 0.26x reg…
- `SEMI_JOIN_EXISTS`: NEVER convert EXISTS to IN/NOT IN or materialized CTEs. 0.50x, 0.75x observed. Note: NOT EXISTS anti-join decorrelation can still be valid when replacing large correlated anti patterns.
- `INNER_JOIN_REORDERING`: Don't restructure INNER JOIN orders. Focus on LEFT JOIN blocking or comma-join confusion.
- `INDEX_ONLY_SCAN`: Small dimension lookups (<10K rows) may not need CTEs.

### Known Gaps (exploit these)
- `COMMA_JOIN_WEAKNESS` [HIGH] detect: FROM t1, t2, t3 WHERE t1.key = t2.key (comma joins, no explicit JOIN). Poor row estimates in EXPLAIN. | action: Convert comma-joins to explicit JOIN...ON syntax. Best when combined with date_cte_isolate.
- `CORRELATED_SUBQUERY_PARALYSIS` [HIGH] detect: Nested loop in EXPLAIN, inner re-executes aggregate per outer row. SQL: WHERE col > (SELECT AGG FROM ... WHERE outer.key = inner.key). Hash… | action: Convert correlated WHERE to explicit CTE with GROUP BY + JOIN.
- `NON_EQUI_JOIN_INPUT_BLINDNESS` [HIGH] detect: Expensive non-equi join (BETWEEN, <, >) with large inputs on both sides. Neither side filtered. | action: Reduce fact table input size via filtered CTE before the non-equi join.
- `CTE_MATERIALIZATION_FENCE` [MEDIUM] detect: Large CTE + small post-filter. Multi-referenced CTE that blocks predicate pushdown. | action: Materialize STRATEGICALLY: only when CTE is expensive and reused. Avoid fencing single-use cases.
- `CROSS_CTE_PREDICATE_BLINDNESS` [MEDIUM] detect: Sequential scan on dimension table without index condition. Late filter after large scan/join. | action: Pre-filter into CTE definition. But be more cautious than on DuckDB.

### Transform Recipe
- `transform_id`: `single_pass_aggregation`
- `family`: `C`
- `principle`: Single-Pass Aggregation: consolidate multiple scalar subqueries on the same table into one CTE using CASE expressions inside aggregate functions. Reduces N separate table scans to 1 pass.
- `expected_features`: `AGG_AVG`, `AGG_COUNT`, `SCALAR_SUB_2+`, `TABLE_REPEAT_3+`
- `confirm_with_explain`: true

### Gold Pattern Reference
- `plan_id`: `gold_postgres_pg_self_join_pivot`
- `step_ops`: insert_cte -> insert_cte -> insert_cte -> insert_cte -> replace_from -> replace_where_predicate
- `ctes`: `ss_all_quarters`, `ss_pivot`, `ws_all_quarters`, `ws_pivot`
- Reuse pattern shape, not literal table/column names.


## RETRY — Gate failure feedback (attempt 2/2)
Your previous patch failed validation. Return a corrected PatchPlan JSON only.
First character must be `{` and output must contain no markdown/prose.

### Failure Object
```json
{
  "probe_id": "p12",
  "transform_id": "single_pass_aggregation",
  "gate": "tier1_structural",
  "status": "FAIL",
  "error": "Tier-1: COLUMN REF MISMATCH: Original columns missing from rewrite \u2014 ['store_sales', 'web_sales']. The rewrite references different table columns."
}
```

### Failed SQL (from attempt 1)
```sql
WITH ss AS (SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ws AS (SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') GROUP BY ca_county, d_qoy, d_year), ss_all_quarters AS (SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ss_ext_sales_price ELSE 0 END) AS q1_sales, SUM(CASE WHEN d_qoy = 2 THEN ss_ext_sales_price ELSE 0 END) AS q2_sales, SUM(CASE WHEN d_qoy = 3 THEN ss_ext_sales_price ELSE 0 END) AS q3_sales FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') AND d_qoy IN (1, 2, 3) GROUP BY ca_county, d_year), ws_all_quarters AS (SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ws_ext_sales_price ELSE 0 END) AS q1_sales, SUM(CASE WHEN d_qoy = 2 THEN ws_ext_sales_price ELSE 0 END) AS q2_sales, SUM(CASE WHEN d_qoy = 3 THEN ws_ext_sales_price ELSE 0 END) AS q3_sales FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS', 'OH') AND d_qoy IN (1, 2, 3) GROUP BY ca_county, d_year) SELECT ss.ca_county, ss.d_year, CASE WHEN ws.q1_sales > 0 THEN CAST(ws.q2_sales AS DOUBLE PRECISION) / ws.q1_sales ELSE NULL END AS web_q1_q2_increase, CASE WHEN ss.q1_sales > 0 THEN CAST(ss.q2_sales AS DOUBLE PRECISION) / ss.q1_sales ELSE NULL END AS store_q1_q2_increase, CASE WHEN ws.q2_sales > 0 THEN CAST(ws.q3_sales AS DOUBLE PRECISION) / ws.q2_sales ELSE NULL END AS web_q2_q3_increase, CASE WHEN ss.q2_sales > 0 THEN CAST(ss.q3_sales AS DOUBLE PRECISION) / ss.q2_sales ELSE NULL END AS store_q2_q3_increase FROM ss_all_quarters AS ss, ws_all_quarters AS ws WHERE ss.ca_county = ws.ca_county AND ss.d_year = 1999 AND ws.d_year = 1999 AND CASE WHEN ws.q1_sales > 0 THEN CAST(ws.q2_sales AS DOUBLE PRECISION) / ws.q1_sales ELSE NULL END > CASE WHEN ss.q1_sales > 0 THEN CAST(ss.q2_sales AS DOUBLE PRECISION) / ss.q1_sales ELSE NULL END AND CASE WHEN ws.q2_sales > 0 THEN CAST(ws.q3_sales AS DOUBLE PRECISION) / ws.q2_sales ELSE NULL END > CASE WHEN ss.q2_sales > 0 THEN CAST(ss.q3_sales AS DOUBLE PRECISION) / ss.q2_sales ELSE NULL END ORDER BY ss1.d_year;
```

### Previous Worker Output (attempt 1)
```
{
  "probe_id": "p01",
  "transform_id": "single_pass_aggregation",
  "family": "C",
  "dialect": "postgres",
  "hypothesis": "Consolidate repeated quarterly aggregations on store_sales and web_sales into single-pass CTEs using conditional aggregates to eliminate self-joins and reduce fact table scans.",
  "reasoning_trace": [
    "Original query scans store_sales and web_sales 3 times each due to ss1/ss2/ss3 and ws1/ws2/ws3 CTEs.",
    "Each scan filters by d_qoy = 1, 2, or 3 respectively but shares identical base predicates.",
    "Using CASE inside SUM allows pivoting quarters in one scan, avoiding costly self-joins."
  ],
  "target_ir": "Two CTEs (ss_all_quarters, ws_all_quarters) with conditional aggregates; main query joins them once per source.",
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {"by_node_id": "S0"},
      "payload": {
        "cte_name": "ss_all_quarters",
        "cte_query_sql": "SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ss_ext_sales_price ELSE 0 END) AS q1_sales, SUM(CASE WHEN d_qoy = 2 THEN ss_ext_sales_price ELSE 0 END) AS q2_sales, SUM(CASE WHEN d_qoy = 3 THEN ss_ext_sales_price ELSE 0 END) AS q3_sales FROM store_sales, date_dim, customer_address, item WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND ss_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ss_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS','OH') AND d_qoy IN (1,2,3) GROUP BY ca_county, d_year"
      }
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {"by_node_id": "S0"},
      "payload": {
        "cte_name": "ws_all_quarters",
        "cte_query_sql": "SELECT ca_county, d_year, SUM(CASE WHEN d_qoy = 1 THEN ws_ext_sales_price ELSE 0 END) AS q1_sales, SUM(CASE WHEN d_qoy = 2 THEN ws_ext_sales_price ELSE 0 END) AS q2_sales, SUM(CASE WHEN d_qoy = 3 THEN ws_ext_sales_price ELSE 0 END) AS q3_sales FROM web_sales, date_dim, customer_address, item WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND ws_item_sk = i_item_sk AND i_color IN ('dark', 'puff') AND i_manager_id BETWEEN 15 AND 34 AND ws_list_price BETWEEN 244 AND 258 AND ca_state IN ('KS','OH') AND d_qoy IN (1,2,3) GROUP BY ca_county, d_year"
      }
    },
    {
      "step_id": "s3",
      "op": "replace_from",
      "target": {"by_node_id": "S0"},
      "payload": {
        "from_sql": "ss_all_quarters ss, ws_all_quarters ws"
      }
    },
    {
      "step_id": "s4",
      "op": "replace_where_predicate",
      "target": {"by_node_id": "S0"},
      "payload": {
        "expr_sql": "ss.ca_county = ws.ca_county AND ss.d_year = 1999 AND ws.d_year = 1999 AND CASE WHEN ws.q1_sales > 0 THEN ws.q2_sales::FLOAT / ws.q1_sales ELSE NULL END > CASE WHEN ss.q1_sales > 0 THEN ss.q2_sales::FLOAT / ss.q1_sales ELSE NULL END AND CASE WHEN ws.q2_sales > 0 THEN ws.q3_sales::FLOAT / ws.q2_sales ELSE NULL END > CASE WHEN ss.q2_sales > 0 THEN ss.q3_sales::FLOAT / ss.q2_sales ELSE NULL END"
      }
    },
    {
      "step_id": "s5",
      "op": "replace_select",
      "target": {"by_node_id": "S0"},
      "payload": {
        "sql_fragment": "ss.ca_county, ss.d_year, CASE WHEN ws.q1_sales > 0 THEN ws.q2_sales::FLOAT / ws.q1_sales ELSE NULL END AS web_q1_q2_increase, CASE WHEN ss.q1_sales > 0 THEN ss.q2_sales::FLOAT / ss.q1_sales ELSE NULL END AS store_q1_q2_increase, CASE WHEN ws.q2_sales > 0 THEN ws.q3_sales::FLOAT / ws.q2_sales ELSE NULL END AS web_q2_q3_increase, CASE WHEN ss.q2_sales > 0 THEN ss.q3_sales::FLOAT / ss.q2_sales ELSE NULL END AS store_q2_q3_increase"
      }
    }
  ]
}
```

Fix only what caused the gate failure while preserving transform intent and semantics.
Output ONLY valid PatchPlan JSON.
Never emit payload.sql; use payload.sql_fragment where SQL fragments are required.