## Role

You are **W2 "Unnester"** — Logic simplification — decorrelation, aggregation pushdown. Eliminate per-row re-execution: convert correlated subqueries to GROUP BY CTEs, push aggregation before joins when GROUP BY keys ⊇ join keys.

Transform this SQL query from its CURRENT IR structure to a TARGET IR structure using patch operations. Output a single PatchPlan JSON.

**Family**: C+B — agg_pushdown_with_dimension_filters+decorrelate_fixed
**Hypothesis**: Fix t1's regression by adding store/item filters to the pre-aggregation CTE. The original t1 scanned 1.5M store_sales rows (time=180ms). With store/item filters, input to pre_agg should match the original 1-row store scan. | Rescue decorrelation by fixing column references. The original Nested Loop (519ms) suggests per-row execution. Standalone CTEs could eliminate correlation.

## Original SQL

```sql
select  i_item_id,
        s_state, grouping(s_state) g_state,
        avg(ss_quantity) agg1,
        avg(ss_list_price) agg2,
        avg(ss_coupon_amt) agg3,
        avg(ss_sales_price) agg4
from store_sales, customer_demographics, date_dim, store, item
where ss_sold_date_sk = d_date_sk and
      ss_item_sk = i_item_sk and
      ss_store_sk = s_store_sk and
      ss_cdemo_sk = cd_demo_sk and
      cd_gender = 'M' and
      cd_marital_status = 'W' and
      cd_education_status = 'Secondary' and
      d_year = 1999 and
      s_state = 'OH' and
     i_category  = 'Music'
 group by rollup (i_item_id, s_state)
 order by i_item_id
         ,s_state
 limit 100;
```

## Current IR Node Map

```
S0 [SELECT]
  MAIN QUERY (via Q_S0)
    FROM: store_sales, customer_demographics, date_dim, store, item
    WHERE [67958869346fab14]: ss_sold_date_sk = d_date_sk AND ss_item_sk = i_item_sk AND ss_store_sk = s_store_sk AND ss_cdemo_...
    ORDER BY: i_item_id, s_state

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Target IR (what the optimized query should look like)

```
S0: replace_from with filtered pre_agg (include store/item conditions)
---
S0: replace_from with decorrelated CTEs (corrected column aliases)
```

## Patch Operations

| Op | Description | Payload |
|----|-------------|---------|
| insert_cte | Add a new CTE to the WITH clause | cte_name, cte_query_sql |
| replace_from | Replace the FROM clause | from_sql |
| replace_where_predicate | Replace the WHERE clause | expr_sql |
| replace_body | Replace entire query body (SELECT, FROM, WHERE, GROUP BY) | sql_fragment |
| replace_expr_subtree | Replace a specific expression | expr_sql (+ by_anchor_hash) |
| delete_expr_subtree | Remove a specific expression | (target only, no payload) |

## Gold Patch Example (reference pattern)

```json
{
  "plan_id": "gold_postgres_pg_materialized_dimension_fact_prefilter",
  "dialect": "postgres",
  "description": "Pre-filter ALL dimension tables AND the fact table into MATERIALIZED CTEs, then join with explicit JOIN syntax. On queries with expensive non-equi joins (inventory quantity < sales quantity, week_seq correlation), reducing both dimension AND fact table sizes before the join dramatically cuts the search space. The MATERIALIZED keyword on PG12+ forces early execution of each CTE.",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_date",
        "cte_query_sql": "SELECT d_date_sk, d_date, d_week_seq FROM date_dim WHERE d_year = 1998"
      },
      "description": "Insert CTE 'filtered_date' for date dimension filtering"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_item",
        "cte_query_sql": "SELECT i_item_sk, i_item_desc FROM item WHERE i_category IN ('Home', 'Men', 'Music')"
      },
      "description": "Insert CTE 'filtered_item'"
    },
    {
      "step_id": "s3",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_cd",
        "cte_query_sql": "SELECT cd_demo_sk FROM customer_demographics WHERE cd_marital_status = 'M' AND cd_dep_count BETWEEN 9 AND 11"
      },
      "description": "Insert CTE 'filtered_cd'"
    },
    {
      "step_id": "s4",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_hd",
        "cte_query_sql": "SELECT hd_demo_sk FROM household_demographics WHERE hd_buy_potential = '501-1000'"
      },
      "description": "Insert CTE 'filtered_hd'"
    },
    {
      "step_id": "s5",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "cs_filtered",
        "cte_query_sql": "SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk, cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost, cs_order_number FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 34 AND 54"
      },
      "description": "Insert CTE 'cs_filtered' for date dimension filtering"
    },
    {
      "step_id": "s6",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "cs_filtered AS cs JOIN inventory AS inv ON cs.cs_item_sk = inv.inv_item_sk JOIN warehouse AS w ON w.w_warehouse_sk = inv.inv_warehouse_sk JOIN filtered_item AS i ON i.i_item_sk = cs.cs_item_sk JOIN filtered_cd AS cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk JOIN filtered_hd AS hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk JOIN filtered_date AS d1 ON cs.cs_sold_date_sk = d1.d_date_sk JOIN date_dim AS d2 ON inv.inv_date_sk = d2.d_date_sk JOIN date_dim AS d3 ON cs.cs_ship_date_sk = d3.d_date_sk LEFT OUTER JOIN promotion AS p ON cs.cs_promo_sk = p.p_promo_sk LEFT OUTER JOIN catalog_returns AS cr ON cr.cr_item_sk = cs.cs_item_sk AND cr.cr_order_number = cs.cs_order_number"
      },
      "description": "Replace FROM clause with CTE-based JOINs"
    },
    {
      "step_id": "s7",
      "op": "replace_where_predicate",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "c7c12190f04335b3"
      },
      "payload": {
        "expr_sql": "d1.d_week_seq = d2.d_week_seq AND inv.inv_quantity_on_hand < cs.cs_quantity AND d3.d_date > d1.d_date + INTERVAL '3 DAY'"
      },
      "description": "Replace WHERE predicate with optimized version"
    }
  ]
}
```

## Instructions

Adapt the gold example pattern to match the ORIGINAL SQL above.
Use the TARGET IR as your structural guide — create CTEs matching the target's CTE names and structure.
Preferred approach: insert_cte (x2-3) + replace_from or replace_body.
All SQL in payloads must be complete, executable fragments (no ellipsis).
Use dialect: "postgres" in the output.
Target all steps at by_node_id: "S0" (the main statement).

Output ONLY the JSON object (no markdown, no explanation):
## Additional Gold Examples (for compound strategy)

**Gold Example 2:**
```json
{
  "plan_id": "gold_postgres_pg_shared_scan_decorrelate",
  "dialect": "postgres",
  "description": "When a correlated subquery re-scans the same fact table as the outer query, extract the common scan into a shared CTE, then derive both the threshold computation and the outer rows from a single materialized result. Eliminates O(N*M) re-execution of the fact+date join.",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "common_scan",
        "cte_query_sql": "SELECT ws_item_sk, ws_ext_discount_amt, ws_sales_price, ws_list_price FROM web_sales INNER JOIN date_dim ON d_date_sk = ws_sold_date_sk WHERE d_date BETWEEN '1998-03-13' AND CAST('1998-03-13' AS DATE) + INTERVAL '90 DAY' AND ws_wholesale_cost BETWEEN 26 AND 46"
      },
      "description": "Insert CTE 'common_scan' for date dimension filtering"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "threshold_computation",
        "cte_query_sql": "SELECT ws_item_sk, 1.3 * AVG(ws_ext_discount_amt) AS threshold FROM common_scan WHERE ws_sales_price / ws_list_price BETWEEN 34 * 0.01 AND 49 * 0.01 GROUP BY ws_item_sk"
      },
      "description": "Insert CTE 'threshold_computation' for pre-aggregated computation"
    },
    {
      "step_id": "s3",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "outer_rows",
        "cte_query_sql": "SELECT cs.ws_item_sk, cs.ws_ext_discount_amt FROM common_scan AS cs INNER JOIN item ON i_item_sk = cs.ws_item_sk WHERE i_manufact_id BETWEEN 341 AND 540 OR i_category IN ('Home', 'Men', 'Music')"
      },
      "description": "Insert CTE 'outer_rows' for pre-filtered join"
    },
    {
      "step_id": "s4",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "join_filter",
        "cte_query_sql": "SELECT o.ws_ext_discount_amt FROM outer_rows AS o INNER JOIN threshold_computation AS t ON o.ws_item_sk = t.ws_item_sk WHERE o.ws_ext_discount_amt > t.threshold"
      },
      "description": "Insert CTE 'join_filter' for pre-filtered join"
    },
    {
      "step_id": "s5",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "join_filter"
      },
      "description": "Replace comma-join FROM with explicit JOINs"
    },
    {
      "step_id": "s6",
      "op": "delete_expr_subtree",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "0ef6ffe2461512ae"
      },
      "description": "Remove WHERE clause (conditions moved to CTEs)"
    }
  ]
}
```

Combine techniques from ALL gold examples above into a single unified patch plan.