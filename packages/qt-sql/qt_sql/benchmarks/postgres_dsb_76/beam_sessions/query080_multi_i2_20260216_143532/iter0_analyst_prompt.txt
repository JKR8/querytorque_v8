## Role

You are a SQL optimization analyst. Your task is to analyze this query, identify the primary bottleneck, and design structural optimization targets.

For each target, describe the STRUCTURAL SHAPE of the optimized query using an IR node map (CTE names, FROM tables, WHERE conditions, GROUP BY, ORDER BY). A separate code-generation worker will convert your targets into executable patch plans.

Identify the primary bottleneck. Only provide secondary targets if they are distinct and high-confidence. **Quality > Quantity.**

## Query: query080_multi_i2

**Dialect**: POSTGRES

```sql
with ssr as
 (select  s_store_id as store_id,
          sum(ss_ext_sales_price) as sales,
          sum(coalesce(sr_return_amt, 0)) as returns,
          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit
  from store_sales left outer join store_returns on
         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),
     date_dim,
     store,
     item,
     promotion
 where ss_sold_date_sk = d_date_sk
       and d_date between cast('1999-10-21' as date)
                  and cast('1999-10-21' as date) + interval '30 day'
       and ss_store_sk = s_store_sk
       and ss_item_sk = i_item_sk
       and i_current_price > 50
       and ss_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'N'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'N'
       and ss_wholesale_cost BETWEEN 21 AND 36
       and i_category IN ('Men', 'Music')
 group by s_store_id)
 ,
 csr as
 (select  cp_catalog_page_id as catalog_page_id,
          sum(cs_ext_sales_price) as sales,
          sum(coalesce(cr_return_amount, 0)) as returns,
          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit
  from catalog_sales left outer join catalog_returns on
         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),
     date_dim,
     catalog_page,
     item,
     promotion
 where cs_sold_date_sk = d_date_sk
       and d_date between cast('1999-10-21' as date)
                  and cast('1999-10-21' as date) + interval '30 day'
        and cs_catalog_page_sk = cp_catalog_page_sk
       and cs_item_sk = i_item_sk
       and i_current_price > 50
       and cs_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'N'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'N'
       and cs_wholesale_cost BETWEEN 21 AND 36
       and i_category IN ('Men', 'Music')
group by cp_catalog_page_id)
 ,
 wsr as
 (select  web_site_id,
          sum(ws_ext_sales_price) as sales,
          sum(coalesce(wr_return_amt, 0)) as returns,
          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit
  from web_sales left outer join web_returns on
         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),
     date_dim,
     web_site,
     item,
     promotion
 where ws_sold_date_sk = d_date_sk
       and d_date between cast('1999-10-21' as date)
                  and cast('1999-10-21' as date) + interval '30 day'
        and ws_web_site_sk = web_site_sk
       and ws_item_sk = i_item_sk
       and i_current_price > 50
       and ws_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'N'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'N'
       and ws_wholesale_cost BETWEEN 21 AND 36
       and i_category IN ('Men', 'Music')
group by web_site_id)
  select  channel
        , id
        , sum(sales) as sales
        , sum(returns) as returns
        , sum(profit) as profit
 from
 (select 'store channel' as channel
        , 'store' || store_id as id
        , sales
        , returns
        , profit
 from   ssr
 union all
 select 'catalog channel' as channel
        , 'catalog_page' || catalog_page_id as id
        , sales
        , returns
        , profit
 from  csr
 union all
 select 'web channel' as channel
        , 'web_site' || web_site_id as id
        , sales
        , returns
        , profit
 from   wsr
 ) x
 group by rollup (channel, id)
 order by channel
         ,id
 limit 100;
```


## Current Execution Plan

```
Limit  (rows=6, time=117.426)
  Aggregate  (rows=6, time=117.425)
    Sort  (rows=3, time=117.409)
      Append  (rows=3, time=117.393)
        Subquery Scan (ssr)  (rows=2, time=43.395)
          Aggregate  (rows=2, time=43.391)
            Sort  (rows=2, time=43.376)
              Nested Loop  (rows=2, time=43.363)
                Nested Loop  (rows=2, time=43.319)
                  Gather  (rows=2, time=42.19)
                    Nested Loop  (rows=1, time=16.099)
                      Hash Join  (rows=207, time=15.016)
                        Nested Loop  (rows=5432, time=14.715)
                          Index Scan on date_dim  (rows=10, time=3.724)
                          Index Only Scan on store_sales  (rows=526, time=1.035)
                        Hash  (rows=18, time=0.099)
                          Seq Scan on promotion  (rows=18, time=0.094)
                      Index Scan on item  (rows=0, time=0.005)
                  Index Scan on store_returns  (rows=0, time=0.561)
                Index Only Scan on store  (rows=1, time=0.018)
        Subquery Scan (csr)  (rows=1, time=29.327)
          Aggregate  (rows=1, time=29.324)
            Sort  (rows=1, time=29.317)
              Nested Loop  (rows=1, time=29.299)
                Nested Loop  (rows=1, time=28.779)
                  Gather  (rows=1, time=28.361)
                    Nested Loop  (rows=0, time=15.726)
                      Hash Join  (rows=326, time=14.293)
                        Nested Loop  (rows=10428, time=13.802)
                          Seq Scan on date_dim (date_dim_1)  (rows=16, time=3.236)
                          Index Scan on catalog_sales  (rows=673, time=0.626)
                        Hash  (rows=18, time=0.085)
                          Seq Scan on promotion (promotion_1)  (rows=18, time=0.081)
                      Index Scan on item (item_1)  (rows=0, time=0.004)
                  Index Scan on catalog_returns  (rows=0, time=0.414)
                Index Scan on catalog_page  (rows=1, time=0.516)
        Subquery Scan (wsr)  (rows=0, time=44.663)
          Aggregate  (rows=0, time=44.661)
            Nested Loop  (rows=0, time=44.66)
              Gather Merge  (rows=0, time=44.659)
                Sort  (rows=0, time=24.081)
                  Nested Loop  (rows=0, time=24.053)
                    Nested Loop  (rows=0, time=24.052)
                      Hash Join  (rows=446, time=21.866)
                        Nested Loop  (rows=9748, time=21.282)
                          Seq Scan on date_dim (date_dim_2)  (rows=16, time=2.585)
                          Index Scan on web_sales  (rows=629, time=1.147)
                        Hash  (rows=18, time=0.057)
                          Seq Scan on promotion (promotion_2)  (rows=18, time=0.053)
                      Index Scan on item (item_2)  (rows=0, time=0.005)
                    Index Scan on web_site  (rows=0, time=0.0)
              Index Scan on web_returns  (rows=0, time=0.0)
```


## IR Structure (for patch targeting)

```
S0 [SELECT]
  CTE: ssr  (via CTE_Q_S0_ssr)
    FROM: store_sales, store_returns, date_dim, store, item, promotion
    WHERE [fe4ed6f8f1b0d0b5]: ss_sold_date_sk = d_date_sk AND d_date BETWEEN CAST('1999-10-21' AS DATE) AND CAST('1999-10-21' A...
    GROUP BY: s_store_id
  CTE: csr  (via CTE_Q_S0_csr)
    FROM: catalog_sales, catalog_returns, date_dim, catalog_page, item, promotion
    WHERE [96df8080780c093f]: cs_sold_date_sk = d_date_sk AND d_date BETWEEN CAST('1999-10-21' AS DATE) AND CAST('1999-10-21' A...
    GROUP BY: cp_catalog_page_id
  CTE: wsr  (via CTE_Q_S0_wsr)
    FROM: web_sales, web_returns, date_dim, web_site, item, promotion
    WHERE [0f90d5ad6b1f86af]: ws_sold_date_sk = d_date_sk AND d_date BETWEEN CAST('1999-10-21' AS DATE) AND CAST('1999-10-21' A...
    GROUP BY: web_site_id
  MAIN QUERY (via Q_S0)
    FROM: (subquery) x
    ORDER BY: channel, id

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

**Note**: Use `by_node_id` (e.g., "S0") and `by_anchor_hash` (16-char hex) from map above to target patch operations.


## Optimization Families

Review the 6 families below. Each has a proven gold example.

Choose up to **4 most relevant families** for this query based on:
- Query structure (CTEs, subqueries, joins, aggregations, set operations)
- Execution plan signals (WHERE placement, repeated scans, correlated subqueries)
- Problem signature (cardinality estimation errors, loops vs sets, filter ordering)



### Family A: Early Filtering (Predicate Pushback)
**Description**: Push small filters into CTEs early, reduce row count before expensive operations
**Speedup Range**: 1.3–4.0x (~35% of all wins)
**Use When**:
  1. Late WHERE filters on dimension tables
  2. Cascading CTEs with filters applied downstream
  3. Expensive joins after filters could be pushed earlier

**Gold Example**: `pg_date_cte_explicit_join` (2.28x)



### Family B: Decorrelation (Sets Over Loops)
**Description**: Convert correlated subqueries to standalone CTEs with GROUP BY, eliminate per-row re-execution
**Speedup Range**: 2.4–2.9x (~15% of all wins)
**Use When**:
  1. Correlated subqueries in WHERE clause
  2. Scalar aggregates computed per outer row
  3. DELIM_SCAN in execution plan (indicates correlation)

**Gold Example**: `pg_shared_scan_decorrelate` (8043.91x (timeout rescue))



### Family C: Aggregation Pushdown (Minimize Rows Touched)
**Description**: Aggregate before expensive joins when GROUP BY keys ⊇ join keys, reduce intermediate sizes
**Speedup Range**: 1.3–15.3x (~5% of all wins (high variance))
**Use When**:
  1. GROUP BY happens after large joins
  2. GROUP BY keys are subset of join keys
  3. Intermediate result size >> final result size

**Gold Example**: `pg_materialized_dimension_fact_prefilter` (12.07x (V2 DSB SF10, was 2.68x in V1))



### Family D: Set Operation Optimization (Sets Over Loops)
**Description**: Replace INTERSECT/UNION-based patterns with EXISTS/NOT EXISTS, avoid full materialization
**Speedup Range**: 1.7–2.7x (~8% of all wins)
**Use When**:
  1. INTERSECT patterns between large sets
  2. UNION ALL with duplicate elimination
  3. Set operations materializing full intermediate results

**Gold Example**: `pg_intersect_to_exists` (1.78x)



### Family E: Materialization / Prefetch (Don't Repeat Work)
**Description**: Extract repeated scans or pre-compute intermediate results for reuse across multiple consumers
**Speedup Range**: 1.3–6.2x (~18% of all wins)
**Use When**:
  1. Repeated scans of same table with different filters
  2. Dimension filters applied independently multiple times
  3. CTE referenced multiple times with implicit re-evaluation

**Gold Example**: `multi_dimension_prefetch` (2.71x)



### Family F: Join Transform (Right Shape First)
**Description**: Restructure join topology: convert comma joins to explicit INNER JOIN, optimize join order, eliminate self-joins via single-pass aggregation
**Speedup Range**: 1.8–8.6x (~19% of all wins)
**Use When**:
  1. Comma-separated joins (implicit cross joins) in FROM clause
  2. Self-joins scanning same table multiple times
  3. Dimension-fact join order suboptimal for predicate pushdown

**Gold Example**: `pg_explicit_join_materialized` (8.56x)



## Worker Routing

Your targets will be routed to specialized workers:
- **W1 "Reducer"** (Families A, D): Cardinality reduction — early filtering, set operations
- **W2 "Unnester"** (Families B, C): Decorrelation, aggregation pushdown
- **W3 "Builder"** (Families F, E): Join restructuring, materialization/prefetch
- **W4 "Wildcard"** (Dynamic): Deep specialist — your **#1 target** gets maximum effort

The highest-relevance target always goes to W4. Design diverse targets across worker roles for maximum coverage.


## Your Task

Analyze this query against the 6 families above.

Identify the **primary bottleneck**. Only provide secondary targets if they are distinct and high-confidence. Quality > Quantity.

For each target (1 to 4):
1. Describe the bottleneck hypothesis
2. Design a TARGET IR node map showing what the optimized query SHOULD look like
3. Score relevance (0.0–1.0)
4. Recommend which gold example(s) a code-generation worker should use as reference


**Output format**:

```json
[
  {
    "family": "B",
    "transform": "shared_scan_decorrelate",
    "target_id": "t1",
    "relevance_score": 0.95,
    "hypothesis": "Correlated scalar subquery re-scans web_sales per row. Shared-scan variant: inner=outer table with same date filter.",
    "target_ir": "S0 [SELECT]\n  CTE: common_scan  (via Q1)\n    FROM: web_sales, date_dim\n    WHERE: d_date BETWEEN ... AND d_date_sk = ws_sold_date_sk\n  CTE: thresholds  (via Q2)\n    FROM: common_scan\n    GROUP BY: ws_item_sk\n  MAIN QUERY (via Q0)\n    FROM: common_scan cs, item, thresholds t\n    WHERE: i_manufact_id = 320 AND ... AND cs.ws_ext_discount_amt > t.threshold\n    ORDER BY: sum(ws_ext_discount_amt)",
    "recommended_examples": ["sf_shared_scan_decorrelate"]
  }
]
```

**Rules**:
- target_ir must follow the IR node map format (same as Section 4)
- target_ir describes the STRUCTURAL SHAPE of the optimized query (CTE names, FROM tables, WHERE conditions, GROUP BY, ORDER BY)
- recommended_examples: list gold example IDs the worker should use as reference patch template
- Each target should represent a DIFFERENT optimization strategy
- Rank by relevance_score (highest first)
- Output up to 4 targets

After JSON, provide analysis:

## Analysis
For each available family, explain relevance (HIGH / MEDIUM / LOW) in 1-2 sentences.
**Chosen families**: [list]
**Confidence**: High/Medium/Low
