## Role

You are **W4 "Wildcard"** — Deep specialist for the #1 identified problem. Focus entirely on the highest-priority optimization target. May combine strategies from multiple families or try novel approaches not covered by other workers.

Transform this SQL query from its CURRENT IR structure to a TARGET IR structure using patch operations. Output a single PatchPlan JSON.

**Family**: C — aggregation_pushdown
**Hypothesis**: Aggregation occurs after large joins with dimension table (store), carrying unnecessary columns. Push aggregation to store key before joining store attributes.

## Original SQL

```sql
select 
   s_store_name
  ,s_company_id
  ,s_street_number
  ,s_street_name
  ,s_street_type
  ,s_suite_number
  ,s_city
  ,s_county
  ,s_state
  ,s_zip
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 30) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 60) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk > 90) and
                 (sr_returned_date_sk - ss_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (sr_returned_date_sk - ss_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   store_sales
  ,store_returns
  ,store
  ,date_dim d1
  ,date_dim d2
where
    d2.d_year = 1999
and d2.d_moy  = 7
and ss_ticket_number = sr_ticket_number
and ss_item_sk = sr_item_sk
and ss_sold_date_sk   = d1.d_date_sk
and sr_returned_date_sk   = d2.d_date_sk
and ss_customer_sk = sr_customer_sk
and ss_store_sk = s_store_sk
and d1.d_date between (d2.d_date - interval '120 day')
               and d2.d_date
group by
   s_store_name
  ,s_company_id
  ,s_street_number
  ,s_street_name
  ,s_street_type
  ,s_suite_number
  ,s_city
  ,s_county
  ,s_state
  ,s_zip
order by s_store_name
        ,s_company_id
        ,s_street_number
        ,s_street_name
        ,s_street_type
        ,s_suite_number
        ,s_city
        ,s_county
        ,s_state
        ,s_zip
limit 100;
```

## Current IR Node Map

```
S0 [SELECT]
  MAIN QUERY (via Q_S0)
    FROM: store_sales, store_returns, store, date_dim d1, date_dim d2
    WHERE [444f6473896f7965]: d2.d_year = 1999 AND d2.d_moy = 7 AND ss_ticket_number = sr_ticket_number AND ss_item_sk = sr_ite...
    GROUP BY: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip
    ORDER BY: s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Target IR (what the optimized query should look like)

```
S0 [SELECT]
  CTE: pre_agg (via Q1)
    SELECT
      ss_store_sk,
      sum(case when (sr_returned_date_sk - ss_sold_date_sk <= 30) then 1 else 0 end) as "30 days",
      sum(case when (sr_returned_date_sk - ss_sold_date_sk > 30 and sr_returned_date_sk - ss_sold_date_sk <= 60) then 1 else 0 end) as "31-60 days",
      sum(case when (sr_returned_date_sk - ss_sold_date_sk > 60 and sr_returned_date_sk - ss_sold_date_sk <= 90) then 1 else 0 end) as "61-90 days",
      sum(case when (sr_returned_date_sk - ss_sold_date_sk > 90 and sr_returned_date_sk - ss_sold_date_sk <= 120) then 1 else 0 end) as "91-120 days",
      sum(case when (sr_returned_date_sk - ss_sold_date_sk > 120) then 1 else 0 end) as ">120 days"
    FROM store_sales
    JOIN store_returns ON ss_ticket_number = sr_ticket_number AND ss_item_sk = sr_item_sk AND ss_customer_sk = sr_customer_sk
    JOIN date_dim d1 ON ss_sold_date_sk = d1.d_date_sk
    JOIN date_dim d2 ON sr_returned_date_sk = d2.d_date_sk
    WHERE d2.d_year = 1999 AND d2.d_moy = 7
      AND d1.d_date BETWEEN (d2.d_date - interval '120 day') AND d2.d_date
    GROUP BY ss_store_sk
  MAIN QUERY (via Q0)
    SELECT 
      s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number,
      s_city, s_county, s_state, s_zip,
      "30 days", "31-60 days", "61-90 days", "91-120 days", ">120 days"
    FROM pre_agg
    JOIN store ON ss_store_sk = s_store_sk
    ORDER BY s_store_name, s_company_id, s_street_number, s_street_name, s_street_type, s_suite_number, s_city, s_county, s_state, s_zip
    LIMIT 100
```

## Patch Operations

| Op | Description | Payload |
|----|-------------|---------|
| insert_cte | Add a new CTE to the WITH clause | cte_name, cte_query_sql |
| replace_from | Replace the FROM clause | from_sql |
| replace_where_predicate | Replace the WHERE clause | expr_sql |
| replace_body | Replace entire query body (SELECT, FROM, WHERE, GROUP BY) | sql_fragment |
| replace_expr_subtree | Replace a specific expression | expr_sql (+ by_anchor_hash) |
| delete_expr_subtree | Remove a specific expression | (target only, no payload) |

## Gold Patch Example (reference pattern)

```json
{
  "plan_id": "gold_postgres_pg_materialized_dimension_fact_prefilter",
  "dialect": "postgres",
  "description": "Pre-filter ALL dimension tables AND the fact table into MATERIALIZED CTEs, then join with explicit JOIN syntax. On queries with expensive non-equi joins (inventory quantity < sales quantity, week_seq correlation), reducing both dimension AND fact table sizes before the join dramatically cuts the search space. The MATERIALIZED keyword on PG12+ forces early execution of each CTE.",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_date",
        "cte_query_sql": "SELECT d_date_sk, d_date, d_week_seq FROM date_dim WHERE d_year = 1998"
      },
      "description": "Insert CTE 'filtered_date' for date dimension filtering"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_item",
        "cte_query_sql": "SELECT i_item_sk, i_item_desc FROM item WHERE i_category IN ('Home', 'Men', 'Music')"
      },
      "description": "Insert CTE 'filtered_item'"
    },
    {
      "step_id": "s3",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_cd",
        "cte_query_sql": "SELECT cd_demo_sk FROM customer_demographics WHERE cd_marital_status = 'M' AND cd_dep_count BETWEEN 9 AND 11"
      },
      "description": "Insert CTE 'filtered_cd'"
    },
    {
      "step_id": "s4",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_hd",
        "cte_query_sql": "SELECT hd_demo_sk FROM household_demographics WHERE hd_buy_potential = '501-1000'"
      },
      "description": "Insert CTE 'filtered_hd'"
    },
    {
      "step_id": "s5",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "cs_filtered",
        "cte_query_sql": "SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk, cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost, cs_order_number FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 34 AND 54"
      },
      "description": "Insert CTE 'cs_filtered' for date dimension filtering"
    },
    {
      "step_id": "s6",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "cs_filtered AS cs JOIN inventory AS inv ON cs.cs_item_sk = inv.inv_item_sk JOIN warehouse AS w ON w.w_warehouse_sk = inv.inv_warehouse_sk JOIN filtered_item AS i ON i.i_item_sk = cs.cs_item_sk JOIN filtered_cd AS cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk JOIN filtered_hd AS hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk JOIN filtered_date AS d1 ON cs.cs_sold_date_sk = d1.d_date_sk JOIN date_dim AS d2 ON inv.inv_date_sk = d2.d_date_sk JOIN date_dim AS d3 ON cs.cs_ship_date_sk = d3.d_date_sk LEFT OUTER JOIN promotion AS p ON cs.cs_promo_sk = p.p_promo_sk LEFT OUTER JOIN catalog_returns AS cr ON cr.cr_item_sk = cs.cs_item_sk AND cr.cr_order_number = cs.cs_order_number"
      },
      "description": "Replace FROM clause with CTE-based JOINs"
    },
    {
      "step_id": "s7",
      "op": "replace_where_predicate",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "c7c12190f04335b3"
      },
      "payload": {
        "expr_sql": "d1.d_week_seq = d2.d_week_seq AND inv.inv_quantity_on_hand < cs.cs_quantity AND d3.d_date > d1.d_date + INTERVAL '3 DAY'"
      },
      "description": "Replace WHERE predicate with optimized version"
    }
  ]
}
```

## Instructions

Adapt the gold example pattern to match the ORIGINAL SQL above.
Use the TARGET IR as your structural guide — create CTEs matching the target's CTE names and structure.
Preferred approach: insert_cte (x2-3) + replace_from or replace_body.
All SQL in payloads must be complete, executable fragments (no ellipsis).
Use dialect: "postgres" in the output.
Target all steps at by_node_id: "S0" (the main statement).

Output ONLY the JSON object (no markdown, no explanation):