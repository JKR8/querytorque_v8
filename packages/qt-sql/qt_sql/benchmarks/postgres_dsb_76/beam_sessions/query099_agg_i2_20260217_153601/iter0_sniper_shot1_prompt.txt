## Role

You are the **Beam Sniper** for SQL optimization on the target runtime dialect.

You receive the full Battle Damage Assessment (BDA) from 4-16 single-transform probes.
You are an evidence-informed analyst: you now have both wide knowledge and query-specific empirical results.

Your task: produce **exactly TWO optimization attempts** as compound PatchPlan candidates.

You may:
- combine winning worker ideas into one SQL patch when compatible
- introduce a new transform not tried by workers when evidence shows workers missed the real bottleneck

You must:
- ground decisions in BDA plus explain deltas
- preserve semantics
- avoid known regressions

---

## Prompt Map (cache friendly)

### Phase A - Cached Context (static)
A1. Dialect reminders plus regression registry
A2. Combination hazards (duplication, multiplicity, CTE fences)
A3. Evidence-first decision procedure (mechanical)
A4. Sniper output contract (strict JSON array)

### Phase B - Query-Specific Input (dynamic; after cache boundary)
B1. Importance star rating (1-3)
B2. Original SQL plus original plan
B3. IR structure plus anchor hashes
B4. BDA table (ALL probes: status, speedup, explain delta, failure reasons)
B5. Worker SQL patch outcomes (full rewritten SQL per probe plus top EXPLAIN nodes plus model description)
B6. Engine-specific knowledge profile (strengths, gaps, contraindications)

---

## Dialect reminders

Use runtime-injected **Engine-Specific Knowledge** as authoritative.
If static defaults conflict with runtime profile, follow runtime profile.

---

## Regression Registry (hard bans)

Do not produce a sniper plan that:
- forces materialization of a simple EXISTS already planned as a semi-join
- duplicates base scans (orphaned original scans after replacement)
- introduces unfiltered massive CTEs
- builds over-deep fact chains that lock join order
- applies same-column OR to UNION ALL by default on PostgreSQL

OR to UNION exception for PostgreSQL:
- only consider it when EXPLAIN evidence shows OR blocks index usage and UNION branches become index scans

---

## Combination hazards (what to watch)

- **Duplicate sources**: merging two plans that each add a filtered fact CTE can scan the same fact twice.
- **Join multiplicity**: turning EXISTS into JOIN can multiply rows unless keys are unique or aggregated.
- **CTE fences**: materialized CTEs can block pushdown and join reorder.
- **Overlapping edits**: if two probes edit the same anchor or predicate, unify them in one rewrite.

---

## Evidence-first decision procedure (mechanical)

1) Read the BDA table:
   - identify best verified winners: PASS/WIN with real speedup and stable equivalence
   - identify what still dominates: use explain deltas and original plan to find remaining hotspot

2) Choose a foundation:
   - prefer the best verified winner as the base
   - if none pass, base on the original query and propose the most justified fix

3) Decide the next move:
   - **combine** one compatible improvement from another passing probe if it targets a different hotspot and avoids hazards
   - **invent** one new transform not attempted if workers missed the hotspot, justified by plan evidence
   - for portability-style moves, proceed only when beam evidence and EXPLAIN deltas support transferability and runtime engine knowledge does not contradict it

4) Produce exactly two PatchPlans:
   - prefer 1-3 steps per plan; if more than 3, justify in `risk_notes`
   - use operationally targeted edits (prefer insert_cte/replace_from/replace_where_predicate)
   - payload SQL must be complete and executable

5) Provide expected EXPLAIN deltas and risks:
   - what should change if it works (operators, loops, rows)
   - biggest semantic risks
   - optional fallback probe if compound plan fails

---

## Sniper Output Contract (MUST follow)

Tier-0 output contract:
- response must be valid JSON
- first character must be `[` (no leading whitespace or newlines)
- top-level value must be an array of exactly two objects
- no markdown fences, no prose, no commentary

Schema rules:
- each object must include: `plan_id`, `dialect`, `hypothesis`, `target_ir`, `steps`
- optional `based_on` must be a string, never an array
- do not emit key `sql`; use `sql_fragment` where SQL fragment payload is required
- steps must target `{"by_node_id":"S0"}` unless an anchor hash is explicitly required

Allowed ops:
- insert_cte
- replace_from
- replace_where_predicate
- replace_body
- replace_expr_subtree
- delete_expr_subtree
- replace_join_condition
- replace_select
- replace_block_with_cte_pair
- wrap_query_with_cte

SQL payload rules:
- `replace_body`, `replace_select`, and `replace_block_with_cte_pair` must place SQL in `payload.sql_fragment`
- payload SQL must be complete and executable

Output JSON shape:
[
  {
    "plan_id": "snipe_p1",
    "dialect": "<target_dialect>",
    "confidence": 0.81,
    "based_on": "p03,p11",
    "strategy": "Foundation plus one compatible add-on",
    "hypothesis": "Plan evidence and expected win mechanism",
    "target_ir": "Short structural description of final query shape",
    "steps": [
      {
        "step_id": "s1",
        "op": "replace_body",
        "target": {"by_node_id": "S0"},
        "payload": {"sql_fragment": "SELECT c_customer_sk FROM customer"}
      }
    ]
  },
  {
    "plan_id": "snipe_p2",
    "dialect": "<target_dialect>",
    "confidence": 0.73,
    "based_on": "p07",
    "strategy": "Alternative independent pathway",
    "hypothesis": "Plan evidence for second pathway",
    "target_ir": "Alternative structural description",
    "steps": [
      {
        "step_id": "s1",
        "op": "insert_cte",
        "target": {"by_node_id": "S0"},
        "payload": {
          "cte_name": "filtered_sales",
          "cte_query_sql": "SELECT ss_customer_sk FROM store_sales WHERE ss_quantity > 0"
        }
      }
    ]
  }
]

---

## Cache Boundary
Everything below is query-specific input.

## Query ID
query099_agg_i2

## Runtime Dialect Contract
- target_dialect: postgres
- runtime_dialect_is_source_of_truth: true
- if static examples conflict, follow runtime dialect behavior

## Importance
- importance_stars: 3
- importance_label: ***

## Original SQL
```sql
select 
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   catalog_sales
  ,warehouse
  ,ship_mode
  ,call_center
  ,date_dim
where
d_month_seq between 1191 and 1191 + 23
and cs_ship_date_sk   = d_date_sk
and cs_warehouse_sk   = w_warehouse_sk
and cs_ship_mode_sk   = sm_ship_mode_sk
and cs_call_center_sk = cc_call_center_sk
and cs_list_price between 244 and 273
and sm_type = 'LIBRARY'
and cc_class = 'medium'
and w_gmt_offset = -5
group by
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
order by substring(w_warehouse_name,1,20)
        ,sm_type
        ,cc_name
limit 100;
```

## Original Plan
```
Limit  (rows=11, time=190459.459)
  Aggregate  (rows=11, time=190445.894)
    Gather Merge  (rows=25, time=190445.877)
      Aggregate  (rows=8, time=170970.421)
        Sort  (rows=826, time=170970.29)
          Hash Join  (rows=826, time=170968.736)
            Hash Join  (rows=1287, time=170957.303)
              Hash Join  (rows=4948, time=170953.203)
                Nested Loop  (rows=25870, time=170930.171)
                  Index Only Scan on date_dim  (rows=244, time=14.296)
                  Index Scan on catalog_sales  (rows=106, time=701.374)
                Hash  (rows=3, time=0.268)
                  Seq Scan on ship_mode  (rows=3, time=0.264)
              Hash  (rows=2, time=0.321)
                Seq Scan on warehouse  (rows=2, time=0.319)
            Hash  (rows=13, time=9.072)
              Seq Scan on call_center  (rows=13, time=9.067)
```

## IR Structure + Anchor Hashes
```
S0 [SELECT]
  MAIN QUERY (via Q_S0)
    FROM: catalog_sales, warehouse, ship_mode, call_center, date_dim
    WHERE [d8eb84395846e3bc]: d_month_seq BETWEEN 1191 AND 1191 + 23 AND cs_ship_date_sk = d_date_sk AND cs_warehouse_sk = w_wa...
    GROUP BY: SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name
    ORDER BY: SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name

Patch operations (core+advanced): insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree, replace_body, replace_join_condition, replace_select, replace_block_with_cte_pair, wrap_query_with_cte
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Schema / Index / Stats Context
- source: postgres
- referenced_tables: 5

| Table | Rows(est) | PK | Indexes |
|-------|-----------|----|---------|
| call_center | 24 | cc_call_center_sk | call_center_pkey |
| catalog_sales | 14397255 | cs_item_sk, cs_order_number | catalog_sales_pkey, _dta_index_catalog_sales_6_1301579675__k1_k16_k5_k4_3_6_18_19_2, _dta_index_catalog_sales_6_1301579675__k17_k6_k3_k5_k1_k16_12_1, _dta_index_catalog_sales_6_1301579675__k1_4_16_18_19_21_24, _dta_index_catalog_sales_6_1301579675__k3_k12_k14_k15_16_18, _dta_index_catalog_sales_6_1301579675__k1_k16_k4_18_34 |
| date_dim | 73049 | d_date_sk | date_dim_pkey, _dta_index_date_dim_6_661577395__k7_k4_k9_k1, _dta_index_date_dim_6_661577395__k7_k9_k1, _dta_index_date_dim_6_661577395__k1_k7_k9, _dta_index_date_dim_6_661577395__k7_k11_k1, _dta_index_date_dim_6_661577395__k9_k7_k1 |
| ship_mode | 20 | sm_ship_mode_sk | ship_mode_pkey |
| warehouse | 10 | w_warehouse_sk | warehouse_pkey |

## Engine-Specific Knowledge
## Dialect Profile (POSTGRES)

**Combined Intelligence Baseline**: Combined intelligence baseline from 53 validated DSB queries at SF5-SF10, plus regression registry outcomes. PostgreSQL has bitmap index scans, JIT compilation, and aggressive CTE materialization. Techniques that work on DuckDB often regress here.

### Optimizer Strengths (don't fight these)
- `BITMAP_OR_SCAN`: Avoid splitting OR conditions into UNION ALL by default. Only consider OR→UNION when EXPLAIN shows OR blocks index usage and UNION branches become index scans. 0.21x and 0.26x reg…
- `SEMI_JOIN_EXISTS`: NEVER convert EXISTS to IN/NOT IN or materialized CTEs. 0.50x, 0.75x observed. Note: NOT EXISTS anti-join decorrelation can still be valid when replacing large correlated anti patterns.
- `INNER_JOIN_REORDERING`: Don't restructure INNER JOIN orders. Focus on LEFT JOIN blocking or comma-join confusion.
- `INDEX_ONLY_SCAN`: Small dimension lookups (<10K rows) may not need CTEs.

### Known Gaps (exploit these)
- `COMMA_JOIN_WEAKNESS` [HIGH] detect: FROM t1, t2, t3 WHERE t1.key = t2.key (comma joins, no explicit JOIN). Poor row estimates in EXPLAIN. | action: Convert comma-joins to explicit JOIN...ON syntax. Best when combined with date_cte_isolate.
- `CORRELATED_SUBQUERY_PARALYSIS` [HIGH] detect: Nested loop in EXPLAIN, inner re-executes aggregate per outer row. SQL: WHERE col > (SELECT AGG FROM ... WHERE outer.key = inner.key). Hash… | action: Convert correlated WHERE to explicit CTE with GROUP BY + JOIN.
- `NON_EQUI_JOIN_INPUT_BLINDNESS` [HIGH] detect: Expensive non-equi join (BETWEEN, <, >) with large inputs on both sides. Neither side filtered. | action: Reduce fact table input size via filtered CTE before the non-equi join.
- `CTE_MATERIALIZATION_FENCE` [MEDIUM] detect: Large CTE + small post-filter. Multi-referenced CTE that blocks predicate pushdown. | action: Materialize STRATEGICALLY: only when CTE is expensive and reused. Avoid fencing single-use cases.
- `CROSS_CTE_PREDICATE_BLINDNESS` [MEDIUM] detect: Sequential scan on dimension table without index condition. Late filter after large scan/join. | action: Pre-filter into CTE definition. But be more cautious than on DuckDB.

## Dispatcher Hypothesis
Nested Loop between date_dim and catalog_sales dominates execution time (170s) with 244 outer rows and 106 inner rows per loop. Pre-aggregating the fact table after joining with filtered date_dim should reduce rows before joining dimensions. Explicit joins may improve cardinality estimates.

## Dispatcher Reasoning Trace
- Cost spine: Index Only Scan → Nested Loop → Hash Joins → Sort → Aggregate
- Nested Loop amplifies 244 date_dim scans into 25,870 catalog_sales accesses
- Late filtering on small dimensions (ship_mode/warehouse) despite selective predicates

## Equivalence Tier
- unordered

## Additional Intelligence
### AST Feature Detection

- **date_cte_explicit_join**: 100% match (AGG_SUM, BETWEEN, CASE_EXPR, DATE_DIM) (gap: COMMA_JOIN_WEAKNESS)  [SUPPORT: native_or_universal]
- **multi_dimension_prefetch**: 100% match (AGG_SUM, CASE_EXPR, DATE_DIM, GROUP_BY) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [SUPPORT: portability_candidate; engines=duckdb]
- **prefetch_fact_join**: 100% match (AGG_SUM, DATE_DIM, GROUP_BY, STAR_JOIN) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: MAX_2_CHAINS] [SUPPORT: portability_candidate; engines=duckdb]
- **dimension_cte_isolate**: 100% match (DATE_DIM, GROUP_BY, MULTI_TABLE_5+) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: CROSS_JOIN_3_DIMS, UNFILTERED_CTE] [SUPPORT: portability_candidate; engines=duckdb]
- **sf_sk_pushdown_multi_fact**: 100% match (DATE_DIM, MULTI_TABLE_5+) (gap: PREDICATE_TRANSITIVITY_FAILURE) [SUPPORT: portability_candidate; engines=snowflake]


## Probe Summary
7 probes fired, 0 passed validation, 0 showed speedup.

## BDA Table (all probes)

| Probe | Transform | Family | Status | Speedup | Top EXPLAIN Nodes | Model Description | SQL Patch | Error/Notes |
|-------|-----------|--------|--------|---------|-------------------|-------------------|-----------|-------------|
| p01 | date_cte_explicit_join | F | ERROR | - | - | Convert comma-join to explicit INNER JOIN syntax between all tables with precise ON conditions | p01 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p04 | materialized_dimension_fact_prefilter | F | ERROR | - | - | Materialize filtered date_dim and catalog_sales join first in CTE | p04 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p07 | early_filter | A | ERROR | - | - | Apply cs_list_price filter directly in catalog_sales scan condition | p07 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p02 | aggregate_pushdown | C | ERROR | - | - | Pre-aggregate catalog_sales joined with date_dim in CTE before joining other dimensions | p02 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p06 | pg_self_join_decomposition | E | ERROR | - | - | Materialize base fact-dimension join as CTE before aggregation | p06 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p05 | dimension_cte_isolate | A | ERROR | - | - | Isolate ship_mode/warehouse/call_center into CTEs with filters applied early | p05 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p03 | dimension_prefetch_star | F | ERROR | - | - | Pre-filter all dimensions into CTEs before joining with catalog_sales | p03 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |

## Worker SQL Patches

### p01: date_cte_explicit_join (ERROR, n/a)
```sql
WITH filtered_date_dim AS (SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1191 AND 1191 + 23) SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 30) AND (cs_ship_date_sk - cs_sold_date_sk <= 60) THEN 1 ELSE 0 END) AS "31-60 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 60) AND (cs_ship_date_sk - cs_sold_date_sk <= 90) THEN 1 ELSE 0 END) AS "61-90 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 90) AND (cs_ship_date_sk - cs_sold_date_sk <= 120) THEN 1 ELSE 0 END) AS "91-120 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 120) THEN 1 ELSE 0 END) AS ">120 days" FROM catalog_sales AS cs INNER JOIN filtered_date_dim AS dd ON cs.cs_ship_date_sk = dd.d_date_sk INNER JOIN warehouse AS w ON cs.cs_warehouse_sk = w.w_warehouse_sk INNER JOIN ship_mode AS sm ON cs.cs_ship_mode_sk = sm.sm_ship_mode_sk INNER JOIN call_center AS cc ON cs.cs_call_center_sk = cc.cc_call_center_sk WHERE d_month_seq BETWEEN 1191 AND 1191 + 23 AND cs_ship_date_sk = d_date_sk AND cs_warehouse_sk = w_warehouse_sk AND cs_ship_mode_sk = sm_ship_mode_sk AND cs_call_center_sk = cc_call_center_sk AND cs_list_price BETWEEN 244 AND 273 AND sm_type = 'LIBRARY' AND cc_class = 'medium' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name LIMIT 100;
```

### p04: materialized_dimension_fact_prefilter (ERROR, n/a)
```sql
WITH filtered_date_sales AS (SELECT cs_ship_date_sk, cs_sold_date_sk, cs_warehouse_sk, cs_ship_mode_sk, cs_call_center_sk FROM catalog_sales JOIN date_dim ON cs_ship_date_sk = d_date_sk WHERE d_month_seq BETWEEN 1191 AND 1191 + 23 AND cs_list_price BETWEEN 244 AND 273) SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 30) AND (cs_ship_date_sk - cs_sold_date_sk <= 60) THEN 1 ELSE 0 END) AS "31-60 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 60) AND (cs_ship_date_sk - cs_sold_date_sk <= 90) THEN 1 ELSE 0 END) AS "61-90 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 90) AND (cs_ship_date_sk - cs_sold_date_sk <= 120) THEN 1 ELSE 0 END) AS "91-120 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 120) THEN 1 ELSE 0 END) AS ">120 days" FROM filtered_date_sales AS fds JOIN warehouse AS w ON fds.cs_warehouse_sk = w_w_warehouse_sk JOIN ship_mode AS sm ON fds.cs_ship_mode_sk = sm.sm_ship_mode_sk JOIN call_center AS cc ON fds.cs_call_center_sk = cc.cc_call_center_sk WHERE d_month_seq BETWEEN 1191 AND 1191 + 23 AND cs_ship_date_sk = d_date_sk AND cs_warehouse_sk = w_warehouse_sk AND cs_ship_mode_sk = sm_ship_mode_sk AND cs_call_center_sk = cc_call_center_sk AND cs_list_price BETWEEN 244 AND 273 AND sm_type = 'LIBRARY' AND cc_class = 'medium' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name LIMIT 100;
```

### p07: early_filter (ERROR, n/a)
```sql
WITH filtered_catalog_sales AS (SELECT * FROM catalog_sales WHERE cs_list_price BETWEEN 244 AND 273) SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 30) AND (cs_ship_date_sk - cs_sold_date_sk <= 60) THEN 1 ELSE 0 END) AS "31-60 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 60) AND (cs_ship_date_sk - cs_sold_date_sk <= 90) THEN 1 ELSE 0 END) AS "61-90 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 90) AND (cs_ship_date_sk - cs_sold_date_sk <= 120) THEN 1 ELSE 0 END) AS "91-120 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 120) THEN 1 ELSE 0 END) AS ">120 days" FROM filtered_catalog_sales, warehouse, ship_mode, call_center, date_dim WHERE d_month_seq BETWEEN 1191 AND 1191 + 23 AND cs_ship_date_sk = d_date_sk AND cs_warehouse_sk = w_warehouse_sk AND cs_ship_mode_sk = sm_ship_mode_sk AND cs_call_center_sk = cc_call_center_sk AND sm_type = 'LIBRARY' AND cc_class = 'medium' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name LIMIT 100;
```

### p02: aggregate_pushdown (ERROR, n/a)
```sql
WITH agg_catalog_sales AS (SELECT cs_warehouse_sk, cs_ship_mode_sk, cs_call_center_sk, cs_ship_date_sk, cs_sold_date_sk, COUNT(*) AS cnt FROM catalog_sales JOIN date_dim ON cs_ship_date_sk = d_date_sk WHERE d_month_seq BETWEEN 1191 AND 1191 + 23 AND cs_list_price BETWEEN 244 AND 273 GROUP BY cs_warehouse_sk, cs_ship_mode_sk, cs_call_center_sk, cs_ship_date_sk, cs_sold_date_sk) SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 30) AND (cs_ship_date_sk - cs_sold_date_sk <= 60) THEN 1 ELSE 0 END) AS "31-60 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 60) AND (cs_ship_date_sk - cs_sold_date_sk <= 90) THEN 1 ELSE 0 END) AS "61-90 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 90) AND (cs_ship_date_sk - cs_sold_date_sk <= 120) THEN 1 ELSE 0 END) AS "91-120 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 120) THEN 1 ELSE 0 END) AS ">120 days" FROM agg_catalog_sales AS acs, warehouse AS w, ship_mode AS sm, call_center AS cc WHERE acs.cs_warehouse_sk = w.w_warehouse_sk AND acs.cs_ship_mode_sk = sm.sm_ship_mode_sk AND acs.cs_call_center_sk = cc.cc_call_center_sk AND sm_type = 'LIBRARY' AND cc_class = 'medium' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name LIMIT 100;
```

### p06: pg_self_join_decomposition (ERROR, n/a)
```sql
WITH filtered_sales_dates AS (SELECT cs_ship_date_sk, cs_sold_date_sk, cs_warehouse_sk, cs_ship_mode_sk, cs_call_center_sk FROM catalog_sales JOIN date_dim ON cs_ship_date_sk = d_date_sk WHERE d_month_seq BETWEEN 1191 AND 1191 + 23) SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 30) AND (cs_ship_date_sk - cs_sold_date_sk <= 60) THEN 1 ELSE 0 END) AS "31-60 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 60) AND (cs_ship_date_sk - cs_sold_date_sk <= 90) THEN 1 ELSE 0 END) AS "61-90 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 90) AND (cs_ship_date_sk - cs_sold_date_sk <= 120) THEN 1 ELSE 0 END) AS "91-120 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 120) THEN 1 ELSE 0 END) AS ">120 days" FROM filtered_sales_dates AS fsd JOIN warehouse AS w ON fsd.cs_warehouse_sk = w_warehouse_sk JOIN ship_mode AS sm ON fsd.cs_ship_mode_sk = sm.sm_ship_mode_sk JOIN call_center AS cc ON fsd.cs_call_center_sk = cc.cc_call_center_sk WHERE sm_type = 'LIBRARY' AND cc_class = 'medium' AND w_gmt_offset = -5 AND cs_list_price BETWEEN 244 AND 273 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name LIMIT 100;
```

### p05: dimension_cte_isolate (ERROR, n/a)
```sql
WITH filtered_ship_mode AS (SELECT sm_ship_mode_sk, sm_type FROM ship_mode WHERE sm_type = 'LIBRARY'), filtered_warehouse AS (SELECT w_warehouse_sk, w_warehouse_name FROM warehouse WHERE w_gmt_offset = -5), filtered_call_center AS (SELECT cc_call_center_sk, cc_name FROM call_center WHERE cc_class = 'medium') SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 30) AND (cs_ship_date_sk - cs_sold_date_sk <= 60) THEN 1 ELSE 0 END) AS "31-60 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 60) AND (cs_ship_date_sk - cs_sold_date_sk <= 90) THEN 1 ELSE 0 END) AS "61-90 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 90) AND (cs_ship_date_sk - cs_sold_date_sk <= 120) THEN 1 ELSE 0 END) AS "91-120 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 120) THEN 1 ELSE 0 END) AS ">120 days" FROM catalog_sales JOIN date_dim ON cs_ship_date_sk = d_date_sk JOIN filtered_warehouse AS fw ON cs_warehouse_sk = fw.w_warehouse_sk JOIN filtered_ship_mode AS fsm ON cs_ship_mode_sk = fsm.sm_ship_mode_sk JOIN filtered_call_center AS fcc ON cs_call_center_sk = fcc.cc_call_center_sk WHERE d_month_seq BETWEEN 1191 AND 1191 + 23 AND cs_ship_date_sk = d_date_sk AND cs_warehouse_sk = w_warehouse_sk AND cs_ship_mode_sk = sm_ship_mode_sk AND cs_call_center_sk = cc_call_center_sk AND cs_list_price BETWEEN 244 AND 273 AND sm_type = 'LIBRARY' AND cc_class = 'medium' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name LIMIT 100;
```

### p03: dimension_prefetch_star (ERROR, n/a)
```sql
WITH filtered_date_dim AS (SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1191 AND 1191 + 23), filtered_warehouse AS (SELECT w_warehouse_sk, w_warehouse_name FROM warehouse WHERE w_gmt_offset = -5), filtered_ship_mode AS (SELECT sm_ship_mode_sk, sm_type FROM ship_mode WHERE sm_type = 'LIBRARY'), filtered_call_center AS (SELECT cc_call_center_sk, cc_name FROM call_center WHERE cc_class = 'medium') SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 30) AND (cs_ship_date_sk - cs_sold_date_sk <= 60) THEN 1 ELSE 0 END) AS "31-60 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 60) AND (cs_ship_date_sk - cs_sold_date_sk <= 90) THEN 1 ELSE 0 END) AS "61-90 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 90) AND (cs_ship_date_sk - cs_sold_date_sk <= 120) THEN 1 ELSE 0 END) AS "91-120 days", SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk > 120) THEN 1 ELSE 0 END) AS ">120 days" FROM catalog_sales AS cs JOIN filtered_date_dim AS dd ON cs.cs_ship_date_sk = dd.d_date_sk JOIN filtered_warehouse AS w ON cs.cs_warehouse_sk = w.w_warehouse_sk JOIN filtered_ship_mode AS sm ON cs.cs_ship_mode_sk = sm.sm_ship_mode_sk JOIN filtered_call_center AS cc ON cs.cs_call_center_sk = cc.cc_call_center_sk WHERE d_month_seq BETWEEN 1191 AND 1191 + 23 AND cs_ship_date_sk = d_date_sk AND cs_warehouse_sk = w_warehouse_sk AND cs_ship_mode_sk = sm_ship_mode_sk AND cs_call_center_sk = cc_call_center_sk AND cs_list_price BETWEEN 244 AND 273 AND sm_type = 'LIBRARY' AND cc_class = 'medium' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name LIMIT 100;
```
