## Role

You are **W3 "Builder"** — Structural optimization — join restructuring, materialization. Restructure join topology and materialize repeated work: convert comma joins to explicit INNER JOIN, extract shared scans into CTEs, prefetch dimension tables.

Transform this SQL query from its CURRENT IR structure to a TARGET IR structure using patch operations. Output a single PatchPlan JSON.

**Family**: E — date_dim_prefetch
**Hypothesis**: Repeated scans of date_dim (d1/d2/d3) with similar filters cause redundant work. Materializing filtered date keys upfront reduces re-evaluation overhead.

## Original SQL

```sql
select 
 i_item_id
 ,i_item_desc
 ,s_store_id
 ,s_store_name
 ,stddev_samp(ss_net_profit) as store_sales_profit
 ,stddev_samp(sr_net_loss) as store_returns_loss
 ,stddev_samp(cs_net_profit) as catalog_sales_profit
 from
 store_sales
 ,store_returns
 ,catalog_sales
 ,date_dim d1
 ,date_dim d2
 ,date_dim d3
 ,store
 ,item
 where
 d1.d_moy = 2
 and d1.d_year = 2000
 and d1.d_date_sk = ss_sold_date_sk
 and i_item_sk = ss_item_sk
 and s_store_sk = ss_store_sk
 and ss_customer_sk = sr_customer_sk
 and ss_item_sk = sr_item_sk
 and ss_ticket_number = sr_ticket_number
 and sr_returned_date_sk = d2.d_date_sk
 and d2.d_moy               between 2 and  2 + 2
 and d2.d_year              = 2000
 and sr_customer_sk = cs_bill_customer_sk
 and sr_item_sk = cs_item_sk
 and cs_sold_date_sk = d3.d_date_sk
 and d3.d_moy               between 2 and  2 + 2
 and d3.d_year              = 2000
 group by
 i_item_id
 ,i_item_desc
 ,s_store_id
 ,s_store_name
 order by
 i_item_id
 ,i_item_desc
 ,s_store_id
 ,s_store_name
 limit 100;
```

## Current IR Node Map

```
S0 [SELECT]
  MAIN QUERY (via Q_S0)
    FROM: store_sales, store_returns, catalog_sales, date_dim d1, date_dim d2, date_dim d3, store, item
    WHERE [b0b26a1f74d8058a]: d1.d_moy = 2 AND d1.d_year = 2000 AND d1.d_date_sk = ss_sold_date_sk AND i_item_sk = ss_item_sk A...
    GROUP BY: i_item_id, i_item_desc, s_store_id, s_store_name
    ORDER BY: i_item_id, i_item_desc, s_store_id, s_store_name

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Target IR (what the optimized query should look like)

```
S0 [SELECT]
  CTE: filtered_dates AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE (d_moy = 2 AND d_year = 2000) OR (d_moy BETWEEN 2 AND 4 AND d_year = 2000)
  )
  MAIN QUERY (via Q_S0)
    FROM: store_sales
      INNER JOIN filtered_dates d1 ON (d1.d_date_sk = ss_sold_date_sk)
      INNER JOIN store ON (s_store_sk = ss_store_sk)
      INNER JOIN item ON (i_item_sk = ss_item_sk)
      INNER JOIN store_returns ON (ss_customer_sk = sr_customer_sk AND ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number)
        INNER JOIN filtered_dates d2 ON (sr_returned_date_sk = d2.d_date_sk)
      INNER JOIN catalog_sales ON (sr_customer_sk = cs_bill_customer_sk AND sr_item_sk = cs_item_sk)
        INNER JOIN filtered_dates d3 ON (cs_sold_date_sk = d3.d_date_sk)
    WHERE: d1.d_moy = 2  -- Additional filter for d1
    GROUP BY: i_item_id, i_item_desc, s_store_id, s_store_name
    ORDER BY: i_item_id, i_item_desc, s_store_id, s_store_name
```

## Patch Operations

| Op | Description | Payload |
|----|-------------|---------|
| insert_cte | Add a new CTE to the WITH clause | cte_name, cte_query_sql |
| replace_from | Replace the FROM clause | from_sql |
| replace_where_predicate | Replace the WHERE clause | expr_sql |
| replace_body | Replace entire query body (SELECT, FROM, WHERE, GROUP BY) | sql_fragment |
| replace_expr_subtree | Replace a specific expression | expr_sql (+ by_anchor_hash) |
| delete_expr_subtree | Remove a specific expression | (target only, no payload) |

## Gold Patch Example (reference pattern)

```json
{
  "plan_id": "gold_duckdb_multi_dimension_prefetch",
  "dialect": "duckdb",
  "description": "Pre-filter multiple dimension tables (date + store) into separate CTEs before joining with fact table",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_dates",
        "cte_query_sql": "SELECT d_date_sk, d_day_name FROM date_dim WHERE d_year = 2000"
      },
      "description": "Insert CTE 'filtered_dates' for date dimension filtering"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_stores",
        "cte_query_sql": "SELECT s_store_sk, s_store_id, s_store_name FROM store WHERE s_gmt_offset = -5"
      },
      "description": "Insert CTE 'filtered_stores'"
    },
    {
      "step_id": "s3",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_sales",
        "cte_query_sql": "SELECT ss_sales_price, d_day_name, s_store_id, s_store_name FROM store_sales JOIN filtered_dates ON d_date_sk = ss_sold_date_sk JOIN filtered_stores ON s_store_sk = ss_store_sk"
      },
      "description": "Insert CTE 'filtered_sales' for date dimension filtering"
    },
    {
      "step_id": "s4",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "filtered_sales"
      },
      "description": "Replace FROM clause with optimized version"
    },
    {
      "step_id": "s5",
      "op": "delete_expr_subtree",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "834e9c75d01a8fa3"
      },
      "description": "Remove WHERE clause (conditions moved to CTEs)"
    }
  ]
}
```

## Instructions

Adapt the gold example pattern to match the ORIGINAL SQL above.
Use the TARGET IR as your structural guide — create CTEs matching the target's CTE names and structure.
Preferred approach: insert_cte (x2-3) + replace_from or replace_body.
All SQL in payloads must be complete, executable fragments (no ellipsis).
Use dialect: "postgres" in the output.
Target all steps at by_node_id: "S0" (the main statement).

Output ONLY the JSON object (no markdown, no explanation):