## Role

You are a **Principal SQL Optimization Reviewer**.
Active SQL dialect is the runtime `postgresql` declared in the Runtime Dialect Contract.

You receive Battle Damage Assessment (BDA) from 4-16 workers.
Your job is to:
1. Evaluate ALL probe outcomes — successes AND failures are evidence.
2. Detect residual hotspot gaps not addressed by any probe.
3. Synthesize the best final tree attempt(s) from the full evidence set.
4. Attempt your own version of sound-but-failed probes when worker execution was the problem.

Success condition:
- produce semantically safe, executable attempt(s)
- maximize expected plan improvement from proven evidence
- return strict JSON only

Failure behavior:
- if evidence is insufficient for a safe rewrite, return one safe no-change attempt

---

## Prompt Map (cache friendly)

### Phase A — Cached Context (static)
A1. Terminology and decision policy
A2. Dialect reminders and regression registry
A3. Combination hazards
A4. Evidence-first compiler procedure
A5. Tree output contract + validation rules
A6. Worked valid and invalid examples

### Phase B — Query-Specific Input (dynamic; after cache boundary)
B1. Importance stars (1-3)
B2. Original SQL and original plan
B3. IR structure and anchor hashes
B4. BDA table (all probes: status, failure_category, speedup, explain delta, failure reasons)
B5. Worker outputs (full SQL and tree evidence)
B6. Schema excerpt (tables, columns, keys, indexes)
B7. Engine-specific knowledge profile

---

## Terminology (normative)

- **winner**: probe with status `WIN` and validated semantics.
- **near_miss**: probe with strong plan impact signal but failed a fixable structural gate.
- **foundation_shape**: the primary candidate shape used as merge base.
- **distinct_pathway**: candidate with materially different mechanism from another candidate.
  Different transform family OR different changed-node set OR different join topology.
- **semantic_drift**: any change to result rows, multiplicity, grouping semantics, literals, aliases, order, or limit behavior.

---

## Input Contract

Required Phase B inputs:
- B2 original SQL
- B4 BDA table
- B5 worker outputs

Optional but useful:
- B3 IR map
- B6 schema context
- B7 engine profile

Missing-input handling:
- if any required input is missing or contradictory, return one safe no-change attempt
- set `confidence` to `0.20` or lower
- explain the missing input in `hypothesis`

---

## Decision Priority Ladder

Resolve conflicts in this strict order:
1. semantic safety
2. executability
3. dialect compliance
4. expected speedup

Never trade higher-priority constraints for lower-priority gains.

---

## Regression Registry (hard bans)

Do not emit a compiler attempt that:
- duplicates base scans after replacement
- introduces unfiltered massive CTEs
- builds over-deep fact chains that lock join order
- changes semantics of EXISTS or NOT EXISTS or aggregation multiplicity
- applies same-column OR to UNION ALL by default on PostgreSQL

OR to UNION exception for PostgreSQL:
- only when EXPLAIN evidence shows OR blocks index usage and UNION branches become index scans

---

## Combination Hazards

- Duplicate source introduction when merging candidates.
- Join multiplicity drift from EXISTS to JOIN rewrites.
- CTE fences blocking pushdown and reorder.
- Overlapping predicate edits that must be unified.
- Alias drift where a referenced alias is not defined in scope.

---

## Failure Analysis Protocol

For each failed probe in the BDA:
1. Read the worker's `failure_reason` and `partial_work`.
2. Classify: was the failure due to (a) flawed hypothesis, (b) execution error, or (c) structural impossibility?
3. For (b) execution errors where hypothesis_still_valid=true: attempt your own version of the rewrite.
4. For (a) flawed hypothesis: note the insight and avoid the same trap.
5. For (c) structural impossibility: document in your hypothesis why this path is blocked.

Failed probes with articulate field notes are MORE valuable than silent successes
— they narrow the search space.

---

## Residual Gap Detection (mandatory)

Before finalizing attempts:
1. List all fact-table scan hotspots from the original plan (by bytes/partitions).
2. For each hotspot, check if ANY successful probe addressed it.
3. If the largest hotspot is unaddressed, you MUST attempt a rewrite targeting it
   (even if no worker succeeded on it).
4. Note the residual coverage percentage in your hypothesis:
   "Probes collectively address X% of original scan volume; Y% remains unaddressed."

---

## Evidence-First Compiler Procedure

1) Parse BDA and rank candidates by validated evidence.
2) Select one foundation shape from strongest safe evidence.
3) Attempt improvement by adding one compatible tactic only when hazards remain controlled.
4) Consider two-attempt output only if there are two distinct pathways.
5) Run semantic and structural self-check before finalizing JSON.

Checkpoint rules:
- reject any merge that introduces multiplicity risk without explicit guard.
- reject any merge where changed nodes conflict on the same predicate scope.
- prefer fewer changed nodes when expected gains are similar.

Tie-break rules when candidates are close:
1. lower semantic risk
2. fewer changed nodes
3. cleaner dependency graph
4. higher expected explain delta

---

## Distinct Pathway Decision Matrix

Output one attempt when:
- one clearly dominant safe pathway exists, or
- alternatives differ only cosmetically.

Output two attempts when:
- both attempts are semantically safe and executable,
- pathways are distinct by mechanism,
- each has non-overlapping justification from BDA evidence,
- each specifies separate `based_on` evidence.

Output three to four attempts when:
- a clear winner exists AND a residual gap attempt is warranted, OR
- multiple distinct safe pathways exist AND a hybrid synthesis is possible.
Maximum: 4 attempts.

---

## Tree Output Contract (MUST follow)

Tier-0 output contract:
- response must be valid JSON
- first character must be `{` or `[` (no leading whitespace/newlines)
- top-level value may be:
  - one object (single attempt), or
  - an array of one to four objects (multiple attempts)
- no markdown fences, no prose, no commentary

Per-attempt schema:

| key | type | required | constraints |
|---|---|---|---|
| `plan_id` | string | yes | non-empty, unique across attempts |
| `dialect` | string | yes | runtime dialect |
| `hypothesis` | string | yes | evidence-grounded, one to three sentences |
| `target_ir` | string | yes | structural intent summary |
| `tree` | object | yes | must satisfy tree validation rules |
| `confidence` | number | recommended | range 0.0 to 1.0 |
| `based_on` | string | recommended | comma-separated probe ids |
| `strategy` | string | recommended | concise mechanism summary |
| `expected_explain_delta` | string | recommended | operator-level expected change |

Tree validation rules:
- `tree.root_node_id` must exist and resolve to a node id in `tree.nodes`
- `tree.nodes` must be a non-empty array
- each node must include `node_id`, `parent_node_id`, `sources`, `outputs`, and `changed`
- changed nodes MUST include full executable SQL in `sql`
- unchanged nodes MUST omit `sql`
- every non-root node must have a resolvable `parent_node_id`
- every source in `sources` must resolve to a node in `tree.nodes` or a valid base source from runtime context
- tree must be acyclic and connected from `root_node_id`
- preserve literals and output semantics exactly
- preserve final output columns, aliases, order, and limit behavior

---

## Worked Valid Example (single attempt object)

{
  "plan_id": "compile_p1",
  "dialect": "duckdb",
  "confidence": 0.84,
  "based_on": "p03",
  "strategy": "Keep winning decorrelation shape and add multiplicity guard.",
  "hypothesis": "Winning probe removed repeated correlated work. Distinct keyset guard preserves multiplicity and keeps output contract stable.",
  "expected_explain_delta": "Nested-loop correlation operators disappear and one hash join over keyset remains.",
  "target_ir": "Add store_averages node and update final_select join graph.",
  "tree": {
    "root_node_id": "final_select",
    "nodes": [
      {
        "node_id": "final_select",
        "parent_node_id": null,
        "sources": ["customer_total_return", "store_averages", "store", "customer"],
        "outputs": ["c_customer_id"],
        "changed": true,
        "sql": "SELECT c_customer_id FROM customer_total_return ctr1 JOIN store_averages sa ON ctr1.ctr_store_sk = sa.ctr_store_sk JOIN store s ON s.s_store_sk = ctr1.ctr_store_sk JOIN customer c ON c.c_customer_sk = ctr1.ctr_customer_sk WHERE s.s_state = 'SD' AND ctr1.ctr_total_return > sa.avg_return ORDER BY c_customer_id LIMIT 100"
      },
      {
        "node_id": "store_averages",
        "parent_node_id": "final_select",
        "sources": ["customer_total_return"],
        "outputs": ["ctr_store_sk", "avg_return"],
        "changed": true,
        "sql": "SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return FROM customer_total_return GROUP BY ctr_store_sk"
      },
      {
        "node_id": "customer_total_return",
        "parent_node_id": "final_select",
        "sources": ["store_returns", "date_dim"],
        "outputs": ["ctr_customer_sk", "ctr_store_sk", "ctr_total_return"],
        "changed": false
      }
    ]
  }
}

---

## Worked Valid Example (two-attempt array)

[
  {
    "plan_id": "compile_p1",
    "dialect": "duckdb",
    "confidence": 0.81,
    "based_on": "p03,p09",
    "strategy": "Decorrelation-first with early aggregate support.",
    "hypothesis": "Primary hotspot is repeated correlated work. This pathway removes repeated scans before aggregation.",
    "expected_explain_delta": "Loop amplification removed and aggregate input reduced.",
    "target_ir": "Update final_select and keep aggregate support node.",
    "tree": {
      "root_node_id": "final_select",
      "nodes": [
        {
          "node_id": "final_select",
          "parent_node_id": null,
          "sources": ["customer_total_return", "store_averages", "store", "customer"],
          "outputs": ["c_customer_id"],
          "changed": true,
          "sql": "SELECT c_customer_id FROM customer_total_return ctr1 JOIN store_averages sa ON ctr1.ctr_store_sk = sa.ctr_store_sk JOIN store s ON s.s_store_sk = ctr1.ctr_store_sk JOIN customer c ON c.c_customer_sk = ctr1.ctr_customer_sk WHERE s.s_state = 'SD' AND ctr1.ctr_total_return > sa.avg_return ORDER BY c_customer_id LIMIT 100"
        },
        {
          "node_id": "store_averages",
          "parent_node_id": "final_select",
          "sources": ["customer_total_return"],
          "outputs": ["ctr_store_sk", "avg_return"],
          "changed": true,
          "sql": "SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return FROM customer_total_return GROUP BY ctr_store_sk"
        },
        {
          "node_id": "customer_total_return",
          "parent_node_id": "final_select",
          "sources": ["store_returns", "date_dim"],
          "outputs": ["ctr_customer_sk", "ctr_store_sk", "ctr_total_return"],
          "changed": false
        }
      ]
    }
  },
  {
    "plan_id": "compile_p2",
    "dialect": "duckdb",
    "confidence": 0.76,
    "based_on": "p11",
    "strategy": "Aggregate-first pathway with safe join topology.",
    "hypothesis": "Secondary pathway pre-aggregates earlier to reduce rows entering the final join spine.",
    "expected_explain_delta": "Aggregate input shrinks before final join operators.",
    "target_ir": "Change customer_total_return shape and keep final_select projection contract.",
    "tree": {
      "root_node_id": "final_select",
      "nodes": [
        {
          "node_id": "final_select",
          "parent_node_id": null,
          "sources": ["customer_total_return", "store", "customer"],
          "outputs": ["c_customer_id"],
          "changed": false
        },
        {
          "node_id": "customer_total_return",
          "parent_node_id": "final_select",
          "sources": ["store_returns", "date_dim"],
          "outputs": ["ctr_customer_sk", "ctr_store_sk", "ctr_total_return"],
          "changed": true,
          "sql": "SELECT sr.sr_customer_sk AS ctr_customer_sk, sr.sr_store_sk AS ctr_store_sk, SUM(sr.sr_fee) AS ctr_total_return FROM store_returns sr JOIN date_dim d ON sr.sr_returned_date_sk = d.d_date_sk WHERE d.d_year = 2000 GROUP BY sr.sr_customer_sk, sr.sr_store_sk"
        }
      ]
    }
  }
]

---

## Worked Invalid Example (do not produce)

{
  "plan_id": "compile_bad",
  "dialect": "duckdb",
  "hypothesis": "Fast result",
  "target_ir": "mixed",
  "tree": {
    "root_node_id": "missing_node",
    "nodes": [
      {
        "node_id": "final_select",
        "parent_node_id": "missing_parent",
        "sources": ["unknown_node"],
        "outputs": ["c_customer_id"],
        "changed": true
      }
    ]
  }
}

Why invalid:
- `root_node_id` does not resolve
- unresolved parent `missing_parent`
- unresolved source `unknown_node`
- changed node missing required `sql`

Corrective action:
- emit a structurally valid tree
- include full SQL for each changed node
- resolve all dependencies

---

## Safe No-Change Fallback (required capability)

If evidence is insufficient or required inputs are missing, output one valid no-change attempt:
- keep all nodes `changed: false`
- preserve executable tree structure
- explain missing evidence in `hypothesis`

---

## Cache Boundary
Everything below is query-specific input.

## Query ID
query059_multi_i1

## Runtime Dialect Contract
- target_dialect: postgres
- runtime_dialect_is_source_of_truth: true
- if static examples conflict, follow runtime dialect behavior

## Importance
- importance_stars: 1
- importance_label: *

## Original SQL
```sql
with wss as
 (select d_week_seq,
        ss_store_sk,
        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,
        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,
        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,
        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,
        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,
        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,
        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales
 from store_sales,date_dim
 where d_date_sk = ss_sold_date_sk
 and ss_sales_price / ss_list_price BETWEEN 57 * 0.01 AND 77 * 0.01
 group by d_week_seq,ss_store_sk
 )
  select  s_store_name1,s_store_id1,d_week_seq1
       ,sun_sales1/sun_sales2,mon_sales1/mon_sales2
       ,tue_sales1/tue_sales2,wed_sales1/wed_sales2,thu_sales1/thu_sales2
       ,fri_sales1/fri_sales2,sat_sales1/sat_sales2
 from
 (select s_store_name s_store_name1,wss.d_week_seq d_week_seq1
        ,s_store_id s_store_id1,sun_sales sun_sales1
        ,mon_sales mon_sales1,tue_sales tue_sales1
        ,wed_sales wed_sales1,thu_sales thu_sales1
        ,fri_sales fri_sales1,sat_sales sat_sales1
  from wss,store,date_dim d
  where d.d_week_seq = wss.d_week_seq and
        ss_store_sk = s_store_sk and
        d_month_seq between 1187 and 1187 + 11
        and s_state in ('AR','CO','IA'
                    ,'IL','NC','NY','PA','TX')
        ) y,
 (select s_store_name s_store_name2,wss.d_week_seq d_week_seq2
        ,s_store_id s_store_id2,sun_sales sun_sales2
        ,mon_sales mon_sales2,tue_sales tue_sales2
        ,wed_sales wed_sales2,thu_sales thu_sales2
        ,fri_sales fri_sales2,sat_sales sat_sales2
  from wss,store,date_dim d
  where d.d_week_seq = wss.d_week_seq and
        ss_store_sk = s_store_sk and
        d_month_seq between 1187+ 12 and 1187 + 23
        and s_state in ('AR','CO','IA'
                    ,'IL','NC','NY','PA','TX')) x
 where s_store_id1=s_store_id2
   and d_week_seq1=d_week_seq2-52
 order by s_store_name1,s_store_id1,d_week_seq1
limit 100;
```

## Original Plan
```
Limit  (rows=100, time=31799.119)
  Aggregate  (rows=9176, time=31357.981)
    Gather Merge  (rows=6944132, time=30531.497)
      Sort  (rows=2314711, time=27100.516)
        Nested Loop  (rows=2314711, time=20781.586)
          Seq Scan on store_sales  (rows=2342989, time=20251.452)
          Memoize  (rows=1, time=0.0)
            Index Scan on date_dim  (rows=1, time=0.008)
  Sort  (rows=100, time=31367.194)
    Hash Join  (rows=10176, time=31365.747)
      Hash Join  (rows=1184, time=25113.772)
        CTE Scan (wss)  (rows=9176, time=25112.548)
        Hash  (rows=10, time=0.826)
          Seq Scan on store  (rows=10, time=0.816)
      Hash  (rows=10176, time=6246.72)
        Hash Join  (rows=10176, time=6244.978)
          Hash Join  (rows=1464, time=6243.147)
            Hash Join  (rows=1184, time=6242.317)
              CTE Scan (wss_1)  (rows=9176, time=6239.604)
              Hash  (rows=10, time=0.038)
                Seq Scan on store (store_1)  (rows=10, time=0.034)
            Hash  (rows=366, time=0.423)
              Index Scan on date_dim (d_1)  (rows=366, time=0.404)
          Hash  (rows=365, time=1.339)
            Index Scan on date_dim (d)  (rows=365, time=1.316)
```

## Current TREE Node Map
```
## Base Tree Spec
Use this as the authoritative node tree for rewrite proposals.

node: wss
  parent_node_id: final_select
  sources: ['store_sales', 'date_dim']
  outputs: ['d_week_seq', 'ss_store_sk', 'sun_sales', 'mon_sales', 'tue_sales', 'wed_sales', 'thu_sales', 'fri_sales', 'sat_sales']
  sql: OMITTED

node: final_select
  parent_node_id: None
  sources: ['wss', 'store', 'date_dim']
  outputs: ['s_store_name1', 's_store_id1', 'd_week_seq1', 'sun_sales1 / sun_sales2', 'mon_sales1 / mon_sales2', 'tue_sales1 / tue_sales2', 'wed_sales1 / wed_sales2', 'thu_sales1 / thu_sales2', 'fri_sales1 / fri_sales2', 'sat_sales1 / sat_sales2']
  sql: OMITTED

root_node_id: final_select
```

## Schema / Index / Stats Context
- source: postgres
- referenced_tables: 3

| Table | Rows(est) | PK | Indexes |
|-------|-----------|----|---------|
| date_dim | 73049 | d_date_sk | date_dim_pkey, _dta_index_date_dim_6_661577395__k1_k7_k9, _dta_index_date_dim_6_661577395__k4_1, _dta_index_date_dim_6_661577395__k4_k3, _dta_index_date_dim_6_661577395__k7_k1, _dta_index_date_dim_6_661577395__k7_k11_k1 |
| store | 102 | s_store_sk | store_pkey, _dta_index_store_6_885578193__k1_2_6, _dta_index_store_6_885578193__k25_k1 |
| store_sales | 28800492 | ss_item_sk, ss_ticket_number | store_sales_pkey, _dta_index_store_sales_5_1333579789__k4_k8_k3_k1_16, _dta_index_store_sales_6_1333579789__k10_k3, _dta_index_store_sales_6_1333579789__k1_k23_k14_k6_k8_k5_k7_3_4, _dta_index_store_sales_6_1333579789__k1_k3_11_13, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_23 |

### Column Signatures
| Table | Column | Type | Nullable | Key Hint |
|-------|--------|------|----------|----------|
| date_dim | d_date_sk | integer | NO | PK |
| date_dim | d_date_id | character | NO | - |
| date_dim | d_date | date | YES | - |
| date_dim | d_month_seq | integer | YES | - |
| date_dim | d_week_seq | integer | YES | - |
| date_dim | d_quarter_seq | integer | YES | - |
| date_dim | d_year | integer | YES | - |
| date_dim | d_dow | integer | YES | - |
| date_dim | d_moy | integer | YES | - |
| date_dim | d_dom | integer | YES | - |
| date_dim | d_qoy | integer | YES | - |
| date_dim | d_fy_year | integer | YES | - |
| date_dim | d_fy_quarter_seq | integer | YES | - |
| date_dim | d_fy_week_seq | integer | YES | - |
| date_dim | d_day_name | character | YES | - |
| date_dim | d_quarter_name | character | YES | - |
| date_dim | d_holiday | character | YES | - |
| date_dim | d_weekend | character | YES | - |
| date_dim | d_following_holiday | character | YES | - |
| date_dim | d_first_dom | integer | YES | - |
| date_dim | d_last_dom | integer | YES | - |
| date_dim | d_same_day_ly | integer | YES | - |
| date_dim | d_same_day_lq | integer | YES | - |
| date_dim | d_current_day | character | YES | - |
| store | s_store_sk | integer | NO | PK |
| store | s_store_id | character | NO | - |
| store | s_rec_start_date | date | YES | - |
| store | s_rec_end_date | date | YES | - |
| store | s_closed_date_sk | integer | YES | - |
| store | s_store_name | character varying | YES | - |
| store | s_number_employees | integer | YES | - |
| store | s_floor_space | integer | YES | - |
| store | s_hours | character | YES | - |
| store | s_manager | character varying | YES | - |
| store | s_market_id | integer | YES | - |
| store | s_geography_class | character varying | YES | - |
| store | s_market_desc | character varying | YES | - |
| store | s_market_manager | character varying | YES | - |
| store | s_division_id | integer | YES | - |
| store | s_division_name | character varying | YES | - |
| store | s_company_id | integer | YES | - |
| store | s_company_name | character varying | YES | - |
| store | s_street_number | character varying | YES | - |
| store | s_street_name | character varying | YES | - |
| store | s_street_type | character | YES | - |
| store | s_suite_number | character | YES | - |
| store | s_city | character varying | YES | - |
| store | s_county | character varying | YES | - |
| store_sales | ss_sold_date_sk | integer | YES | - |
| store_sales | ss_sold_time_sk | integer | YES | - |
| store_sales | ss_item_sk | integer | NO | PK |
| store_sales | ss_customer_sk | integer | YES | - |
| store_sales | ss_cdemo_sk | integer | YES | - |
| store_sales | ss_hdemo_sk | integer | YES | - |
| store_sales | ss_addr_sk | integer | YES | - |
| store_sales | ss_store_sk | integer | YES | - |
| store_sales | ss_promo_sk | integer | YES | - |
| store_sales | ss_ticket_number | integer | NO | PK |
| store_sales | ss_quantity | integer | YES | - |
| store_sales | ss_wholesale_cost | numeric | YES | - |
| store_sales | ss_list_price | numeric | YES | - |
| store_sales | ss_sales_price | numeric | YES | - |
| store_sales | ss_ext_discount_amt | numeric | YES | - |
| store_sales | ss_ext_sales_price | numeric | YES | - |
| store_sales | ss_ext_wholesale_cost | numeric | YES | - |
| store_sales | ss_ext_list_price | numeric | YES | - |
| store_sales | ss_ext_tax | numeric | YES | - |
| store_sales | ss_coupon_amt | numeric | YES | - |
| store_sales | ss_net_paid | numeric | YES | - |
| store_sales | ss_net_paid_inc_tax | numeric | YES | - |
| store_sales | ss_net_profit | numeric | YES | - |

## Engine-Specific Knowledge
## Dialect Intelligence (POSTGRESQL)

# PostgreSQL Dialect Knowledge

## Engine Strengths (Do Not Fight)
| Strength ID | Summary | Implication | Evidence |
|---|---|---|---|
| `BITMAP_OR_SCAN` | Indexed OR predicates use BitmapOr. | Avoid default OR-to-UNION rewrites when indexes are already used. | `engine_profile_postgresql.json` |
| `SEMI_JOIN_EXISTS` | EXISTS/NOT EXISTS use semi-join early-stop. | Protect EXISTS paths from materialization rewrites. | `engine_profile_postgresql.json` |
| `INNER_JOIN_REORDERING` | Inner joins reorder well via cost model. | Prefer cardinality reduction over manual join-order forcing. | `engine_profile_postgresql.json` |
| `INDEX_ONLY_SCAN` | Covering indexes can avoid heap reads. | Small dimensions may not benefit from heavy CTE staging. | `engine_profile_postgresql.json` |
| `PARALLEL_QUERY_EXECUTION` | Large scans/aggregates parallelize. | Extra CTE fences can reduce useful parallelism. | `engine_profile_postgresql.json` |
| `JIT_COMPILATION` | Complex expressions are JIT-compiled on longer runs. | Expression complexity alone is not always the runtime bottleneck. | `engine_profile_postgresql.json` |

## Global Guards
| Guard ID | Rule | Severity | Fail Action | Source |
|---|---|---|---|---|
| `G_PG_OR_INDEX_PROTECTED` | Do not split same-column indexed OR predicates into UNION ALL. | `BLOCKER` | `SKIP_TRANSFORM` | `BITMAP_OR_SCAN`, `0.21x`, `0.26x` regressions |
| `G_PG_EXISTS_PROTECTED` | Keep simple EXISTS/NOT EXISTS in native semi-join form. | `BLOCKER` | `SKIP_TRANSFORM` | `SEMI_JOIN_EXISTS`, `0.50x`, `0.75x` regressions |
| `G_PG_CTE_DUPLICATION_STOP` | Never duplicate a 5+ table CTE body to push filters inward. | `BLOCKER` | `SKIP_TRANSFORM` | `CTE_MATERIALIZATION_FENCE` field notes |
| `G_PG_SCALE_VALIDATION` | Validate at target scale before promoting rewrite. | `HIGH` | `REQUIRE_MANUAL_REVIEW` | SF5->SF10 drift note in profile |
| `G_PG_LOW_BASELINE_SKIP_HEAVY` | If baseline is low (`<100ms`), avoid structural rewrite churn. | `MEDIUM` | `DOWNRANK_TO_EXPLORATION` | existing knowledge guidance |
| `G_PG_EXPLICIT_JOIN_STYLE` | Normalize comma joins to explicit `JOIN ... ON`. | `MEDIUM` | `DOWNRANK_TO_EXPLORATION` | `COMMA_JOIN_WEAKNESS` |

## Decision Gates (Normative Contract)
| Gate ID | Scope | Type | Severity | Check | Pass Criteria | Fail Action | Evidence Required |
|---|---|---|---|---|---|---|---|
| `DG_TYPE_ENUM` | global | `SEMANTIC_RISK` | `BLOCKER` | Gate type validity | One of `SQL_PATTERN`, `PLAN_SIGNAL`, `RUNTIME_CONTEXT`, `SEMANTIC_RISK` | `REQUIRE_MANUAL_REVIEW` | gate row schema |
| `DG_SEVERITY_ENUM` | global | `SEMANTIC_RISK` | `BLOCKER` | Severity validity | One of `BLOCKER`, `HIGH`, `MEDIUM` | `REQUIRE_MANUAL_REVIEW` | gate row schema |
| `DG_FAIL_ACTION_ENUM` | global | `SEMANTIC_RISK` | `BLOCKER` | Fail action validity | One of `SKIP_PATHOLOGY`, `SKIP_TRANSFORM`, `DOWNRANK_TO_EXPLORATION`, `REQUIRE_MANUAL_REVIEW` | `REQUIRE_MANUAL_REVIEW` | gate row schema |
| `DG_BLOCKER_POLICY` | global | `RUNTIME_CONTEXT` | `BLOCKER` | Any blocker failed | Failed blocker always blocks that pattern/transform path | `SKIP_PATHOLOGY` | failed gate log |
| `DG_MIN_PATTERN_GATES` | pattern | `RUNTIME_CONTEXT` | `HIGH` | Gate coverage | Each pattern has at least 1 `SEMANTIC_RISK`, 1 `PLAN_SIGNAL`, 1 `RUNTIME_CONTEXT` gate | `REQUIRE_MANUAL_REVIEW` | pattern gate table |
| `DG_EVIDENCE_BINDING` | global | `RUNTIME_CONTEXT` | `HIGH` | Claim traceability | Quantitative claims map to example IDs or benchmark artifacts | `REQUIRE_MANUAL_REVIEW` | evidence table row |

## Gap-Driven Optimization Patterns

### Pattern ID: `COMMA_JOIN_WEAKNESS` (`HIGH`)
- Goal: `ARM_THE_OPTIMIZER`
- Detect: comma-separated FROM with join predicates in WHERE and poor row estimates.
- Preferred transforms: `date_cte_explicit_join`, `dimension_prefetch_star`, `explicit_join_materialized`.

#### Decision Gates for `COMMA_JOIN_WEAKNESS`
| Gate ID | Type | Severity | Check | Pass Criteria | Fail Action | Evidence |
|---|---|---|---|---|---|---|
| `G_PG_COMMA_JOIN_PRESENT` | `SQL_PATTERN` | `HIGH` | Comma-join pattern exists | Multiple comma-joined relations with equi-join predicates | `SKIP_TRANSFORM` | SQL parse |
| `G_PG_COMMA_FACT_FANOUT` | `RUNTIME_CONTEXT` | `HIGH` | Fact-table fanout | 1-2 fact tables; avoid broad multi-fact lockups | `DOWNRANK_TO_EXPLORATION` | join graph |
| `G_PG_COMMA_SEMANTIC` | `SEMANTIC_RISK` | `MEDIUM` | Explicit-join conversion safety | Join predicates preserved exactly | `REQUIRE_MANUAL_REVIEW` | predicate diff |

#### Evidence Table
| Example ID | Query | Warehouse | Validation | Orig ms | Opt ms | Speedup | Outcome |
|---|---|---|---|---:|---:|---:|---|
| `pg_explicit_join_materialized` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `8.56x` | `WIN` |
| `pg_dimension_prefetch_star` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `3.32x` | `WIN` |
| `pg_date_cte_explicit_join` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `2.28x` | `WIN` |

#### Failure Modes
| Pattern | Impact | Triggered Gate | Mitigation |
|---|---|---|---|
| Existing explicit join order rewritten unnecessarily | qualitative risk | `G_PG_COMMA_JOIN_PRESENT` | skip when joins already explicit |

### Pattern ID: `CORRELATED_SUBQUERY_PARALYSIS` (`HIGH`)
- Goal: `SETS_OVER_LOOPS`
- Detect: correlated scalar aggregate subquery re-executes per outer row.
- Preferred transforms: `inline_decorrelate_materialized`, `pg_shared_scan_decorrelate`, `pg_state_avg_decorrelate`, `early_filter_decorrelate`.

#### Decision Gates for `CORRELATED_SUBQUERY_PARALYSIS`
| Gate ID | Type | Severity | Check | Pass Criteria | Fail Action | Evidence |
|---|---|---|---|---|---|---|
| `G_PG_CORR_SCALAR_REQUIRED` | `SQL_PATTERN` | `BLOCKER` | Correlated scalar aggregate exists | Pattern present and correlation key identified | `SKIP_PATHOLOGY` | SQL + AST |
| `G_PG_CORR_ALREADY_DECORRELATED` | `PLAN_SIGNAL` | `HIGH` | Already hash-decorrelated | Skip if plan already flattened on correlation key | `SKIP_TRANSFORM` | EXPLAIN |
| `G_PG_CORR_EXISTS_PROTECTION` | `SEMANTIC_RISK` | `BLOCKER` | EXISTS/NOT EXISTS transform request | Keep EXISTS protected | `SKIP_PATHOLOGY` | SQL + plan |
| `G_PG_CORR_FACT_COUNT` | `RUNTIME_CONTEXT` | `HIGH` | Fact-join complexity | 1-2 fact tables preferred; 3+ needs manual review | `REQUIRE_MANUAL_REVIEW` | join graph |

#### Evidence Table
| Example ID | Query | Warehouse | Validation | Orig ms | Opt ms | Speedup | Outcome |
|---|---|---|---|---:|---:|---:|---|
| `pg_shared_scan_decorrelate` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `8043.91x (timeout rescue)` | `WIN` |
| `inline_decorrelate_materialized` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `1465x (timeout rescue)` | `WIN` |
| `pg_state_avg_decorrelate` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `438.93x (timeout rescue)` | `WIN` |
| `early_filter_decorrelate` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `27.80x` | `WIN` |

#### Failure Modes
| Pattern | Impact | Triggered Gate | Mitigation |
|---|---|---|---|
| EXISTS path materialized | `0.75x` | `G_PG_CORR_EXISTS_PROTECTION` | preserve semi-join EXISTS shape |
| Multi-fact lock during decorrelation | `0.51x` | `G_PG_CORR_FACT_COUNT` | avoid aggressive decorrelation on broad multi-fact joins |

### Pattern ID: `NON_EQUI_JOIN_INPUT_BLINDNESS` (`HIGH`)
- Goal: `MINIMIZE_ROWS_TOUCHED`
- Detect: non-equi join with high input cardinality and late selectivity.
- Preferred transforms: `materialized_dimension_fact_prefilter`.

#### Decision Gates for `NON_EQUI_JOIN_INPUT_BLINDNESS`
| Gate ID | Type | Severity | Check | Pass Criteria | Fail Action | Evidence |
|---|---|---|---|---|---|---|
| `G_PG_NONEQUI_PRESENT` | `SQL_PATTERN` | `HIGH` | Non-equi predicate exists | BETWEEN/< /> on join path | `SKIP_TRANSFORM` | SQL parse |
| `G_PG_NONEQUI_CARDINALITY` | `PLAN_SIGNAL` | `HIGH` | Input size pressure | Large inputs on both sides with late drop | `DOWNRANK_TO_EXPLORATION` | plan rows |
| `G_PG_NONEQUI_FILTER_QUALITY` | `SEMANTIC_RISK` | `HIGH` | Prefilter selectivity realism | Tight, not loose superset prefilter | `SKIP_TRANSFORM` | predicate audit |

#### Evidence Table
| Example ID | Query | Warehouse | Validation | Orig ms | Opt ms | Speedup | Outcome |
|---|---|---|---|---:|---:|---:|---|
| `pg_materialized_dimension_fact_prefilter` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `12.07x` | `WIN` |

#### Failure Modes
| Pattern | Impact | Triggered Gate | Mitigation |
|---|---|---|---|
| Loose OR/UNION superset filter | `0.79x` | `G_PG_NONEQUI_FILTER_QUALITY` | require tight prefilter predicates only |

### Pattern ID: `CTE_MATERIALIZATION_FENCE` (`MEDIUM`)
- Goal: `ARM_THE_OPTIMIZER`
- Detect: large CTE fences block predicate pushdown or parallel flow.
- Preferred transforms: strategic materialization only when reuse is real.

#### Decision Gates for `CTE_MATERIALIZATION_FENCE`
| Gate ID | Type | Severity | Check | Pass Criteria | Fail Action | Evidence |
|---|---|---|---|---|---|---|
| `G_PG_CTE_DUPLICATION_BLOCK` | `SEMANTIC_RISK` | `BLOCKER` | CTE body duplication | No duplication of heavy CTE bodies | `SKIP_PATHOLOGY` | rewrite diff |
| `G_PG_CTE_REUSE_REQUIRED` | `RUNTIME_CONTEXT` | `HIGH` | Reuse benefit | CTE has meaningful multi-consumer reuse | `DOWNRANK_TO_EXPLORATION` | reference count |
| `G_PG_CTE_EXISTS_INTERSECT_RISK` | `PLAN_SIGNAL` | `HIGH` | High-risk contexts | avoid problematic EXISTS or INTERSECT fences | `SKIP_TRANSFORM` | SQL + EXPLAIN |

#### Evidence Table
| Example ID | Query | Warehouse | Validation | Orig ms | Opt ms | Speedup | Outcome |
|---|---|---|---|---:|---:|---:|---|
| `profile_note_strategic_materialization` | `n/a` | `n/a` | `engine profile` | `n/a` | `n/a` | `1.95x` | `WIN` |

#### Failure Modes
| Pattern | Impact | Triggered Gate | Mitigation |
|---|---|---|---|
| Fence blocked pushdown | `0.74x` | `G_PG_CTE_REUSE_REQUIRED` | avoid forced fence without reuse |
| Date CTE fence blocked INTERSECT optimization | `0.77x` | `G_PG_CTE_EXISTS_INTERSECT_RISK` | avoid fence in set-operation paths |
| Duplicated 18-table CTE body | `0.65x` | `G_PG_CTE_DUPLICATION_BLOCK` | filter materialized output, not CTE body copy |

### Pattern ID: `CROSS_CTE_PREDICATE_BLINDNESS` (`MEDIUM`)
- Goal: `SMALLEST_SET_FIRST`
- Detect: selective predicates applied too late after CTE boundaries.
- Preferred transforms: `date_cte_explicit_join`, `early_filter_decorrelate`, explicit join cleanup.

#### Decision Gates for `CROSS_CTE_PREDICATE_BLINDNESS`
| Gate ID | Type | Severity | Check | Pass Criteria | Fail Action | Evidence |
|---|---|---|---|---|---|---|
| `G_PG_CROSS_CTE_COMMA_JOIN_PAIRING` | `SQL_PATTERN` | `HIGH` | Comma-join pairing with filter push | perform explicit join cleanup with push | `DOWNRANK_TO_EXPLORATION` | SQL rewrite plan |
| `G_PG_CROSS_CTE_SCALE_GUARD` | `RUNTIME_CONTEXT` | `HIGH` | Target-scale confidence | evidence validated near target scale | `REQUIRE_MANUAL_REVIEW` | benchmark scope |
| `G_PG_CROSS_CTE_SETOP_RISK` | `SEMANTIC_RISK` | `MEDIUM` | Set-op sensitivity | avoid blind pushdown through INTERSECT/EXCEPT-heavy shapes | `SKIP_TRANSFORM` | SQL structure |

#### Evidence Table
| Example ID | Query | Warehouse | Validation | Orig ms | Opt ms | Speedup | Outcome |
|---|---|---|---|---:|---:|---:|---|
| `pg_date_cte_explicit_join` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `2.28x` | `WIN` |
| `pg_dimension_prefetch_star` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `3.32x` | `WIN` |
| `early_filter_decorrelate` | `n/a` | `n/a` | `n/a` | `n/a` | `n/a` | `27.80x` | `WIN` |

#### Failure Modes
| Pattern | Impact | Triggered Gate | Mitigation |
|---|---|---|---|
| SF5 win did not hold at SF10 | `0.97x` at target | `G_PG_CROSS_CTE_SCALE_GUARD` | require target-scale validation |
| Over-decomposition of efficient query | `0.55x` | `G_PG_CROSS_CTE_SETOP_RISK` | avoid excessive decomposition |

## Pruning Guide
| Plan shows | Skip |
|---|---|
| All joins already explicit and estimates stable | `COMMA_JOIN_WEAKNESS` |
| No correlated scalar aggregate in SQL/plan | `CORRELATED_SUBQUERY_PARALYSIS` |
| No non-equi join predicate | `NON_EQUI_JOIN_INPUT_BLINDNESS` |
| CTE is single-use and not expensive | `CTE_MATERIALIZATION_FENCE` |
| Predicate already applied at the earliest valid node | `CROSS_CTE_PREDICATE_BLINDNESS` |
| Baseline < 100ms | most structural rewrite paths |

## Regression Registry
| Severity | Transform | Speedup | Query | Root Cause |
|---|---|---:|---|---|
| `SEVERE` | `or_to_union` style split on indexed OR | `0.21x` | `n/a` | fought BitmapOr strength |
| `SEVERE` | `or_to_union` style split on indexed OR | `0.26x` | `n/a` | fought BitmapOr strength |
| `MAJOR` | decorrelation on protected EXISTS path | `0.50x` | `n/a` | semi-join path broken |
| `MODERATE` | broad decorrelation on multi-fact shape | `0.51x` | `n/a` | join-order lock |
| `MODERATE` | duplicated deep CTE body | `0.65x` | `n/a` | forced materialization cost |
| `MODERATE` | CTE fence blocked pushdown | `0.74x` | `n/a` | optimization fence |
| `MODERATE` | CTE fence harmed set-op path | `0.77x` | `n/a` | blocked INTERSECT optimization |
| `MINOR` | loose prefilter before non-equi join | `0.79x` | `n/a` | low-selectivity staging |

## Notes
- Config tuning is separate from rewrite logic. Use `knowledge/config/postgresql.json` after semantic-safe SQL is established.
- `set_local_config_intel` in engine profile is authoritative for runtime knobs, not this rewrite playbook.

## Analyst Hypothesis
The CTE wss scans the entire store_sales table (28.8M rows) and aggregates before applying selective date_dim filters, causing 20+ seconds of unnecessary I/O. Pushing date filters into the CTE via separate materialized CTEs per date range should reduce fact scan volume by ~24x (two 12-month ranges vs full table).

## Analyst Reasoning Trace
- Seq Scan on store_sales in wss CTE takes 20251 ms and reads 2.34M rows (full table scan).
- Outer query filters date_dim.d_month_seq to two 12-month ranges (1187-1198 and 1199-1210) but these filters are applied after the CTE aggregation.
- Plan shows two separate CTE scans (wss and wss_1) with identical logic, indicating repeated work.
- Hash Join in y branch (25113 ms) dominates runtime after the initial scan.

## Equivalence Tier
- unordered

## Additional Intelligence (Pre-screening Context)
AST/pathology pre-screening results for this query; use them to validate transform applicability against engine gates.

### AST Feature Detection
AST pre-screening results for this query; use to validate transform applicability against runtime gates.

- **date_cte_explicit_join**: 100% match (AGG_SUM, BETWEEN, CASE_EXPR, DATE_DIM) (gap: COMMA_JOIN_WEAKNESS)  [SUPPORT: native_or_universal]
- **multi_dimension_prefetch**: 100% match (AGG_SUM, CASE_EXPR, DATE_DIM, GROUP_BY) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [SUPPORT: portability_candidate; engines=duckdb]
- **deferred_window_aggregation**: 86% match (AGG_SUM, BETWEEN, CASE_EXPR, CTE) [SUPPORT: portability_candidate; engines=duckdb]
  Missing: WINDOW_FUNC
- **decorrelate**: 83% match (AGG_SUM, CORRELATED_SUB, CTE, DATE_DIM) (gap: CORRELATED_SUBQUERY_PARALYSIS) [CAUTION: MISSING_FILTER, ALREADY_DECORRELATED] [SUPPORT: portability_candidate; engines=duckdb]
  Missing: AGG_AVG
- **early_filter_decorrelate**: 83% match (AGG_SUM, BETWEEN, CTE, DATE_DIM) (gap: CORRELATED_SUBQUERY_PARALYSIS)  [SUPPORT: native_or_universal]
  Missing: AGG_AVG


## Estimation Errors (Q-Error)
### §2b-i. Cardinality Estimation Routing (Q-Error)

Direction: UNDER_EST (actual >> estimated — planner under-provisions this operator)
Locus: JOIN — worst mismatch at Hash Join (est=1, act=10K)

Pathology routing: P2, P0, P6, P5, P1
(Locus+Direction routing is 85% accurate at predicting where the winning transform operates)

Structural signals:
  - EST_ONE_NONLEAF: planner guessing on non-leaf node → check P0 (predicate pushback), P1 (repeated scans). Only P2 (decorrelation) if nested loops + correlated subquery confirmed in EXPLAIN
  - REPEATED_TABLE: same table scanned multiple times → single-pass opportunity (P1)

IMPORTANT: Cross-check structural signals against the PRUNING GUIDE in §III. If the EXPLAIN shows no nested loops, skip P2. If each table appears once, skip P1. The pruning guide overrides routing suggestions.


## Probe Summary
4 probes fired, 1 passed validation, 1 showed speedup.

## BDA Table (all probes)

| Probe | Transform | Family | Status | Failure Category | Speedup | Rank Rationale | Top EXPLAIN Nodes | Model Description | SQL Patch | Failure Reason | Partial Work | Error/Notes |
|-------|-----------|--------|--------|------------------|---------|----------------|-------------------|-------------------|-----------|----------------|--------------|-------------|
| p01 | multi_date_range_cte | A | WIN | none | 1.36x (6211→4574ms) | Targets primary hotspot — eliminates full store_sales scan by pushing date filters into CTE definitions. | - | [scout:qwen/qwen3-coder] Replace the single wss CTE with two materialized CTEs (wss_y, wss_x) that embed the respective date_dim.d_month_seq filters (1187-1198 and 1199-1210) directly in their definitions, joining store_sales only with rows from the required date ranges. | p01 |  | - |  |
| p02 | dimension_prefetch_star | F | REGRESSION | regression | 0.37x (6211→16909ms) | Addresses secondary hotspot — improves join planning and reduces fact scan via prefetched dimension keys. | - | [scout:qwen/qwen3-coder] Pre-filter store and date_dim into materialized CTEs before joining with store_sales in the wss CTE, and convert comma joins to explicit JOIN syntax to improve cardinality estimates. | p02 |  | - |  |
| p03 | pg_self_join_decomposition | E | REGRESSION | regression | 0.85x (6211→7342ms) | Exploration — tests whether materialization reuse beats filtered scans, targeting the repeated‑scan pattern. | - | [scout:qwen/qwen3-coder] Materialize the base wss CTE once with all data, then create two derived CTEs that filter by the respective date ranges via join with date_dim, avoiding recomputation of the full aggregation. | p03 |  | - |  |
| p04 | aggregate_pushdown | C | REGRESSION | regression | 0.37x (6211→16910ms) | Exploration — targets aggregation‑after‑join pattern; may reduce compute in the wss CTE. | - | [scout:qwen/qwen3-coder] Pre‑aggregate store_sales by week and store within each date range before joining with date_dim and store, reducing rows early in the pipeline. | p04 |  | - |  |

## Worker SQL Patches

### p01: multi_date_range_cte (WIN, 1.36x (6211ms→4574ms))
```sql
WITH wss_y AS (select d_week_seq,
        ss_store_sk,
        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,
        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,
        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,
        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,
        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,
        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,
        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales
 from store_sales,date_dim
 where d_date_sk = ss_sold_date_sk
 and ss_sales_price / ss_list_price BETWEEN 57 * 0.01 AND 77 * 0.01
 and d_month_seq between 1187 and 1187 + 11
 group by d_week_seq,ss_store_sk), wss_x AS (select d_week_seq,
        ss_store_sk,
        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,
        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,
        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,
        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,
        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,
        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,
        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales
 from store_sales,date_dim
 where d_date_sk = ss_sold_date_sk
 and ss_sales_price / ss_list_price BETWEEN 57 * 0.01 AND 77 * 0.01
 and d_month_seq between 1187 + 12 and 1187 + 23
 group by d_week_seq,ss_store_sk) select  s_store_name1,s_store_id1,d_week_seq1
       ,sun_sales1/sun_sales2,mon_sales1/mon_sales2
       ,tue_sales1/tue_sales2,wed_sales1/wed_sales2,thu_sales1/thu_sales2
       ,fri_sales1/fri_sales2,sat_sales1/sat_sales2
 from
 (select s_store_name s_store_name1,wss_y.d_week_seq d_week_seq1
        ,s_store_id s_store_id1,sun_sales sun_sales1
        ,mon_sales mon_sales1,tue_sales tue_sales1
        ,wed_sales wed_sales1,thu_sales thu_sales1
        ,fri_sales fri_sales1,sat_sales sat_sales1
  from wss_y,store,date_dim d
  where d.d_week_seq = wss_y.d_week_seq and
        ss_store_sk = s_store_sk and
        d_month_seq between 1187 and 1187 + 11
        and s_state in ('AR','CO','IA'
                    ,'IL','NC','NY','PA','TX')
        ) y,
 (select s_store_name s_store_name2,wss_x.d_week_seq d_week_seq2
        ,s_store_id s_store_id2,sun_sales sun_sales2
        ,mon_sales mon_sales2,tue_sales tue_sales2
        ,wed_sales wed_sales2,thu_sales thu_sales2
        ,fri_sales fri_sales2,sat_sales sat_sales2
  from wss_x,store,date_dim d
  where d.d_week_seq = wss_x.d_week_seq and
        ss_store_sk = s_store_sk and
        d_month_seq between 1187+ 12 and 1187 + 23
        and s_state in ('AR','CO','IA'
                    ,'IL','NC','NY','PA','TX')) x
 where s_store_id1=s_store_id2
   and d_week_seq1=d_week_seq2-52
 order by s_store_name1,s_store_id1,d_week_seq1
limit 100;
```

### p02: dimension_prefetch_star (REGRESSION, 0.37x (6211ms→16909ms))
```sql
WITH wss AS (SELECT d.d_week_seq,
       ss.ss_store_sk,
       SUM(CASE WHEN (d.d_day_name='Sunday') THEN ss.ss_sales_price ELSE NULL END) AS sun_sales,
       SUM(CASE WHEN (d.d_day_name='Monday') THEN ss.ss_sales_price ELSE NULL END) AS mon_sales,
       SUM(CASE WHEN (d.d_day_name='Tuesday') THEN ss.ss_sales_price ELSE NULL END) AS tue_sales,
       SUM(CASE WHEN (d.d_day_name='Wednesday') THEN ss.ss_sales_price ELSE NULL END) AS wed_sales,
       SUM(CASE WHEN (d.d_day_name='Thursday') THEN ss.ss_sales_price ELSE NULL END) AS thu_sales,
       SUM(CASE WHEN (d.d_day_name='Friday') THEN ss.ss_sales_price ELSE NULL END) AS fri_sales,
       SUM(CASE WHEN (d.d_day_name='Saturday') THEN ss.ss_sales_price ELSE NULL END) AS sat_sales
FROM store_sales ss
JOIN date_dim d ON d.d_date_sk = ss.ss_sold_date_sk
WHERE ss.ss_sales_price / ss.ss_list_price BETWEEN 0.57 AND 0.77
GROUP BY d.d_week_seq, ss.ss_store_sk), d1 AS (SELECT d_week_seq, d_month_seq
FROM date_dim
WHERE d_month_seq BETWEEN 1187 AND 1198), d2 AS (SELECT d_week_seq, d_month_seq
FROM date_dim
WHERE d_month_seq BETWEEN 1199 AND 1210), y AS (SELECT s.s_store_name AS s_store_name1, wss.d_week_seq AS d_week_seq1,
       s.s_store_id AS s_store_id1, wss.sun_sales AS sun_sales1,
       wss.mon_sales AS mon_sales1, wss.tue_sales AS tue_sales1,
       wss.wed_sales AS wed_sales1, wss.thu_sales AS thu_sales1,
       wss.fri_sales AS fri_sales1, wss.sat_sales AS sat_sales1
FROM wss
JOIN store s ON wss.ss_store_sk = s.s_store_sk
JOIN d1 ON d1.d_week_seq = wss.d_week_seq
WHERE s.s_state IN ('AR','CO','IA','IL','NC','NY','PA','TX')), x AS (SELECT s.s_store_name AS s_store_name2, wss.d_week_seq AS d_week_seq2,
       s.s_store_id AS s_store_id2, wss.sun_sales AS sun_sales2,
       wss.mon_sales AS mon_sales2, wss.tue_sales AS tue_sales2,
       wss.wed_sales AS wed_sales2, wss.thu_sales AS thu_sales2,
       wss.fri_sales AS fri_sales2, wss.sat_sales AS sat_sales2
FROM wss
JOIN store s ON wss.ss_store_sk = s.s_store_sk
JOIN d2 ON d2.d_week_seq = wss.d_week_seq
WHERE s.s_state IN ('AR','CO','IA','IL','NC','NY','PA','TX')) SELECT s_store_name1,s_store_id1,d_week_seq1
,sun_sales1/sun_sales2,mon_sales1/mon_sales2
,tue_sales1/tue_sales2,wed_sales1/wed_sales2,thu_sales1/thu_sales2
,fri_sales1/fri_sales2,sat_sales1/sat_sales2
FROM y
JOIN x ON s_store_id1=s_store_id2 AND d_week_seq1=d_week_seq2-52
ORDER BY s_store_name1,s_store_id1,d_week_seq1
LIMIT 100;
```

### p03: pg_self_join_decomposition (REGRESSION, 0.85x (6211ms→7342ms))
```sql
WITH wss AS (SELECT d_week_seq,
        ss_store_sk,
        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,
        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,
        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,
        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,
        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,
        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,
        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales
 FROM store_sales,date_dim
 WHERE d_date_sk = ss_sold_date_sk
 and ss_sales_price / ss_list_price BETWEEN 57 * 0.01 AND 77 * 0.01
 group by d_week_seq,ss_store_sk), wss_y AS (SELECT wss.*
FROM wss
JOIN date_dim d ON d.d_week_seq = wss.d_week_seq
WHERE d.d_month_seq BETWEEN 1187 AND 1187 + 11), wss_x AS (SELECT wss.*
FROM wss
JOIN date_dim d ON d.d_week_seq = wss.d_week_seq
WHERE d.d_month_seq BETWEEN 1187 + 12 AND 1187 + 23) SELECT  s_store_name1,s_store_id1,d_week_seq1
       ,sun_sales1/sun_sales2,mon_sales1/mon_sales2
       ,tue_sales1/tue_sales2,wed_sales1/wed_sales2,thu_sales1/thu_sales2
       ,fri_sales1/fri_sales2,sat_sales1/sat_sales2
 FROM
 (SELECT s_store_name s_store_name1,wss_y.d_week_seq d_week_seq1
        ,s_store_id s_store_id1,sun_sales sun_sales1
        ,mon_sales mon_sales1,tue_sales tue_sales1
        ,wed_sales wed_sales1,thu_sales thu_sales1
        ,fri_sales fri_sales1,sat_sales sat_sales1
  FROM wss_y,store
  WHERE ss_store_sk = s_store_sk
        AND s_state in ('AR','CO','IA'
                    ,'IL','NC','NY','PA','TX')
        ) y,
 (SELECT s_store_name s_store_name2,wss_x.d_week_seq d_week_seq2
        ,s_store_id s_store_id2,sun_sales sun_sales2
        ,mon_sales mon_sales2,tue_sales tue_sales2
        ,wed_sales wed_sales2,thu_sales thu_sales2
        ,fri_sales fri_sales2,sat_sales sat_sales2
  FROM wss_x,store
  WHERE ss_store_sk = s_store_sk
        AND s_state in ('AR','CO','IA'
                    ,'IL','NC','NY','PA','TX')) x
 WHERE s_store_id1=s_store_id2
   AND d_week_seq1=d_week_seq2-52
 ORDER BY s_store_name1,s_store_id1,d_week_seq1
LIMIT 100;
```

### p04: aggregate_pushdown (REGRESSION, 0.37x (6211ms→16910ms))
```sql
WITH wss AS (SELECT d_week_seq, ss_store_sk, SUM(CASE WHEN (d_day_name = 'Sunday') THEN ss_sales_price ELSE NULL END) AS sun_sales, SUM(CASE WHEN (d_day_name = 'Monday') THEN ss_sales_price ELSE NULL END) AS mon_sales, SUM(CASE WHEN (d_day_name = 'Tuesday') THEN ss_sales_price ELSE NULL END) AS tue_sales, SUM(CASE WHEN (d_day_name = 'Wednesday') THEN ss_sales_price ELSE NULL END) AS wed_sales, SUM(CASE WHEN (d_day_name = 'Thursday') THEN ss_sales_price ELSE NULL END) AS thu_sales, SUM(CASE WHEN (d_day_name = 'Friday') THEN ss_sales_price ELSE NULL END) AS fri_sales, SUM(CASE WHEN (d_day_name = 'Saturday') THEN ss_sales_price ELSE NULL END) AS sat_sales FROM store_sales, date_dim WHERE d_date_sk = ss_sold_date_sk AND ss_sales_price / ss_list_price BETWEEN 57 * 0.01 AND 77 * 0.01 GROUP BY d_week_seq, ss_store_sk) SELECT s_store_name1, s_store_id1, d_week_seq1, sun_sales1 / sun_sales2, mon_sales1 / mon_sales2, tue_sales1 / tue_sales2, wed_sales1 / wed_sales2, thu_sales1 / thu_sales2, fri_sales1 / fri_sales2, sat_sales1 / sat_sales2 FROM (SELECT s_store_name AS s_store_name1, wss.d_week_seq AS d_week_seq1, s_store_id AS s_store_id1, sun_sales AS sun_sales1, mon_sales AS mon_sales1, tue_sales AS tue_sales1, wed_sales AS wed_sales1, thu_sales AS thu_sales1, fri_sales AS fri_sales1, sat_sales AS sat_sales1 FROM wss, store, date_dim AS d WHERE d.d_week_seq = wss.d_week_seq AND ss_store_sk = s_store_sk AND d_month_seq BETWEEN 1187 AND 1187 + 11 AND s_state IN ('AR', 'CO', 'IA', 'IL', 'NC', 'NY', 'PA', 'TX')) AS y, (SELECT s_store_name AS s_store_name2, wss.d_week_seq AS d_week_seq2, s_store_id AS s_store_id2, sun_sales AS sun_sales2, mon_sales AS mon_sales2, tue_sales AS tue_sales2, wed_sales AS wed_sales2, thu_sales AS thu_sales2, fri_sales AS fri_sales2, sat_sales AS sat_sales2 FROM wss, store, date_dim AS d WHERE d.d_week_seq = wss.d_week_seq AND ss_store_sk = s_store_sk AND d_month_seq BETWEEN 1187 + 12 AND 1187 + 23 AND s_state IN ('AR', 'CO', 'IA', 'IL', 'NC', 'NY', 'PA', 'TX')) AS x WHERE s_store_id1 = s_store_id2 AND d_week_seq1 = d_week_seq2 - 52 ORDER BY s_store_name1, s_store_id1, d_week_seq1 LIMIT 100;
```


## Worker Tree Evidence

### p01: multi_date_range_cte (WIN)
- root_node_id: `final_select`
- nodes: `final_select`, `wss_y`, `wss_x`
- changed_nodes: `final_select`, `wss_y`, `wss_x`
### p02: dimension_prefetch_star (REGRESSION)
- root_node_id: `final_select`
- nodes: `final_select`, `y`, `x`, `wss`, `d1`, `d2`
- changed_nodes: `final_select`, `y`, `x`, `wss`
### p03: pg_self_join_decomposition (REGRESSION)
- root_node_id: `final_select`
- nodes: `final_select`, `wss`, `wss_y`, `wss_x`
- changed_nodes: `final_select`, `wss`, `wss_y`, `wss_x`
### p04: aggregate_pushdown (REGRESSION)
- root_node_id: `final_select`
- nodes: `final_select`, `y`, `x`, `wss_early_1`, `wss_early_2`
- changed_nodes: `y`, `x`, `wss_early_1`, `wss_early_2`

## Runtime Override: TREE Mode (Takes Precedence)
Ignore any conflicting output-shape instructions above.
Compiler may output ONE to FOUR attempts.
No constraint on number of changed nodes.
Output must be JSON object or JSON array (length 1-4), no prose/markdown.
Each attempt should include `plan_id` and `tree`; include full SQL for changed nodes.

Accepted example:
[
  {"plan_id": "snipe_p1", "hypothesis": "...", "tree": {"root_node_id": "final_select", "nodes": [{"node_id":"final_select","parent_node_id":null,"sources":[],"changed":true,"sql":"SELECT ..."}]}}
]

## Base Tree Spec
Use this as the authoritative node tree for rewrite proposals.

node: wss
  parent_node_id: final_select
  sources: ['store_sales', 'date_dim']
  outputs: ['d_week_seq', 'ss_store_sk', 'sun_sales', 'mon_sales', 'tue_sales', 'wed_sales', 'thu_sales', 'fri_sales', 'sat_sales']
  sql: OMITTED

node: final_select
  parent_node_id: None
  sources: ['wss', 'store', 'date_dim']
  outputs: ['s_store_name1', 's_store_id1', 'd_week_seq1', 'sun_sales1 / sun_sales2', 'mon_sales1 / mon_sales2', 'tue_sales1 / tue_sales2', 'wed_sales1 / wed_sales2', 'thu_sales1 / thu_sales2', 'fri_sales1 / fri_sales2', 'sat_sales1 / sat_sales2']
  sql: OMITTED

root_node_id: final_select