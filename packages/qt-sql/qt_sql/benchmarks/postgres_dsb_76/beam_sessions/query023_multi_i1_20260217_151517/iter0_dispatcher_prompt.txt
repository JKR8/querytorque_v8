## Role

You are the **Beam Dispatcher** for SQL query optimization on the target runtime dialect.

Your mission:
1) Diagnose the bottleneck from the execution plan (EXPLAIN / EXPLAIN ANALYZE)
2) Select an appropriate number of independent **single-transform** probes (adaptive count)
3) Specify, for each probe, **where to apply the transform** and what the worker must preserve

Each probe will be executed by a separate worker. One probe = one transform = one PatchPlan.

---

## Prompt Map (cache friendly)

### Phase A — Cached Context (static)
A1. Dialect/engine guardrails (runtime-injected profile is authoritative)
A2. Optimization families (A–F) + decision gates
A3. EXPLAIN analysis procedure (mechanical)
A4. Plan-evidence routing heuristics (priors only)
A5. Regression registry (hard failure modes)
A6. Aggregation equivalence rules
A7. Probe-count policy by ★ importance
A8. Dispatch output contract (JSON schema) + probe summary schema

### Phase B — Query-Specific Input (dynamic; after cache boundary)
B1. Query importance (★ 1–3) + optional budget hint
B2. Original SQL
B3. Execution plan text
B4. IR structure + anchor hashes
B5. Transform catalog (full list; NOT pre-filtered)
B6. Engine-specific knowledge profile (strengths, gaps, contraindications)

> NOTE: Do NOT rely on AST pre-filters or “transform radar”.
> Choose probes using plan evidence + family priors + catalog descriptions.

---

## Probe-count policy (adaptive; prevents “junk probes”)

You MUST choose `probe_count` based on **importance★** and **complexity evidence**.

### Default ranges
- ★★★ (hard / high value): 12–16 probes
- ★★  (medium): 8–12 probes
- ★   (easy / low value): 4–8 probes

### Early Stop (allowed)
Set `early_stop: true` and keep probes near the lower bound if:
- Plan is already efficient (no dominant hotspot; low time; small rows), OR
- One clear pathology with an obvious fix and low uncertainty.

### Exploration probes
If `probe_count >= 8`, include **1–2** exploration probes (`exploration: true`).
If `probe_count < 8`, exploration probes are optional.
Exploration probes must:
- target a **secondary hotspot** (not the primary bottleneck already covered by top probes), and
- use a **family not yet represented** in the current probe set when possible.
- for non-native (`support=portability_candidate`) transforms, include explicit EXPLAIN-grounded reasoning for why it may transfer to this runtime dialect.

---

## Dialect & Engine Guardrails

Use the runtime-injected **Engine-Specific Knowledge** section as authoritative.
If static defaults and runtime profile conflict, follow runtime profile.
Non-native transforms (`support=portability_candidate`) are allowed only when:
- plan evidence strongly supports the transform pattern, and
- runtime engine knowledge does not explicitly contraindicate the move.
Mark such probes as `exploration: true` unless confidence is already very high from direct plan evidence.

---

## Optimization Families (A–F)

A: Early Filtering (Predicate Pushback)  
B: Decorrelation (Sets Over Loops)  
C: Aggregation Pushdown  
D: Set Ops  
E: Materialization / Prefetch  
F: Join Topology  

Use families as priors only; final selection must be justified by plan evidence.

---

## EXPLAIN Analysis Procedure (mechanical)

1) Identify the **cost spine**: the few operators that dominate time.
2) Classify spine nodes: scan / join / agg / materialize / sort.
3) Compute amplification:
   - loops × rows (nested loops)
   - in→out ratios (aggregates)
   - repeated subtree rescans (materialize)
4) Trace where selectivity happens (early vs late).
5) Write a 2–3 sentence hypothesis: “PG is doing X because Y; transform family Z should reduce it.”

---

## Plan-evidence routing heuristics (priors)

Route by plan symptom:
- Flat rows, late drop → A
- Nested loop with re-exec inner work → B (or E if reuse)
- Aggregate after big join → C
- Set op materialization → D
- Repeated scans/subtrees → E
- Comma joins / cardinality mismatch → F

Prune only when evidence is absent:
- No nested loops → most B unlikely
- No repeated scans → most E unlikely
- No GROUP BY → most C unlikely
- No set ops → most D unlikely
- No comma joins → most F-comma unlikely

---

## Regression Registry (hard gates)

Do NOT dispatch transforms that trigger these:
- Materialize a simple EXISTS path when PG already uses semi-join
- Orphaned original scans after replacement (double scans)
- Unfiltered “new CTE” that explodes work
- Over-deep fact-table CTE chains (parallelism loss / join-order lock)
- Same-column OR → UNION ALL split by default on PostgreSQL

OR to UNION exception for PostgreSQL:
- only consider when EXPLAIN evidence shows OR blocks index usage and UNION branches become index scans

---

## Aggregation Equivalence Rules (sniper + workers must obey)

- GROUP BY keys must remain compatible with join keys after rewrite.
- AVG/STDDEV/VARIANCE are duplication-sensitive.
- FILTER() and CASE pivot semantics must match exactly.
- If pushdown changes join multiplicity, it’s invalid.

---

## Equivalence Tier Hint (for downstream validation)

Set `dispatch.equivalence_tier` using query shape:
- `exact`: deterministic query, stable row identity
- `unordered`: row set equivalent but order not guaranteed (e.g., no ORDER BY)
- `nondeterministic`: query uses RANDOM/NOW/volatile expressions or unstable LIMIT semantics

---

## Dispatch Output Contract (MUST follow)

Tier-0 output contract:
- first character must be `{` (no leading whitespace/newlines)
- top-level value must be one JSON object
- no markdown fences, no prose, no commentary

Output JSON shape:
{
  "dispatch": {
    "dialect": "<target_dialect>",
    "importance_stars": 3,
    "probe_count": 12,
    "early_stop": false,
    "equivalence_tier": "exact",
    "hypothesis": "2–3 sentences; cite key plan operators, rows/loops/times",
    "reasoning_trace": [
      "Cost spine dominated by Nested Loop Anti on ss/cd path",
      "Late selectivity at date_dim filter suggests early filter + decorrelation candidates"
    ],
    "cost_spine": ["Op1 → Op2 → Op3"],
    "hotspots": [
      {"op": "Nested Loop Anti", "why": "loops×rows amplification", "evidence": "loops=312, rows=4.2M, time=1840ms"}
    ],
    "do_not_do": ["short list of banned moves for this query"]
  },
  "probe_summary_schema": [
    "probe_id",
    "transform_id",
    "family",
    "status",
    "speedup",
    "expected_explain_delta",
    "ops_used",
    "confidence",
    "exploration",
    "failure_reason",
    "target"
  ],
  "probes": [
    {
      "probe_id": "p01",
      "transform_id": "decorrelate_not_exists_to_cte",
      "family": "B",
      "target": "Precise instruction: what predicate/subquery to rewrite and what join/CTE shape to use",
      "node_contract": {
        "from_must_include": ["store_sales ss", "date_dim d"],
        "where_must_preserve": ["ss.ss_sold_date_sk = d.d_date_sk", "d.d_year = 2001"],
        "output_must_preserve": ["all original SELECT columns", "original ORDER BY/LIMIT semantics"]
      },
      "gates_checked": ["no_or_to_union:PASS", "not_simple_exists:PASS"],
      "exploration": false,
      "exploration_hypothesis": "Required when exploration=true; explain why this is worth trying from plan evidence",
      "confidence": 0.84,
      "expected_explain_delta": "What should change in EXPLAIN if this works (1 sentence)",
      "recommended_patch_ops": ["insert_cte", "replace_from", "replace_where_predicate"],
      "gold_example_id": "optional_string"
    }
  ],
  "dropped": [
    {"transform_id": "or_to_union", "family": "D", "reason": "regression registry: bitmap-or capable"}
  ]
}

Rules:
- `probes.length` MUST equal `dispatch.probe_count`
- One probe = one transform (no compound transforms here)
- Rank by expected impact
- Be explicit and operational (workers should not infer intent)

---

## Cache Boundary
Everything below is query-specific input.

## Query ID
query023_multi_i1

## Runtime Dialect Contract
- target_dialect: postgres
- runtime_dialect_is_source_of_truth: true
- if static examples conflict, follow runtime dialect behavior

## Query Importance
- importance_stars: 3
- importance_label: ***
- budget_hint: n/a

## Original SQL
```sql
with frequent_ss_items as
 (select substring(i_item_desc,1,30) itemdesc,i_item_sk item_sk,d_date solddate,count(*) cnt
  from store_sales
      ,date_dim
      ,item
  where ss_sold_date_sk = d_date_sk
    and ss_item_sk = i_item_sk
    and d_year = 1998
    and i_manager_id BETWEEN 81 and 100
     AND i_category IN ('Children', 'Men', 'Sports')
  group by substring(i_item_desc,1,30),i_item_sk,d_date
  having count(*) >4),
 max_store_sales as
 (select max(csales) tpcds_cmax
  from (select c_customer_sk,sum(ss_quantity*ss_sales_price) csales
        from store_sales
            ,customer
            ,date_dim
        where ss_customer_sk = c_customer_sk
         and ss_sold_date_sk = d_date_sk
         and d_year = 1998
         and ss_wholesale_cost BETWEEN 11 AND 21
        group by c_customer_sk) tmp1),
 best_ss_customer as
 (select c_customer_sk,sum(ss_quantity*ss_sales_price) ssales
  from store_sales
      ,customer
  where ss_customer_sk = c_customer_sk
  and c_birth_year BETWEEN 1934 AND 1940
  group by c_customer_sk
  having sum(ss_quantity*ss_sales_price) > (95/100.0) * (select
  *
from
 max_store_sales))
  select  sum(sales)
 from (select cs_quantity*cs_list_price sales
       from catalog_sales
           ,date_dim
       where d_year = 1998
         and d_moy = 10
         and cs_sold_date_sk = d_date_sk
         and cs_item_sk in (select item_sk from frequent_ss_items)
         and cs_bill_customer_sk in (select c_customer_sk from best_ss_customer)
         and cs_wholesale_cost BETWEEN 11 AND 21
      union all
      select ws_quantity*ws_list_price sales
       from web_sales
           ,date_dim
       where d_year = 1998
         and d_moy = 10
         and ws_sold_date_sk = d_date_sk
         and ws_item_sk in (select item_sk from frequent_ss_items)
         and ws_bill_customer_sk in (select c_customer_sk from best_ss_customer)
         and ws_wholesale_cost BETWEEN 11 AND 21) tmp2
 limit 100;
```

## Execution Plan
```
Limit  (rows=1, time=98347.77)
  Aggregate  (rows=3, time=15469.945)
    Gather Merge  (rows=139930, time=15454.834)
      Aggregate  (rows=139930, time=15448.911)
        Sort  (rows=151572, time=15430.683)
          Hash Join  (rows=151572, time=14873.749)
            Nested Loop  (rows=4520756, time=13682.353)
              Seq Scan on date_dim (date_dim_2)  (rows=365, time=301.52)
              Index Only Scan on store_sales  (rows=12386, time=36.197)
            Hash  (rows=6872, time=821.744)
              Seq Scan on item  (rows=6872, time=817.825)
  Aggregate  (rows=24387, time=79636.184)
    Aggregate  (rows=1, time=43024.676)
      Aggregate  (rows=135776, time=43019.266)
        Gather Merge  (rows=135776, time=42981.659)
          Aggregate  (rows=135776, time=42976.077)
            Sort  (rows=256261, time=42919.65)
              Nested Loop  (rows=256261, time=42180.317)
                Nested Loop  (rows=259471, time=40221.094)
                  Index Only Scan on date_dim (date_dim_3)  (rows=365, time=55.275)
                  Index Only Scan on store_sales (store_sales_1)  (rows=711, time=109.985)
                Index Only Scan on customer  (rows=1, time=0.007)
    Gather Merge  (rows=44534, time=36526.531)
      Aggregate  (rows=44534, time=36515.803)
        Nested Loop  (rows=2635989, time=36148.405)
          Index Scan on customer (customer_1)  (rows=48009, time=4259.981)
          Index Only Scan on store_sales (store_sales_2)  (rows=55, time=0.661)
  Aggregate  (rows=1, time=97646.124)
    Append  (rows=0, time=97646.099)
      Hash Join  (rows=0, time=96540.649)
        Hash Join  (rows=0, time=16856.847)
          Gather  (rows=8790, time=1385.348)
            Nested Loop  (rows=8790, time=1384.057)
              Index Only Scan on date_dim  (rows=31, time=72.54)
              Index Scan on catalog_sales  (rows=284, time=42.254)
          Hash  (rows=3, time=15469.598)
            Aggregate  (rows=3, time=15469.59)
              CTE Scan (frequent_ss_items)  (rows=3, time=15469.56)
        Hash  (rows=24387, time=79683.787)
          Aggregate  (rows=24387, time=79682.644)
            CTE Scan (best_ss_customer)  (rows=24387, time=79657.493)
      Hash Join  (rows=0, time=1105.447)
        Hash Join  (rows=0, time=1100.615)
          Gather  (rows=11612, time=1099.09)
            Nested Loop  (rows=11612, time=1098.037)
              Index Only Scan on date_dim (date_dim_1)  (rows=31, time=62.583)
              Index Scan on web_sales  (rows=375, time=33.36)
          Hash  (rows=3, time=0.019)
            Aggregate  (rows=3, time=0.016)
              CTE Scan (frequent_ss_items_1)  (rows=3, time=0.01)
        Hash  (rows=24387, time=4.818)
          Aggregate  (rows=24387, time=3.813)
            CTE Scan (best_ss_customer_1)  (rows=24387, time=0.817)
```

## IR Patch Contract Reference
- `S0` = top-level SELECT statement for this query mission.
- Use `target: {"by_node_id": "S0"}` for all coarse-grained edits.
- Use `by_anchor_hash` only for exact expression/predicate subtree edits.
- Anchor hashes are parser-generated and formatting-stable; copy verbatim.
- If anchor is ambiguous, prefer safe coarse ops (`replace_where_predicate`) or no-op.

## IR Structure + Anchor Hashes
```
S0 [SELECT]
  CTE: frequent_ss_items  (via CTE_Q_S0_frequent_ss_items)
    FROM: store_sales, date_dim, item
    WHERE [89fc2fb260a938e8]: ss_sold_date_sk = d_date_sk AND ss_item_sk = i_item_sk AND d_year = 1998 AND i_manager_id BETWEEN...
    GROUP BY: SUBSTRING(i_item_desc FROM 1 FOR 30), i_item_sk, d_date
  CTE: max_store_sales  (via CTE_Q_S0_max_store_sales)
    FROM: (subquery) tmp1
  CTE: best_ss_customer  (via CTE_Q_S0_best_ss_customer)
    FROM: store_sales, customer
    WHERE [8e7b5f6e04cda7e3]: ss_customer_sk = c_customer_sk AND c_birth_year BETWEEN 1934 AND 1940
    GROUP BY: c_customer_sk
  MAIN QUERY (via Q_S0)
    FROM: (subquery) tmp2

Patch operations (core+advanced): insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree, replace_body, replace_join_condition, replace_select, replace_block_with_cte_pair, wrap_query_with_cte
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Transform Catalog (full list; not pre-filtered)

- runtime_dialect: `postgresql`
- selection_policy: prioritize native/universal transforms first.
- portability_policy: non-native transforms may be used as exploration probes when runtime syntax/semantics remain valid and engine knowledge does not contraindicate.

- `date_cte_isolate` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Dimension Isolation: extract small dimension lookups into CTEs so they materialize once and subsequent joins probe a tiny hash table instead of rescanning.
- `dimension_cte_isolate` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Early Selection: pre-filter dimension tables into CTEs returning only surrogate keys before joining with fact tables. Each dimension CTE is tiny, creating small hash tables that speed up the fact table probe.
- `early_filter` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Early Selection: filter small dimension tables first, then join to large fact tables. This reduces the fact table scan to only rows matching the filter, rather than scanning all rows and filtering after the join.
- `multi_date_range_cte` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Early Selection per Alias: when a query joins the same dimension table multiple times with different filters (d1, d2, d3), create separate CTEs for each filter and pre-join with fact tables to reduce rows entering the main join.
- `multi_dimension_prefetch` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Multi-Dimension Prefetch: when multiple dimension tables have selective filters, pre-filter ALL of them into CTEs before the fact table join. Combined selectivity compounds — each dimension CTE reduces the fact scan further.
- `prefetch_fact_join` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Staged Join Pipeline: build a CTE chain that progressively reduces data — first CTE filters the dimension, second CTE pre-joins filtered dimension keys with the fact table, subsequent CTEs join remaining dimensions against the already-reduced fact set.
- `sf_sk_pushdown_multi_fact` (Family A, gap `PREDICATE_TRANSITIVITY_FAILURE`, support `portability_candidate`, engines `snowflake`): Add date_sk BETWEEN to each fact table when joined to date_dim via comma join
- `sf_sk_pushdown_union_all` (Family A, gap `PREDICATE_TRANSITIVITY_FAILURE`, support `portability_candidate`, engines `snowflake`): Push date_sk BETWEEN into UNION ALL branches for micro-partition pruning
- `shared_dimension_multi_channel` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Shared Dimension Extraction: when multiple channel CTEs (store/catalog/web) apply identical dimension filters, extract those shared filters into one CTE and reference it from each channel. Avoids redundant dimension scans.
- `composite_decorrelate_union` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `portability_candidate`, engines `duckdb`): Composite Decorrelation: when multiple correlated EXISTS share common filters, extract shared dimensions into a single CTE and decorrelate the EXISTS checks into pre-materialized key sets joined via UNION.
- `decorrelate` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `portability_candidate`, engines `duckdb`): Decorrelation: convert correlated subqueries to standalone CTEs with GROUP BY, then JOIN. Correlated subqueries re-execute per outer row; a pre-computed CTE executes once.
- `early_filter_decorrelate` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `native_or_universal`, engines `postgresql`): Early Selection + Decorrelation: push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN.
- `inline_decorrelate_materialized` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `native_or_universal`, engines `postgresql`): Inline Decorrelation with MATERIALIZED CTEs: When a WHERE clause contains a correlated scalar subquery (e.g., col > (SELECT 1.3 * avg(col) FROM ... WHERE correlated_key = outer.key)), PostgreSQL re-executes the subquery per outer row. Fix: decompose into 3 MATERIALIZED CTEs — (1) pre-filter dimension table, (2) pre-filter fact table by date range, (3) compute per-key aggregate threshold from filtered data — then JOIN the threshold CTE in the final query. MATERIALIZED keyword prevents PG from inlining the CTEs back into correlated form.
- `sf_inline_decorrelate` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `portability_candidate`, engines `snowflake`): Decompose correlated scalar subquery with aggregation into 3 CTEs: shared scan, per-key threshold, filtered main query
- `sf_shared_scan_decorrelate` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `portability_candidate`, engines `snowflake`): Shared-scan variant: inner and outer scan same fact table with same filters, decompose into shared CTE + threshold CTE
- `aggregate_pushdown` (Family C, gap `AGGREGATE_BELOW_JOIN_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Push aggregation below joins: when a GROUP BY + aggregate operates on a single fact table joined with dimensions, pre-aggregate the fact table on the join key first, THEN join with dimensions. Reduces rows entering the join from millions to thousands.
- `channel_bitmap_aggregation` (Family C, gap `REDUNDANT_SCAN_ELIMINATION`, support `portability_candidate`, engines `duckdb`): Consolidate repeated scans of the same fact table (one per time/channel bucket) into a single scan with CASE WHEN labels and conditional aggregation
- `deferred_window_aggregation` (Family C, gap `None`, support `portability_candidate`, engines `duckdb`): Deferred Aggregation: delay expensive operations (window functions) until after joins reduce the dataset. Computing window functions inside individual CTEs then joining is more expensive than joining first and computing windows once on the combined result.
- `early_filter` (Family C, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): Scan Consolidation: when multiple subqueries scan the same table with similar patterns, consolidate them into CTEs that compute all needed aggregates in fewer passes. Reduces N scans to fewer scans.
- `single_pass_aggregation` (Family C, gap `REDUNDANT_SCAN_ELIMINATION`, support `portability_candidate`, engines `duckdb`): Single-Pass Aggregation: consolidate multiple scalar subqueries on the same table into one CTE using CASE expressions inside aggregate functions. Reduces N separate table scans to 1 pass.
- `intersect_to_exists` (Family D, gap `None`, support `portability_candidate`, engines `duckdb`): Semi-Join Short-Circuit: replace INTERSECT with EXISTS to avoid full materialization and sorting. INTERSECT must compute complete result sets before intersecting; EXISTS stops at the first match per row, enabling semi-join optimizations.
- `multi_intersect_exists_cte` (Family D, gap `None`, support `portability_candidate`, engines `duckdb`): Convert cascading INTERSECT operations into correlated EXISTS subqueries with pre-materialized date and channel CTEs
- `or_to_union` (Family D, gap `CROSS_COLUMN_OR_DECOMPOSITION`, support `portability_candidate`, engines `duckdb`): OR-to-UNION Decomposition: split OR conditions on different columns into separate UNION ALL branches, each with a focused predicate. The optimizer can use different access paths per branch instead of a single scan with a complex filter.
- `rollup_to_union_windowing` (Family D, gap `UNION_CTE_SELF_JOIN_DECOMPOSITION`, support `portability_candidate`, engines `duckdb`): Replace GROUP BY ROLLUP with explicit UNION ALL of pre-aggregated CTEs at each hierarchy level, combined with window functions for ranking
- `union_cte_split` (Family D, gap `UNION_CTE_SELF_JOIN_DECOMPOSITION`, support `portability_candidate`, engines `duckdb`): CTE Specialization: when a generic CTE is scanned multiple times with different filters (e.g., by year), split it into specialized CTEs that embed the filter in their definition. Each specialized CTE processes only its relevant subset, eliminating redundant scans.
- `materialize_cte` (Family E, gap `None`, support `portability_candidate`, engines `duckdb`): Shared Materialization: extract repeated subquery patterns into CTEs to avoid recomputation. When the same logical check appears multiple times, compute it once and reference the result.
- `pg_self_join_decomposition` (Family E, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `postgresql`): Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.
- `date_cte_explicit_join` (Family F, gap `COMMA_JOIN_WEAKNESS`, support `native_or_universal`, engines `postgresql`): Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.
- `dimension_prefetch_star` (Family F, gap `COMMA_JOIN_WEAKNESS`, support `native_or_universal`, engines `postgresql`): Multi-Dimension Prefetch (PG): pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax. PostgreSQL's optimizer gets better cardinality estimates from pre-materialized small dimension results.
- `inner_join_conversion` (Family F, gap `LEFT_JOIN_FILTER_ORDER_RIGIDITY`, support `portability_candidate`, engines `duckdb`): When a LEFT JOIN is immediately followed by a WHERE filter on the right table that eliminates NULL rows, convert to INNER JOIN + early filter CTE. The WHERE clause already makes the LEFT JOIN behave as an INNER JOIN, but the optimizer keeps the LEFT JOIN semantics (preserving all left rows), wasting work on rows that are filtered out.
- `materialized_dimension_fact_prefilter` (Family F, gap `NON_EQUI_JOIN_INPUT_BLINDNESS`, support `native_or_universal`, engines `postgresql`): Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.
- `self_join_decomposition` (Family F, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `duckdb`): When a CTE is self-joined with different filter values (e.g., inv1.d_moy=1 AND inv2.d_moy=2), split into separate CTEs each embedding their filter. The optimizer cannot push the outer WHERE filter into the CTE's GROUP BY, causing full materialization and post-filtering.


## Schema / Index / Stats Context
- source: postgres
- referenced_tables: 6

| Table | Rows(est) | PK | Indexes |
|-------|-----------|----|---------|
| catalog_sales | 14397255 | cs_item_sk, cs_order_number | catalog_sales_pkey, _dta_index_catalog_sales_6_1301579675__k1_k16_k5_k4_3_6_18_19_2, _dta_index_catalog_sales_6_1301579675__k17_k6_k3_k5_k1_k16_12_1, _dta_index_catalog_sales_6_1301579675__k1_4_16_18_19_21_24, _dta_index_catalog_sales_6_1301579675__k3_k12_k14_k15_16_18, _dta_index_catalog_sales_6_1301579675__k1_k16_k4_18_34 |
| customer | 500000 | c_customer_sk | customer_pkey, _dta_index_customer_6_949578421__k9_k10, _dta_index_customer_6_949578421__k1_k5, _dta_index_customer_5_949578421__k13_k5 |
| date_dim | 73049 | d_date_sk | date_dim_pkey, _dta_index_date_dim_6_661577395__k7_k4_k9_k1, _dta_index_date_dim_6_661577395__k7_k9_k1, _dta_index_date_dim_6_661577395__k1_k7_k9, _dta_index_date_dim_6_661577395__k7_k11_k1, _dta_index_date_dim_6_661577395__k9_k7_k1 |
| item | 102000 | i_item_sk | item_pkey, _dta_index_item_6_853578079__k1_2_5, _dta_index_item_6_853578079__k13_k11_k1, _dta_index_item_6_853578079__k18, _dta_index_item_6_853578079__k2_k1 |
| store_sales | 28806628 | ss_item_sk, ss_ticket_number | store_sales_pkey, _dta_index_store_sales_6_1333579789__k1_k23_k14_k6_k8_k5_k7_3_4, _dta_index_store_sales_6_1333579789__k1_k5_k8_k3_11_13_14_20, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_9_16_23, _dta_index_store_sales_6_1333579789__k4_1_3_10_11_14, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_23 |
| web_sales | 7197533 | ws_item_sk, ws_order_number | web_sales_pkey, _dta_index_web_sales_6_1269579561__k3_k18_k12_k14_16_29_34, _dta_index_web_sales_6_1269579561__k1_k4_k5_18, _dta_index_web_sales_6_1269579561__k1_8_24, _dta_index_web_sales_6_1269579561__k18_16, _dta_index_web_sales_6_1269579561__k1_k5 |

## Engine-Specific Knowledge
## Dialect Profile (POSTGRES)

**Combined Intelligence Baseline**: Combined intelligence baseline from 53 validated DSB queries at SF5-SF10, plus regression registry outcomes. PostgreSQL has bitmap index scans, JIT compilation, and aggressive CTE materialization. Techniques that work on DuckDB often regress here.

### Optimizer Strengths (don't fight these)
- `BITMAP_OR_SCAN`: Avoid splitting OR conditions into UNION ALL by default. Only consider OR→UNION when EXPLAIN shows OR blocks index usage and UNION branches become index scans. 0.21x and 0.26x reg…
- `SEMI_JOIN_EXISTS`: NEVER convert EXISTS to IN/NOT IN or materialized CTEs. 0.50x, 0.75x observed. Note: NOT EXISTS anti-join decorrelation can still be valid when replacing large correlated anti patterns.
- `INNER_JOIN_REORDERING`: Don't restructure INNER JOIN orders. Focus on LEFT JOIN blocking or comma-join confusion.
- `INDEX_ONLY_SCAN`: Small dimension lookups (<10K rows) may not need CTEs.

### Known Gaps (exploit these)
- `COMMA_JOIN_WEAKNESS` [HIGH] detect: FROM t1, t2, t3 WHERE t1.key = t2.key (comma joins, no explicit JOIN). Poor row estimates in EXPLAIN. | action: Convert comma-joins to explicit JOIN...ON syntax. Best when combined with date_cte_isolate.
- `CORRELATED_SUBQUERY_PARALYSIS` [HIGH] detect: Nested loop in EXPLAIN, inner re-executes aggregate per outer row. SQL: WHERE col > (SELECT AGG FROM ... WHERE outer.key = inner.key). Hash… | action: Convert correlated WHERE to explicit CTE with GROUP BY + JOIN.
- `NON_EQUI_JOIN_INPUT_BLINDNESS` [HIGH] detect: Expensive non-equi join (BETWEEN, <, >) with large inputs on both sides. Neither side filtered. | action: Reduce fact table input size via filtered CTE before the non-equi join.
- `CTE_MATERIALIZATION_FENCE` [MEDIUM] detect: Large CTE + small post-filter. Multi-referenced CTE that blocks predicate pushdown. | action: Materialize STRATEGICALLY: only when CTE is expensive and reused. Avoid fencing single-use cases.
- `CROSS_CTE_PREDICATE_BLINDNESS` [MEDIUM] detect: Sequential scan on dimension table without index condition. Late filter after large scan/join. | action: Pre-filter into CTE definition. But be more cautious than on DuckDB.

## Additional Intelligence
### AST Feature Detection

- **materialize_cte**: 100% match (AGG_COUNT, AGG_SUM, BETWEEN, CTE) [SUPPORT: portability_candidate; engines=duckdb]
- **prefetch_fact_join**: 100% match (AGG_SUM, DATE_DIM, GROUP_BY, STAR_JOIN) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: MAX_2_CHAINS] [SUPPORT: portability_candidate; engines=duckdb]
- **dimension_cte_isolate**: 100% match (DATE_DIM, GROUP_BY, MULTI_TABLE_5+) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: CROSS_JOIN_3_DIMS, UNFILTERED_CTE] [SUPPORT: portability_candidate; engines=duckdb]
- **sf_sk_pushdown_union_all**: 100% match (DATE_DIM, MULTI_CHANNEL, UNION) (gap: PREDICATE_TRANSITIVITY_FAILURE) [SUPPORT: portability_candidate; engines=snowflake]
- **sf_sk_pushdown_multi_fact**: 100% match (DATE_DIM, MULTI_TABLE_5+) (gap: PREDICATE_TRANSITIVITY_FAILURE) [SUPPORT: portability_candidate; engines=snowflake]
