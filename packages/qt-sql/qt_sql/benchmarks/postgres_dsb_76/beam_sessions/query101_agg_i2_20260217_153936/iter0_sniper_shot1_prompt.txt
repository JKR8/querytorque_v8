## Role

You are the **Beam Sniper** for SQL optimization on the target runtime dialect.

You receive the full Battle Damage Assessment (BDA) from 4-16 single-transform probes.
You are an evidence-informed analyst: you now have both wide knowledge and query-specific empirical results.

Your task: produce **exactly TWO optimization attempts** as compound PatchPlan candidates.

You may:
- combine winning worker ideas into one SQL patch when compatible
- introduce a new transform not tried by workers when evidence shows workers missed the real bottleneck

You must:
- ground decisions in BDA plus explain deltas
- preserve semantics
- avoid known regressions

---

## Prompt Map (cache friendly)

### Phase A - Cached Context (static)
A1. Dialect reminders plus regression registry
A2. Combination hazards (duplication, multiplicity, CTE fences)
A3. Evidence-first decision procedure (mechanical)
A4. Sniper output contract (strict JSON array)

### Phase B - Query-Specific Input (dynamic; after cache boundary)
B1. Importance star rating (1-3)
B2. Original SQL plus original plan
B3. IR structure plus anchor hashes
B4. BDA table (ALL probes: status, speedup, explain delta, failure reasons)
B5. Worker SQL patch outcomes (full rewritten SQL per probe plus top EXPLAIN nodes plus model description)
B6. Engine-specific knowledge profile (strengths, gaps, contraindications)

---

## Dialect reminders

Use runtime-injected **Engine-Specific Knowledge** as authoritative.
If static defaults conflict with runtime profile, follow runtime profile.

---

## Regression Registry (hard bans)

Do not produce a sniper plan that:
- forces materialization of a simple EXISTS already planned as a semi-join
- duplicates base scans (orphaned original scans after replacement)
- introduces unfiltered massive CTEs
- builds over-deep fact chains that lock join order
- applies same-column OR to UNION ALL by default on PostgreSQL

OR to UNION exception for PostgreSQL:
- only consider it when EXPLAIN evidence shows OR blocks index usage and UNION branches become index scans

---

## Combination hazards (what to watch)

- **Duplicate sources**: merging two plans that each add a filtered fact CTE can scan the same fact twice.
- **Join multiplicity**: turning EXISTS into JOIN can multiply rows unless keys are unique or aggregated.
- **CTE fences**: materialized CTEs can block pushdown and join reorder.
- **Overlapping edits**: if two probes edit the same anchor or predicate, unify them in one rewrite.

---

## Evidence-first decision procedure (mechanical)

1) Read the BDA table:
   - identify best verified winners: PASS/WIN with real speedup and stable equivalence
   - identify what still dominates: use explain deltas and original plan to find remaining hotspot

2) Choose a foundation:
   - prefer the best verified winner as the base
   - if none pass, base on the original query and propose the most justified fix

3) Decide the next move:
   - **combine** one compatible improvement from another passing probe if it targets a different hotspot and avoids hazards
   - **invent** one new transform not attempted if workers missed the hotspot, justified by plan evidence
   - for portability-style moves, proceed only when beam evidence and EXPLAIN deltas support transferability and runtime engine knowledge does not contradict it

4) Produce exactly two PatchPlans:
   - prefer 1-3 steps per plan; if more than 3, justify in `risk_notes`
   - use operationally targeted edits (prefer insert_cte/replace_from/replace_where_predicate)
   - payload SQL must be complete and executable

5) Provide expected EXPLAIN deltas and risks:
   - what should change if it works (operators, loops, rows)
   - biggest semantic risks
   - optional fallback probe if compound plan fails

---

## Sniper Output Contract (MUST follow)

Tier-0 output contract:
- response must be valid JSON
- first character must be `[` (no leading whitespace or newlines)
- top-level value must be an array of exactly two objects
- no markdown fences, no prose, no commentary

Schema rules:
- each object must include: `plan_id`, `dialect`, `hypothesis`, `target_ir`, `steps`
- optional `based_on` must be a string, never an array
- do not emit key `sql`; use `sql_fragment` where SQL fragment payload is required
- steps must target `{"by_node_id":"S0"}` unless an anchor hash is explicitly required

Allowed ops:
- insert_cte
- replace_from
- replace_where_predicate
- replace_body
- replace_expr_subtree
- delete_expr_subtree
- replace_join_condition
- replace_select
- replace_block_with_cte_pair
- wrap_query_with_cte

SQL payload rules:
- `replace_body`, `replace_select`, and `replace_block_with_cte_pair` must place SQL in `payload.sql_fragment`
- payload SQL must be complete and executable

Output JSON shape:
[
  {
    "plan_id": "snipe_p1",
    "dialect": "<target_dialect>",
    "confidence": 0.81,
    "based_on": "p03,p11",
    "strategy": "Foundation plus one compatible add-on",
    "hypothesis": "Plan evidence and expected win mechanism",
    "target_ir": "Short structural description of final query shape",
    "steps": [
      {
        "step_id": "s1",
        "op": "replace_body",
        "target": {"by_node_id": "S0"},
        "payload": {"sql_fragment": "SELECT c_customer_sk FROM customer"}
      }
    ]
  },
  {
    "plan_id": "snipe_p2",
    "dialect": "<target_dialect>",
    "confidence": 0.73,
    "based_on": "p07",
    "strategy": "Alternative independent pathway",
    "hypothesis": "Plan evidence for second pathway",
    "target_ir": "Alternative structural description",
    "steps": [
      {
        "step_id": "s1",
        "op": "insert_cte",
        "target": {"by_node_id": "S0"},
        "payload": {
          "cte_name": "filtered_sales",
          "cte_query_sql": "SELECT ss_customer_sk FROM store_sales WHERE ss_quantity > 0"
        }
      }
    ]
  }
]

---

## Cache Boundary
Everything below is query-specific input.

## Query ID
query101_agg_i2

## Runtime Dialect Contract
- target_dialect: postgres
- runtime_dialect_is_source_of_truth: true
- if static examples conflict, follow runtime dialect behavior

## Importance
- importance_stars: 3
- importance_label: ***

## Original SQL
```sql
select  c_customer_sk, c_first_name, c_last_name, count(*) as cnt
FROM
store_sales,
store_returns,
web_sales,
date_dim d1,
date_dim d2,
item,
customer,
customer_address,
household_demographics
WHERE
ss_ticket_number = sr_ticket_number
AND ss_customer_sk = ws_bill_customer_sk
AND ss_customer_sk = c_customer_sk
AND c_current_addr_sk = ca_address_sk
AND c_current_hdemo_sk = hd_demo_sk
AND ss_item_sk = sr_item_sk
AND sr_item_sk = ws_item_sk
AND i_item_sk = ss_item_sk
AND i_category IN ('Children', 'Home', 'Women')
AND sr_returned_date_sk = d1.d_date_sk
AND ws_sold_date_sk = d2.d_date_sk
AND d2.d_date between d1.d_date AND (d1.d_date + interval '90 day')
AND ca_state in ('AR', 'GA', 'IN', 'KY', 'VA')
AND d1.d_year = 2000
AND hd_income_band_sk BETWEEN 8 AND 14
AND hd_buy_potential = '501-1000'
AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01
GROUP BY c_customer_sk, c_first_name, c_last_name
ORDER BY cnt
;
```

## Original Plan
```
Sort  (rows=0, time=164693.703)
  Aggregate  (rows=0, time=164693.69)
    Sort  (rows=0, time=164693.688)
      Nested Loop  (rows=0, time=164693.681)
        Nested Loop  (rows=1, time=164693.312)
          Nested Loop  (rows=2, time=164692.495)
            Gather  (rows=1917, time=152449.891)
              Nested Loop  (rows=639, time=66015.041)
                Nested Loop  (rows=10493, time=65948.471)
                  Nested Loop  (rows=10609, time=63767.758)
                    Hash Join  (rows=74035, time=42700.505)
                      Nested Loop  (rows=389199, time=42437.958)
                        Index Scan on date_dim (d1)  (rows=122, time=93.502)
                        Index Only Scan on store_returns  (rows=3190, time=346.303)
                      Hash  (rows=9203, time=79.348)
                        Index Only Scan on item  (rows=9203, time=78.194)
                    Index Scan on store_sales  (rows=0, time=0.284)
                  Index Scan on customer  (rows=1, time=0.204)
                Index Scan on household_demographics  (rows=0, time=0.005)
            Bitmap Heap Scan on web_sales  (rows=0, time=6.383)
              Bitmap Index Scan  (rows=50, time=0.252)
          Index Scan on date_dim (d2)  (rows=1, time=0.405)
        Index Scan on customer_address  (rows=0, time=0.368)
```

## IR Structure + Anchor Hashes
```
S0 [SELECT]
  MAIN QUERY (via Q_S0)
    FROM: store_sales, store_returns, web_sales, date_dim d1, date_dim d2, item, customer, customer_address, household_demographics
    WHERE [f2ece665ad1a915f]: ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk =...
    GROUP BY: c_customer_sk, c_first_name, c_last_name
    ORDER BY: cnt

Patch operations (core+advanced): insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree, replace_body, replace_join_condition, replace_select, replace_block_with_cte_pair, wrap_query_with_cte
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Schema / Index / Stats Context
- source: postgres
- referenced_tables: 8

| Table | Rows(est) | PK | Indexes |
|-------|-----------|----|---------|
| customer | 500000 | c_customer_sk | customer_pkey, _dta_index_customer_6_949578421__k9_k10, _dta_index_customer_6_949578421__k1_k5, _dta_index_customer_5_949578421__k13_k5 |
| customer_address | 250000 | ca_address_sk | customer_address_pkey |
| date_dim | 73049 | d_date_sk | date_dim_pkey, _dta_index_date_dim_6_661577395__k7_k4_k9_k1, _dta_index_date_dim_6_661577395__k7_k9_k1, _dta_index_date_dim_6_661577395__k1_k7_k9, _dta_index_date_dim_6_661577395__k7_k11_k1, _dta_index_date_dim_6_661577395__k9_k7_k1 |
| household_demographics | 7200 | hd_demo_sk | household_demographics_pkey |
| item | 102000 | i_item_sk | item_pkey, _dta_index_item_6_853578079__k1_2_5, _dta_index_item_6_853578079__k13_k11_k1, _dta_index_item_6_853578079__k18, _dta_index_item_6_853578079__k2_k1 |
| store_returns | 7197499 | sr_item_sk, sr_ticket_number | store_returns_pkey, _dta_index_store_returns_6_1013578649__k1_3_4_10_20, _dta_index_store_returns_6_1013578649__k5_1_3_10_11, _dta_index_store_returns_6_1013578649__k1_3_4_10 |
| store_sales | 28806628 | ss_item_sk, ss_ticket_number | store_sales_pkey, _dta_index_store_sales_6_1333579789__k1_k23_k14_k6_k8_k5_k7_3_4, _dta_index_store_sales_6_1333579789__k1_k5_k8_k3_11_13_14_20, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_9_16_23, _dta_index_store_sales_6_1333579789__k4_1_3_10_11_14, _dta_index_store_sales_6_1333579789__k1_k3_k10_k4_k8_23 |
| web_sales | 7197533 | ws_item_sk, ws_order_number | web_sales_pkey, _dta_index_web_sales_6_1269579561__k3_k18_k12_k14_16_29_34, _dta_index_web_sales_6_1269579561__k1_k4_k5_18, _dta_index_web_sales_6_1269579561__k1_8_24, _dta_index_web_sales_6_1269579561__k18_16, _dta_index_web_sales_6_1269579561__k1_k5 |

## Engine-Specific Knowledge
## Dialect Profile (POSTGRES)

**Combined Intelligence Baseline**: Combined intelligence baseline from 53 validated DSB queries at SF5-SF10, plus regression registry outcomes. PostgreSQL has bitmap index scans, JIT compilation, and aggressive CTE materialization. Techniques that work on DuckDB often regress here.

### Optimizer Strengths (don't fight these)
- `BITMAP_OR_SCAN`: Avoid splitting OR conditions into UNION ALL by default. Only consider OR→UNION when EXPLAIN shows OR blocks index usage and UNION branches become index scans. 0.21x and 0.26x reg…
- `SEMI_JOIN_EXISTS`: NEVER convert EXISTS to IN/NOT IN or materialized CTEs. 0.50x, 0.75x observed. Note: NOT EXISTS anti-join decorrelation can still be valid when replacing large correlated anti patterns.
- `INNER_JOIN_REORDERING`: Don't restructure INNER JOIN orders. Focus on LEFT JOIN blocking or comma-join confusion.
- `INDEX_ONLY_SCAN`: Small dimension lookups (<10K rows) may not need CTEs.

### Known Gaps (exploit these)
- `COMMA_JOIN_WEAKNESS` [HIGH] detect: FROM t1, t2, t3 WHERE t1.key = t2.key (comma joins, no explicit JOIN). Poor row estimates in EXPLAIN. | action: Convert comma-joins to explicit JOIN...ON syntax. Best when combined with date_cte_isolate.
- `CORRELATED_SUBQUERY_PARALYSIS` [HIGH] detect: Nested loop in EXPLAIN, inner re-executes aggregate per outer row. SQL: WHERE col > (SELECT AGG FROM ... WHERE outer.key = inner.key). Hash… | action: Convert correlated WHERE to explicit CTE with GROUP BY + JOIN.
- `NON_EQUI_JOIN_INPUT_BLINDNESS` [HIGH] detect: Expensive non-equi join (BETWEEN, <, >) with large inputs on both sides. Neither side filtered. | action: Reduce fact table input size via filtered CTE before the non-equi join.
- `CTE_MATERIALIZATION_FENCE` [MEDIUM] detect: Large CTE + small post-filter. Multi-referenced CTE that blocks predicate pushdown. | action: Materialize STRATEGICALLY: only when CTE is expensive and reused. Avoid fencing single-use cases.
- `CROSS_CTE_PREDICATE_BLINDNESS` [MEDIUM] detect: Sequential scan on dimension table without index condition. Late filter after large scan/join. | action: Pre-filter into CTE definition. But be more cautious than on DuckDB.

## Dispatcher Hypothesis
Cost spine dominated by Nested Loop (42437ms) and Hash Join (42700ms) processing 389k rows from store_returns. Late filtering on date_dim d1 and item causes full fact scans. Explicit JOIN syntax and dimension isolation should reduce intermediate rows and enable better join planning.

## Dispatcher Reasoning Trace
- Nested Loop between date_dim d1 and store_returns amplifies rows to 389k
- Hash Join with item occurs before store_sales join, missing early reduction
- Comma joins prevent optimal join reordering (COMMA_JOIN_WEAKNESS gap)
- d2.d_date BETWEEN condition creates non-equi join after large result set

## Equivalence Tier
- unordered

## Additional Intelligence
### AST Feature Detection

- **dimension_cte_isolate**: 100% match (DATE_DIM, GROUP_BY, MULTI_TABLE_5+) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: CROSS_JOIN_3_DIMS, UNFILTERED_CTE] [SUPPORT: portability_candidate; engines=duckdb]
- **sf_sk_pushdown_multi_fact**: 100% match (DATE_DIM, MULTI_TABLE_5+) (gap: PREDICATE_TRANSITIVITY_FAILURE) [SUPPORT: portability_candidate; engines=snowflake]
- **prefetch_fact_join**: 75% match (DATE_DIM, GROUP_BY, STAR_JOIN) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: MAX_2_CHAINS] [SUPPORT: portability_candidate; engines=duckdb]
  Missing: AGG_SUM
- **multi_date_range_cte**: 67% match (BETWEEN, DATE_DIM, GROUP_BY, MULTI_TABLE_5+) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [SUPPORT: portability_candidate; engines=duckdb]
  Missing: AGG_AVG, TABLE_REPEAT_3+
- **sf_sk_pushdown_union_all**: 67% match (DATE_DIM, MULTI_CHANNEL) (gap: PREDICATE_TRANSITIVITY_FAILURE) [SUPPORT: portability_candidate; engines=snowflake]
  Missing: UNION


## Probe Summary
12 probes fired, 0 passed validation, 0 showed speedup.

## BDA Table (all probes)

| Probe | Transform | Family | Status | Speedup | Top EXPLAIN Nodes | Model Description | SQL Patch | Error/Notes |
|-------|-----------|--------|--------|---------|-------------------|-------------------|-----------|-------------|
| p10 | pg_self_join_decomposition | E | ERROR | - | - | Materialize store_sales with ss_sales_price/ss_list_price filter into CTE before joining with store_returns. | p10 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p12 | multi_dimension_prefetch | A | ERROR | - | - | Combine d1, item, hd filters into single CTE, then join with store_returns in one step. | p12 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p05 | dimension_cte_isolate | A | ERROR | - | - | Create CTE for household_demographics (hd_income_band_sk BETWEEN 8 AND 14) and join early with customer. | p05 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p07 | multi_date_range_cte | A | ERROR | - | - | Materialize d2 range as CTE using d1 min/max: WHERE d_date BETWEEN (SELECT MIN(d_date) FROM d1) AND (SELECT MAX(d_date) + 90 FROM d1) | p07 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p03 | materialized_dimension_fact_prefilter | F | ERROR | - | - | Create CTEs for filtered dimensions (d1, item, hd) and pre-join with store_returns before joining with store_sales. | p03 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p04 | early_filter_decorrelate | B | ERROR | - | - | Push d1 filter into CTE definition. Pre-join store_returns with d1_cte before main query. | p04 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p02 | date_cte_explicit_join | F | ERROR | - | - | Materialize filtered d1 (d_year=2000) and d2 (d_date range) as CTEs. Use explicit JOINs between date CTEs and fact tables. | p02 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p01 | dimension_prefetch_star | F | ERROR | - | - | Convert all comma joins to explicit INNER JOIN syntax. Pre-filter selective dimensions (d1, item, hd, ca) into CTEs before joining with fact tables. | p01 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p11 | sf_sk_pushdown_multi_fact | A | ERROR | - | - | Add d_date_sk BETWEEN filter to store_returns and web_sales CTEs using d1/d2 surrogate keys. | p11 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p08 | shared_dimension_multi_channel | A | ERROR | - | - | Create shared CTE for item (i_category filter) referenced by both store and web sales paths. | p08 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p09 | aggregate_pushdown | C | ERROR | - | - | Pre-aggregate store_returns by sr_ticket_number, sr_item_sk before joining with store_sales. | p09 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |
| p06 | prefetch_fact_join | A | ERROR | - | - | Build CTE chain: 1) Filter d1, item, hd 2) Pre-join with store_returns 3) Join result with store_sales and customer. | p06 | Synthetic semantic check failed: SyntheticDataGenerator._generate_value() got an unexpected keyword argument 'row_context' |

## Worker SQL Patches

### p10: pg_self_join_decomposition (ERROR, n/a)
```sql
WITH filtered_store_sales AS (SELECT ss_ticket_number, ss_item_sk, ss_customer_sk FROM store_sales WHERE ss_sales_price / ss_list_price BETWEEN 0.76 AND 0.96) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM filtered_store_sales AS ss, store_returns AS sr, web_sales AS ws, date_dim AS d1, date_dim AS d2, item AS i, customer AS c, customer_address AS ca, household_demographics AS hd WHERE ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_hdemo_sk = hd_demo_sk AND ss_item_sk = sr_item_sk AND sr_item_sk = ws_item_sk AND i_item_sk = ss_item_sk AND i_category IN ('Children', 'Home', 'Women') AND sr_returned_date_sk = d1.d_date_sk AND ws_sold_date_sk = d2.d_date_sk AND d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND d1.d_year = 2000 AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p12: multi_dimension_prefetch (ERROR, n/a)
```sql
WITH filtered_dimensions AS (SELECT d1.d_date_sk, i_item_sk, hd_demo_sk FROM date_dim AS d1, item, household_demographics WHERE d1.d_year = 2000 AND i_category IN ('Children', 'Home', 'Women') AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000') SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales JOIN store_returns ON ss_ticket_number = sr_ticket_number AND ss_item_sk = sr_item_sk JOIN web_sales ON ss_customer_sk = ws_bill_customer_sk JOIN customer ON ss_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk JOIN filtered_dimensions AS fd ON sr_returned_date_sk = fd.d_date_sk AND ss_item_sk = fd.i_item_sk AND c_current_hdemo_sk = fd.hd_demo_sk JOIN date_dim AS d2 ON ws_sold_date_sk = d2.d_date_sk WHERE ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_hdemo_sk = hd_demo_sk AND ss_item_sk = sr_item_sk AND sr_item_sk = ws_item_sk AND i_item_sk = ss_item_sk AND i_category IN ('Children', 'Home', 'Women') AND sr_returned_date_sk = d1.d_date_sk AND ws_sold_date_sk = d2.d_date_sk AND d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND d1.d_year = 2000 AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p05: dimension_cte_isolate (ERROR, n/a)
```sql
WITH filtered_households AS (SELECT hd_demo_sk FROM household_demographics WHERE hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000') SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales, store_returns, web_sales, date_dim AS d1, date_dim AS d2, item, customer, customer_address, filtered_households WHERE ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_hdemo_sk = filtered_households.hd_demo_sk AND ss_item_sk = sr_item_sk AND sr_item_sk = ws_item_sk AND i_item_sk = ss_item_sk AND i_category IN ('Children', 'Home', 'Women') AND sr_returned_date_sk = d1.d_date_sk AND ws_sold_date_sk = d2.d_date_sk AND d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND d1.d_year = 2000 AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p07: multi_date_range_cte (ERROR, n/a)
```sql
WITH filtered_d2 AS (SELECT d2.d_date_sk, d2.d_date FROM date_dim AS d2 JOIN date_dim AS d1 ON d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') WHERE d1.d_year = 2000) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales, store_returns, web_sales, date_dim AS d1, filtered_d2 AS d2, item, customer, customer_address, household_demographics WHERE ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_hdemo_sk = hd_demo_sk AND ss_item_sk = sr_item_sk AND sr_item_sk = ws_item_sk AND i_item_sk = ss_item_sk AND i_category IN ('Children', 'Home', 'Women') AND sr_returned_date_sk = d1.d_date_sk AND ws_sold_date_sk = d2.d_date_sk AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p03: materialized_dimension_fact_prefilter (ERROR, n/a)
```sql
WITH filtered_date_dim AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2000), filtered_item AS (SELECT i_item_sk FROM item WHERE i_category IN ('Children', 'Home', 'Women')) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales AS ss JOIN store_returns AS sr ON ss.ss_ticket_number = sr.sr_ticket_number AND ss.ss_item_sk = sr.sr_item_sk JOIN web_sales AS ws ON ss.ss_customer_sk = ws.ws_bill_customer_sk AND sr.sr_item_sk = ws.ws_item_sk JOIN filtered_date_dim AS d1 ON sr.sr_returned_date_sk = d1.d_date_sk JOIN date_dim AS d2 ON ws.ws_sold_date_sk = d2.d_date_sk JOIN filtered_item AS i ON i.i_item_sk = ss.ss_item_sk JOIN customer AS c ON ss.ss_customer_sk = c.c_customer_sk JOIN customer_address AS ca ON c.c_current_addr_sk = ca.ca_address_sk JOIN household_demographics AS hd ON c.c_current_hdemo_sk = hd.hd_demo_sk WHERE ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_hdemo_sk = hd_demo_sk AND ss_item_sk = sr_item_sk AND sr_item_sk = ws_item_sk AND i_item_sk = ss_item_sk AND i_category IN ('Children', 'Home', 'Women') AND sr_returned_date_sk = d1.d_date_sk AND ws_sold_date_sk = d2.d_date_sk AND d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND d1.d_year = 2000 AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p04: early_filter_decorrelate (ERROR, n/a)
```sql
WITH filtered_store_returns AS (SELECT sr_item_sk, sr_ticket_number FROM store_returns AS sr JOIN date_dim AS d1 ON sr.sr_returned_date_sk = d1.d_date_sk WHERE d1.d_year = 2000) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales, filtered_store_returns, web_sales, date_dim AS d2, item, customer, customer_address, household_demographics WHERE ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_hdemo_sk = hd_demo_sk AND ss_item_sk = sr_item_sk AND sr_item_sk = ws_item_sk AND i_item_sk = ss_item_sk AND i_category IN ('Children', 'Home', 'Women') AND ws_sold_date_sk = d2.d_date_sk AND d2.d_date BETWEEN (SELECT MIN(d1.d_date) FROM date_dim AS d1 WHERE d1.d_year = 2000) AND ((SELECT MIN(d1.d_date) FROM date_dim AS d1 WHERE d1.d_year = 2000) + INTERVAL '90 DAY') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p02: date_cte_explicit_join (ERROR, n/a)
```sql
WITH d1_cte AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2000), d2_cte AS (SELECT d_date_sk, d_date FROM date_dim WHERE d_date BETWEEN (SELECT MIN(d_date) FROM date_dim WHERE d_year = 2000) AND (SELECT MIN(d_date) + INTERVAL '90 DAY' FROM date_dim WHERE d_year = 2000)) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales AS ss JOIN store_returns AS sr ON ss.ss_ticket_number = sr.sr_ticket_number AND ss.ss_item_sk = sr.sr_item_sk JOIN web_sales AS ws ON ss.ss_customer_sk = ws.ws_bill_customer_sk AND sr.sr_item_sk = ws.ws_item_sk JOIN d1_cte AS d1 ON sr.sr_returned_date_sk = d1.d_date_sk JOIN d2_cte AS d2 ON ws.ws_sold_date_sk = d2.d_date_sk JOIN item AS i ON i.i_item_sk = ss.ss_item_sk JOIN customer AS c ON ss.ss_customer_sk = c.c_customer_sk JOIN customer_address AS ca ON c.c_current_addr_sk = ca.ca_address_sk JOIN household_demographics AS hd ON c.c_current_hdemo_sk = hd.hd_demo_sk WHERE i.i_category IN ('Children', 'Home', 'Women') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss.ss_sales_price / ss.ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p01: dimension_prefetch_star (ERROR, n/a)
```sql
WITH filtered_date_dim_d1 AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2000), filtered_item AS (SELECT i_item_sk FROM item WHERE i_category IN ('Children', 'Home', 'Women')), filtered_customer_address AS (SELECT ca_address_sk FROM customer_address WHERE ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA')), filtered_household_demographics AS (SELECT hd_demo_sk FROM household_demographics WHERE hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000') SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales AS ss JOIN store_returns AS sr ON ss.ss_ticket_number = sr.sr_ticket_number AND ss.ss_item_sk = sr.sr_item_sk JOIN web_sales AS ws ON sr.sr_item_sk = ws.ws_item_sk AND ss.ss_customer_sk = ws.ws_bill_customer_sk JOIN filtered_date_dim_d1 AS d1 ON sr.sr_returned_date_sk = d1.d_date_sk JOIN date_dim AS d2 ON ws.ws_sold_date_sk = d2.d_date_sk JOIN filtered_item AS i ON i.i_item_sk = ss.ss_item_sk JOIN customer AS c ON ss.ss_customer_sk = c.c_customer_sk JOIN filtered_customer_address AS ca ON c.c_current_addr_sk = ca.ca_address_sk JOIN filtered_household_demographics AS hd ON c.c_current_hdemo_sk = hd.hd_demo_sk WHERE d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p11: sf_sk_pushdown_multi_fact (ERROR, n/a)
```sql
WITH filtered_store_returns AS (SELECT * FROM store_returns WHERE sr_returned_date_sk BETWEEN (SELECT MIN(d_date_sk) FROM date_dim WHERE d_year = 2000) AND (SELECT MAX(d_date_sk) FROM date_dim WHERE d_year = 2000)), filtered_web_sales AS (SELECT * FROM web_sales WHERE ws_sold_date_sk BETWEEN (SELECT MIN(d_date_sk) FROM date_dim WHERE d_year = 2000) AND (SELECT MAX(d_date_sk) FROM date_dim WHERE d_year = 2000)) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM filtered_store_returns, filtered_web_sales, date_dim AS d1, date_dim AS d2, item, customer, customer_address, household_demographics WHERE ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_hdemo_sk = hd_demo_sk AND ss_item_sk = sr_item_sk AND sr_item_sk = ws_item_sk AND i_item_sk = ss_item_sk AND i_category IN ('Children', 'Home', 'Women') AND sr_returned_date_sk = d1.d_date_sk AND ws_sold_date_sk = d2.d_date_sk AND d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND d1.d_year = 2000 AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p08: shared_dimension_multi_channel (ERROR, n/a)
```sql
WITH filtered_items AS (SELECT i_item_sk FROM item WHERE i_category IN ('Children', 'Home', 'Women')) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales AS ss JOIN store_returns AS sr ON ss.ss_ticket_number = sr.sr_ticket_number AND ss.ss_item_sk = sr.sr_item_sk JOIN web_sales AS ws ON ss.ss_customer_sk = ws.ws_bill_customer_sk AND sr.sr_item_sk = ws.ws_item_sk JOIN date_dim AS d1 ON sr.sr_returned_date_sk = d1.d_date_sk JOIN date_dim AS d2 ON ws.ws_sold_date_sk = d2.d_date_sk JOIN customer AS c ON ss.ss_customer_sk = c.c_customer_sk JOIN customer_address AS ca ON c.c_current_addr_sk = ca.ca_address_sk JOIN household_demographics AS hd ON c.c_current_hdemo_sk = hd.hd_demo_sk JOIN filtered_items AS fi ON fi.i_item_sk = ss.ss_item_sk WHERE d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND d1.d_year = 2000 AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss.ss_sales_price / ss.ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p09: aggregate_pushdown (ERROR, n/a)
```sql
WITH agg_store_returns AS (SELECT sr_ticket_number, sr_item_sk, COUNT(*) AS return_cnt FROM store_returns GROUP BY sr_ticket_number, sr_item_sk) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales AS ss JOIN agg_store_returns AS sr ON ss.ss_ticket_number = sr.sr_ticket_number AND ss.ss_item_sk = sr.sr_item_sk JOIN web_sales AS ws ON ss.ss_customer_sk = ws.ws_bill_customer_sk AND sr.sr_item_sk = ws.ws_item_sk JOIN date_dim AS d1 ON sr.sr_returned_date_sk = d1.d_date_sk JOIN date_dim AS d2 ON ws.ws_sold_date_sk = d2.d_date_sk JOIN item AS i ON i.i_item_sk = ss.ss_item_sk JOIN customer AS c ON ss.ss_customer_sk = c.c_customer_sk JOIN customer_address AS ca ON c.c_current_addr_sk = ca.ca_address_sk JOIN household_demographics AS hd ON c.c_current_hdemo_sk = hd.hd_demo_sk WHERE ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_hdemo_sk = hd_demo_sk AND ss_item_sk = sr_item_sk AND sr_item_sk = ws_item_sk AND i_item_sk = ss_item_sk AND i_category IN ('Children', 'Home', 'Women') AND sr_returned_date_sk = d1.d_date_sk AND ws_sold_date_sk = d2.d_date_sk AND d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND d1.d_year = 2000 AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

### p06: prefetch_fact_join (ERROR, n/a)
```sql
WITH filtered_date_item AS (SELECT d1.d_date_sk, i_item_sk FROM date_dim AS d1, item WHERE d1.d_year = 2000 AND i_category IN ('Children', 'Home', 'Women')), prejoined_returns AS (SELECT sr_item_sk, sr_ticket_number, sr_returned_date_sk FROM store_returns JOIN filtered_date_item AS fdi ON sr_item_sk = fdi.i_item_sk AND sr_returned_date_sk = fdi.d_date_sk) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales AS ss JOIN prejoined_returns AS sr ON ss.ss_ticket_number = sr.sr_ticket_number AND ss.ss_item_sk = sr.sr_item_sk JOIN web_sales AS ws ON ss.ss_customer_sk = ws.ws_bill_customer_sk AND sr.sr_item_sk = ws.ws_item_sk JOIN customer AS c ON ss.ss_customer_sk = c.c_customer_sk JOIN customer_address AS ca ON c.c_current_addr_sk = ca.ca_address_sk JOIN household_demographics AS hd ON c.c_current_hdemo_sk = hd.hd_demo_sk JOIN date_dim AS d2 ON ws.ws_sold_date_sk = d2.d_date_sk WHERE ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 AND d2.d_date BETWEEN (SELECT MIN(d_date) FROM filtered_date_item) AND (SELECT MIN(d_date) + INTERVAL '90 DAY' FROM filtered_date_item) GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```
