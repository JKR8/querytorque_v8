## Role

You are a SQL optimization analyst reviewing benchmark results. Analyze what worked, what failed, and design refined targets for the next round of workers.

Identify the primary bottleneck. Only provide secondary targets if they are distinct and high-confidence. Quality > Quantity.

You will see the original query, execution plan, IR structure, and detailed results from previous rounds.

## Query: query101_agg_i2

**Dialect**: POSTGRES

```sql
select  c_customer_sk, c_first_name, c_last_name, count(*) as cnt
FROM
store_sales,
store_returns,
web_sales,
date_dim d1,
date_dim d2,
item,
customer,
customer_address,
household_demographics
WHERE
ss_ticket_number = sr_ticket_number
AND ss_customer_sk = ws_bill_customer_sk
AND ss_customer_sk = c_customer_sk
AND c_current_addr_sk = ca_address_sk
AND c_current_hdemo_sk = hd_demo_sk
AND ss_item_sk = sr_item_sk
AND sr_item_sk = ws_item_sk
AND i_item_sk = ss_item_sk
AND i_category IN ('Children', 'Home', 'Women')
AND sr_returned_date_sk = d1.d_date_sk
AND ws_sold_date_sk = d2.d_date_sk
AND d2.d_date between d1.d_date AND (d1.d_date + interval '90 day')
AND ca_state in ('AR', 'GA', 'IN', 'KY', 'VA')
AND d1.d_year = 2000
AND hd_income_band_sk BETWEEN 8 AND 14
AND hd_buy_potential = '501-1000'
AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01
GROUP BY c_customer_sk, c_first_name, c_last_name
ORDER BY cnt
;
```


## Current Execution Plan

```
Sort  (rows=0, time=2521.478)
  Aggregate  (rows=0, time=2521.466)
    Nested Loop  (rows=0, time=2521.465)
      Nested Loop  (rows=0, time=2521.464)
        Gather Merge  (rows=107, time=2507.537)
          Sort  (rows=107, time=2506.77)
            Nested Loop  (rows=107, time=2506.404)
              Nested Loop  (rows=1917, time=2484.902)
                Nested Loop  (rows=31479, time=2401.29)
                  Nested Loop  (rows=31826, time=2141.002)
                    Hash Join  (rows=222105, time=476.388)
                      Nested Loop  (rows=1167596, time=182.94)
                        Index Scan on date_dim (d1)  (rows=366, time=13.744)
                        Index Only Scan on store_returns  (rows=3190, time=0.287)
                      Hash  (rows=27610, time=13.913)
                        Index Only Scan on item  (rows=27610, time=9.343)
                    Index Scan on store_sales  (rows=0, time=0.007)
                  Index Scan on customer  (rows=1, time=0.008)
                Index Scan on household_demographics  (rows=0, time=0.002)
              Index Scan on customer_address  (rows=0, time=0.01)
        Bitmap Heap Scan on web_sales  (rows=49, time=0.126)
          Bitmap Index Scan  (rows=49, time=0.02)
      Index Scan on date_dim (d2)  (rows=0, time=0.0)
```


## IR Structure (for patch targeting)

```
S0 [SELECT]
  MAIN QUERY (via Q_S0)
    FROM: store_sales, store_returns, web_sales, date_dim d1, date_dim d2, item, customer, customer_address, household_demographics
    WHERE [f2ece665ad1a915f]: ss_ticket_number = sr_ticket_number AND ss_customer_sk = ws_bill_customer_sk AND ss_customer_sk =...
    GROUP BY: c_customer_sk, c_first_name, c_last_name
    ORDER BY: cnt

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

**Note**: Use `by_node_id` (e.g., "S0") and `by_anchor_hash` (16-char hex) from map above to target patch operations.


## Optimization Families

Review the 6 families below. Each has a proven gold example.

Choose up to **4 most relevant families** for this query based on:
- Query structure (CTEs, subqueries, joins, aggregations, set operations)
- Execution plan signals (WHERE placement, repeated scans, correlated subqueries)
- Problem signature (cardinality estimation errors, loops vs sets, filter ordering)



### Family A: Early Filtering (Predicate Pushback)
**Description**: Push small filters into CTEs early, reduce row count before expensive operations
**Speedup Range**: 1.3–4.0x (~35% of all wins)
**Use When**:
  1. Late WHERE filters on dimension tables
  2. Cascading CTEs with filters applied downstream
  3. Expensive joins after filters could be pushed earlier

**Gold Example**: `pg_date_cte_explicit_join` (2.28x)



### Family B: Decorrelation (Sets Over Loops)
**Description**: Convert correlated subqueries to standalone CTEs with GROUP BY, eliminate per-row re-execution
**Speedup Range**: 2.4–2.9x (~15% of all wins)
**Use When**:
  1. Correlated subqueries in WHERE clause
  2. Scalar aggregates computed per outer row
  3. DELIM_SCAN in execution plan (indicates correlation)

**Gold Example**: `pg_shared_scan_decorrelate` (8043.91x (timeout rescue))



### Family C: Aggregation Pushdown (Minimize Rows Touched)
**Description**: Aggregate before expensive joins when GROUP BY keys ⊇ join keys, reduce intermediate sizes
**Speedup Range**: 1.3–15.3x (~5% of all wins (high variance))
**Use When**:
  1. GROUP BY happens after large joins
  2. GROUP BY keys are subset of join keys
  3. Intermediate result size >> final result size

**Gold Example**: `pg_materialized_dimension_fact_prefilter` (12.07x (V2 DSB SF10, was 2.68x in V1))



### Family D: Set Operation Optimization (Sets Over Loops)
**Description**: Replace INTERSECT/UNION-based patterns with EXISTS/NOT EXISTS, avoid full materialization
**Speedup Range**: 1.7–2.7x (~8% of all wins)
**Use When**:
  1. INTERSECT patterns between large sets
  2. UNION ALL with duplicate elimination
  3. Set operations materializing full intermediate results

**Gold Example**: `pg_intersect_to_exists` (1.78x)



### Family E: Materialization / Prefetch (Don't Repeat Work)
**Description**: Extract repeated scans or pre-compute intermediate results for reuse across multiple consumers
**Speedup Range**: 1.3–6.2x (~18% of all wins)
**Use When**:
  1. Repeated scans of same table with different filters
  2. Dimension filters applied independently multiple times
  3. CTE referenced multiple times with implicit re-evaluation

**Gold Example**: `multi_dimension_prefetch` (2.71x)



### Family F: Join Transform (Right Shape First)
**Description**: Restructure join topology: convert comma joins to explicit INNER JOIN, optimize join order, eliminate self-joins via single-pass aggregation
**Speedup Range**: 1.8–8.6x (~19% of all wins)
**Use When**:
  1. Comma-separated joins (implicit cross joins) in FROM clause
  2. Self-joins scanning same table multiple times
  3. Dimension-fact join order suboptimal for predicate pushdown

**Gold Example**: `pg_explicit_join_materialized` (8.56x)



## Optimization History

### History — All Prior Patches

| Iter | Patch | Family | Transform | Speedup | Status | Orig ms | Patch ms | Error (summary) |
|------|-------|--------|-----------|---------|--------|---------|----------|-----------------|
| 0 | t1 | F | explicit_join_restructure | — | FAIL | — | — | Tier-1 structural: LITERAL MISMATCH: Ori |
| 0 | t2 | A | dimension_predicate_pushdown | — | FAIL | — | — | Tier-1 structural: LITERAL MISMATCH: Ori |
| 0 | t3 | E | date_dim_prefetch | — | FAIL | — | — | Equivalence execution error: column refe |
| 0 | syn_w2 | B | decorrelate | — | FAIL | — | — | Tier-1 structural: LITERAL MISMATCH: Ori |



### Latest Iteration 0 — Detailed Results

#### Race Results

| Patch | Family | Transform | Speedup | Status | Orig ms | Patch ms | Semantic | Error |
|-------|--------|-----------|---------|--------|---------|----------|----------|-------|
| t1 | F | explicit_join_restructure | — | FAIL | — | — | FAIL | Tier-1 structural: LITERAL MISMATCH: Original literals missing from rewrite — nu |
| t2 | A | dimension_predicate_pushdown | — | FAIL | — | — | FAIL | Tier-1 structural: LITERAL MISMATCH: Original literals missing from rewrite — nu |
| t3 | E | date_dim_prefetch | — | FAIL | — | — | FAIL | Equivalence execution error: column reference "d_date_sk" is ambiguous
LINE 1: . |
| syn_w2 | B | decorrelate | — | FAIL | — | — | FAIL | Tier-1 structural: LITERAL MISMATCH: Original literals missing from rewrite — nu |

#### Patched SQL

**t1 (Family F, explicit_join_restructure):**
```sql
SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales INNER JOIN store_returns ON ss_ticket_number = sr_ticket_number INNER JOIN item ON ss_item_sk = i_item_sk AND i_category IN ('Children', 'Home', 'Women') INNER JOIN customer ON ss_customer_sk = c_customer_sk INNER JOIN customer_address ON c_current_addr_sk = ca_address_sk AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') INNER JOIN household_demographics ON c_current_hdemo_sk = hd_demo_sk AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' INNER JOIN date_dim AS d1 ON sr_returned_date_sk = d1.d_date_sk AND d1.d_year = 2000 INNER JOIN web_sales ON ss_customer_sk = ws_bill_customer_sk AND sr_item_sk = ws_item_sk INNER JOIN date_dim AS d2 ON ws_sold_date_sk = d2.d_date_sk AND d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') WHERE ss_sales_price / ss_list_price BETWEEN 0.76 AND 0.96 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

**t2 (Family A, dimension_predicate_pushdown):**
```sql
WITH filtered_item AS (SELECT i_item_sk FROM item WHERE i_category IN ('Children', 'Home', 'Women')), filtered_ca AS (SELECT ca_address_sk FROM customer_address WHERE ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA')), filtered_hd AS (SELECT hd_demo_sk FROM household_demographics WHERE hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000') SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales JOIN store_returns ON ss_ticket_number = sr_ticket_number AND ss_item_sk = sr_item_sk JOIN web_sales ON ss_customer_sk = ws_bill_customer_sk AND sr_item_sk = ws_item_sk JOIN date_dim AS d1 ON sr_returned_date_sk = d1.d_date_sk AND d1.d_year = 2000 JOIN date_dim AS d2 ON ws_sold_date_sk = d2.d_date_sk JOIN customer ON ss_customer_sk = c_customer_sk JOIN filtered_item ON i_item_sk = ss_item_sk JOIN filtered_ca ON c_current_addr_sk = ca_address_sk JOIN filtered_hd ON c_current_hdemo_sk = hd_demo_sk WHERE d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY') AND ss_sales_price / ss_list_price BETWEEN 0.76 AND 0.96 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

**t3 (Family E, date_dim_prefetch):**
```sql
WITH d1_cte AS (SELECT * FROM date_dim WHERE d_year = 2000), d2_range AS (SELECT d_date_sk, d_date FROM d1_cte CROSS JOIN LATERAL (SELECT d_date_sk, d_date FROM date_dim WHERE d_date BETWEEN d1_cte.d_date AND (d1_cte.d_date + INTERVAL '90 DAY')) AS d2_sub) SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM store_sales JOIN store_returns ON ss_ticket_number = sr_ticket_number AND ss_item_sk = sr_item_sk JOIN web_sales ON ss_customer_sk = ws_bill_customer_sk AND sr_item_sk = ws_item_sk JOIN d1_cte ON sr_returned_date_sk = d1_cte.d_date_sk JOIN d2_range ON ws_sold_date_sk = d2_range.d_date_sk JOIN item ON i_item_sk = ss_item_sk JOIN customer ON ss_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk JOIN household_demographics ON c_current_hdemo_sk = hd_demo_sk WHERE i_category IN ('Children', 'Home', 'Women') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND ss_sales_price / ss_list_price BETWEEN 76 * 0.01 AND 96 * 0.01 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

**syn_w2 (Family B, decorrelate):**
```sql
WITH joined_data AS (SELECT ss_customer_sk, ss_item_sk, ss_ticket_number, ss_sales_price, ss_list_price, sr_item_sk, sr_ticket_number, sr_returned_date_sk, ws_bill_customer_sk, ws_item_sk, ws_sold_date_sk, i_category, ca_state, hd_income_band_sk, hd_buy_potential, d1.d_date, d2.d_date AS d2_date FROM store_sales INNER JOIN store_returns ON ss_ticket_number = sr_ticket_number INNER JOIN web_sales ON ss_customer_sk = ws_bill_customer_sk AND sr_item_sk = ws_item_sk INNER JOIN item ON ss_item_sk = i_item_sk INNER JOIN customer ON ss_customer_sk = c_customer_sk INNER JOIN customer_address ON c_current_addr_sk = ca_address_sk INNER JOIN household_demographics ON c_current_hdemo_sk = hd_demo_sk INNER JOIN date_dim AS d1 ON sr_returned_date_sk = d1.d_date_sk INNER JOIN date_dim AS d2 ON ws_sold_date_sk = d2.d_date_sk WHERE i_category IN ('Children', 'Home', 'Women') AND ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000' AND d1.d_year = 2000 AND d2.d_date BETWEEN d1.d_date AND (d1.d_date + INTERVAL '90 DAY')), filtered_customers AS (SELECT c_customer_sk, c_first_name, c_last_name FROM customer INNER JOIN customer_address ON c_current_addr_sk = ca_address_sk INNER JOIN household_demographics ON c_current_hdemo_sk = hd_demo_sk WHERE ca_state IN ('AR', 'GA', 'IN', 'KY', 'VA') AND hd_income_band_sk BETWEEN 8 AND 14 AND hd_buy_potential = '501-1000') SELECT c_customer_sk, c_first_name, c_last_name, COUNT(*) AS cnt FROM joined_data AS jd INNER JOIN filtered_customers AS fc ON jd.ss_customer_sk = fc.c_customer_sk WHERE jd.ss_sales_price / jd.ss_list_price BETWEEN 0.76 AND 0.96 GROUP BY c_customer_sk, c_first_name, c_last_name ORDER BY cnt;
```

#### Execution Plans

**Original EXPLAIN:**
```
Sort  (rows=0, time=2521.478)
  Aggregate  (rows=0, time=2521.466)
    Nested Loop  (rows=0, time=2521.465)
      Nested Loop  (rows=0, time=2521.464)
        Gather Merge  (rows=107, time=2507.537)
          Sort  (rows=107, time=2506.77)
            Nested Loop  (rows=107, time=2506.404)
              Nested Loop  (rows=1917, time=2484.902)
                Nested Loop  (rows=31479, time=2401.29)
                  Nested Loop  (rows=31826, time=2141.002)
                    Hash Join  (rows=222105, time=476.388)
                      Nested Loop  (rows=1167596, time=182.94)
                        Index Scan on date_dim (d1)  (rows=366, time=13.744)
                        Index Only Scan on store_returns  (rows=3190, time=0.287)
                      Hash  (rows=27610, time=13.913)
                        Index Only Scan on item  (rows=27610, time=9.343)
                    Index Scan on store_sales  (rows=0, time=0.007)
                  Index Scan on customer  (rows=1, time=0.008)
                Index Scan on household_demographics  (rows=0, time=0.002)
              Index Scan on customer_address  (rows=0, time=0.01)
        Bitmap Heap Scan on web_sales  (rows=49, time=0.126)
          Bitmap Index Scan  (rows=49, time=0.02)
      Index Scan on date_dim (d2)  (rows=0, time=0.0)
```

#### Error Details

- **t1** (FAIL): Tier-1 structural: LITERAL MISMATCH: Original literals missing from rewrite — numbers: ['0.01', '76.0', '96.0']. The rewrite changed filter values instead of preserving them.
- **t2** (FAIL): Tier-1 structural: LITERAL MISMATCH: Original literals missing from rewrite — numbers: ['0.01', '76.0', '96.0']. The rewrite changed filter values instead of preserving them.
- **t3** (FAIL): Equivalence execution error: column reference "d_date_sk" is ambiguous
LINE 1: ...ate_dim WHERE d_year = 2000), d2_range AS (SELECT d_date_sk,...
                                                             ^

- **syn_w2** (FAIL): Tier-1 structural: LITERAL MISMATCH: Original literals missing from rewrite — numbers: ['0.01', '76.0', '96.0']. The rewrite changed filter values instead of preserving them.


## Your Task — Snipe Round 1


Results from latest iteration: **4 FAIL**.

Follow this protocol exactly.

### Step 1 — Compare EXPLAIN Plans

For each patch above, compare its EXPLAIN plan to the Original EXPLAIN.

For each **WIN**, answer:
- QUOTE the operator line(s) from the original that got cheaper or were eliminated. Give the exact operator name, time, and row count from the plan text above.
- What structural SQL change caused that operator improvement?
- What is the **most expensive remaining operator** in this winner's plan? QUOTE its line (name, time, rows).

For each **FAIL/NEUTRAL/REGRESSION**:
- QUOTE the operator(s) that got MORE expensive vs the original.
- Why did the structural change backfire?

Then classify winners as REDUNDANT (same core structural change, same operators improved) or COMPLEMENTARY (different operators improved, different structural changes).

### Step 2 — Design Targets by Combining Strategies

Start from the **best winner's SQL** as your baseline.

**CRITICAL**: Do NOT invent new hypotheses about row counts or selectivity. Every claim about rows, times, or costs MUST be a direct quote from an EXPLAIN plan above. If a number is not in the plans, you do not know it.

**CRITICAL**: Do NOT spend targets on optimizer-equivalent rewrites (UNION↔UNION ALL, JOIN↔WHERE IN, CTE↔subquery). These produce identical plans. Focus on changes that **eliminate operators** or **reduce input rows to expensive operators** as shown in the plans.

Design up to 4 targets, prioritized:

1. **Combination** (primary if complementary winners exist): Take the best winner's SQL. Layer on the structural change from a complementary winner that addresses a DIFFERENT expensive operator. Cite both operators by name from the EXPLAIN plans.
2. **Refinement**: Take the best winner's SQL. Target its most expensive remaining operator (quoted in Step 1). Design a structural change that reduces input rows to that operator. CITE the operator and its current row count from the plan.
3. **Rescue** (if a failed patch had a sound structural idea): Fix the implementation while preserving the best winner's gains.
4. **Novel**: A new structural approach that targets the most expensive remaining operator. Cite the operator from the plan.

**Combined families**: You MAY combine families in a single target (e.g. "A+B", "B+E", "A+F"). The worker will receive gold examples from ALL referenced families.

Output up to 4 targets. Same JSON format:

```json
[
  {
    "family": "A+B",
    "transform": "early_filter_then_decorrelate",
    "target_id": "t1",
    "relevance_score": 0.95,
    "hypothesis": "...",
    "target_ir": "...",
    "recommended_examples": ["date_cte_isolate", "shared_scan_decorrelate"]
  }
]
```

Output up to 4 targets. Fewer strong targets beat padding with weak ones.
