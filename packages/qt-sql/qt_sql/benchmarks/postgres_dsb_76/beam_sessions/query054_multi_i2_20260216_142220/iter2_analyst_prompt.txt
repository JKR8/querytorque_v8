## Role

You are a SQL optimization analyst reviewing benchmark results. Analyze what worked, what failed, and design refined targets for the next round of workers.

Identify the primary bottleneck. Only provide secondary targets if they are distinct and high-confidence. Quality > Quantity.

You will see the original query, execution plan, IR structure, and detailed results from previous rounds.

## Query: query054_multi_i2

**Dialect**: POSTGRES

```sql
with my_customers as (
 select distinct c_customer_sk
        , c_current_addr_sk
 from
        ( select cs_sold_date_sk sold_date_sk,
                 cs_bill_customer_sk customer_sk,
                 cs_item_sk item_sk,
                 cs_wholesale_cost wholesale_cost
          from   catalog_sales
          union all
          select ws_sold_date_sk sold_date_sk,
                 ws_bill_customer_sk customer_sk,
                 ws_item_sk item_sk,
                 ws_wholesale_cost wholesale_cost
          from   web_sales
         ) cs_or_ws_sales,
         item,
         date_dim,
         customer
 where   sold_date_sk = d_date_sk
         and item_sk = i_item_sk
         and i_category = 'Home'
         and i_class = 'curtains/drapes'
         and c_customer_sk = cs_or_ws_sales.customer_sk
         and d_moy = 5
         and d_year = 1998
         and wholesale_cost BETWEEN 70 AND 100
         and c_birth_year BETWEEN 1942 AND 1955
 )
 , my_revenue as (
 select c_customer_sk,
        sum(ss_ext_sales_price) as revenue
 from   my_customers,
        store_sales,
        customer_address,
        store,
        date_dim
 where  c_current_addr_sk = ca_address_sk
        and ca_county = s_county
        and ca_state = s_state
        and ss_sold_date_sk = d_date_sk
        and c_customer_sk = ss_customer_sk
        and ss_wholesale_cost BETWEEN 70 AND 100
        and s_state in ('AR','GA','IN'
                    ,'KS','KY','NC'
                    ,'OH','PA','SD'
                    ,'VA')
        and d_month_seq between (select distinct d_month_seq+1
                                 from   date_dim where d_year = 1998 and d_moy = 5)
                           and  (select distinct d_month_seq+3
                                 from   date_dim where d_year = 1998 and d_moy = 5)
 group by c_customer_sk
 )
 , segments as
 (select cast((revenue/50) as int) as segment
  from   my_revenue
 )
  select  segment, count(*) as num_customers, segment*50 as segment_base
 from segments
 group by segment
 order by segment, num_customers
 limit 100;
```


## Current Execution Plan

```
Limit  (rows=0, time=74.871)
  Sort  (rows=0, time=74.869)
    Aggregate  (rows=0, time=74.854)
      Sort  (rows=0, time=74.853)
        Subquery Scan (my_revenue)  (rows=0, time=74.848)
          Aggregate  (rows=0, time=74.847)
            Aggregate  (rows=0, time=0.0)
              Index Only Scan on date_dim (date_dim_2)  (rows=0, time=0.0)
            Aggregate  (rows=0, time=0.0)
              Index Only Scan on date_dim (date_dim_3)  (rows=0, time=0.0)
            Nested Loop  (rows=0, time=74.843)
              Nested Loop  (rows=0, time=74.842)
                Nested Loop  (rows=0, time=74.841)
                  Nested Loop  (rows=131, time=74.668)
                    Unique  (rows=131, time=73.834)
                      Sort  (rows=132, time=73.822)
                        Nested Loop  (rows=132, time=73.749)
                          Gather  (rows=707, time=67.076)
                            Nested Loop  (rows=236, time=23.146)
                              Index Only Scan on date_dim (date_dim_1)  (rows=10, time=1.148)
                              Nested Loop  (rows=23, time=2.126)
                                Index Only Scan on item  (rows=833, time=0.243)
                                Append  (rows=0, time=0.002)
                                  Index Scan on catalog_sales  (rows=0, time=0.001)
                                  Index Scan on web_sales  (rows=0, time=0.001)
                          Index Scan on customer  (rows=0, time=0.009)
                    Index Scan on customer_address  (rows=1, time=0.006)
                  Index Scan on store  (rows=0, time=0.001)
                Bitmap Heap Scan on store_sales  (rows=0, time=0.0)
                  Bitmap Index Scan  (rows=0, time=0.0)
              Index Scan on date_dim  (rows=0, time=0.0)
```


## IR Structure (for patch targeting)

```
S0 [SELECT]
  CTE: my_customers  (via CTE_Q_S0_my_customers)
    FROM: (subquery) cs_or_ws_sales, item, date_dim, customer
    WHERE [b05f804bc25a41cf]: sold_date_sk = d_date_sk AND item_sk = i_item_sk AND i_category = 'Home' AND i_class = 'curtains/...
  CTE: my_revenue  (via CTE_Q_S0_my_revenue)
    FROM: my_customers, store_sales, customer_address, store, date_dim
    WHERE [763590318bd26331]: c_current_addr_sk = ca_address_sk AND ca_county = s_county AND ca_state = s_state AND ss_sold_dat...
    GROUP BY: c_customer_sk
  CTE: segments  (via CTE_Q_S0_segments)
    FROM: my_revenue
  MAIN QUERY (via Q_S0)
    FROM: segments
    GROUP BY: segment
    ORDER BY: segment, num_customers

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

**Note**: Use `by_node_id` (e.g., "S0") and `by_anchor_hash` (16-char hex) from map above to target patch operations.


## Optimization Families

Review the 6 families below. Each has a proven gold example.

Choose up to **4 most relevant families** for this query based on:
- Query structure (CTEs, subqueries, joins, aggregations, set operations)
- Execution plan signals (WHERE placement, repeated scans, correlated subqueries)
- Problem signature (cardinality estimation errors, loops vs sets, filter ordering)



### Family A: Early Filtering (Predicate Pushback)
**Description**: Push small filters into CTEs early, reduce row count before expensive operations
**Speedup Range**: 1.3–4.0x (~35% of all wins)
**Use When**:
  1. Late WHERE filters on dimension tables
  2. Cascading CTEs with filters applied downstream
  3. Expensive joins after filters could be pushed earlier

**Gold Example**: `pg_date_cte_explicit_join` (2.28x)



### Family B: Decorrelation (Sets Over Loops)
**Description**: Convert correlated subqueries to standalone CTEs with GROUP BY, eliminate per-row re-execution
**Speedup Range**: 2.4–2.9x (~15% of all wins)
**Use When**:
  1. Correlated subqueries in WHERE clause
  2. Scalar aggregates computed per outer row
  3. DELIM_SCAN in execution plan (indicates correlation)

**Gold Example**: `pg_shared_scan_decorrelate` (8043.91x (timeout rescue))



### Family C: Aggregation Pushdown (Minimize Rows Touched)
**Description**: Aggregate before expensive joins when GROUP BY keys ⊇ join keys, reduce intermediate sizes
**Speedup Range**: 1.3–15.3x (~5% of all wins (high variance))
**Use When**:
  1. GROUP BY happens after large joins
  2. GROUP BY keys are subset of join keys
  3. Intermediate result size >> final result size

**Gold Example**: `pg_materialized_dimension_fact_prefilter` (12.07x (V2 DSB SF10, was 2.68x in V1))



### Family D: Set Operation Optimization (Sets Over Loops)
**Description**: Replace INTERSECT/UNION-based patterns with EXISTS/NOT EXISTS, avoid full materialization
**Speedup Range**: 1.7–2.7x (~8% of all wins)
**Use When**:
  1. INTERSECT patterns between large sets
  2. UNION ALL with duplicate elimination
  3. Set operations materializing full intermediate results

**Gold Example**: `pg_intersect_to_exists` (1.78x)



### Family E: Materialization / Prefetch (Don't Repeat Work)
**Description**: Extract repeated scans or pre-compute intermediate results for reuse across multiple consumers
**Speedup Range**: 1.3–6.2x (~18% of all wins)
**Use When**:
  1. Repeated scans of same table with different filters
  2. Dimension filters applied independently multiple times
  3. CTE referenced multiple times with implicit re-evaluation

**Gold Example**: `multi_dimension_prefetch` (2.71x)



### Family F: Join Transform (Right Shape First)
**Description**: Restructure join topology: convert comma joins to explicit INNER JOIN, optimize join order, eliminate self-joins via single-pass aggregation
**Speedup Range**: 1.8–8.6x (~19% of all wins)
**Use When**:
  1. Comma-separated joins (implicit cross joins) in FROM clause
  2. Self-joins scanning same table multiple times
  3. Dimension-fact join order suboptimal for predicate pushdown

**Gold Example**: `pg_explicit_join_materialized` (8.56x)



## Optimization History

### History — All Prior Patches

| Iter | Patch | Family | Transform | Speedup | Status | Orig ms | Patch ms | Error (summary) |
|------|-------|--------|-----------|---------|--------|---------|----------|-----------------|
| 0 | t1 | B | subquery_decorrelation | 1.07x | IMPROVED | 61 | 57 |  |
| 0 | t2 | A | push_filters_into_union_branches | — | FAIL | — | — | Step s1 failed: No target found for repl |
| 0 | t3 | F | explicit_join_restructure | — | FAIL | — | — | Step s1 failed: Cannot parse body sql_fr |
| 0 | syn_w2 | B | decorrelate | 1.03x | NEUTRAL | 61 | 59 |  |
| 1 | t1 | A | push_wholesale_filter | — | FAIL | — | — | Tier-1 structural: COLUMN REF MISMATCH:  |
| 1 | t1 | A | push_wholesale_filter | — | FAIL | — | — | Tier-1 structural: COLUMN REF MISMATCH:  |
| 1 | t1 | A | push_wholesale_filter | — | FAIL | — | — | Tier-1 structural: COLUMN REF MISMATCH:  |



### Latest Iteration 1 — Detailed Results

#### Race Results

| Patch | Family | Transform | Speedup | Status | Orig ms | Patch ms | Semantic | Error |
|-------|--------|-----------|---------|--------|---------|----------|----------|-------|
| t1 | A | push_wholesale_filter | — | FAIL | — | — | FAIL | Tier-1 structural: COLUMN REF MISMATCH: Original columns missing from rewrite —  |
| t1 | A | push_wholesale_filter | — | FAIL | — | — | FAIL | Tier-1 structural: COLUMN REF MISMATCH: Original columns missing from rewrite —  |
| t1 | A | push_wholesale_filter | — | FAIL | — | — | FAIL | Tier-1 structural: COLUMN REF MISMATCH: Original columns missing from rewrite —  |

#### Patched SQL

**t1 (Family A, push_wholesale_filter):**
```sql
WITH my_customers AS (SELECT DISTINCT c_customer_sk, c_current_addr_sk FROM (SELECT cs_sold_date_sk AS sold_date_sk, cs_bill_customer_sk AS customer_sk, cs_item_sk AS item_sk, cs_wholesale_cost AS wholesale_cost FROM catalog_sales UNION ALL SELECT ws_sold_date_sk AS sold_date_sk, ws_bill_customer_sk AS customer_sk, ws_item_sk AS item_sk, ws_wholesale_cost AS wholesale_cost FROM web_sales) AS cs_or_ws_sales, item, date_dim, customer WHERE sold_date_sk = d_date_sk AND item_sk = i_item_sk AND i_category = 'Home' AND i_class = 'curtains/drapes' AND c_customer_sk = cs_or_ws_sales.customer_sk AND d_moy = 5 AND d_year = 1998 AND c_birth_year BETWEEN 1942 AND 1955), my_revenue AS (SELECT c_customer_sk, SUM(ss_ext_sales_price) AS revenue FROM my_customers, store_sales, customer_address, store, date_dim WHERE c_current_addr_sk = ca_address_sk AND ca_county = s_county AND ca_state = s_state AND ss_sold_date_sk = d_date_sk AND c_customer_sk = ss_customer_sk AND ss_wholesale_cost BETWEEN 70 AND 100 AND s_state IN ('AR', 'GA', 'IN', 'KS', 'KY', 'NC', 'OH', 'PA', 'SD', 'VA') AND d_month_seq BETWEEN (SELECT DISTINCT d_month_seq + 1 FROM date_dim WHERE d_year = 1998 AND d_moy = 5) AND (SELECT DISTINCT d_month_seq + 3 FROM date_dim WHERE d_year = 1998 AND d_moy = 5) GROUP BY c_customer_sk), segments AS (SELECT CAST((revenue / 50) AS INT) AS segment FROM my_revenue), catalog_sales_filtered AS (SELECT cs_sold_date_sk AS sold_date_sk, cs_bill_customer_sk AS customer_sk, cs_item_sk AS item_sk FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 70 AND 100), web_sales_filtered AS (SELECT ws_sold_date_sk AS sold_date_sk, ws_bill_customer_sk AS customer_sk, ws_item_sk AS item_sk FROM web_sales WHERE ws_wholesale_cost BETWEEN 70 AND 100) SELECT segment, COUNT(*) AS num_customers, segment * 50 AS segment_base FROM (SELECT sold_date_sk, customer_sk, item_sk FROM catalog_sales_filtered UNION ALL SELECT sold_date_sk, customer_sk, item_sk FROM web_sales_filtered) AS cs_or_ws_sales, item, date_dim, customer GROUP BY segment ORDER BY segment, num_customers LIMIT 100;
```

**t1 (Family A, push_wholesale_filter):**
```sql
WITH my_customers AS (SELECT DISTINCT c_customer_sk, c_current_addr_sk FROM (SELECT cs_sold_date_sk AS sold_date_sk, cs_bill_customer_sk AS customer_sk, cs_item_sk AS item_sk, cs_wholesale_cost AS wholesale_cost FROM catalog_sales UNION ALL SELECT ws_sold_date_sk AS sold_date_sk, ws_bill_customer_sk AS customer_sk, ws_item_sk AS item_sk, ws_wholesale_cost AS wholesale_cost FROM web_sales) AS cs_or_ws_sales, item, date_dim, customer WHERE sold_date_sk = d_date_sk AND item_sk = i_item_sk AND i_category = 'Home' AND i_class = 'curtains/drapes' AND c_customer_sk = cs_or_ws_sales.customer_sk AND d_moy = 5 AND d_year = 1998 AND c_birth_year BETWEEN 1942 AND 1955), my_revenue AS (SELECT c_customer_sk, SUM(ss_ext_sales_price) AS revenue FROM my_customers, store_sales, customer_address, store, date_dim WHERE c_current_addr_sk = ca_address_sk AND ca_county = s_county AND ca_state = s_state AND ss_sold_date_sk = d_date_sk AND c_customer_sk = ss_customer_sk AND ss_wholesale_cost BETWEEN 70 AND 100 AND s_state IN ('AR', 'GA', 'IN', 'KS', 'KY', 'NC', 'OH', 'PA', 'SD', 'VA') AND d_month_seq BETWEEN (SELECT DISTINCT d_month_seq + 1 FROM date_dim WHERE d_year = 1998 AND d_moy = 5) AND (SELECT DISTINCT d_month_seq + 3 FROM date_dim WHERE d_year = 1998 AND d_moy = 5) GROUP BY c_customer_sk), segments AS (SELECT CAST((revenue / 50) AS INT) AS segment FROM my_revenue), catalog_sales_filtered AS (SELECT cs_sold_date_sk AS sold_date_sk, cs_bill_customer_sk AS customer_sk, cs_item_sk AS item_sk FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 70 AND 100), web_sales_filtered AS (SELECT ws_sold_date_sk AS sold_date_sk, ws_bill_customer_sk AS customer_sk, ws_item_sk AS item_sk FROM web_sales WHERE ws_wholesale_cost BETWEEN 70 AND 100) SELECT segment, COUNT(*) AS num_customers, segment * 50 AS segment_base FROM (SELECT sold_date_sk, customer_sk, item_sk FROM catalog_sales_filtered UNION ALL SELECT sold_date_sk, customer_sk, item_sk FROM web_sales_filtered) AS cs_or_ws_sales, item, date_dim, customer GROUP BY segment ORDER BY segment, num_customers LIMIT 100;
```

**t1 (Family A, push_wholesale_filter):**
```sql
WITH my_customers AS (SELECT DISTINCT c_customer_sk, c_current_addr_sk FROM (SELECT cs_sold_date_sk AS sold_date_sk, cs_bill_customer_sk AS customer_sk, cs_item_sk AS item_sk, cs_wholesale_cost AS wholesale_cost FROM catalog_sales UNION ALL SELECT ws_sold_date_sk AS sold_date_sk, ws_bill_customer_sk AS customer_sk, ws_item_sk AS item_sk, ws_wholesale_cost AS wholesale_cost FROM web_sales) AS cs_or_ws_sales, item, date_dim, customer WHERE sold_date_sk = d_date_sk AND item_sk = i_item_sk AND i_category = 'Home' AND i_class = 'curtains/drapes' AND c_customer_sk = cs_or_ws_sales.customer_sk AND d_moy = 5 AND d_year = 1998 AND c_birth_year BETWEEN 1942 AND 1955), my_revenue AS (SELECT c_customer_sk, SUM(ss_ext_sales_price) AS revenue FROM my_customers, store_sales, customer_address, store, date_dim WHERE c_current_addr_sk = ca_address_sk AND ca_county = s_county AND ca_state = s_state AND ss_sold_date_sk = d_date_sk AND c_customer_sk = ss_customer_sk AND ss_wholesale_cost BETWEEN 70 AND 100 AND s_state IN ('AR', 'GA', 'IN', 'KS', 'KY', 'NC', 'OH', 'PA', 'SD', 'VA') AND d_month_seq BETWEEN (SELECT DISTINCT d_month_seq + 1 FROM date_dim WHERE d_year = 1998 AND d_moy = 5) AND (SELECT DISTINCT d_month_seq + 3 FROM date_dim WHERE d_year = 1998 AND d_moy = 5) GROUP BY c_customer_sk), segments AS (SELECT CAST((revenue / 50) AS INT) AS segment FROM my_revenue), catalog_sales_filtered AS (SELECT cs_sold_date_sk AS sold_date_sk, cs_bill_customer_sk AS customer_sk, cs_item_sk AS item_sk FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 70 AND 100), web_sales_filtered AS (SELECT ws_sold_date_sk AS sold_date_sk, ws_bill_customer_sk AS customer_sk, ws_item_sk AS item_sk FROM web_sales WHERE ws_wholesale_cost BETWEEN 70 AND 100) SELECT segment, COUNT(*) AS num_customers, segment * 50 AS segment_base FROM (SELECT sold_date_sk, customer_sk, item_sk FROM catalog_sales_filtered UNION ALL SELECT sold_date_sk, customer_sk, item_sk FROM web_sales_filtered) AS cs_or_ws_sales, item, date_dim, customer GROUP BY segment ORDER BY segment, num_customers LIMIT 100;
```

#### Execution Plans

**Original EXPLAIN:**
```
Limit  (rows=0, time=74.871)
  Sort  (rows=0, time=74.869)
    Aggregate  (rows=0, time=74.854)
      Sort  (rows=0, time=74.853)
        Subquery Scan (my_revenue)  (rows=0, time=74.848)
          Aggregate  (rows=0, time=74.847)
            Aggregate  (rows=0, time=0.0)
              Index Only Scan on date_dim (date_dim_2)  (rows=0, time=0.0)
            Aggregate  (rows=0, time=0.0)
              Index Only Scan on date_dim (date_dim_3)  (rows=0, time=0.0)
            Nested Loop  (rows=0, time=74.843)
              Nested Loop  (rows=0, time=74.842)
                Nested Loop  (rows=0, time=74.841)
                  Nested Loop  (rows=131, time=74.668)
                    Unique  (rows=131, time=73.834)
                      Sort  (rows=132, time=73.822)
                        Nested Loop  (rows=132, time=73.749)
                          Gather  (rows=707, time=67.076)
                            Nested Loop  (rows=236, time=23.146)
                              Index Only Scan on date_dim (date_dim_1)  (rows=10, time=1.148)
                              Nested Loop  (rows=23, time=2.126)
                                Index Only Scan on item  (rows=833, time=0.243)
                                Append  (rows=0, time=0.002)
                                  Index Scan on catalog_sales  (rows=0, time=0.001)
                                  Index Scan on web_sales  (rows=0, time=0.001)
                          Index Scan on customer  (rows=0, time=0.009)
                    Index Scan on customer_address  (rows=1, time=0.006)
                  Index Scan on store  (rows=0, time=0.001)
                Bitmap Heap Scan on store_sales  (rows=0, time=0.0)
                  Bitmap Index Scan  (rows=0, time=0.0)
              Index Scan on date_dim  (rows=0, time=0.0)
```

#### Error Details

- **t1** (FAIL): Tier-1 structural: COLUMN REF MISMATCH: Original columns missing from rewrite — ['wholesale_cost']. The rewrite references different table columns.
- **t1** (FAIL): Tier-1 structural: COLUMN REF MISMATCH: Original columns missing from rewrite — ['wholesale_cost']. The rewrite references different table columns.
- **t1** (FAIL): Tier-1 structural: COLUMN REF MISMATCH: Original columns missing from rewrite — ['wholesale_cost']. The rewrite references different table columns.


## Your Task — Snipe Round 2


Results from latest iteration: **3 FAIL**.

Follow this protocol exactly.

### Step 1 — Compare EXPLAIN Plans

For each patch above, compare its EXPLAIN plan to the Original EXPLAIN.

For each **WIN**, answer:
- QUOTE the operator line(s) from the original that got cheaper or were eliminated. Give the exact operator name, time, and row count from the plan text above.
- What structural SQL change caused that operator improvement?
- What is the **most expensive remaining operator** in this winner's plan? QUOTE its line (name, time, rows).

For each **FAIL/NEUTRAL/REGRESSION**:
- QUOTE the operator(s) that got MORE expensive vs the original.
- Why did the structural change backfire?

Then classify winners as REDUNDANT (same core structural change, same operators improved) or COMPLEMENTARY (different operators improved, different structural changes).

### Step 2 — Design Targets by Combining Strategies

Start from the **best winner's SQL** as your baseline.

**CRITICAL**: Do NOT invent new hypotheses about row counts or selectivity. Every claim about rows, times, or costs MUST be a direct quote from an EXPLAIN plan above. If a number is not in the plans, you do not know it.

**CRITICAL**: Do NOT spend targets on optimizer-equivalent rewrites (UNION↔UNION ALL, JOIN↔WHERE IN, CTE↔subquery). These produce identical plans. Focus on changes that **eliminate operators** or **reduce input rows to expensive operators** as shown in the plans.

Design up to 4 targets, prioritized:

1. **Combination** (primary if complementary winners exist): Take the best winner's SQL. Layer on the structural change from a complementary winner that addresses a DIFFERENT expensive operator. Cite both operators by name from the EXPLAIN plans.
2. **Refinement**: Take the best winner's SQL. Target its most expensive remaining operator (quoted in Step 1). Design a structural change that reduces input rows to that operator. CITE the operator and its current row count from the plan.
3. **Rescue** (if a failed patch had a sound structural idea): Fix the implementation while preserving the best winner's gains.
4. **Novel**: A new structural approach that targets the most expensive remaining operator. Cite the operator from the plan.

**Combined families**: You MAY combine families in a single target (e.g. "A+B", "B+E", "A+F"). The worker will receive gold examples from ALL referenced families.

Output up to 4 targets. Same JSON format:

```json
[
  {
    "family": "A+B",
    "transform": "early_filter_then_decorrelate",
    "target_id": "t1",
    "relevance_score": 0.95,
    "hypothesis": "...",
    "target_ir": "...",
    "recommended_examples": ["date_cte_isolate", "shared_scan_decorrelate"]
  }
]
```

Output up to 4 targets. Fewer strong targets beat padding with weak ones.
