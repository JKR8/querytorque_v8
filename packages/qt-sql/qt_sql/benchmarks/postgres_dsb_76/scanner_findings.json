{
  "metadata": {
    "extracted_at": "2026-02-10T00:30:00",
    "pass1_model": "manual",
    "pass2_model": "manual",
    "n_findings": 10
  },
  "findings": [
    {
      "id": "SF-001",
      "claim": "Default 'random_page_cost' prevents discovery of cheaper plans for >50% of complex queries",
      "category": "cost_model",
      "supporting_queries": ["query014_multi_i1", "query013_spj_i1", "query064_multi_i1", "query031_multi_i1", "query054_multi_i2"],
      "evidence_summary": "43 distinct query variants found cheaper plans (cost ratio > 1.0) when random_page_cost was reduced to 1.1; Q014 saw 1.23x wall-clock speedup.",
      "evidence_count": 43,
      "contradicting_count": 0,
      "boundaries": ["Applies to SSD-backed environments where random access is comparable to sequential"],
      "mechanism": "Lowering random_page_cost reduces the penalty for Index Scans, allowing the optimizer to prefer them over Sequential Scans for large dimension lookups.",
      "confidence": "high",
      "confidence_rationale": "Overwhelming volume of plan changes (43 observations) with validated wall-clock improvements on subset.",
      "implication": "Tuning random_page_cost=1.1 is the single most effective configuration change for this workload."
    },
    {
      "id": "SF-002",
      "claim": "Disabling Nested Loops causes catastrophic regressions (up to 184x) on latency-sensitive queries",
      "category": "join_sensitivity",
      "supporting_queries": ["query080_multi_i1", "query010_multi_i1", "query010_multi_i2"],
      "evidence_summary": "Q080 regressed from 73ms to 13,440ms (wall=0.01x) when Nested Loop was disabled; Q010 regressed 6x.",
      "evidence_count": 3,
      "contradicting_count": 0,
      "boundaries": ["Applies to 'short' queries (<100ms baseline) performing specific PK lookups"],
      "mechanism": "The optimizer correctly uses Nested Loops for high-selectivity joins; forcing Hash/Merge requires full table scans of unrelated partitions.",
      "confidence": "high",
      "confidence_rationale": "Extreme magnitude of regression (184x) validates the optimizer's dependency on this join type.",
      "implication": "Never globally disable nested loops; the engine relies on them for star-schema point lookups."
    },
    {
      "id": "SF-003",
      "claim": "The optimizer falls into a 'Nested Loop Trap' on mid-range joins, where forcing Hash Join is ~40% faster",
      "category": "join_method",
      "supporting_queries": ["query014_multi_i1", "query065_multi_i1"],
      "evidence_summary": "Q014 wall speedup 1.40x when Nested Loop disabled; Q065 wall speedup 1.07x (jit interaction) or neutral. Q014 baseline chose NL but Hash was better.",
      "evidence_count": 2,
      "contradicting_count": 0,
      "boundaries": ["Applies to queries with mid-sized dimension tables that fit in hash memory but have misleading statistics"],
      "mechanism": "Optimizer underestimates cost of repeated index lookups (NL) compared to one-time hash table build.",
      "confidence": "medium",
      "confidence_rationale": "Strong signal on Q014, but fewer occurrences than other patterns.",
      "implication": "Watch for 'loop-heavy' plans on queries taking 1-10 seconds; hint Hash Join if rows > 100k."
    },
    {
      "id": "SF-004",
      "claim": "Manual join ordering outperforms the optimizer by >2x on complex multi-joins",
      "category": "join_order",
      "supporting_queries": ["query010_multi_i1", "query010_multi_i2"],
      "evidence_summary": "Forcing manual order (no_reorder) improved Q010 wall time from 1343ms to 898ms (1.49x) and 1160ms to 486ms (2.38x).",
      "evidence_count": 2,
      "contradicting_count": 1,
      "boundaries": ["Specific to queries with >5 joins where the manual SQL text reflects a logical filtration order"],
      "mechanism": "The optimizer's genetic or dynamic programming search missed the optimal left-deep tree that the query author implicitly defined.",
      "confidence": "medium",
      "confidence_rationale": "High impact (2.4x speedup) but only observed on Q010; Q014 regressed with this flag.",
      "implication": "For stubborn queries, setting `join_collapse_limit=1` to respect SQL authorship order can fix bad plans."
    },
    {
      "id": "SF-005",
      "claim": "Parallelism cost model is overly conservative; forcing max workers often reveals cheaper plans",
      "category": "parallelism",
      "supporting_queries": ["query023_multi_i1", "query030_multi_i1", "query064_multi_i1", "query075_multi_i1", "query083_multi_i1", "query091_agg_i1"],
      "evidence_summary": "15+ queries show `max_parallel` producing plans with significantly lower costs (cost ratio 1.1x - 1.4x), yet these weren't picked by default.",
      "evidence_count": 20,
      "contradicting_count": 1,
      "boundaries": ["Aggregation-heavy queries where parallel scan/agg benefits exceed gathering costs"],
      "mechanism": "The planner over-penalizes `Gather` or `Parallel Setup` costs, defaulting to sequential plans even when parallel plans are calculated to be cheaper.",
      "confidence": "high",
      "confidence_rationale": "Widespread pattern of `cost > 1` under `max_parallel` flag.",
      "implication": "Aggressively tune `min_parallel_table_scan_size` and `parallel_setup_cost` to encourage parallelism."
    },
    {
      "id": "SF-006",
      "claim": "JIT compilation overhead causes regressions for sub-second queries",
      "category": "jit",
      "supporting_queries": ["query080_multi_i1", "query065_multi_i1"],
      "evidence_summary": "Q080 (73ms baseline) improved to 1.29x speed (56ms) when JIT was disabled.",
      "evidence_count": 2,
      "contradicting_count": 1,
      "boundaries": ["Queries with execution time < 100ms"],
      "mechanism": "The time spent optimizing/inlining LLVM code exceeds the execution time saved for short-running queries.",
      "confidence": "medium",
      "confidence_rationale": "Consistent with known JIT behavior, though only captured on 2 wall-clock validated queries here.",
      "implication": "Disable JIT (`jit=off`) for high-throughput, low-latency reporting dashboards."
    },
    {
      "id": "SF-007",
      "claim": "Increasing `work_mem` yields distinct plan improvements and ~30% wall-clock speedup",
      "category": "memory",
      "supporting_queries": ["query001_multi_i1", "query014_multi_i1", "query064_multi_i1"],
      "evidence_summary": "Q001 speedup 1.35x and Q014 speedup 1.11x when work_mem increased (256MB/1GB). Q064 found 20% cheaper plan.",
      "evidence_count": 6,
      "contradicting_count": 0,
      "boundaries": ["Memory-intensive hash joins and sorts"],
      "mechanism": "Allows Hash Joins to stay in memory (avoiding batching/spilling) and enables larger in-memory sorts.",
      "confidence": "high",
      "confidence_rationale": "Consistent positive correlation between work_mem and performance/cost.",
      "implication": "Allocate higher `work_mem` (e.g., 256MB+) for analytic sessions compared to TP defaults."
    },
    {
      "id": "SF-008",
      "claim": "Interaction of 'dumb' flags (no hash, no merge) can accidentally discover 7x faster plans",
      "category": "interaction",
      "supporting_queries": ["query083_multi_i1"],
      "evidence_summary": "Q083 improved from 143ms to 20ms (6.99x speedup) when HashJoin and MergeJoin were both disabled.",
      "evidence_count": 1,
      "contradicting_count": 0,
      "boundaries": ["Specific high-selectivity multi-joins"],
      "mechanism": "By removing the 'smart' join options, the planner was forced into a highly efficient Nested Loop Index Scan that it previously underestimated.",
      "confidence": "medium",
      "confidence_rationale": "Single data point, but the magnitude (7x) is significant.",
      "implication": "Use `SET LOCAL enable_hashjoin=off` as a debugging tactic for unexplained slow queries to check for better nested loop paths."
    },
    {
      "id": "SF-009",
      "claim": "Hash Join is the structural bottleneck; disabling it causes near-total cost model failure",
      "category": "join_method",
      "supporting_queries": ["query069_multi_i1", "query092_multi_i1", "query094_multi_i1", "query050_agg_i1"],
      "evidence_summary": "Dozens of queries show `no_hashjoin` cost dropping to <0.1 (meaning baseline was much cheaper), often coinciding with JOIN_ORDER_TRAP.",
      "evidence_count": 30,
      "contradicting_count": 2,
      "boundaries": ["Large aggregation/star-schema queries"],
      "mechanism": "Merge Join requires sorting (expensive) and Nested Loop is impossible for large tables; Hash Join is the only viable path.",
      "confidence": "high",
      "confidence_rationale": "Broad consensus across the dataset.",
      "implication": "Ensure `hash_mem_multiplier` and memory settings prioritize Hash Join efficiency."
    },
    {
      "id": "SF-010",
      "claim": "Parallelism provides a reliable ~2x speedup for aggregation queries",
      "category": "parallelism",
      "supporting_queries": ["query014_multi_i1", "query013_agg_i1", "query013_spj_i1"],
      "evidence_summary": "Disabling parallelism (`no_parallel`) caused ~0.5x speed regressions (2x slowdown) across multiple wall-clock validated queries.",
      "evidence_count": 5,
      "contradicting_count": 0,
      "boundaries": ["Queries scanning large fact tables"],
      "mechanism": "Linear scaling of scan/agg throughput with worker count (likely 2 workers used here).",
      "confidence": "high",
      "confidence_rationale": "Consistent wall-clock validation.",
      "implication": "Parallelism is working correctly when engaged; the issue is the optimizer's reluctance to engage it (see SF-005)."
    }
  ]
}
