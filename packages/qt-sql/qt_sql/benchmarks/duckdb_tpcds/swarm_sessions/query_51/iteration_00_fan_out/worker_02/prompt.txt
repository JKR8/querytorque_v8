You are a SQL rewrite engine for DuckDB v1.4.3. Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

DuckDB specifics: columnar storage (SELECT only needed columns). CTEs referenced once are typically inlined; CTEs referenced multiple times may be materialized. FILTER clause is native (`COUNT(*) FILTER (WHERE cond)`). Predicate pushdown stops at UNION ALL boundaries and multi-level CTE references.

## Semantic Contract (MUST preserve)

(a) Business intent: Compare item-level cumulative daily sales between web and store channels over month sequence 1216-1227, returning dates where web cumulative sales exceed store cumulative sales.
(b) JOIN semantics: FULL OUTER JOIN between web and store CTEs on item_sk and d_date preserves rows from both channels even when one channel has no sales on a given day; missing values become NULL.
(c) Aggregation traps: The window function SUM(SUM(...)) OVER computes running totals; the outer SUM OVER is monotonic and grouping-safe. The final MAX OVER carries forward last non-null cumulative value.
(d) Filter dependencies: The date filter d_month_seq BETWEEN 1216 AND 1216+11 must be applied before joining with fact tables; web/item_sk IS NOT NULL filters are redundant but safe.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
date_cte -> web_cumulative -> store_cumulative -> full_outer_join -> main_window -> final_filter
NODE_CONTRACTS:
  date_cte:
    FROM: date_dim
    WHERE: d_month_seq BETWEEN 1216 AND 1216+11
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 365
    CONSUMERS: web_cumulative, store_cumulative
  web_cumulative:
    FROM: web_sales INNER JOIN date_cte ON ws_sold_date_sk = d_date_sk
    WHERE: ws_item_sk IS NOT NULL
    GROUP BY: ws_item_sk, d_date
    AGGREGATE: daily_web = SUM(ws_sales_price)
    WINDOW: PARTITION BY ws_item_sk ORDER BY d_date
    OUTPUT: ws_item_sk AS item_sk, d_date, SUM(daily_web) OVER (PARTITION BY ws_item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS cume_sales
    EXPECTED_ROWS: 1.4M
    CONSUMERS: full_outer_join
  store_cumulative:
    FROM: store_sales INNER JOIN date_cte ON ss_sold_date_sk = d_date_sk
    WHERE: ss_item_sk IS NOT NULL
    GROUP BY: ss_item_sk, d_date
    AGGREGATE: daily_store = SUM(ss_sales_price)
    WINDOW: PARTITION BY ss_item_sk ORDER BY d_date
    OUTPUT: ss_item_sk AS item_sk, d_date, SUM(daily_store) OVER (PARTITION BY ss_item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS cume_sales
    EXPECTED_ROWS: 4.6M
    CONSUMERS: full_outer_join
  full_outer_join:
    FROM: web_cumulative FULL OUTER JOIN store_cumulative ON web_cumulative.item_sk = store_cumulative.item_sk AND web_cumulative.d_date = store_cumulative.d_date
    OUTPUT: COALESCE(web_cumulative.item_sk, store_cumulative.item_sk) AS item_sk, COALESCE(web_cumulative.d_date, store_cumulative.d_date) AS d_date, web_cumulative.cume_sales AS web_sales, store_cumulative.cume_sales AS store_sales
    EXPECTED_ROWS: 5.5M
    CONSUMERS: main_window
  main_window:
    FROM: full_outer_join
    WINDOW: PARTITION BY item_sk ORDER BY d_date
    OUTPUT: item_sk, d_date, web_sales, store_sales, MAX(web_sales) OVER (PARTITION BY item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS web_cumulative, MAX(store_sales) OVER (PARTITION BY item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS store_cumulative
    EXPECTED_ROWS: 5.5M
    CONSUMERS: final_filter
  final_filter:
    FROM: main_window
    WHERE: web_cumulative > store_cumulative
    ORDER BY: item_sk, d_date
    LIMIT: 100
    OUTPUT: item_sk, d_date, web_sales, store_sales, web_cumulative, store_cumulative
    EXPECTED_ROWS: 100

NODE_CONTRACTS:
date_cte:
    FROM: date_dim
    WHERE: d_month_seq BETWEEN 1216 AND 1216+11
    OUTPUT: d_date_sk, d_date
    EXPECTED_ROWS: 365
    CONSUMERS: web_cumulative, store_cumulative
  web_cumulative:
    FROM: web_sales INNER JOIN date_cte ON ws_sold_date_sk = d_date_sk
    WHERE: ws_item_sk IS NOT NULL
    GROUP BY: ws_item_sk, d_date
    AGGREGATE: daily_web = SUM(ws_sales_price)
    WINDOW: PARTITION BY ws_item_sk ORDER BY d_date
    OUTPUT: ws_item_sk AS item_sk, d_date, SUM(daily_web) OVER (PARTITION BY ws_item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS cume_sales
    EXPECTED_ROWS: 1.4M
    CONSUMERS: full_outer_join
  store_cumulative:
    FROM: store_sales INNER JOIN date_cte ON ss_sold_date_sk = d_date_sk
    WHERE: ss_item_sk IS NOT NULL
    GROUP BY: ss_item_sk, d_date
    AGGREGATE: daily_store = SUM(ss_sales_price)
    WINDOW: PARTITION BY ss_item_sk ORDER BY d_date
    OUTPUT: ss_item_sk AS item_sk, d_date, SUM(daily_store) OVER (PARTITION BY ss_item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS cume_sales
    EXPECTED_ROWS: 4.6M
    CONSUMERS: full_outer_join
  full_outer_join:
    FROM: web_cumulative FULL OUTER JOIN store_cumulative ON web_cumulative.item_sk = store_cumulative.item_sk AND web_cumulative.d_date = store_cumulative.d_date
    OUTPUT: COALESCE(web_cumulative.item_sk, store_cumulative.item_sk) AS item_sk, COALESCE(web_cumulative.d_date, store_cumulative.d_date) AS d_date, web_cumulative.cume_sales AS web_sales, store_cumulative.cume_sales AS store_sales
    EXPECTED_ROWS: 5.5M
    CONSUMERS: main_window
  main_window:
    FROM: full_outer_join
    WINDOW: PARTITION BY item_sk ORDER BY d_date
    OUTPUT: item_sk, d_date, web_sales, store_sales, MAX(web_sales) OVER (PARTITION BY item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS web_cumulative, MAX(store_sales) OVER (PARTITION BY item_sk ORDER BY d_date ROWS UNBOUNDED PRECEDING) AS store_cumulative
    EXPECTED_ROWS: 5.5M
    CONSUMERS: final_filter
  final_filter:
    FROM: main_window
    WHERE: web_cumulative > store_cumulative
    ORDER BY: item_sk, d_date
    LIMIT: 100
    OUTPUT: item_sk, d_date, web_sales, store_sales, web_cumulative, store_cumulative
    EXPECTED_ROWS: 100

## Hazard Flags (avoid these specific risks)

- The window functions in channel CTEs are still computed before the join, which may be redundant with the main window.
- The date_cte may be inlined (single reference), but we reference it twice; ensure it's materialized.

## Regression Warnings (observed failures on similar queries)

1. regression_q51_date_cte_isolate (0.87x):
   CAUSE: Materializing cumulative window aggregates into CTEs before a join that filters on those aggregates. The optimizer can co-optimize window evaluation and join filtering.
   RULE: Do not materialize running/cumulative window aggregates into CTEs before joins that filter based on those aggregates.
2. regression_q31_pushdown (0.49x):
   CAUSE: Keeping both filtered and original CTEs causes redundant materialization and cardinality misestimates.
   RULE: When creating filtered CTEs, remove the original unfiltered CTEs.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Output must include item_sk, d_date, web_sales, store_sales, web_cumulative, store_cumulative.
- CTE_COLUMN_COMPLETENESS: Each CTE must output item_sk, d_date, and cumulative sales columns referenced downstream.
- LITERAL_PRESERVATION: Date filter values 1216 and 1216+11 must be preserved exactly.
- SEMANTIC_EQUIVALENCE: Must return same 100 rows ordered by item_sk, d_date.
- CROSS_CTE_PREDICATE_BLINDNESS: Date filter applied twice (once per channel CTE) causing two date_dim scans (365 rows each) in EXPLAIN.
- UNION_CTE_SELF_JOIN_DECOMPOSITION: Not applicable; no UNION CTE.
- REDUNDANT_SCAN_ELIMINATION: Not applicable; each fact table scanned once per channel.

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

Apply shared date dimension extraction from shared_dimension_multi_channel: create one date CTE referenced by both channel CTEs. Ignore the promotion/item filters from the example; we only have date filter.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. shared_dimension_multi_channel (1.30x)

**Principle:** Shared Dimension Extraction: when multiple channel CTEs (store/catalog/web) apply identical dimension filters, extract those shared filters into one CTE and reference it from each channel. Avoids redundant dimension scans.

**BEFORE (slow):**
```sql
with ssr as
 (select  s_store_id as store_id,
          sum(ss_ext_sales_price) as sales,
          sum(coalesce(sr_return_amt, 0)) as "returns",
          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit
  from store_sales left outer join store_returns on
         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),
     date_dim,
     store,
     item,
     promotion
 where ss_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-28' as date) 
                  and (cast('1998-08-28' as date) + INTERVAL 30 DAY)
       and ss_store_sk = s_store_sk
       and ss_item_sk = i_item_sk
       and i_current_price > 50
       and ss_promo_sk = p_promo_sk
       and p_channel_tv = 'N'
 group by s_store_id)
 ,
 csr as
 (select  cp_catalog_page_id as catalog_page_id,
          sum(cs_ext_sales_price) as sales,
          sum(coalesce(cr_return_amount, 0)) as "returns",
          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit
  from catalog_sales left outer join catalog_returns on
         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),
     date_dim,
     catalog_page,
     item,
     promotion
 where cs_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-28' as date)
                  and (cast('1998-08-28' as date) + INTERVAL 30 DAY)
        and cs_catalog_page_sk = cp_catalog_page_sk
       and cs_item_sk = i_item_sk
       and i_current_price > 50
       and cs_promo_sk = p_promo_sk
       and p_channel_tv = 'N'
group by cp_catalog_page_id)
 ,
 wsr as
 (select  web_site_id,
          sum(ws_ext_sales_price) as sales,
          sum(coalesce(wr_return_amt, 0)) as "returns",
          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit
  from web_sales left outer join web_returns on
         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),
     date_dim,
     web_site,
     item,
     promotion
 where ws_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-28' as date)
                  and (cast('1998-08-28' as date) + INTERVAL 30 DAY)
        and ws_web_site_sk = web_site_sk
       and ws_item_sk = i_item_sk
       and i_current_price > 50
       and ws_promo_sk = p_promo_sk
       and p_channel_tv = 'N'
group by web_site_id)
  select channel
        , id
        , sum(sales) as sales
        , sum("returns") as "returns"
        , sum(profit) as profit
 from 
 (select 'store channel' as channel
        , 'store' || store_id as id
        , sales
        , "returns"
        , profit
 from   ssr
 union all
 select 'catalog channel' as channel
        , 'catalog_page' || catalog_page_id as id
        , sales
        , "returns"
        , profit
 from  csr
 union all
 select 'web channel' as channel
        , 'web_site' || web_site_id as id
        , sales
        , "returns"
        , profit
 from   wsr
 ) x
 group by rollup (channel, id)
 order by channel
         ,id
 LIMIT 100;
```

**AFTER (fast):**
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-28' AS DATE) AND (CAST('1998-08-28' AS DATE) + INTERVAL '30' DAY)
```
[filtered_items]:
```sql
SELECT i_item_sk FROM item WHERE i_current_price > 50
```
[filtered_promotions]:
```sql
SELECT p_promo_sk FROM promotion WHERE p_channel_tv = 'N'
```
[prefiltered_store_sales]:
```sql
SELECT ss_item_sk, ss_store_sk, ss_ticket_number, ss_ext_sales_price, ss_net_profit FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk JOIN filtered_items ON ss_item_sk = i_item_sk JOIN filtered_promotions ON ss_promo_sk = p_promo_sk
```
[prefiltered_web_sales]:
```sql
SELECT ws_item_sk, ws_web_site_sk, ws_order_number, ws_ext_sales_price, ws_net_profit FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk JOIN filtered_items ON ws_item_sk = i_item_sk JOIN filtered_promotions ON ws_promo_sk = p_promo_sk
```
[ssr]:
```sql
SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS returns, SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM prefiltered_store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) JOIN store ON ss_store_sk = s_store_sk GROUP BY s_store_id
```
[wsr]:
```sql
SELECT web_site_id, SUM(ws_ext_sales_price) AS sales, SUM(COALESCE(wr_return_amt, 0)) AS returns, SUM(ws_net_profit - COALESCE(wr_net_loss, 0)) AS profit FROM prefiltered_web_sales LEFT OUTER JOIN web_returns ON (ws_item_sk = wr_item_sk AND ws_order_number = wr_order_number) JOIN web_site ON ws_web_site_sk = web_site_sk GROUP BY web_site_id
```

### 2. date_cte_isolate (4.00x)

**Principle:** Dimension Isolation: extract small dimension lookups into CTEs so they materialize once and subsequent joins probe a tiny hash table instead of rescanning.

**BEFORE (slow):**
```sql
select a.ca_state state, count(*) cnt
 from customer_address a
     ,customer c
     ,store_sales s
     ,date_dim d
     ,item i
 where       a.ca_address_sk = c.c_current_addr_sk
 	and c.c_customer_sk = s.ss_customer_sk
 	and s.ss_sold_date_sk = d.d_date_sk
 	and s.ss_item_sk = i.i_item_sk
 	and d.d_month_seq = 
 	     (select distinct (d_month_seq)
 	      from date_dim
               where d_year = 2002
 	        and d_moy = 3 )
 	and i.i_current_price > 1.2 * 
             (select avg(j.i_current_price) 
 	     from item j 
 	     where j.i_category = i.i_category)
 group by a.ca_state
 having count(*) >= 10
 order by cnt, a.ca_state
 LIMIT 100;
```

**AFTER (fast):**
[target_month]:
```sql
SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1
```
[category_avg_price]:
```sql
SELECT i_category, AVG(i_current_price) * 1.2 AS avg_threshold FROM item GROUP BY i_category
```
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim JOIN target_month ON d_month_seq = target_month.d_month_seq
```
[filtered_sales]:
```sql
SELECT ss_customer_sk, ss_item_sk FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk
```
[main_query]:
```sql
SELECT a.ca_state AS state, COUNT(*) AS cnt FROM customer_address a JOIN customer c ON a.ca_address_sk = c.c_current_addr_sk JOIN filtered_sales s ON c.c_customer_sk = s.ss_customer_sk JOIN item i ON s.ss_item_sk = i.i_item_sk JOIN category_avg_price cap ON i.i_category = cap.i_category WHERE i.i_current_price > cap.avg_threshold GROUP BY a.ca_state HAVING COUNT(*) >= 10 ORDER BY cnt, a.ca_state LIMIT 100
```

## Original SQL

```sql
-- start query 51 in stream 0 using template query51.tpl
WITH web_v1 as (
select
  ws_item_sk item_sk, d_date,
  sum(sum(ws_sales_price))
      over (partition by ws_item_sk order by d_date rows between unbounded preceding and current row) cume_sales
from web_sales
    ,date_dim
where ws_sold_date_sk=d_date_sk
  and d_month_seq between 1216 and 1216+11
  and ws_item_sk is not NULL
group by ws_item_sk, d_date),
store_v1 as (
select
  ss_item_sk item_sk, d_date,
  sum(sum(ss_sales_price))
      over (partition by ss_item_sk order by d_date rows between unbounded preceding and current row) cume_sales
from store_sales
    ,date_dim
where ss_sold_date_sk=d_date_sk
  and d_month_seq between 1216 and 1216+11
  and ss_item_sk is not NULL
group by ss_item_sk, d_date)
 select *
from (select item_sk
     ,d_date
     ,web_sales
     ,store_sales
     ,max(web_sales)
         over (partition by item_sk order by d_date rows between unbounded preceding and current row) web_cumulative
     ,max(store_sales)
         over (partition by item_sk order by d_date rows between unbounded preceding and current row) store_cumulative
     from (select case when web.item_sk is not null then web.item_sk else store.item_sk end item_sk
                 ,case when web.d_date is not null then web.d_date else store.d_date end d_date
                 ,web.cume_sales web_sales
                 ,store.cume_sales store_sales
           from web_v1 web full outer join store_v1 store on (web.item_sk = store.item_sk
                                                          and web.d_date = store.d_date)
          )x )y
where web_cumulative > store_cumulative
order by item_sk
        ,d_date
 LIMIT 100;

-- end query 51 in stream 0 using template query51.tpl
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

### Column Completeness Contract

Your `main_query` component MUST produce **exactly** these output columns (same names, same order):

  1. `*`

Do NOT add, remove, or rename any output columns. The result set schema must be identical to the original query.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
├── [CTE] store_v1  [=]  Cost: 33%  Rows: ~1K  — Compute cumulative store sales per item by date within the same sequence using windowed running sums.
│   ├── SCAN (store_sales, date_dim (join))
│   ├── JOIN (ss_sold_date_sk = d_date_sk)
│   ├── FILTER (d_month_seq BETWEEN 1216 AND 1216 + 11)
│   ├── FILTER (NOT ss_item_sk IS NULL)
│   ├── AGG (GROUP BY)
│   ├── WINDOW
│   ├── SORT (d_date ASC)
│   └── OUTPUT (item_sk, d_date, cume_sales)
├── [CTE] web_v1  [=]  Cost: 33%  Rows: ~1K  — Compute cumulative web sales per item by date within the 12-month sequence using windowed running sums.
│   ├── SCAN (web_sales, date_dim (join))
│   ├── JOIN (ws_sold_date_sk = d_date_sk)
│   ├── FILTER (d_month_seq BETWEEN 1216 AND 1216 + 11)
│   ├── FILTER (NOT ws_item_sk IS NULL)
│   ├── AGG (GROUP BY)
│   ├── WINDOW
│   ├── SORT (d_date ASC)
│   └── OUTPUT (item_sk, d_date, cume_sales)
└── [MAIN] main_query  [=]  Cost: 33%  Rows: ~1K  — Full-outer-join web and store daily cumulative series by item/date, carry forward cumulative maxima, and keep rows where web cumulative exceeds store cumulative.
    ├── SCAN (web_v1 AS web (join), store_v1 AS store (join))
    ├── FILTER (web_cumulative > store_cumulative)
    ├── AGG (GROUP BY)
    ├── SORT (item_sk ASC, d_date ASC)
    └── OUTPUT (*)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: