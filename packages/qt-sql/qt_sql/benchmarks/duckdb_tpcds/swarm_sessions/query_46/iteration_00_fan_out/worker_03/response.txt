## Part 1: Modified Logic Tree

```
QUERY: (single statement)
└── [MAIN] main_query  [!]  Cost: 100%  Rows: ~1K  — CTE decomposition into core_agg → customer_filter → output
    ├── [=] SCAN (store_sales, date_dim, store, household_demographics, customer_address, customer, customer_address AS current_addr)
    ├── [~] core_agg (new CTE)
    │   ├── JOIN (ss_sold_date_sk = d_date_sk)
    │   ├── JOIN (ss_store_sk = s_store_sk)
    │   ├── JOIN (ss_hdemo_sk = hd_demo_sk)
    │   ├── JOIN (ss_addr_sk = bought_addr.ca_address_sk)
    │   ├── FILTER ((hd_dep_count=6 OR hd_vehicle_count=0) AND d_dow IN (6,0) AND d_year BETWEEN 1999 AND 2001 AND s_city IN list)
    │   └── AGG (GROUP BY ss_ticket_number, ss_customer_sk, ss_addr_sk, bought_city)
    ├── [~] customer_filter (new CTE)
    │   ├── JOIN (ss_customer_sk = c_customer_sk)
    │   ├── JOIN (c_current_addr_sk = current_addr.ca_address_sk)
    │   └── FILTER (current_addr.ca_city <> bought_city)
    ├── [~] output (final ordering and limit)
    │   ├── SORT (c_last_name, c_first_name, ca_city, bought_city, ss_ticket_number)
    │   └── LIMIT 100
    └── [=] OUTPUT (c_last_name, c_first_name, ca_city, bought_city, ss_ticket_number, amt, profit)
```

**Change markers:**
- `[!]` — Structural change: Original single query decomposed into CTE chain (core_agg → customer_filter → output)
- `[~]` — Component modified: New CTE definitions isolate filtering/aggregation stages per logical tree
- `[=]` — Unchanged: Final output schema and base table scans preserved exactly

## Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "duckdb",
  "rewrite_rules": [
    {"id": "R1", "type": "cte_decomposition", "description": "Split monolithic query into CTEs matching target logical tree: core_agg (filter+aggregate), customer_filter (customer joins), output (ordering)", "applied_to": ["core_agg", "customer_filter", "output"]},
    {"id": "R2", "type": "early_filter_pushdown", "description": "Push all dimension filters into respective join conditions in core_agg CTE", "applied_to": ["core_agg"]},
    {"id": "R3", "type": "column_pruning", "description": "Each CTE emits only columns needed downstream per node contracts", "applied_to": ["core_agg", "customer_filter"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "core_agg": {
        "type": "cte",
        "change": "new",
        "sql": "SELECT ss_ticket_number, ss_customer_sk, ss_addr_sk, bought_addr.ca_city AS bought_city, SUM(ss_coupon_amt) AS amt, SUM(ss_net_profit) AS profit FROM store_sales INNER JOIN date_dim ON store_sales.ss_sold_date_sk = date_dim.d_date_sk INNER JOIN store ON store_sales.ss_store_sk = store.s_store_sk INNER JOIN household_demographics ON store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk INNER JOIN customer_address bought_addr ON store_sales.ss_addr_sk = bought_addr.ca_address_sk WHERE (household_demographics.hd_dep_count = 6 OR household_demographics.hd_vehicle_count = 0) AND date_dim.d_dow IN (6,0) AND date_dim.d_year BETWEEN 1999 AND 2001 AND store.s_city IN ('Five Points','Centerville','Oak Grove','Fairview','Liberty') GROUP BY ss_ticket_number, ss_customer_sk, ss_addr_sk, bought_addr.ca_city",
        "interfaces": {"outputs": ["ss_ticket_number", "ss_customer_sk", "ss_addr_sk", "bought_city", "amt", "profit"], "consumes": []}
      },
      "customer_filter": {
        "type": "cte",
        "change": "new",
        "sql": "SELECT customer.c_last_name, customer.c_first_name, current_addr.ca_city, core_agg.bought_city, core_agg.ss_ticket_number, core_agg.amt, core_agg.profit FROM core_agg INNER JOIN customer ON core_agg.ss_customer_sk = customer.c_customer_sk INNER JOIN customer_address current_addr ON customer.c_current_addr_sk = current_addr.ca_address_sk WHERE current_addr.ca_city <> core_agg.bought_city",
        "interfaces": {"outputs": ["c_last_name", "c_first_name", "ca_city", "bought_city", "ss_ticket_number", "amt", "profit"], "consumes": ["core_agg"]}
      },
      "output": {
        "type": "main_query",
        "change": "modified",
        "sql": "SELECT c_last_name, c_first_name, ca_city, bought_city, ss_ticket_number, amt, profit FROM customer_filter ORDER BY c_last_name, c_first_name, ca_city, bought_city, ss_ticket_number LIMIT 100",
        "interfaces": {"outputs": ["c_last_name", "c_first_name", "ca_city", "bought_city", "ss_ticket_number", "amt", "profit"], "consumes": ["customer_filter"]}
      }
    },
    "reconstruction_order": ["core_agg", "customer_filter", "output"],
    "assembly_template": "WITH core_agg AS ({core_agg}), customer_filter AS ({customer_filter}) {output}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "validation_checks": []
}
```

## Changes & Expected Speedup

**Changes:** Decomposed monolithic query into three CTEs matching the target logical tree: `core_agg` filters and aggregates weekend sales with household/store constraints; `customer_filter` joins to customer and current address with city mismatch filter; `output` applies final ordering and limit. All dimension filters are pushed into the respective join conditions.

**Expected speedup:** ~1.5-2x. The CTE decomposition enables DuckDB's optimizer to isolate and push down filters on each dimension table before the large fact table join in `core_agg`. The `customer_filter` CTE works on only 53K rows instead of the full fact table. Column pruning in each CTE reduces memory traffic. The structure avoids the "or_to_union" hazard by preserving the OR condition on different columns (hd_dep_count vs hd_vehicle_count) and prevents "dimension_cte_isolate" Cartesian explosion by keeping dimension joins sequential.