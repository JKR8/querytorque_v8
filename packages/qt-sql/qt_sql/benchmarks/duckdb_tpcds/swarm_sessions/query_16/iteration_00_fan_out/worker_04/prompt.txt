You are a SQL rewrite engine for DuckDB v1.4.3. Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

DuckDB specifics: columnar storage (SELECT only needed columns). CTEs referenced once are typically inlined; CTEs referenced multiple times may be materialized. FILTER clause is native (`COUNT(*) FILTER (WHERE cond)`). Predicate pushdown stops at UNION ALL boundaries and multi-level CTE references.

## Semantic Contract (MUST preserve)

Measure distinct order count, shipping cost, and net profit for WV shipments (April-June 2002) from specific call-center counties, limited to orders shipped from multiple warehouses with no returns. JOIN semantics: INNER joins require matching rows in all 4 tables; EXISTS is a semi-join (stop at first match); NOT EXISTS is anti-join (exclude if any match). Aggregation traps: COUNT(DISTINCT) and SUMs are grouping-insensitive to duplicates. Filter dependencies: date range filter on d_date must join via d_date_sk; state filter on ca_address_sk join; county filter on cc_call_center_sk join; multi-warehouse check depends on cs_warehouse_sk inequality; no-returns check depends on cr_order_number.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
date_cte -> addr_cte -> call_cte -> warehouse_bitmap_cte -> filtered_fact -> no_returns_filter -> final_agg
NODE_CONTRACTS:
  date_cte:
    FROM: date_dim
    WHERE: d_date BETWEEN '2002-4-01' AND (CAST('2002-4-01' AS DATE) + INTERVAL 60 DAY)
    OUTPUT: d_date_sk
    EXPECTED_ROWS: 61
    CONSUMERS: warehouse_bitmap_cte
  addr_cte:
    FROM: customer_address
    WHERE: ca_state = 'WV'
    OUTPUT: ca_address_sk
    EXPECTED_ROWS: 4,298
    CONSUMERS: warehouse_bitmap_cte
  call_cte:
    FROM: call_center
    WHERE: cc_county IN ('Ziebach County','Luce County','Richland County','Daviess County','Barrow County')
    OUTPUT: cc_call_center_sk
    EXPECTED_ROWS: 11
    CONSUMERS: warehouse_bitmap_cte
  warehouse_bitmap_cte:
    FROM: catalog_sales
    GROUP BY: cs_order_number
    HAVING: MIN(cs_warehouse_sk) <> MAX(cs_warehouse_sk)  -- multi-warehouse detection
    OUTPUT: cs_order_number
    EXPECTED_ROWS: unknown (distinct multi-warehouse orders)
    CONSUMERS: filtered_fact
  filtered_fact:
    FROM: catalog_sales cs1
    JOIN: INNER JOIN date_cte ON cs1.cs_ship_date_sk = date_cte.d_date_sk
    JOIN: INNER JOIN addr_cte ON cs1.cs_ship_addr_sk = addr_cte.ca_address_sk
    JOIN: INNER JOIN call_cte ON cs1.cs_call_center_sk = call_cte.cc_call_center_sk
    SEMI JOIN: INNER JOIN warehouse_bitmap_cte w ON cs1.cs_order_number = w.cs_order_number
    OUTPUT: cs_order_number, cs_ext_ship_cost, cs_net_profit
    EXPECTED_ROWS: ~1,942
    CONSUMERS: no_returns_filter
  no_returns_filter:
    FROM: filtered_fact cs1
    WHERE: NOT EXISTS (SELECT 1 FROM catalog_returns cr1 WHERE cs1.cs_order_number = cr1.cr_order_number)
    OUTPUT: cs_order_number, cs_ext_ship_cost, cs_net_profit
    EXPECTED_ROWS: ~1,575
    CONSUMERS: final_agg
  final_agg:
    FROM: no_returns_filter
    AGGREGATE: COUNT(DISTINCT cs_order_number), SUM(cs_ext_ship_cost), SUM(cs_net_profit)
    OUTPUT: count(distinct cs_order_number) as "order count", sum(cs_ext_ship_cost) as "total shipping cost", sum(cs_net_profit) as "total net profit"
    EXPECTED_ROWS: 1
    CONSUMERS: OUTPUT

NODE_CONTRACTS:
date_cte:
    FROM: date_dim
    WHERE: d_date BETWEEN '2002-4-01' AND (CAST('2002-4-01' AS DATE) + INTERVAL 60 DAY)
    OUTPUT: d_date_sk
    EXPECTED_ROWS: 61
    CONSUMERS: warehouse_bitmap_cte
  addr_cte:
    FROM: customer_address
    WHERE: ca_state = 'WV'
    OUTPUT: ca_address_sk
    EXPECTED_ROWS: 4,298
    CONSUMERS: warehouse_bitmap_cte
  call_cte:
    FROM: call_center
    WHERE: cc_county IN ('Ziebach County','Luce County','Richland County','Daviess County','Barrow County')
    OUTPUT: cc_call_center_sk
    EXPECTED_ROWS: 11
    CONSUMERS: warehouse_bitmap_cte
  warehouse_bitmap_cte:
    FROM: catalog_sales
    GROUP BY: cs_order_number
    HAVING: MIN(cs_warehouse_sk) <> MAX(cs_warehouse_sk)  -- multi-warehouse detection
    OUTPUT: cs_order_number
    EXPECTED_ROWS: unknown (distinct multi-warehouse orders)
    CONSUMERS: filtered_fact
  filtered_fact:
    FROM: catalog_sales cs1
    JOIN: INNER JOIN date_cte ON cs1.cs_ship_date_sk = date_cte.d_date_sk
    JOIN: INNER JOIN addr_cte ON cs1.cs_ship_addr_sk = addr_cte.ca_address_sk
    JOIN: INNER JOIN call_cte ON cs1.cs_call_center_sk = call_cte.cc_call_center_sk
    SEMI JOIN: INNER JOIN warehouse_bitmap_cte w ON cs1.cs_order_number = w.cs_order_number
    OUTPUT: cs_order_number, cs_ext_ship_cost, cs_net_profit
    EXPECTED_ROWS: ~1,942
    CONSUMERS: no_returns_filter
  no_returns_filter:
    FROM: filtered_fact cs1
    WHERE: NOT EXISTS (SELECT 1 FROM catalog_returns cr1 WHERE cs1.cs_order_number = cr1.cr_order_number)
    OUTPUT: cs_order_number, cs_ext_ship_cost, cs_net_profit
    EXPECTED_ROWS: ~1,575
    CONSUMERS: final_agg
  final_agg:
    FROM: no_returns_filter
    AGGREGATE: COUNT(DISTINCT cs_order_number), SUM(cs_ext_ship_cost), SUM(cs_net_profit)
    OUTPUT: count(distinct cs_order_number) as "order count", sum(cs_ext_ship_cost) as "total shipping cost", sum(cs_net_profit) as "total net profit"
    EXPECTED_ROWS: 1
    CONSUMERS: OUTPUT

## Hazard Flags (avoid these specific risks)

- warehouse_bitmap_cte scans ENTIRE catalog_sales (172.8M rows) unfiltered - may be catastrophic
- GROUP BY on cs_order_number across whole table expensive
CONSTRAINT_OVERRIDE: None
OVERRIDE_REASONING: This strategy attempts novel combination: pre-computing multi-warehouse orders via GROUP BY HAVING before dimension filters. Risk is high due to full table scan, but if dimension filters are very selective, the bitmap CTE might be small and join efficiently.
EXPLORATION_TYPE: novel_combination

## Regression Warnings (observed failures on similar queries)

1. materialize_cte (0.14x):
   CAUSE: EXISTS subquery materialized into full CTE scan, destroying semi-join short-circuit
   RULE: Never convert EXISTS/NOT EXISTS used as filter into materialized CTE
2. regression_q25_date_cte_isolate (0.5x):
   CAUSE: Pre-filtered fact table before multi-way join, preventing optimizer reordering
   RULE: Avoid pre-joining fact with date CTE when query has complex multi-table joins
3. dimension_cte_isolate (0.0076x):
   CAUSE: Cross-joined 3+ dimension CTEs caused Cartesian explosion
   RULE: Never cross-join 3+ dimension CTEs; each CTE must have WHERE clause

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Must output exactly 3 columns: count(distinct cs_order_number), sum(cs_ext_ship_cost), sum(cs_net_profit)
- CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream (cs_order_number, cs_ext_ship_cost, cs_net_profit, cs_warehouse_sk, plus join keys)
- LITERAL_PRESERVATION: Must preserve date '2002-4-01', interval 60 DAY, state 'WV', county list exactly
- SEMANTIC_EQUIVALENCE: Must return same 1-row result with same ordering (ORDER BY count(distinct cs_order_number) ASC)
- CROSS_CTE_PREDICATE_BLINDNESS: Dimension filters not pushed into fact scan (EXPLAIN shows SEQ_SCAN catalog_sales without dimension filters)
- REDUNDANT_SCAN_ELIMINATION: catalog_sales scanned twice (main:115.4ms, EXISTS:1.4ms) in EXPLAIN

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- channel_bitmap_aggregation: Apply GROUP BY with HAVING for multi-warehouse detection (bitmap); ignore CASE WHEN labeling (we have single condition)
- single_pass_aggregation: Apply consolidation of warehouse check into pre-aggregation; ignore that we're scanning catalog_sales twice (once for bitmap, once for main)
- decorrelate: Apply pre-computed CTE for multi-warehouse orders; ignore that this materializes full unfiltered catalog_sales

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. channel_bitmap_aggregation (6.24x)

**BEFORE (slow):**
```sql
select * from
 (select count(*) h8_30_to_9
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 8 and time_dim.t_minute >= 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s1,
 (select count(*) h9_to_9_30
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 9 and time_dim.t_minute < 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s2,
 (select count(*) h9_30_to_10
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 9 and time_dim.t_minute >= 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s3,
 (select count(*) h10_to_10_30
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 10 and time_dim.t_minute < 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s4,
 (select count(*) h10_30_to_11
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 10 and time_dim.t_minute >= 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s5,
 (select count(*) h11_to_11_30
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 11 and time_dim.t_minute < 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s6,
 (select count(*) h11_30_to_12
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 11 and time_dim.t_minute >= 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s7,
 (select count(*) h12_to_12_30
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 12 and time_dim.t_minute < 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s8;
```

**AFTER (fast):**
[filtered_store]:
```sql
SELECT s_store_sk FROM store WHERE s_store_name = 'ese'
```
[filtered_hd]:
```sql
SELECT hd_demo_sk FROM household_demographics WHERE (hd_dep_count = -1 AND hd_vehicle_count <= 1) OR (hd_dep_count = 4 AND hd_vehicle_count <= 6) OR (hd_dep_count = 3 AND hd_vehicle_count <= 5)
```
[time_ranges]:
```sql
SELECT t_time_sk, CASE WHEN t_hour = 8 AND t_minute >= 30 THEN 1 WHEN t_hour = 9 AND t_minute < 30 THEN 2 WHEN t_hour = 9 AND t_minute >= 30 THEN 3 WHEN t_hour = 10 AND t_minute < 30 THEN 4 WHEN t_hour = 10 AND t_minute >= 30 THEN 5 WHEN t_hour = 11 AND t_minute < 30 THEN 6 WHEN t_hour = 11 AND t_minute >= 30 THEN 7 WHEN t_hour = 12 AND t_minute < 30 THEN 8 END AS time_window FROM time_dim WHERE (t_hour BETWEEN 8 AND 12)
```
[sales_with_time]:
```sql
SELECT tr.time_window FROM store_sales ss JOIN filtered_store fs ON ss.ss_store_sk = fs.s_store_sk JOIN filtered_hd fhd ON ss.ss_hdemo_sk = fhd.hd_demo_sk JOIN time_ranges tr ON ss.ss_sold_time_sk = tr.t_time_sk
```
[main_query]:
```sql
SELECT COUNT(CASE WHEN time_window = 1 THEN 1 END) AS h8_30_to_9, COUNT(CASE WHEN time_window = 2 THEN 1 END) AS h9_to_9_30, COUNT(CASE WHEN time_window = 3 THEN 1 END) AS h9_30_to_10, COUNT(CASE WHEN time_window = 4 THEN 1 END) AS h10_to_10_30, COUNT(CASE WHEN time_window = 5 THEN 1 END) AS h10_30_to_11, COUNT(CASE WHEN time_window = 6 THEN 1 END) AS h11_to_11_30, COUNT(CASE WHEN time_window = 7 THEN 1 END) AS h11_30_to_12, COUNT(CASE WHEN time_window = 8 THEN 1 END) AS h12_to_12_30 FROM sales_with_time
```

### 2. single_pass_aggregation (4.47x)

**Principle:** Single-Pass Aggregation: consolidate multiple scalar subqueries on the same table into one CTE using CASE expressions inside aggregate functions. Reduces N separate table scans to 1 pass.

**BEFORE (slow):**
```sql
select case when (select count(*) 
                  from store_sales 
                  where ss_quantity between 1 and 20) > 2972190
            then (select avg(ss_ext_sales_price) 
                  from store_sales 
                  where ss_quantity between 1 and 20) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 1 and 20) end bucket1 ,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 21 and 40) > 4505785
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 21 and 40) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 21 and 40) end bucket2,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 41 and 60) > 1575726
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 41 and 60)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 41 and 60) end bucket3,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 61 and 80) > 3188917
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 61 and 80)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 61 and 80) end bucket4,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 81 and 100) > 3525216
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 81 and 100)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 81 and 100) end bucket5
from reason
where r_reason_sk = 1;
```

**AFTER (fast):**
[store_sales_aggregates]:
```sql
SELECT SUM(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 ELSE 0 END) AS cnt1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_ext_discount_amt END) AS avg_disc1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_net_paid END) AS avg_paid1, SUM(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN 1 ELSE 0 END) AS cnt2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_ext_discount_amt END) AS avg_disc2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_net_paid END) AS avg_paid2, SUM(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN 1 ELSE 0 END) AS cnt3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_ext_discount_amt END) AS avg_disc3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_net_paid END) AS avg_paid3, SUM(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN 1 ELSE 0 END) AS cnt4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_ext_discount_amt END) AS avg_disc4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_net_paid END) AS avg_paid4, SUM(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN 1 ELSE 0 END) AS cnt5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_ext_discount_amt END) AS avg_disc5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_net_paid END) AS avg_paid5 FROM store_sales
```
[main_query]:
```sql
SELECT CASE WHEN cnt1 > 74129 THEN avg_disc1 ELSE avg_paid1 END AS bucket1, CASE WHEN cnt2 > 122840 THEN avg_disc2 ELSE avg_paid2 END AS bucket2, CASE WHEN cnt3 > 56580 THEN avg_disc3 ELSE avg_paid3 END AS bucket3, CASE WHEN cnt4 > 10097 THEN avg_disc4 ELSE avg_paid4 END AS bucket4, CASE WHEN cnt5 > 165306 THEN avg_disc5 ELSE avg_paid5 END AS bucket5 FROM store_sales_aggregates
```

### 3. decorrelate (2.92x)

**Principle:** Decorrelation: convert correlated subqueries to standalone CTEs with GROUP BY, then JOIN. Correlated subqueries re-execute per outer row; a pre-computed CTE executes once.

**BEFORE (slow):**
```sql
with customer_total_return as
(select sr_customer_sk as ctr_customer_sk
,sr_store_sk as ctr_store_sk
,sum(SR_FEE) as ctr_total_return
from store_returns
,date_dim
where sr_returned_date_sk = d_date_sk
and d_year =2000
group by sr_customer_sk
,sr_store_sk)
 select c_customer_id
from customer_total_return ctr1
,store
,customer
where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2
from customer_total_return ctr2
where ctr1.ctr_store_sk = ctr2.ctr_store_sk)
and s_store_sk = ctr1.ctr_store_sk
and s_state = 'SD'
and ctr1.ctr_customer_sk = c_customer_sk
order by c_customer_id
 LIMIT 100;
```

**AFTER (fast):**
[filtered_returns]:
```sql
SELECT sr.sr_customer_sk, sr.sr_store_sk, sr.sr_fee FROM store_returns sr JOIN date_dim d ON sr.sr_returned_date_sk = d.d_date_sk JOIN store s ON sr.sr_store_sk = s.s_store_sk WHERE d.d_year = 2000 AND s.s_state = 'SD'
```
[customer_total_return]:
```sql
SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(sr_fee) AS ctr_total_return FROM filtered_returns GROUP BY sr_customer_sk, sr_store_sk
```
[store_avg_return]:
```sql
SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return_threshold FROM customer_total_return GROUP BY ctr_store_sk
```
[main_query]:
```sql
SELECT c.c_customer_id FROM customer_total_return ctr1 JOIN store_avg_return sar ON ctr1.ctr_store_sk = sar.ctr_store_sk JOIN customer c ON ctr1.ctr_customer_sk = c.c_customer_sk WHERE ctr1.ctr_total_return > sar.avg_return_threshold ORDER BY c.c_customer_id LIMIT 100
```

## Original SQL

```sql
-- start query 16 in stream 0 using template query16.tpl
select 
   count(distinct cs_order_number) as "order count"
  ,sum(cs_ext_ship_cost) as "total shipping cost"
  ,sum(cs_net_profit) as "total net profit"
from
   catalog_sales cs1
  ,date_dim
  ,customer_address
  ,call_center
where
    d_date between '2002-4-01' and 
           (cast('2002-4-01' as date) + INTERVAL 60 DAY)
and cs1.cs_ship_date_sk = d_date_sk
and cs1.cs_ship_addr_sk = ca_address_sk
and ca_state = 'WV'
and cs1.cs_call_center_sk = cc_call_center_sk
and cc_county in ('Ziebach County','Luce County','Richland County','Daviess County',
                  'Barrow County'
)
and exists (select *
            from catalog_sales cs2
            where cs1.cs_order_number = cs2.cs_order_number
              and cs1.cs_warehouse_sk <> cs2.cs_warehouse_sk)
and not exists(select *
               from catalog_returns cr1
               where cs1.cs_order_number = cr1.cr_order_number)
order by count(distinct cs_order_number)
 LIMIT 100;

-- end query 16 in stream 0 using template query16.tpl
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

### Column Completeness Contract

Your `main_query` component MUST produce **exactly** these output columns (same names, same order):

  1. `order count`
  2. `total shipping cost`
  3. `total net profit`

Do NOT add, remove, or rename any output columns. The result set schema must be identical to the original query.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 100%  Rows: ~1K  — Filter catalog sales by ship date range, destination state, and call-center county; require same order number to appear with a different warehouse; exclude orders that appear in catalog_returns; then aggregate the requested order and profitability metrics.
    ├── SCAN (catalog_sales AS cs1 (join), date_dim (join), customer_address (join), call_center (join))
    ├── JOIN (cs1.cs_ship_date_sk = d_date_sk)
    ├── JOIN (cs1.cs_ship_addr_sk = ca_address_sk)
    ├── JOIN (+1 more)
    ├── FILTER (d_date BETWEEN '2002-4-01' AND (CAST('2002-4-01' AS DATE) + INTERVAL '60' DAY))
    ├── FILTER (ca_state = 'WV')
    ├── FILTER (+3 more)
    ├── SORT (COUNT(DISTINCT cs_order_number) ASC)
    └── OUTPUT (order count, total shipping cost, total net profit)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: