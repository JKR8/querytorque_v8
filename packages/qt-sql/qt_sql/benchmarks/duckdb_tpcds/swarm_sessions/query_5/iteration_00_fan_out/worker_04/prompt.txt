You are a SQL rewrite engine for DuckDB v1.4.3. Follow the Target Logical Tree structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

DuckDB specifics: columnar storage (SELECT only needed columns). CTEs referenced once are typically inlined; CTEs referenced multiple times may be materialized. FILTER clause is native (`COUNT(*) FILTER (WHERE cond)`). Predicate pushdown stops at UNION ALL boundaries and multi-level CTE references.

## Semantic Contract (MUST preserve)

Summarize a 14-day window starting 2000-08-19 by channel and channel entity (store, catalog page, web site), reporting sales, returns, and net profit after losses, with rollup subtotals. All joins are INNER (intersection) except the LEFT OUTER JOIN in wsr's returns branch which must preserve all web_returns rows even without matching web_sales (though TPC-DS referential integrity ensures matches). Aggregations are SUM only, duplicate-insensitive. The date filter is identical across three independent channel CTEs and must be applied to both sales and returns date keys.

## Target Logical Tree + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_LOGICAL_TREE:
date_range -> store_facts -> ssr -> main_query
  date_range -> catalog_facts -> csr -> main_query
  date_range -> web_consolidated -> wsr -> main_query
NODE_CONTRACTS:
  date_range: (same as Worker 1)
  store_facts: (same as Worker 1)
  ssr: (same as Worker 1)
  catalog_facts: (same as Worker 1)
  csr: (same as Worker 1)
  web_consolidated:
    FROM: web_sales JOIN date_range ON ws_sold_date_sk = d_date_sk LEFT OUTER JOIN web_returns ON wr_item_sk = ws_item_sk AND wr_order_number = ws_order_number AND wr_returned_date_sk = d_date_sk
    OUTPUT: ws_web_site_sk, ws_sold_date_sk, ws_ext_sales_price, ws_net_profit, wr_return_amt, wr_net_loss
    EXPECTED_ROWS: 79K (sales) + ? (returns) but aim to reduce scans
    CONSUMERS: wsr
  wsr:
    FROM: (SELECT ws_web_site_sk, ws_sold_date_sk, ws_ext_sales_price, ws_net_profit, CAST(0 AS DECIMAL(7,2)), CAST(0 AS DECIMAL(7,2)) FROM web_consolidated UNION ALL SELECT ws_web_site_sk, ws_sold_date_sk, CAST(0 AS DECIMAL(7,2)), CAST(0 AS DECIMAL(7,2)), wr_return_amt, wr_net_loss FROM web_consolidated WHERE wr_return_amt IS NOT NULL) AS salesreturns JOIN web_site ON wsr_web_site_sk = web_site_sk
    GROUP BY: web_site_id
    AGGREGATE: SUM(sales_price) AS sales, SUM(profit) AS profit, SUM(return_amt) AS returns, SUM(net_loss) AS profit_loss
    OUTPUT: web_site_id, sales, profit, returns, profit_loss
    EXPECTED_ROWS: 21
    CONSUMERS: main_query
  main_query: (same as Worker 1)

NODE_CONTRACTS:
date_range: (same as Worker 1)
  store_facts: (same as Worker 1)
  ssr: (same as Worker 1)
  catalog_facts: (same as Worker 1)
  csr: (same as Worker 1)
  web_consolidated:
    FROM: web_sales JOIN date_range ON ws_sold_date_sk = d_date_sk LEFT OUTER JOIN web_returns ON wr_item_sk = ws_item_sk AND wr_order_number = ws_order_number AND wr_returned_date_sk = d_date_sk
    OUTPUT: ws_web_site_sk, ws_sold_date_sk, ws_ext_sales_price, ws_net_profit, wr_return_amt, wr_net_loss
    EXPECTED_ROWS: 79K (sales) + ? (returns) but aim to reduce scans
    CONSUMERS: wsr
  wsr:
    FROM: (SELECT ws_web_site_sk, ws_sold_date_sk, ws_ext_sales_price, ws_net_profit, CAST(0 AS DECIMAL(7,2)), CAST(0 AS DECIMAL(7,2)) FROM web_consolidated UNION ALL SELECT ws_web_site_sk, ws_sold_date_sk, CAST(0 AS DECIMAL(7,2)), CAST(0 AS DECIMAL(7,2)), wr_return_amt, wr_net_loss FROM web_consolidated WHERE wr_return_amt IS NOT NULL) AS salesreturns JOIN web_site ON wsr_web_site_sk = web_site_sk
    GROUP BY: web_site_id
    AGGREGATE: SUM(sales_price) AS sales, SUM(profit) AS profit, SUM(return_amt) AS returns, SUM(net_loss) AS profit_loss
    OUTPUT: web_site_id, sales, profit, returns, profit_loss
    EXPECTED_ROWS: 21
    CONSUMERS: main_query
  main_query: (same as Worker 1)

## Hazard Flags (avoid these specific risks)

- The consolidated scan may duplicate web_sales rows if multiple returns per sale, causing overcounting in sales branch. Must deduplicate sales branch by using DISTINCT or aggregating by web_sales key (not available). Risky.
- LEFT JOIN condition must include date filter on wr_returned_date_sk to match original semantics.
CONSTRAINT_OVERRIDE: None
OVERRIDE_REASONING: The regression warnings for date_cte_isolate and prefetch_fact_join are based on fast baseline queries; this query is slow (1138ms) so overhead is acceptable. The wsr restructuring is novel but must ensure no row duplication.
EXPLORATION_TYPE: compound_strategy

## Regression Warnings (observed failures on similar queries)

1. date_cte_isolate (observed regression 0.49x on Q31):
   CAUSE: Baseline <100ms, CTE overhead exceeded savings.
   RULE: Skip if baseline <100ms; this query is 1138ms, so applicable.
2. prefetch_fact_join (observed regression 0.50x on Q25):
   CAUSE: Baseline <50ms, CTE overhead dominated.
   RULE: This query is 1138ms, so applicable but limit to 2 cascading fact-table CTE chains.
3. dimension_cte_isolate (observed regression 0.0076x on Q26):
   CAUSE: Cross-joined 3+ dimension CTEs causing Cartesian explosion.
   RULE: Never cross-join 3+ dimension CTEs; each CTE must have a WHERE clause.

## Constraints (analyst-filtered for this query)

- COMPLETE_OUTPUT: Must output channel, id, sales, returns, profit ordered by channel, id with LIMIT 100.
- CTE_COLUMN_COMPLETENESS: Each channel CTE must output dimension key (s_store_id, cp_catalog_page_id, web_site_id) and aggregates (sales, profit, returns, profit_loss) for main query.
- LITERAL_PRESERVATION: Date literal '2000-08-19' and interval 14 days must be preserved exactly.
- SEMANTIC_EQUIVALENCE: Result set must match exactly, including rollup rows.
- CROSS_CTE_PREDICATE_BLINDNESS: EXPLAIN shows date filter applied after fact table joins, not pushed into fact scans.
- REDUNDANT_SCAN_ELIMINATION: date_dim scanned 3 times (0.6ms, 0.7ms, 0.8ms). web_sales scanned twice in wsr.

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

- single_pass_aggregation: Consolidate web_sales and web_returns scans into one scan with LEFT JOIN; ignore CASE aggregation (use UNION ALL).
- channel_bitmap_aggregation: Use a single scan of web_sales with LEFT JOIN to web_returns; ignore bitmap labeling.
- date_cte_isolate: Apply date filtering early via date_range CTE; ignore other channels.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. single_pass_aggregation (4.47x)

**Principle:** Single-Pass Aggregation: consolidate multiple scalar subqueries on the same table into one CTE using CASE expressions inside aggregate functions. Reduces N separate table scans to 1 pass.

**BEFORE (slow):**
```sql
select case when (select count(*) 
                  from store_sales 
                  where ss_quantity between 1 and 20) > 2972190
            then (select avg(ss_ext_sales_price) 
                  from store_sales 
                  where ss_quantity between 1 and 20) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 1 and 20) end bucket1 ,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 21 and 40) > 4505785
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 21 and 40) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 21 and 40) end bucket2,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 41 and 60) > 1575726
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 41 and 60)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 41 and 60) end bucket3,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 61 and 80) > 3188917
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 61 and 80)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 61 and 80) end bucket4,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 81 and 100) > 3525216
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 81 and 100)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 81 and 100) end bucket5
from reason
where r_reason_sk = 1;
```

**AFTER (fast):**
[store_sales_aggregates]:
```sql
SELECT SUM(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 ELSE 0 END) AS cnt1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_ext_discount_amt END) AS avg_disc1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_net_paid END) AS avg_paid1, SUM(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN 1 ELSE 0 END) AS cnt2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_ext_discount_amt END) AS avg_disc2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_net_paid END) AS avg_paid2, SUM(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN 1 ELSE 0 END) AS cnt3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_ext_discount_amt END) AS avg_disc3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_net_paid END) AS avg_paid3, SUM(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN 1 ELSE 0 END) AS cnt4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_ext_discount_amt END) AS avg_disc4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_net_paid END) AS avg_paid4, SUM(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN 1 ELSE 0 END) AS cnt5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_ext_discount_amt END) AS avg_disc5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_net_paid END) AS avg_paid5 FROM store_sales
```
[main_query]:
```sql
SELECT CASE WHEN cnt1 > 74129 THEN avg_disc1 ELSE avg_paid1 END AS bucket1, CASE WHEN cnt2 > 122840 THEN avg_disc2 ELSE avg_paid2 END AS bucket2, CASE WHEN cnt3 > 56580 THEN avg_disc3 ELSE avg_paid3 END AS bucket3, CASE WHEN cnt4 > 10097 THEN avg_disc4 ELSE avg_paid4 END AS bucket4, CASE WHEN cnt5 > 165306 THEN avg_disc5 ELSE avg_paid5 END AS bucket5 FROM store_sales_aggregates
```

### 2. channel_bitmap_aggregation (6.24x)

**BEFORE (slow):**
```sql
select * from
 (select count(*) h8_30_to_9
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 8 and time_dim.t_minute >= 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s1,
 (select count(*) h9_to_9_30
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 9 and time_dim.t_minute < 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s2,
 (select count(*) h9_30_to_10
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 9 and time_dim.t_minute >= 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s3,
 (select count(*) h10_to_10_30
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 10 and time_dim.t_minute < 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s4,
 (select count(*) h10_30_to_11
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 10 and time_dim.t_minute >= 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s5,
 (select count(*) h11_to_11_30
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 11 and time_dim.t_minute < 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s6,
 (select count(*) h11_30_to_12
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 11 and time_dim.t_minute >= 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s7,
 (select count(*) h12_to_12_30
 from store_sales, household_demographics, time_dim, store
 where ss_sold_time_sk = time_dim.t_time_sk
   and ss_hdemo_sk = household_demographics.hd_demo_sk
   and ss_store_sk = s_store_sk
   and time_dim.t_hour = 12 and time_dim.t_minute < 30
   and ((household_demographics.hd_dep_count = -1 and household_demographics.hd_vehicle_count<=-1+2) or
        (household_demographics.hd_dep_count = 4 and household_demographics.hd_vehicle_count<=4+2) or
        (household_demographics.hd_dep_count = 3 and household_demographics.hd_vehicle_count<=3+2))
   and store.s_store_name = 'ese') s8;
```

**AFTER (fast):**
[filtered_store]:
```sql
SELECT s_store_sk FROM store WHERE s_store_name = 'ese'
```
[filtered_hd]:
```sql
SELECT hd_demo_sk FROM household_demographics WHERE (hd_dep_count = -1 AND hd_vehicle_count <= 1) OR (hd_dep_count = 4 AND hd_vehicle_count <= 6) OR (hd_dep_count = 3 AND hd_vehicle_count <= 5)
```
[time_ranges]:
```sql
SELECT t_time_sk, CASE WHEN t_hour = 8 AND t_minute >= 30 THEN 1 WHEN t_hour = 9 AND t_minute < 30 THEN 2 WHEN t_hour = 9 AND t_minute >= 30 THEN 3 WHEN t_hour = 10 AND t_minute < 30 THEN 4 WHEN t_hour = 10 AND t_minute >= 30 THEN 5 WHEN t_hour = 11 AND t_minute < 30 THEN 6 WHEN t_hour = 11 AND t_minute >= 30 THEN 7 WHEN t_hour = 12 AND t_minute < 30 THEN 8 END AS time_window FROM time_dim WHERE (t_hour BETWEEN 8 AND 12)
```
[sales_with_time]:
```sql
SELECT tr.time_window FROM store_sales ss JOIN filtered_store fs ON ss.ss_store_sk = fs.s_store_sk JOIN filtered_hd fhd ON ss.ss_hdemo_sk = fhd.hd_demo_sk JOIN time_ranges tr ON ss.ss_sold_time_sk = tr.t_time_sk
```
[main_query]:
```sql
SELECT COUNT(CASE WHEN time_window = 1 THEN 1 END) AS h8_30_to_9, COUNT(CASE WHEN time_window = 2 THEN 1 END) AS h9_to_9_30, COUNT(CASE WHEN time_window = 3 THEN 1 END) AS h9_30_to_10, COUNT(CASE WHEN time_window = 4 THEN 1 END) AS h10_to_10_30, COUNT(CASE WHEN time_window = 5 THEN 1 END) AS h10_30_to_11, COUNT(CASE WHEN time_window = 6 THEN 1 END) AS h11_to_11_30, COUNT(CASE WHEN time_window = 7 THEN 1 END) AS h11_30_to_12, COUNT(CASE WHEN time_window = 8 THEN 1 END) AS h12_to_12_30 FROM sales_with_time
```

### 3. date_cte_isolate (4.00x)

**Principle:** Dimension Isolation: extract small dimension lookups into CTEs so they materialize once and subsequent joins probe a tiny hash table instead of rescanning.

**BEFORE (slow):**
```sql
select a.ca_state state, count(*) cnt
 from customer_address a
     ,customer c
     ,store_sales s
     ,date_dim d
     ,item i
 where       a.ca_address_sk = c.c_current_addr_sk
 	and c.c_customer_sk = s.ss_customer_sk
 	and s.ss_sold_date_sk = d.d_date_sk
 	and s.ss_item_sk = i.i_item_sk
 	and d.d_month_seq = 
 	     (select distinct (d_month_seq)
 	      from date_dim
               where d_year = 2002
 	        and d_moy = 3 )
 	and i.i_current_price > 1.2 * 
             (select avg(j.i_current_price) 
 	     from item j 
 	     where j.i_category = i.i_category)
 group by a.ca_state
 having count(*) >= 10
 order by cnt, a.ca_state
 LIMIT 100;
```

**AFTER (fast):**
[target_month]:
```sql
SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1
```
[category_avg_price]:
```sql
SELECT i_category, AVG(i_current_price) * 1.2 AS avg_threshold FROM item GROUP BY i_category
```
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim JOIN target_month ON d_month_seq = target_month.d_month_seq
```
[filtered_sales]:
```sql
SELECT ss_customer_sk, ss_item_sk FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk
```
[main_query]:
```sql
SELECT a.ca_state AS state, COUNT(*) AS cnt FROM customer_address a JOIN customer c ON a.ca_address_sk = c.c_current_addr_sk JOIN filtered_sales s ON c.c_customer_sk = s.ss_customer_sk JOIN item i ON s.ss_item_sk = i.i_item_sk JOIN category_avg_price cap ON i.i_category = cap.i_category WHERE i.i_current_price > cap.avg_threshold GROUP BY a.ca_state HAVING COUNT(*) >= 10 ORDER BY cnt, a.ca_state LIMIT 100
```

## Original SQL

```sql
-- start query 5 in stream 0 using template query5.tpl
with ssr as
 (select s_store_id,
        sum(sales_price) as sales,
        sum(profit) as profit,
        sum(return_amt) as "returns",
        sum(net_loss) as profit_loss
 from
  ( select  ss_store_sk as store_sk,
            ss_sold_date_sk  as date_sk,
            ss_ext_sales_price as sales_price,
            ss_net_profit as profit,
            cast(0 as decimal(7,2)) as return_amt,
            cast(0 as decimal(7,2)) as net_loss
    from store_sales
    union all
    select sr_store_sk as store_sk,
           sr_returned_date_sk as date_sk,
           cast(0 as decimal(7,2)) as sales_price,
           cast(0 as decimal(7,2)) as profit,
           sr_return_amt as return_amt,
           sr_net_loss as net_loss
    from store_returns
   ) salesreturns,
     date_dim,
     store
 where date_sk = d_date_sk
       and d_date between cast('2000-08-19' as date) 
                  and (cast('2000-08-19' as date) + INTERVAL 14 DAY)
       and store_sk = s_store_sk
 group by s_store_id)
 ,
 csr as
 (select cp_catalog_page_id,
        sum(sales_price) as sales,
        sum(profit) as profit,
        sum(return_amt) as "returns",
        sum(net_loss) as profit_loss
 from
  ( select  cs_catalog_page_sk as page_sk,
            cs_sold_date_sk  as date_sk,
            cs_ext_sales_price as sales_price,
            cs_net_profit as profit,
            cast(0 as decimal(7,2)) as return_amt,
            cast(0 as decimal(7,2)) as net_loss
    from catalog_sales
    union all
    select cr_catalog_page_sk as page_sk,
           cr_returned_date_sk as date_sk,
           cast(0 as decimal(7,2)) as sales_price,
           cast(0 as decimal(7,2)) as profit,
           cr_return_amount as return_amt,
           cr_net_loss as net_loss
    from catalog_returns
   ) salesreturns,
     date_dim,
     catalog_page
 where date_sk = d_date_sk
       and d_date between cast('2000-08-19' as date)
                  and (cast('2000-08-19' as date) + INTERVAL 14 DAY)
       and page_sk = cp_catalog_page_sk
 group by cp_catalog_page_id)
 ,
 wsr as
 (select web_site_id,
        sum(sales_price) as sales,
        sum(profit) as profit,
        sum(return_amt) as "returns",
        sum(net_loss) as profit_loss
 from
  ( select  ws_web_site_sk as wsr_web_site_sk,
            ws_sold_date_sk  as date_sk,
            ws_ext_sales_price as sales_price,
            ws_net_profit as profit,
            cast(0 as decimal(7,2)) as return_amt,
            cast(0 as decimal(7,2)) as net_loss
    from web_sales
    union all
    select ws_web_site_sk as wsr_web_site_sk,
           wr_returned_date_sk as date_sk,
           cast(0 as decimal(7,2)) as sales_price,
           cast(0 as decimal(7,2)) as profit,
           wr_return_amt as return_amt,
           wr_net_loss as net_loss
    from web_returns left outer join web_sales on
         ( wr_item_sk = ws_item_sk
           and wr_order_number = ws_order_number)
   ) salesreturns,
     date_dim,
     web_site
 where date_sk = d_date_sk
       and d_date between cast('2000-08-19' as date)
                  and (cast('2000-08-19' as date) + INTERVAL 14 DAY)
       and wsr_web_site_sk = web_site_sk
 group by web_site_id)
  select channel
        , id
        , sum(sales) as sales
        , sum("returns") as "returns"
        , sum(profit) as profit
 from 
 (select 'store channel' as channel
        , 'store' || s_store_id as id
        , sales
        , "returns"
        , (profit - profit_loss) as profit
 from   ssr
 union all
 select 'catalog channel' as channel
        , 'catalog_page' || cp_catalog_page_id as id
        , sales
        , "returns"
        , (profit - profit_loss) as profit
 from  csr
 union all
 select 'web channel' as channel
        , 'web_site' || web_site_id as id
        , sales
        , "returns"
        , (profit - profit_loss) as profit
 from   wsr
 ) x
 group by rollup (channel, id)
 order by channel
         ,id
 LIMIT 100;

-- end query 5 in stream 0 using template query5.tpl
```

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_LOGICAL_TREE` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

### Column Completeness Contract

Your `main_query` component MUST produce **exactly** these output columns (same names, same order):

  1. `channel`
  2. `id`
  3. `sales`
  4. `returns`
  5. `profit`

Do NOT add, remove, or rename any output columns. The result set schema must be identical to the original query.

## Original Query Structure

This is the current query structure. All nodes are `[=]` (unchanged). Your modified Logic Tree below should show which nodes you changed.

```
QUERY: (single statement)
├── [CTE] csr  [=]  Cost: 25%  Rows: ~1K  — Combine catalog sales and catalog returns into a single stream, align to the date window, and aggregate sales, returns, profit, and net-loss amounts per catalog page id.
│   ├── SCAN (catalog_sales, catalog_returns, date_dim (join), catalog_page (join))
│   ├── JOIN (date_sk = d_date_sk)
│   ├── JOIN (page_sk = cp_catalog_page_sk)
│   ├── FILTER (d_date BETWEEN CAST('2000-08-19' AS DATE) AND (CAST('2000-08-19' AS DATE) + INTERVAL '14' DAY))
│   ├── AGG (GROUP BY)
│   ├── UNION
│   └── OUTPUT (cp_catalog_page_id, sales, profit, returns, profit_loss)
├── [CTE] ssr  [=]  Cost: 25%  Rows: ~1K  — Combine store sales and store returns into a single stream, align to the date window, and aggregate sales, returns, profit, and net-loss amounts per store id.
│   ├── SCAN (store_sales, store_returns, date_dim (join), store (join))
│   ├── JOIN (date_sk = d_date_sk)
│   ├── JOIN (store_sk = s_store_sk)
│   ├── FILTER (d_date BETWEEN CAST('2000-08-19' AS DATE) AND (CAST('2000-08-19' AS DATE) + INTERVAL '14' DAY))
│   ├── AGG (GROUP BY)
│   ├── UNION
│   └── OUTPUT (s_store_id, sales, profit, returns, profit_loss)
├── [CTE] wsr  [=]  Cost: 25%  Rows: ~1K  — Combine web sales with matching web returns, align to the date window, and aggregate sales, returns, profit, and net-loss amounts per web site id.
│   ├── SCAN (web_sales, web_returns, date_dim (join), web_site (join))
│   ├── JOIN (date_sk = d_date_sk)
│   ├── JOIN (wsr_web_site_sk = web_site_sk)
│   ├── FILTER (d_date BETWEEN CAST('2000-08-19' AS DATE) AND (CAST('2000-08-19' AS DATE) + INTERVAL '14' DAY))
│   ├── AGG (GROUP BY)
│   ├── UNION
│   └── OUTPUT (web_site_id, sales, profit, returns, profit_loss)
└── [MAIN] main_query  [=]  Cost: 25%  Rows: ~1K  — Union channel-level aggregates, derive net profit as profit minus loss, and produce grouped totals with rollup across channel and channel-specific id.
    ├── SCAN (wsr, ssr, csr)
    ├── AGG (GROUP BY)
    ├── SORT (channel ASC, id ASC)
    └── OUTPUT (channel, id, sales, returns, profit)
```

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: