### Part 1: Modified Logic Tree
```
QUERY: (single statement)
└── [MAIN] main_query  [~]  Cost: 100%  Rows: ~67  — Restructured into CTEs for early filtering and intermediate aggregation.
    ├── [~] WITH filtered_date AS (SELECT d_date_sk, d_year FROM date_dim WHERE d_moy = 11)
    ├── [~] WITH filtered_item_keys AS (SELECT i_item_sk FROM item WHERE i_manufact_id = 816)
    ├── [~] WITH aggregated_sales AS (SELECT d_year, i_item_sk, SUM(ss_sales_price) AS sum_agg FROM store_sales INNER JOIN filtered_date ON ss_sold_date_sk = d_date_sk INNER JOIN filtered_item_keys ON ss_item_sk = i_item_sk GROUP BY d_year, i_item_sk)
    ├── [~] WITH join_with_brand AS (SELECT aggregated_sales.d_year, item.i_brand_id, item.i_brand, aggregated_sales.sum_agg FROM aggregated_sales INNER JOIN item ON aggregated_sales.i_item_sk = item.i_item_sk WHERE item.i_manufact_id = 816)
    └── [~] SELECT d_year, i_brand_id AS brand_id, i_brand AS brand, sum_agg FROM join_with_brand ORDER BY d_year ASC, sum_agg DESC, i_brand_id ASC LIMIT 100
```

### Part 2: Component Payload JSON
```json
{
  "spec_version": "1.0",
  "dialect": "duckdb",
  "rewrite_rules": [
    {"id": "R1", "type": "dimension_cte_isolate", "description": "Pre-filter date_dim and item into separate CTEs before joining with store_sales.", "applied_to": ["filtered_date", "filtered_item_keys"]},
    {"id": "R2", "type": "early_filter", "description": "Push filters on date_dim (d_moy=11) and item (i_manufact_id=816) down to CTE scans, reducing fact table join size.", "applied_to": ["aggregated_sales"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "filtered_date": {
        "type": "cte",
        "change": "modified",
        "sql": "SELECT d_date_sk, d_year FROM date_dim WHERE d_moy = 11",
        "interfaces": {"outputs": ["d_date_sk", "d_year"], "consumes": []}
      },
      "filtered_item_keys": {
        "type": "cte",
        "change": "modified",
        "sql": "SELECT i_item_sk FROM item WHERE i_manufact_id = 816",
        "interfaces": {"outputs": ["i_item_sk"], "consumes": []}
      },
      "aggregated_sales": {
        "type": "cte",
        "change": "modified",
        "sql": "SELECT d_year, i_item_sk, SUM(ss_sales_price) AS sum_agg FROM store_sales INNER JOIN filtered_date ON ss_sold_date_sk = d_date_sk INNER JOIN filtered_item_keys ON ss_item_sk = i_item_sk GROUP BY d_year, i_item_sk",
        "interfaces": {"outputs": ["d_year", "i_item_sk", "sum_agg"], "consumes": ["filtered_date", "filtered_item_keys"]}
      },
      "join_with_brand": {
        "type": "cte",
        "change": "modified",
        "sql": "SELECT aggregated_sales.d_year, item.i_brand_id, item.i_brand, aggregated_sales.sum_agg FROM aggregated_sales INNER JOIN item ON aggregated_sales.i_item_sk = item.i_item_sk WHERE item.i_manufact_id = 816",
        "interfaces": {"outputs": ["d_year", "i_brand_id", "i_brand", "sum_agg"], "consumes": ["aggregated_sales"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "SELECT d_year, i_brand_id AS brand_id, i_brand AS brand, sum_agg FROM join_with_brand ORDER BY d_year ASC, sum_agg DESC, i_brand_id ASC LIMIT 100",
        "interfaces": {"outputs": ["d_year", "brand_id", "brand", "sum_agg"], "consumes": ["join_with_brand"]}
      }
    },
    "reconstruction_order": ["filtered_date", "filtered_item_keys", "aggregated_sales", "join_with_brand", "main_query"],
    "assembly_template": "WITH filtered_date AS ({filtered_date}), filtered_item_keys AS ({filtered_item_keys}), aggregated_sales AS ({aggregated_sales}), join_with_brand AS ({join_with_brand}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "validation_checks": []
}
```

**Changes**: Restructured into CTEs to filter dimensions (date_dim, item) before joining with the fact table (store_sales), reducing the volume of data scanned and joined. The redundant filter on `i_manufact_id=816` is preserved in `join_with_brand` as a defensive guard.

**Expected speedup**: Moderate (1.5–2.0x) due to early reduction of the fact table probe via pre‑filtered dimension hash tables, and DuckDB’s ability to push filters into the CTE scans.