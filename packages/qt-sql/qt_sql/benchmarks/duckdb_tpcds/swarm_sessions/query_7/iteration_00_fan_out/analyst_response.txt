<reasoning>
1. **CLASSIFY**: This is a classic star-join query with late dimension filtering. A large fact table (store_sales, 345.6M rows) is joined with 4 dimension tables (date_dim, customer_demographics, item, promotion) via foreign keys. Aggregation is performed at the item level after filtering on dimension attributes. No correlated subqueries, no UNION ALL, no self-joins, no window functions. Structural archetype: star-join with late dim filter.

2. **EXPLAIN PLAN ANALYSIS**:
   - Wall-clock ms per major node (exclusive):
     - store_sales SEQ_SCAN: 492.2ms (70% of total)
     - customer_demographics join: 110.8ms (16%)
     - date_dim join: 60.0ms (8%)
     - item join: 8.0ms (1%)
     - promotion join: 2.4ms (<1%)
     - GROUP BY: 17.9ms (3%)
     - TOP_N: 2.0ms (<1%)
   - Bottleneck: The store_sales sequential scan dominates at 70% of runtime. It scans 5.3M rows (1.5% of table) but must read the entire 345.6M row table because no predicate is pushed into the scan.
   - Row count drops:
     - date_dim: 73K → 365 rows (filter d_year=2001)
     - customer_demographics: 23M → 27K rows (filter gender/status/education)
     - promotion: 500 rows (filter channel flags)
     - store_sales: 345.6M → 5.3M rows AFTER join with date_dim, but the scan itself reads all 345.6M rows. This is the missed opportunity: the date range predicate (d_date_sk BETWEEN 2450816 AND 2452642) is not pushed into the store_sales scan.
   - Optimizer already handles: hash join selection, columnar projection, intra-scan predicate pushdown for dimension tables (date_dim filter appears in its scan). It does NOT push the date key range into the store_sales scan.
   - Scans per base table:
     - store_sales: 1 scan (but reads entire table)
     - date_dim: 1 scan (filtered)
     - customer_demographics: 1 scan (filtered)
     - item: 1 scan (no filter)
     - promotion: 1 scan (filtered)
   - No CTEs in original query; all joins are in main FROM.

3. **GAP MATCHING**:
   - **CROSS_CTE_PREDICATE_BLINDNESS**: Active. The date range predicate (d_date_sk BETWEEN ...) is known from date_dim filter but not pushed into store_sales scan. Opportunity: create a CTE with the date key range and explicitly filter store_sales by ss_sold_date_sk BETWEEN.
   - **REDUNDANT_SCAN_ELIMINATION**: Not applicable (single fact scan).
   - **CORRELATED_SUBQUERY_PARALYSIS**: Not applicable.
   - **CROSS_COLUMN_OR_DECOMPOSITION**: The OR condition on p_channel_email and p_channel_event is on the same table (promotion) and same row. Splitting into UNION ALL would duplicate the small promotion scan (500 rows) but not help fact table scan. Low priority.
   - Engine strengths already handle: hash join selection, same-column OR, columnar projection.

4. **AGGREGATION TRAP CHECK**: Only AVG aggregates. All joins are on foreign keys to dimension primary keys, so no row duplication introduced. Changing join order or pre-filtering will not affect aggregation correctness as long as we preserve the same set of store_sales rows that match all dimension filters.

5. **TRANSFORM SELECTION** (ranked by expected value):
   - **star_join_prefetch** (dimension_cte_isolate + early_filter): Pre-filter all dimension tables into CTEs, then join with store_sales using explicit range filter for date. Expected high impact because it allows pushing date range into store_sales scan.
   - **transitive_predicate_propagation**: Explicitly propagate date key range to store_sales via CTE or subquery. Similar to above but focused on predicate movement.
   - **or_to_union**: Split the OR on promotion columns. Lower impact but structurally different.
   - **aggregate_pushdown**: Push aggregation below some joins? Not directly applicable because group by column (i_item_id) comes from item table, which is needed for grouping. But we could filter store_sales first, then join with item and aggregate.
   - **late_attribute_binding**: item table is joined only for i_item_id (used in GROUP BY and SELECT). Could we filter store_sales first, then join with item? Yes, but item has no filter so no reduction. Still may help with join order.

6. **LOGICAL TREE DESIGN**:
   For star_join_prefetch: CTEs for filtered date_dim (with key range), filtered customer_demographics, filtered promotion, then join with store_sales using explicit ss_sold_date_sk BETWEEN, then join with item, then aggregate.
   Need to ensure all required columns are in CTE outputs: date_dim CTE must output d_date_sk; customer_demographics CTE must output cd_demo_sk; promotion CTE must output p_promo_sk; store_sales CTE must output ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price, and the foreign keys for joining with other CTEs.

   For transitive_predicate_propagation: Similar but might use subqueries instead of CTEs.

   For or_to_union: Split into two branches UNION ALL, each with a single promotion filter.

   For exploration: Try combining star_join_prefetch with aggregate_pushdown: filter store_sales by date range and other dimension keys (via CTEs), then join with item, then aggregate. This is essentially the same as star_join_prefetch but with explicit key filtering.

Selected 4 strategies with structural diversity:
1. **star_join_prefetch** (Worker 1): Pre-filter all dimensions into CTEs, explicitly filter store_sales by date key range.
2. **or_to_union** (Worker 2): Split OR on promotion into UNION ALL branches.
3. **late_attribute_binding** (Worker 3): Defer item join until after filtering store_sales by other dimensions.
4. **EXPLORATION: compound star_join_prefetch with aggregate_pushdown** (Worker 4): Filter store_sales by date range and other dimension keys (using CTEs), then join with item and aggregate. This combines techniques.

Check constraints:
- COMPLETE_OUTPUT: Must output i_item_id and 4 AVG columns.
- CTE_COLUMN_COMPLETENESS: Each CTE must include all columns referenced downstream.
- LITERAL_PRESERVATION: All filter values ('F', 'W', 'College', 'N', 2001) must be preserved exactly.
- SEMANTIC_EQUIVALENCE: Must return same rows.

Regression warnings: 
- date_cte_isolate regression on Q31 (baseline <100ms). Our baseline is 707ms, so safe.
- dimension_cte_isolate regression on Q26 (cross-joining 3+ dimension CTEs). We will join dimension CTEs with store_sales sequentially, not cross-join them.
- or_to_union regression on Q90 (same-column OR split). Our OR is on different columns (p_channel_email, p_channel_event), so safe.

</reasoning>

=== SHARED BRIEFING ===

SEMANTIC_CONTRACT:
Compute per-item average purchase metrics for 2001 store sales to female, widowed, college-educated customers under promotions with email or event channel disabled. All joins are INNER (intersection), requiring matches in all dimension tables. Aggregates are AVG over quantity, list price, coupon amount, and sales price; join-induced duplication must be avoided (foreign-key joins preserve cardinality). The OR condition on promotion channels must preserve NULL-handling: rows where p_channel_email or p_channel_event are NULL are excluded by the OR.

BOTTLENECK_DIAGNOSIS:
Scan-bound: store_sales sequential scan consumes 70% (492ms) of total runtime, reading all 345.6M rows to yield only 5.3M matching rows. The date range predicate (d_date_sk BETWEEN 2450816 AND 2452642) derived from d_year=2001 is not pushed into the store_sales scan. Cardinality flow: date_dim (365 rows), customer_demographics (27K rows), promotion (500 rows) are selective; store_sales scan outputs 5.3M rows after join filtering. The optimizer already handles dimension table predicate pushdown and hash joins efficiently; logical-tree cost percentages understate the store_sales scan dominance.

ACTIVE_CONSTRAINTS:
- COMPLETE_OUTPUT: Must output i_item_id, avg(ss_quantity), avg(ss_list_price), avg(ss_coupon_amt), avg(ss_sales_price).
- CTE_COLUMN_COMPLETENESS: Any CTE must include all columns referenced downstream (foreign keys, grouping columns, aggregates).
- LITERAL_PRESERVATION: Filters 'F', 'W', 'College', 'N', 2001 must be preserved exactly.
- SEMANTIC_EQUIVALENCE: Result set must be identical in rows, columns, and ordering.
- CROSS_CTE_PREDICATE_BLINDNESS: Date range predicate not pushed into store_sales scan (EXPLAIN shows store_sales scan without filter).
- CROSS_COLUMN_OR_DECOMPOSITION: OR on p_channel_email and p_channel_event spans different columns; could be split into UNION ALL.

REGRESSION_WARNINGS:
1. date_cte_isolate (Q31, 0.49x):
   CAUSE: Baseline runtime <100ms; CTE materialization overhead dominated savings.
   RULE: Our baseline is 707ms, so CTE overhead is acceptable.
2. dimension_cte_isolate (Q26, 0.0076x):
   CAUSE: Cross-joined 3+ dimension CTEs caused Cartesian explosion.
   RULE: Never cross-join dimension CTEs; join them sequentially with fact table.
3. or_to_union (Q90, 0.59x):
   CAUSE: Split same-column time range OR, duplicating fact scans.
   RULE: Our OR is on different columns (p_channel_email vs p_channel_event), safe to split.

=== WORKER 1 BRIEFING ===

STRATEGY: star_join_prefetch
TARGET_LOGICAL_TREE:
  date_cte -> customer_demo_cte -> promotion_cte -> filtered_store_sales -> item_join -> aggregate -> top_n
NODE_CONTRACTS:
  date_cte:
    FROM: date_dim
    WHERE: d_year = 2001
    OUTPUT: d_date_sk, d_year
    EXPECTED_ROWS: 365
    CONSUMERS: filtered_store_sales (for date range), filtered_store_sales join condition
  customer_demo_cte:
    FROM: customer_demographics
    WHERE: cd_gender = 'F' AND cd_marital_status = 'W' AND cd_education_status = 'College'
    OUTPUT: cd_demo_sk
    EXPECTED_ROWS: 27K
    CONSUMERS: filtered_store_sales join condition
  promotion_cte:
    FROM: promotion
    WHERE: p_channel_email = 'N' OR p_channel_event = 'N'
    OUTPUT: p_promo_sk
    EXPECTED_ROWS: 500
    CONSUMERS: filtered_store_sales join condition
  filtered_store_sales:
    FROM: store_sales
    JOIN: INNER JOIN date_cte ON ss_sold_date_sk = d_date_sk
    WHERE: ss_sold_date_sk BETWEEN (SELECT MIN(d_date_sk) FROM date_cte) AND (SELECT MAX(d_date_sk) FROM date_cte)
    OUTPUT: ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price, ss_cdemo_sk, ss_promo_sk
    EXPECTED_ROWS: 5.3M
    CONSUMERS: item_join
  item_join:
    FROM: filtered_store_sales
    JOIN: INNER JOIN item ON ss_item_sk = i_item_sk
    OUTPUT: i_item_id, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price
    EXPECTED_ROWS: 5.3M
    CONSUMERS: aggregate
  aggregate:
    FROM: item_join
    GROUP BY: i_item_id
    AGGREGATE: AVG(ss_quantity), AVG(ss_list_price), AVG(ss_coupon_amt), AVG(ss_sales_price)
    OUTPUT: i_item_id, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: 39K
    CONSUMERS: top_n
  top_n:
    FROM: aggregate
    ORDER BY: i_item_id ASC
    LIMIT: 100
    OUTPUT: i_item_id, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: 100
    CONSUMERS: final output
EXAMPLES: dimension_cte_isolate, prefetch_fact_join, date_cte_isolate
EXAMPLE_ADAPTATION:
- dimension_cte_isolate: Apply pre-filtering of all dimension tables into CTEs; ignore the cross-join warning (we join sequentially).
- prefetch_fact_join: Apply the CTE chain that filters dimensions first, then join with fact table; ignore the multiple fact table chains (we have only store_sales).
- date_cte_isolate: Apply extracting date filter into CTE and using date key range; ignore the decomposition warning (baseline >100ms).
HAZARD_FLAGS:
- Must ensure the BETWEEN subqueries on date_cte do not cause correlated execution; consider extracting MIN/MAX into scalar CTE.
- All dimension CTEs must be referenced only once to avoid materialization overhead.

=== WORKER 2 BRIEFING ===

STRATEGY: or_to_union
TARGET_LOGICAL_TREE:
  union_branch1 -> union_branch2 -> union_combined -> date_join -> customer_join -> item_join -> aggregate -> top_n
NODE_CONTRACTS:
  union_branch1:
    FROM: store_sales
    JOIN: INNER JOIN promotion p ON ss_promo_sk = p_promo_sk AND p_channel_email = 'N'
    WHERE: (placeholder for other filters applied later)
    OUTPUT: ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price, ss_sold_date_sk, ss_cdemo_sk
    EXPECTED_ROWS: ~half of 5.3M (estimate)
    CONSUMERS: union_combined
  union_branch2:
    FROM: store_sales
    JOIN: INNER JOIN promotion p ON ss_promo_sk = p_promo_sk AND p_channel_event = 'N'
    WHERE: (placeholder for other filters applied later)
    OUTPUT: ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price, ss_sold_date_sk, ss_cdemo_sk
    EXPECTED_ROWS: ~half of 5.3M (estimate)
    CONSUMERS: union_combined
  union_combined:
    FROM: (SELECT * FROM union_branch1 UNION ALL SELECT * FROM union_branch2)
    OUTPUT: ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price, ss_sold_date_sk, ss_cdemo_sk
    EXPECTED_ROWS: ~5.3M (with duplicates from overlapping promotions removed via DISTINCT? Note: UNION ALL keeps duplicates if a promotion satisfies both conditions. Need to deduplicate by store_sales row? Actually, each store_sales row has one ss_promo_sk, so it can appear in at most one branch because the promotion row must satisfy the branch condition. However, a promotion row could satisfy both conditions (email='N' and event='N'), causing the same store_sales row to appear in both branches. We must deduplicate by store_sales surrogate key (e.g., ss_sales_sk). But the original OR condition would include such rows once. So we need to deduplicate. This is a hazard.)
    CONSUMERS: date_join
  date_join:
    FROM: union_combined
    JOIN: INNER JOIN date_dim ON ss_sold_date_sk = d_date_sk AND d_year = 2001
    OUTPUT: ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price, ss_cdemo_sk
    EXPECTED_ROWS: 5.3M
    CONSUMERS: customer_join
  customer_join:
    FROM: date_join
    JOIN: INNER JOIN customer_demographics ON ss_cdemo_sk = cd_demo_sk AND cd_gender = 'F' AND cd_marital_status = 'W' AND cd_education_status = 'College'
    OUTPUT: ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price
    EXPECTED_ROWS: 5.3M
    CONSUMERS: item_join
  item_join:
    FROM: customer_join
    JOIN: INNER JOIN item ON ss_item_sk = i_item_sk
    OUTPUT: i_item_id, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price
    EXPECTED_ROWS: 5.3M
    CONSUMERS: aggregate
  aggregate:
    FROM: item_join
    GROUP BY: i_item_id
    AGGREGATE: AVG(ss_quantity), AVG(ss_list_price), AVG(ss_coupon_amt), AVG(ss_sales_price)
    OUTPUT: i_item_id, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: 39K
    CONSUMERS: top_n
  top_n:
    FROM: aggregate
    ORDER BY: i_item_id ASC
    LIMIT: 100
    OUTPUT: i_item_id, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: 100
    CONSUMERS: final output
EXAMPLES: or_to_union
EXAMPLE_ADAPTATION:
- or_to_union: Apply splitting OR into UNION ALL branches; ignore the warning about same-column OR (our OR is on different columns). Must handle deduplication if a promotion satisfies both conditions.
HAZARD_FLAGS:
- Deduplication required if a promotion row satisfies both channel conditions (email='N' and event='N'). Use DISTINCT on store_sales key before or after UNION.
- Each branch rescans store_sales entirely (345.6M rows), potentially doubling scan cost. Mitigate by pushing date filter into each branch? But date filter is after union in original plan. Consider pushing date join into each branch.

=== WORKER 3 BRIEFING ===

STRATEGY: late_attribute_binding
TARGET_LOGICAL_TREE:
  date_cte -> customer_demo_cte -> promotion_cte -> filtered_sales -> aggregate_pre -> item_join -> final_aggregate -> top_n
NODE_CONTRACTS:
  date_cte:
    FROM: date_dim
    WHERE: d_year = 2001
    OUTPUT: d_date_sk
    EXPECTED_ROWS: 365
    CONSUMERS: filtered_sales
  customer_demo_cte:
    FROM: customer_demographics
    WHERE: cd_gender = 'F' AND cd_marital_status = 'W' AND cd_education_status = 'College'
    OUTPUT: cd_demo_sk
    EXPECTED_ROWS: 27K
    CONSUMERS: filtered_sales
  promotion_cte:
    FROM: promotion
    WHERE: p_channel_email = 'N' OR p_channel_event = 'N'
    OUTPUT: p_promo_sk
    EXPECTED_ROWS: 500
    CONSUMERS: filtered_sales
  filtered_sales:
    FROM: store_sales
    JOIN: INNER JOIN date_cte ON ss_sold_date_sk = d_date_sk
    JOIN: INNER JOIN customer_demo_cte ON ss_cdemo_sk = cd_demo_sk
    JOIN: INNER JOIN promotion_cte ON ss_promo_sk = p_promo_sk
    OUTPUT: ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price
    EXPECTED_ROWS: 5.3M
    CONSUMERS: aggregate_pre
  aggregate_pre:
    FROM: filtered_sales
    GROUP BY: ss_item_sk
    AGGREGATE: AVG(ss_quantity), AVG(ss_list_price), AVG(ss_coupon_amt), AVG(ss_sales_price)
    OUTPUT: ss_item_sk, avg_quantity, avg_list_price, avg_coupon_amt, avg_sales_price
    EXPECTED_ROWS: 39K
    CONSUMERS: item_join
  item_join:
    FROM: aggregate_pre
    JOIN: INNER JOIN item ON ss_item_sk = i_item_sk
    OUTPUT: i_item_id, avg_quantity, avg_list_price, avg_coupon_amt, avg_sales_price
    EXPECTED_ROWS: 39K
    CONSUMERS: final_aggregate
  final_aggregate:
    FROM: item_join
    GROUP BY: i_item_id
    AGGREGATE: MAX(avg_quantity), MAX(avg_list_price), MAX(avg_coupon_amt), MAX(avg_sales_price)  -- because each ss_item_sk maps to one i_item_id
    OUTPUT: i_item_id, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: 39K
    CONSUMERS: top_n
  top_n:
    FROM: final_aggregate
    ORDER BY: i_item_id ASC
    LIMIT: 100
    OUTPUT: i_item_id, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: 100
    CONSUMERS: final output
EXAMPLES: early_filter, dimension_cte_isolate, deferred_window_aggregation (for late join concept)
EXAMPLE_ADAPTATION:
- early_filter: Apply filtering dimension tables first; ignore the fact that item is not filtered.
- dimension_cte_isolate: Apply creating CTEs for filtered dimensions; ignore cross-join risk.
- deferred_window_aggregation: Apply the concept of delaying a join (item) until after aggregation; ignore window function specifics.
HAZARD_FLAGS:
- Aggregating by ss_item_sk before joining with item assumes each ss_item_sk maps to exactly one i_item_id (true by foreign key). The final MAX aggregation is a no-op but required syntactically.
- Must ensure the aggregate_pre output columns are correctly matched to item join.

=== WORKER 4 BRIEFING === (EXPLORATION WORKER)

STRATEGY: compound_star_join_prefetch_with_aggregate_pushdown
TARGET_LOGICAL_TREE:
  date_cte -> customer_demo_cte -> promotion_cte -> filtered_sales -> item_join_aggregate -> top_n
NODE_CONTRACTS:
  date_cte:
    FROM: date_dim
    WHERE: d_year = 2001
    OUTPUT: d_date_sk
    EXPECTED_ROWS: 365
    CONSUMERS: filtered_sales
  customer_demo_cte:
    FROM: customer_demographics
    WHERE: cd_gender = 'F' AND cd_marital_status = 'W' AND cd_education_status = 'College'
    OUTPUT: cd_demo_sk
    EXPECTED_ROWS: 27K
    CONSUMERS: filtered_sales
  promotion_cte:
    FROM: promotion
    WHERE: p_channel_email = 'N' OR p_channel_event = 'N'
    OUTPUT: p_promo_sk
    EXPECTED_ROWS: 500
    CONSUMERS: filtered_sales
  filtered_sales:
    FROM: store_sales
    JOIN: INNER JOIN date_cte ON ss_sold_date_sk = d_date_sk
    JOIN: INNER JOIN customer_demo_cte ON ss_cdemo_sk = cd_demo_sk
    JOIN: INNER JOIN promotion_cte ON ss_promo_sk = p_promo_sk
    OUTPUT: ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price
    EXPECTED_ROWS: 5.3M
    CONSUMERS: item_join_aggregate
  item_join_aggregate:
    FROM: filtered_sales
    JOIN: INNER JOIN item ON ss_item_sk = i_item_sk
    GROUP BY: i_item_id
    AGGREGATE: AVG(ss_quantity), AVG(ss_list_price), AVG(ss_coupon_amt), AVG(ss_sales_price)
    OUTPUT: i_item_id, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: 39K
    CONSUMERS: top_n
  top_n:
    FROM: item_join_aggregate
    ORDER BY: i_item_id ASC
    LIMIT: 100
    OUTPUT: i_item_id, agg1, agg2, agg3, agg4
    EXPECTED_ROWS: 100
    CONSUMERS: final output
EXAMPLES: prefetch_fact_join, dimension_cte_isolate, single_pass_aggregation (for combined filtering and aggregation)
EXAMPLE_ADAPTATION:
- prefetch_fact_join: Apply the CTE chain filtering dimensions then joining with fact table; ignore the warning about baseline <50ms (ours is 707ms).
- dimension_cte_isolate: Apply pre-filtering all dimension tables; ignore cross-join risk.
- single_pass_aggregation: Not directly applicable, but the idea of consolidating filters into a single pass of store_sales is similar.
HAZARD_FLAGS:
- Must ensure the join order (store_sales joining with three dimension CTEs) doesn't cause large intermediate hash tables. The dimension CTEs are small.
- The optimizer might reorder joins anyway; CTEs could be inlined.
CONSTRAINT_OVERRIDE: None
OVERRIDE_REASONING: N/A
EXPLORATION_TYPE: compound_strategy (combining star_join_prefetch with aggregate_pushdown, though aggregate_pushdown is minimal here because aggregation is after item join). This is essentially a more aggressive version of Worker 1's strategy, pushing all dimension filters before the fact table scan via joins rather than explicit BETWEEN.