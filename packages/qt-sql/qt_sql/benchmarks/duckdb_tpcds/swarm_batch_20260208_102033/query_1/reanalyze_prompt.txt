You are analyzing 5 failed optimization attempts to design a refined approach that reaches 2.0x speedup.

Your job: understand WHY each attempt fell short, identify unexplored optimization angles, and synthesize a NEW strategy that combines the best insights while avoiding repeated mistakes.

## Query: query_1
## Target: 2.0x speedup
## Dialect: duckdb

```sql
-- start query 1 in stream 0 using template query1.tpl
with customer_total_return as
(select sr_customer_sk as ctr_customer_sk
,sr_store_sk as ctr_store_sk
,sum(SR_FEE) as ctr_total_return
from store_returns
,date_dim
where sr_returned_date_sk = d_date_sk
and d_year =2000
group by sr_customer_sk
,sr_store_sk)
 select c_customer_id
from customer_total_return ctr1
,store
,customer
where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2
from customer_total_return ctr2
where ctr1.ctr_store_sk = ctr2.ctr_store_sk)
and s_store_sk = ctr1.ctr_store_sk
and s_state = 'SD'
and ctr1.ctr_customer_sk = c_customer_sk
order by c_customer_id
 LIMIT 100;

-- end query 1 in stream 0 using template query1.tpl
```

## Previous Attempts

### Worker 1: conservative_predicate_pushdown
- **Status**: pass (1.01x)
- **Transforms**: none
- **Examples used**: pushdown, early_filter, materialize_cte
- **Strategy hint**: Push filters early into CTEs and materialize reusable aggregates to reduce intermediate data volume before joins.

```sql
WITH customer_total_return AS (
  SELECT
    sr_customer_sk AS ctr_customer_sk,
    sr_store_sk AS ctr_store_sk,
    SUM(SR_FEE) AS ctr_total_return
  FROM store_returns
  JOIN date_dim ON sr_returned_date_sk = d_date_sk
  WHERE d_year = 2000
  GROUP BY
    sr_customer_sk,
    sr_store_sk
),
filtered_stores AS (
  SELECT s_store_sk
  FROM store
  WHERE s_state = 'SD'
),
customer_returns_sd AS (
  SELECT
    ctr.ctr_customer_sk,
    ctr.ctr_store_sk,
    ctr.ctr_total_return
  FROM customer_total_return ctr
  JOIN filtered_stores fs ON ctr.ctr_store_sk = fs.s_store_sk
)
SELECT
  c_customer_id
FROM customer_returns_sd ctr1
JOIN customer ON ctr1.ctr_customer_sk = c_customer_sk
WHERE ctr1.ctr_total_return > (
-- ... (truncated)
```

### Worker 2: moderate_dimension_isolation
- **Status**: pass (1.50x)
- **Transforms**: none
- **Examples used**: date_cte_isolate, dimension_cte_isolate, shared_dimension_multi_channel
- **Strategy hint**: Pre-filter date_dim and store dimension into separate CTEs before the main aggregation to enable better predicate pushdown.

```sql
WITH filtered_dates AS (
  SELECT d_date_sk
  FROM date_dim
  WHERE d_year = 2000
), filtered_stores AS (
  SELECT s_store_sk
  FROM store
  WHERE s_state = 'SD'
), customer_total_return AS (
  SELECT
    sr_customer_sk AS ctr_customer_sk,
    sr_store_sk AS ctr_store_sk,
    SUM(sr_fee) AS ctr_total_return
  FROM store_returns
  JOIN filtered_dates ON sr_returned_date_sk = d_date_sk
  JOIN filtered_stores ON sr_store_sk = s_store_sk
  GROUP BY sr_customer_sk, sr_store_sk
)
SELECT
  c_customer_id
FROM customer_total_return ctr1
JOIN customer ON ctr1.ctr_customer_sk = c_customer_sk
WHERE ctr1.ctr_total_return > (
  SELECT AVG(ctr2.ctr_total_return) * 1.2
  FROM customer_total_return ctr2
  WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk
)
ORDER BY c_customer_id
LIMIT 100
```

### Worker 3: aggressive_multi_cte_prefetch
- **Status**: pass (1.62x)
- **Transforms**: none
- **Examples used**: prefetch_fact_join, multi_dimension_prefetch, single_pass_aggregation
- **Strategy hint**: Pre-join filtered dimensions with fact tables early, then compute both base aggregates and store-level averages in a single pass.

```sql
WITH filtered_date AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year = 2000
),
filtered_store AS (
    SELECT s_store_sk
    FROM store
    WHERE s_state = 'SD'
),
store_returns_filtered AS (
    SELECT 
        sr.sr_customer_sk,
        sr.sr_store_sk,
        sr.SR_FEE
    FROM store_returns sr
    INNER JOIN filtered_date fd ON sr.sr_returned_date_sk = fd.d_date_sk
    INNER JOIN filtered_store fs ON sr.sr_store_sk = fs.s_store_sk
),
customer_store_returns AS (
    SELECT
        sr_customer_sk AS ctr_customer_sk,
        sr_store_sk AS ctr_store_sk,
        SUM(SR_FEE) AS ctr_total_return,
        AVG(SUM(SR_FEE)) OVER (PARTITION BY sr_store_sk) AS store_avg_return
    FROM store_returns_filtered
    GROUP BY sr_customer_sk, sr_store_sk
)
SELECT
    c.c_customer_id
-- ... (truncated)
```

### Worker 4: novel_correlation_elimination
- **Status**: pass (1.01x)
- **Transforms**: none
- **Examples used**: decorrelate, or_to_union, intersect_to_exists
- **Strategy hint**: Eliminate the correlated subquery by precomputing store averages, and explore alternative joins using UNION branches for state filtering.

```sql
WITH customer_total_return AS (
  SELECT
    sr_customer_sk AS ctr_customer_sk,
    sr_store_sk AS ctr_store_sk,
    SUM(SR_FEE) AS ctr_total_return
  FROM store_returns
  JOIN date_dim ON sr_returned_date_sk = d_date_sk
  WHERE d_year = 2000
  GROUP BY
    sr_customer_sk,
    sr_store_sk
),
store_avg_return AS (
  SELECT
    ctr_store_sk,
    AVG(ctr_total_return) * 1.2 AS avg_threshold
  FROM customer_total_return
  GROUP BY ctr_store_sk
)
SELECT
  c_customer_id
FROM customer_total_return ctr1
JOIN store_avg_return sar ON ctr1.ctr_store_sk = sar.ctr_store_sk
JOIN store ON s_store_sk = ctr1.ctr_store_sk
JOIN customer ON ctr1.ctr_customer_sk = c_customer_sk
WHERE ctr1.ctr_total_return > sar.avg_threshold
  AND s_state = 'SD'
ORDER BY c_customer_id
LIMIT 100
```

### Worker 5: refined_snipe
- **Status**: pass (1.05x)
- **Transforms**: none
- **Examples used**: 
- **Strategy hint**: Snipe from iter 1

```sql
WITH customer_total_return AS (
  SELECT
    sr_customer_sk AS ctr_customer_sk,
    sr_store_sk AS ctr_store_sk,
    SUM(SR_FEE) AS ctr_total_return
  FROM store_returns
  JOIN date_dim ON sr_returned_date_sk = d_date_sk
  WHERE d_year = 2000
  GROUP BY
    sr_customer_sk,
    sr_store_sk
),
store_avg_return AS (
  SELECT
    ctr_store_sk,
    AVG(ctr_total_return) * 1.2 AS avg_return_threshold
  FROM customer_total_return
  GROUP BY ctr_store_sk
),
sd_stores AS (
  SELECT s_store_sk
  FROM store
  WHERE s_state = 'SD'
)
SELECT
  c_customer_id
FROM customer_total_return ctr1
JOIN store_avg_return sar ON ctr1.ctr_store_sk = sar.ctr_store_sk
JOIN sd_stores s ON ctr1.ctr_store_sk = s.s_store_sk
JOIN customer c ON ctr1.ctr_customer_sk = c.c_customer_sk
-- ... (truncated)
```

## DAG Structure & Bottlenecks

| Node | Role | Cost % |
|------|------|-------:|
| customer_total_return |  | 0.0% |
| main_query |  | 0.0% |

## Available Examples (Full Catalog)

- **composite_decorrelate_union** (2.42xx) — Decorrelate multiple correlated EXISTS subqueries into pre-materialized DISTINCT
- **date_cte_isolate** (4.00xx) — Extract date filtering into a separate CTE to enable predicate pushdown and redu
- **decorrelate** (2.92xx) — Convert correlated subquery to separate CTE with GROUP BY, then JOIN
- **deferred_window_aggregation** (1.36xx) — When multiple CTEs each perform GROUP BY + WINDOW (cumulative sum), then are joi
- **dimension_cte_isolate** (1.93xx) — Pre-filter ALL dimension tables into CTEs before joining with fact table, not ju
- **early_filter** (4.00xx) — Filter dimension tables FIRST, then join to fact tables to reduce expensive join
- **intersect_to_exists** (1.83xx) — Convert INTERSECT subquery pattern to multiple EXISTS clauses for better join pl
- **materialize_cte** (1.37xx) — Extract repeated subquery patterns into a CTE to avoid recomputation
- **multi_date_range_cte** (2.35xx) — When query uses multiple date_dim aliases with different filters (d1, d2, d3), c
- **multi_dimension_prefetch** (2.71xx) — Pre-filter multiple dimension tables (date + store) into separate CTEs before jo
- **or_to_union** (3.17xx) — Split OR conditions on different columns into UNION ALL branches for better inde
- **prefetch_fact_join** (3.77xx) — Pre-filter dimension table into CTE, then pre-join with fact table in second CTE
- **pushdown** (2.11xx) — Push filters from outer query into CTEs/subqueries to reduce intermediate result
- **shared_dimension_multi_channel** (1.30xx) — Extract shared dimension filters (date, item, promotion) into CTEs when multiple
- **single_pass_aggregation** (4.47xx) — Consolidate multiple subqueries scanning the same table into a single CTE with c
- **union_cte_split** (1.36xx) — Split a generic UNION ALL CTE into specialized CTEs when the main query filters 

## Your Task

Analyze the failed attempts and design a refined approach:

1. **Failure Analysis**: Why did all attempts fall short? Be specific about mechanisms.
2. **Common Patterns**: What did multiple workers try unsuccessfully?
3. **Unexplored Space**: What optimization angles were missed entirely?
4. **Refined Strategy**: Synthesize a NEW approach combining best insights.

### Output Format (follow EXACTLY)

```
FAILURE_ANALYSIS:
<Why all workers fell short — be specific about mechanisms>

UNEXPLORED_OPPORTUNITIES:
<What optimization approaches haven't been tried>

REFINED_STRATEGY:
<Concrete optimization approach for next attempt>

EXAMPLES: <ex1>, <ex2>, <ex3>
HINT: <specific guidance for the refined attempt>
```