You are analyzing 5 failed optimization attempts to design a refined approach that reaches 2.0x speedup.

Your job: understand WHY each attempt fell short, identify unexplored optimization angles, and synthesize a NEW strategy that combines the best insights while avoiding repeated mistakes.

## Query: query_18
## Target: 2.0x speedup
## Dialect: duckdb

```sql
-- start query 18 in stream 0 using template query18.tpl
select i_item_id,
        ca_country,
        ca_state, 
        ca_county,
        avg( cast(cs_quantity as decimal(12,2))) agg1,
        avg( cast(cs_list_price as decimal(12,2))) agg2,
        avg( cast(cs_coupon_amt as decimal(12,2))) agg3,
        avg( cast(cs_sales_price as decimal(12,2))) agg4,
        avg( cast(cs_net_profit as decimal(12,2))) agg5,
        avg( cast(c_birth_year as decimal(12,2))) agg6,
        avg( cast(cd1.cd_dep_count as decimal(12,2))) agg7
 from catalog_sales, customer_demographics cd1, 
      customer_demographics cd2, customer, customer_address, date_dim, item
 where cs_sold_date_sk = d_date_sk and
       cs_item_sk = i_item_sk and
       cs_bill_cdemo_sk = cd1.cd_demo_sk and
       cs_bill_customer_sk = c_customer_sk and
       cd1.cd_gender = 'F' and 
       cd1.cd_education_status = 'Advanced Degree' and
       c_current_cdemo_sk = cd2.cd_demo_sk and
       c_current_addr_sk = ca_address_sk and
       c_birth_month in (10,7,8,4,1,2) and
       d_year = 1998 and
       ca_state in ('WA','GA','NC'
                   ,'ME','WY','OK','IN')
 group by rollup (i_item_id, ca_country, ca_state, ca_county)
 order by ca_country,
        ca_state, 
        ca_county,
	i_item_id
 LIMIT 100;

-- end query 18 in stream 0 using template query18.tpl
```

## Previous Attempts

### Worker 1: conservative_early_filtering
- **Status**: pass (1.06x)
- **Transforms**: none
- **Examples used**: early_filter, pushdown, materialize_cte
- **Strategy hint**: Apply aggressive early filtering on dimension tables before joins, push predicates into base tables, and materialize reusable filtered subsets to reduce join cardinality.

```sql
-- start query 18 in stream 0 using template query18.tpl
select i_item_id,
        ca_country,
        ca_state, 
        ca_county,
        avg( cast(cs_quantity as decimal(12,2))) agg1,
        avg( cast(cs_list_price as decimal(12,2))) agg2,
        avg( cast(cs_coupon_amt as decimal(12,2))) agg3,
        avg( cast(cs_sales_price as decimal(12,2))) agg4,
        avg( cast(cs_net_profit as decimal(12,2))) agg5,
        avg( cast(c_birth_year as decimal(12,2))) agg6,
        avg( cast(cd1.cd_dep_count as decimal(12,2))) agg7
 from catalog_sales, customer_demographics cd1, 
      customer_demographics cd2, customer, customer_address, date_dim, item
 where cs_sold_date_sk = d_date_sk and
       cs_item_sk = i_item_sk and
       cs_bill_cdemo_sk = cd1.cd_demo_sk and
       cs_bill_customer_sk = c_customer_sk and
       cd1.cd_gender = 'F' and 
       cd1.cd_education_status = 'Advanced Degree' and
       c_current_cdemo_sk = cd2.cd_demo_sk and
       c_current_addr_sk = ca_address_sk and
       c_birth_month in (10,7,8,4,1,2) and
       d_year = 1998 and
       ca_state in ('WA','GA','NC'
                   ,'ME','WY','OK','IN')
 group by rollup (i_item_id, ca_country, ca_state, ca_county)
 order by ca_country,
        ca_state, 
        ca_county,
-- ... (truncated)
```

### Worker 2: moderate_dimension_isolation
- **Status**: pass (1.57x)
- **Transforms**: none
- **Examples used**: dimension_cte_isolate, date_cte_isolate, shared_dimension_multi_channel
- **Strategy hint**: Pre-filter all dimension tables into isolated CTEs before joining with the fact table, ensuring predicate pushdown and reuse of filtered dimension sets.

```sql
WITH filtered_date AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year = 1998
),
filtered_cd1 AS (
    SELECT cd_demo_sk, cd_dep_count
    FROM customer_demographics
    WHERE cd_gender = 'F'
      AND cd_education_status = 'Advanced Degree'
),
filtered_address AS (
    SELECT ca_address_sk, ca_country, ca_state, ca_county
    FROM customer_address
    WHERE ca_state IN ('WA', 'GA', 'NC', 'ME', 'WY', 'OK', 'IN')
),
filtered_customer AS (
    SELECT 
        c.c_customer_sk,
        c.c_current_cdemo_sk,
        c.c_birth_year,
        a.ca_country,
        a.ca_state,
        a.ca_county
    FROM customer c
    JOIN filtered_address a ON c.c_current_addr_sk = a.ca_address_sk
    WHERE c.c_birth_month IN (10, 7, 8, 4, 1, 2)
)
SELECT
    i.i_item_id,
-- ... (truncated)
```

### Worker 3: aggressive_prefetch_restructuring
- **Status**: error (0.00x)
- **Error**: Binder Error: Ambiguous reference to column name "cd_dep_count" (use: "prejoined_fact.cd_dep_count" or "cd2.cd_dep_count")
- **Transforms**: none
- **Examples used**: prefetch_fact_join, multi_dimension_prefetch, single_pass_aggregation
- **Strategy hint**: Pre-join filtered dimensions with the fact table in CTEs, prefetch multiple dimension subsets, and consolidate aggregations into single-pass computations.

```sql
WITH filtered_date AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year = 1998
),
filtered_cd1 AS (
    SELECT cd_demo_sk, cd_dep_count
    FROM customer_demographics
    WHERE cd_gender = 'F'
      AND cd_education_status = 'Advanced Degree'
),
filtered_customer AS (
    SELECT c_customer_sk, c_current_cdemo_sk, c_birth_year, c_current_addr_sk
    FROM customer
    WHERE c_birth_month IN (10, 7, 8, 4, 1, 2)
),
filtered_address AS (
    SELECT ca_address_sk, ca_country, ca_state, ca_county
    FROM customer_address
    WHERE ca_state IN ('WA', 'GA', 'NC', 'ME', 'WY', 'OK', 'IN')
),
prejoined_fact AS (
    SELECT
        cs.cs_quantity,
        cs.cs_list_price,
        cs.cs_coupon_amt,
        cs.cs_sales_price,
        cs.cs_net_profit,
        cs.cs_bill_customer_sk,
        i.i_item_id,
-- ... (truncated)
```

### Worker 4: novel_structural_transforms
- **Status**: pass (0.82x)
- **Transforms**: none
- **Examples used**: or_to_union, intersect_to_exists, composite_decorrelate_union
- **Strategy hint**: Transform OR/IN conditions into UNION ALL branches, rewrite intersection patterns as EXISTS, and decorrelate nested patterns through distinct pre-materialization.

```sql
WITH filtered_date AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year = 1998
),
filtered_address AS (
    SELECT ca_address_sk, ca_country, ca_state, ca_county
    FROM customer_address
    WHERE ca_state IN ('WA', 'GA', 'NC', 'ME', 'WY', 'OK', 'IN')
),
filtered_cd1 AS (
    SELECT cd_demo_sk, cd_dep_count
    FROM customer_demographics
    WHERE cd_gender = 'F'
      AND cd_education_status = 'Advanced Degree'
),
filtered_customer AS (
    SELECT c_customer_sk, c_current_cdemo_sk, c_current_addr_sk, c_birth_year
    FROM customer
    WHERE c_birth_month IN (10, 7, 8, 4, 1, 2)
)
SELECT
  i_item_id,
  ca_country,
  ca_state,
  ca_county,
  AVG(CAST(cs_quantity AS DECIMAL(12, 2))) AS agg1,
  AVG(CAST(cs_list_price AS DECIMAL(12, 2))) AS agg2,
  AVG(CAST(cs_coupon_amt AS DECIMAL(12, 2))) AS agg3,
  AVG(CAST(cs_sales_price AS DECIMAL(12, 2))) AS agg4,
-- ... (truncated)
```

### Worker 5: refined_snipe
- **Status**: pass (1.00x)
- **Transforms**: none
- **Examples used**: 
- **Strategy hint**: Snipe from iter 1

```sql
WITH filtered_date AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year = 1998
),
filtered_cd1 AS (
    SELECT cd_demo_sk, cd_dep_count
    FROM customer_demographics
    WHERE cd_gender = 'F'
      AND cd_education_status = 'Advanced Degree'
),
filtered_customer AS (
    SELECT 
        c_customer_sk,
        c_current_cdemo_sk,
        c_current_addr_sk,
        c_birth_year
    FROM customer
    WHERE c_birth_month IN (10, 7, 8, 4, 1, 2)
),
filtered_address AS (
    SELECT 
        ca_address_sk,
        ca_country,
        ca_state,
        ca_county
    FROM customer_address
    WHERE ca_state IN ('WA', 'GA', 'NC', 'ME', 'WY', 'OK', 'IN')
),
joined_facts AS (
-- ... (truncated)
```

## DAG Structure & Bottlenecks

| Node | Role | Cost % |
|------|------|-------:|
| main_query |  | 0.0% |

## Available Examples (Full Catalog)

- **composite_decorrelate_union** (2.42xx) — Decorrelate multiple correlated EXISTS subqueries into pre-materialized DISTINCT
- **date_cte_isolate** (4.00xx) — Extract date filtering into a separate CTE to enable predicate pushdown and redu
- **decorrelate** (2.92xx) — Convert correlated subquery to separate CTE with GROUP BY, then JOIN
- **deferred_window_aggregation** (1.36xx) — When multiple CTEs each perform GROUP BY + WINDOW (cumulative sum), then are joi
- **dimension_cte_isolate** (1.93xx) — Pre-filter ALL dimension tables into CTEs before joining with fact table, not ju
- **early_filter** (4.00xx) — Filter dimension tables FIRST, then join to fact tables to reduce expensive join
- **intersect_to_exists** (1.83xx) — Convert INTERSECT subquery pattern to multiple EXISTS clauses for better join pl
- **materialize_cte** (1.37xx) — Extract repeated subquery patterns into a CTE to avoid recomputation
- **multi_date_range_cte** (2.35xx) — When query uses multiple date_dim aliases with different filters (d1, d2, d3), c
- **multi_dimension_prefetch** (2.71xx) — Pre-filter multiple dimension tables (date + store) into separate CTEs before jo
- **or_to_union** (3.17xx) — Split OR conditions on different columns into UNION ALL branches for better inde
- **prefetch_fact_join** (3.77xx) — Pre-filter dimension table into CTE, then pre-join with fact table in second CTE
- **pushdown** (2.11xx) — Push filters from outer query into CTEs/subqueries to reduce intermediate result
- **shared_dimension_multi_channel** (1.30xx) — Extract shared dimension filters (date, item, promotion) into CTEs when multiple
- **single_pass_aggregation** (4.47xx) — Consolidate multiple subqueries scanning the same table into a single CTE with c
- **union_cte_split** (1.36xx) — Split a generic UNION ALL CTE into specialized CTEs when the main query filters 

## Your Task

Analyze the failed attempts and design a refined approach:

1. **Failure Analysis**: Why did all attempts fall short? Be specific about mechanisms.
2. **Common Patterns**: What did multiple workers try unsuccessfully?
3. **Unexplored Space**: What optimization angles were missed entirely?
4. **Refined Strategy**: Synthesize a NEW approach combining best insights.

### Output Format (follow EXACTLY)

```
FAILURE_ANALYSIS:
<Why all workers fell short — be specific about mechanisms>

UNEXPLORED_OPPORTUNITIES:
<What optimization approaches haven't been tried>

REFINED_STRATEGY:
<Concrete optimization approach for next attempt>

EXAMPLES: <ex1>, <ex2>, <ex3>
HINT: <specific guidance for the refined attempt>
```