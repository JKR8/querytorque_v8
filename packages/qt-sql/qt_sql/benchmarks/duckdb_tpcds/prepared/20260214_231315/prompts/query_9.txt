## §I. ROLE

You are a senior query optimization architect. You analyze slow queries by reasoning about data flow: where rows enter the plan, how they multiply or reduce at each operator, and where the engine wastes work relative to the theoretical minimum.

Your diagnostic lens is six principles. Every slow query violates at least one:

1. **MINIMIZE ROWS TOUCHED** — Every row that doesn't contribute to output is waste.
2. **SMALLEST SET FIRST** — Most selective filter applied earliest. Selectivity compounds.
3. **DON'T REPEAT WORK** — Scan once, compute once, materialize once if needed by many.
4. **SETS OVER LOOPS** — Set operations parallelize. Row-by-row re-execution doesn't.
5. **ARM THE OPTIMIZER** — Restructure so it has full intelligence. Don't force plans.
6. **MINIMIZE DATA MOVEMENT** — Large intermediates built then mostly discarded are waste.

Your primary asset is a library of **gold examples** — proven before/after SQL rewrites with measured speedups gathered from hundreds of benchmark runs. Correctly matching a query to the right gold examples is the single highest-leverage step in this process. The gold example's before/after SQL is a structural template — you adapt the pattern to this query. The diagnosis tells you what's wrong; the examples show exactly how to fix it.

You analyze the query, determine the single best optimization strategy, and produce the optimized SQL directly.

## §II. THE CASE

### A. Original SQL: query_9 (duckdb)

```sql
select case when (select count(*) 
                  from store_sales 
                  where ss_quantity between 1 and 20) > 2972190
            then (select avg(ss_ext_sales_price) 
                  from store_sales 
                  where ss_quantity between 1 and 20) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 1 and 20) end bucket1 ,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 21 and 40) > 4505785
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 21 and 40) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 21 and 40) end bucket2,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 41 and 60) > 1575726
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 41 and 60)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 41 and 60) end bucket3,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 61 and 80) > 3188917
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 61 and 80)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 61 and 80) end bucket4,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 81 and 100) > 3525216
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 81 and 100)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 81 and 100) end bucket5
from reason
where r_reason_sk = 1
;
```

### B. Current Execution Plan (EXPLAIN ANALYZE)

```
Total execution time: 16385ms

CROSS_PRODUCT [1 rows]
  CROSS_PRODUCT [1 rows]
    CROSS_PRODUCT [1 rows]
      CROSS_PRODUCT [1 rows]
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 22.9ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 192.9ms, 1%]  Filters: ss_quantity>=41 AND ss_quantity<=60
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 19.1ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 174.3ms, 1%]  Filters: ss_quantity>=41 AND ss_quantity<=60
      CROSS_PRODUCT [1 rows]
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 2.5ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 110.7ms]  Filters: ss_quantity>=61 AND ss_quantity<=80
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 19.8ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 166.3ms, 1%]  Filters: ss_quantity>=61 AND ss_quantity<=80
    CROSS_PRODUCT [1 rows]
      CROSS_PRODUCT [1 rows]
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 20.5ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 150.7ms]  Filters: ss_quantity>=61 AND ss_quantity<=80
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 2.5ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 102.5ms]  Filters: ss_quantity>=81 AND ss_quantity<=100
      CROSS_PRODUCT [1 rows]
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 19.0ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 137.4ms]  Filters: ss_quantity>=81 AND ss_quantity<=100
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 19.2ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 146.7ms]  Filters: ss_quantity>=81 AND ss_quantity<=100
  CROSS_PRODUCT [1 rows]
    CROSS_PRODUCT [1 rows]
      CROSS_PRODUCT [1 rows]
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 2.5ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 119.6ms]  Filters: ss_quantity>=21 AND ss_quantity<=40
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 20.2ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 156.8ms]  Filters: ss_quantity>=21 AND ss_quantity<=40
      CROSS_PRODUCT [1 rows]
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 19.6ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 161.2ms]  Filters: ss_quantity>=21 AND ss_quantity<=40
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 1.5ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 73.1ms]  Filters: ss_quantity>=41 AND ss_quantity<=60
    CROSS_PRODUCT [1 rows]
      CROSS_PRODUCT [1 rows]
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 13.1ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 7614.3ms, 46%]  Filters: ss_quantity>=1 AND ss_quantity<=20
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 12.1ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 6793.7ms, 41%]  Filters: ss_quantity>=1 AND ss_quantity<=20
      CROSS_PRODUCT [1 rows]
        UNGROUPED_AGGREGATE [1 rows]
          UNGROUPED_AGGREGATE [1 rows, 0.7ms]
            SEQ_SCAN  store_sales [5.5M of 806.4M rows, 63.2ms]  Filters: ss_quantity>=1 AND ss_quantity<=20
        SEQ_SCAN  reason [1 of 45 rows, 1.6ms]  Filters: r_reason_sk=1
```

DuckDB times are operator-exclusive (children excluded). EXPLAIN is ground truth.

### C. Query Map

The semantic structure with filter ratios, join ratios, and join directions. Use this to deduce the optimal path.

```
QUERY: (single statement)
└── [MAIN] main_query  [=]  Cost: 99%  Processes: ~5.5M across subqueries  — For each quantity range (1-20, 21-40, 41-60, 61-80, 81-100), compute count and conditional average selection via CASE expressions, producing one output row with bucket1 through bucket5.
    ├── SCAN reason
    ├── FILTER (r_reason_sk = 1)
    ├── SUBQUERY (scalar aggregate) x3
    │   ├── SCAN store_sales
    │   └── FILTER ss_quantity BETWEEN 1 AND 20
    ├── SUBQUERY (scalar aggregate) x3
    │   ├── SCAN store_sales
    │   └── FILTER ss_quantity BETWEEN 21 AND 40
    ├── SUBQUERY (scalar aggregate) x3
    │   ├── SCAN store_sales
    │   └── FILTER ss_quantity BETWEEN 41 AND 60
    ├── SUBQUERY (scalar aggregate) x3
    │   ├── SCAN store_sales
    │   └── FILTER ss_quantity BETWEEN 61 AND 80
    ├── SUBQUERY (scalar aggregate) x3
    │   ├── SCAN store_sales
    │   └── FILTER ss_quantity BETWEEN 81 AND 100
    └── OUTPUT (bucket1, bucket2, bucket3, bucket4, bucket5)
```

**Intent:** Return five quantity-bucket metrics where each bucket chooses average extended sales price when bucket volume exceeds a threshold, otherwise average net profit, for store sales tied to reason key 1.

### D. Estimation Errors

### §2b-i. Cardinality Estimation Routing (Q-Error)

Structural signals:
  - EST_ONE_NONLEAF: planner guessing on non-leaf node → check P0 (predicate pushback), P1 (repeated scans). Only P2 (decorrelation) if nested loops + correlated subquery confirmed in EXPLAIN

IMPORTANT: Cross-check structural signals against the PRUNING GUIDE in §III. If the EXPLAIN shows no nested loops, skip P2. If each table appears once, skip P1. The pruning guide overrides routing suggestions.


### Node Details

### 1. main_query
**Role**: Root / Output (Definition Order: 0)
**Intent**: For each quantity range (1-20, 21-40, 41-60, 61-80, 81-100), compute count and conditional average selection via CASE expressions, producing one output row with bucket1 through bucket5.
**Stats**: 99% Cost | ~5.5M rows processed across subqueries | Output: from reason (after 1 filter)
**Outputs**: [bucket1, bucket2, bucket3, bucket4, bucket5]
**Dependencies**: reason
**Subqueries**: (scalar aggregate) x3: store_sales | FILTER: ss_quantity BETWEEN 1 AND 20; (scalar aggregate) x3: store_sales | FILTER: ss_quantity BETWEEN 21 AND 40; (scalar aggregate) x3: store_sales | FILTER: ss_quantity BETWEEN 41 AND 60; (scalar aggregate) x3: store_sales | FILTER: ss_quantity BETWEEN 61 AND 80; (scalar aggregate) x3: store_sales | FILTER: ss_quantity BETWEEN 81 AND 100
**Filters**: r_reason_sk = 1
**Operators**: SEQ_SCAN[store_sales], SEQ_SCAN[store_sales], SEQ_SCAN[store_sales], SEQ_SCAN[store_sales], SEQ_SCAN[store_sales]
**Key Logic (SQL)**:
```sql
SELECT
  CASE
    WHEN (
      SELECT
        COUNT(*)
      FROM store_sales
      WHERE
        ss_quantity BETWEEN 1 AND 20
    ) > 2972190
    THEN (
      SELECT
        AVG(ss_ext_sales_price)
      FROM store_sales
      WHERE
        ss_quantity BETWEEN 1 AND 20
    )
    ELSE (
      SELECT
        AVG(ss_net_profit)
      FROM store_sales
...
```



## §III. THIS ENGINE

### DuckDB

Evidence-based exploit algorithm. Use Detect rules to match structural features, then apply the Treatments for matching cases.

# DuckDB Rewrite Playbook
# TPC-DS SF1–SF10 field intelligence

## ENGINE STRENGTHS — do NOT rewrite

1. **Predicate pushdown**: filter inside scan node → leave it.
2. **Same-column OR**: handled natively in one scan. Splitting = lethal (0.23x observed).
3. **Hash join selection**: sound for 2–4 tables. Reduce inputs, not order.
4. **CTE inlining**: single-ref CTEs inlined automatically (zero overhead).
5. **Columnar projection**: only referenced columns read.
6. **Parallel aggregation**: scans and aggregations parallelized across threads.
7. **EXISTS semi-join**: early termination. **Never materialize** (0.14x observed).

## GLOBAL GUARDS

1. EXISTS/NOT EXISTS → never materialize (0.14x, 0.54x — semi-join destroyed)
2. Same-column OR → never split to UNION (0.23x, 0.59x — native OR handling)
3. Baseline < 100ms → skip CTE-based rewrites (overhead exceeds savings)
4. 3+ fact table joins → do not pre-materialize facts (locks join order)
5. Every CTE MUST have a WHERE clause (0.85x observed)
6. No orphaned CTEs — remove original after splitting (0.49x, 0.68x — double materialization)
7. No cross-joining 3+ dimension CTEs (0.0076x — Cartesian product)
8. Max 2 cascading fact-table CTE chains (0.78x observed)
9. Convert comma joins to explicit JOIN...ON
10. NOT EXISTS → NOT IN breaks with NULLs — preserve EXISTS form

---

## DOCUMENTED CASES

Cases ordered by safety (zero-regression cases first, then by decreasing risk).

**P0: Predicate Chain Pushback** (SMALLEST SET FIRST) — ~35% of wins

| Aspect | Detail |
|---|---|
| Detect | Row counts flat through CTE chain, sharp drop at late filter. 2+ stage CTE chain + late predicate with columns available earlier. |
| Gates | Filter ratio >5:1 strong, 2:1–5:1 moderate if baseline >200ms, <2:1 skip. 1 fact = safe, 2 = careful, 3+ = STOP (0.50x). ROLLUP/WINDOW downstream: CAUTION (0.85x). CTE already filtered on this predicate: skip (0.71x). |
| Treatments | date_cte_isolate (12 wins, 1.34x avg), prefetch_fact_join (4 wins, 1.89x avg), multi_dimension_prefetch (3 wins, 1.55x avg), multi_date_range_cte (3 wins, 1.42x avg), shared_dimension_multi_channel (1 win, 1.40x), self_join_decomposition (1 win, 4.76x) |
| Failures | 0.0076x (3 dim CTE cross-join → Cartesian), 0.50x (3-fact join lock), 0.85x (ROLLUP blocked), 0.71x (over-decomposed) |

**P1: Repeated Scans of Same Table** (DON'T REPEAT WORK) — ZERO REGRESSIONS

| Aspect | Detail |
|---|---|
| Detect | N separate SEQ_SCAN nodes on same table, identical joins, different bucket filters. |
| Gates | Identical join structure across all subqueries, max 8 branches, COUNT/SUM/AVG/MIN/MAX only (not STDDEV/VARIANCE/PERCENTILE). |
| Treatments | single_pass_aggregation (8 wins, 1.88x avg), channel_bitmap_aggregation (1 win, 6.24x) |
| Failures | None observed. |

**P3: Aggregation After Join** (MINIMIZE ROWS TOUCHED) — ZERO REGRESSIONS

| Aspect | Detail |
|---|---|
| Detect | GROUP BY input rows >> distinct keys, aggregate node sits after join. |
| Gates | GROUP BY keys ⊇ join keys (CORRECTNESS). Reconstruct AVG from SUM/COUNT when pre-aggregating for ROLLUP. |
| Treatments | aggregate_pushdown, star_join_prefetch. 3 wins (1.3x–42.9x, avg 15.3x). |
| Failures | None observed. |

**P5: LEFT JOIN + NULL-Eliminating WHERE** (ARM THE OPTIMIZER) — ZERO REGRESSIONS

| Aspect | Detail |
|---|---|
| Detect | LEFT JOIN + WHERE on right-table column (proves right non-null). |
| Gates | No CASE WHEN IS NULL / COALESCE on right-table column. |
| Treatments | inner_join_conversion. 2 wins (1.9x–3.4x, avg 2.7x). |
| Failures | None observed. |

**P6: INTERSECT Materializing Both Sides** (SETS OVER LOOPS) — ZERO REGRESSIONS

| Aspect | Detail |
|---|---|
| Detect | INTERSECT between 10K+ row result sets. |
| Gates | Both sides >1K rows. |
| Treatments | intersect_to_exists, multi_intersect_exists_cte. 1 win (2.7x). Related: semi_join_exists (1.67x). |
| Failures | None observed. |

**P8: Window Functions in CTEs Before Join** (MINIMIZE ROWS TOUCHED) — ZERO REGRESSIONS

| Aspect | Detail |
|---|---|
| Detect | N WINDOW nodes inside CTEs, same ORDER BY key, CTEs then joined. |
| Gates | Not LAG/LEAD (depends on pre-join row order), not ROWS BETWEEN with specific frame. SUM() OVER() naturally skips NULLs. |
| Treatments | deferred_window_aggregation. 1 win (1.4x). |
| Failures | None observed. |

**P7: Self-Joined CTE Materialized for All Values** (SMALLEST SET FIRST)

| Aspect | Detail |
|---|---|
| Detect | CTE joined to itself with different WHERE per arm (e.g., period=1 vs period=2). |
| Gates | 2–4 discriminator values, MUST remove original combined CTE after splitting. |
| Treatments | self_join_decomposition (1 win, 4.76x), union_cte_split (2 wins, 1.72x avg), rollup_to_union_windowing (1 win, 2.47x) |
| Failures | 0.49x (orphaned CTE → double materialization), 0.68x (orphaned variant) |

**P2: Correlated Subquery Nested Loop** (SETS OVER LOOPS)

| Aspect | Detail |
|---|---|
| Detect | Nested loop, inner re-executes aggregate per outer row. If EXPLAIN shows hash join on correlation key → already decorrelated → STOP. |
| Gates | NEVER decorrelate EXISTS (0.34x, 0.14x — semi-join destroyed). Preserve ALL WHERE filters. Check if Phase 1 reduced outer to <1000 rows (nested loop may be fast enough). |
| Treatments | decorrelate (3 wins, 2.45x avg), composite_decorrelate_union (1 win, 2.42x) |
| Failures | 0.34x (semi-join destroyed), 0.71x (already decorrelated) |

**P9: Shared Subexpression Executed Multiple Times** (DON'T REPEAT WORK)

| Aspect | Detail |
|---|---|
| Detect | Identical subtrees with identical costs scanning same tables. HARD STOP: EXISTS/NOT EXISTS → NEVER materialize (0.14x). |
| Gates | NOT EXISTS, subquery is expensive (joins/aggregates), CTE must have WHERE. |
| Treatments | materialize_cte. 1 win (1.4x). |
| Failures | 0.14x (EXISTS materialized → semi-join destroyed), 0.54x (correlated EXISTS pairs broken) |

**P4: Cross-Column OR Forcing Full Scan** (MINIMIZE ROWS TOUCHED) — HIGHEST VARIANCE

| Aspect | Detail |
|---|---|
| Detect | Single scan, OR across DIFFERENT columns, 70%+ rows discarded. CRITICAL: same column in all OR arms → STOP (engine handles natively). |
| Gates | Max 3 branches, cross-column only, no self-join, no nested OR (multiplicative expansion). |
| Treatments | or_to_union. 4 wins (1.4x–6.3x, avg 3.1x). |
| Failures | 0.23x (9 branches from nested OR), 0.41x (nested OR expansion), 0.59x (same-col split), 0.51x (self-join re-executed per branch) |

---

## PRUNING GUIDE

| Plan shows | Skip |
|---|---|
| No nested loops | P2 (decorrelation) |
| Each table appears once | P1 (repeated scans) |
| No LEFT JOIN | P5 (INNER conversion) |
| No OR predicates | P4 (OR decomposition) |
| No GROUP BY | P3 (aggregate pushdown) |
| No WINDOW/OVER | P8 (deferred window) |
| No INTERSECT/EXCEPT | P6 (set rewrite) |
| Baseline < 50ms | ALL CTE-based transforms |
| Row counts monotonically decreasing | P0 (predicate pushback) |

## REGRESSION REGISTRY

| Severity | Transform | Result | Root cause |
|----------|-----------|--------|------------|
| CATASTROPHIC | dimension_cte_isolate | 0.0076x | Cross-joined 3 dim CTEs: Cartesian product |
| CATASTROPHIC | materialize_cte | 0.14x | Materialized EXISTS → semi-join destroyed |
| SEVERE | or_to_union | 0.23x | 9 UNION branches from nested OR |
| SEVERE | decorrelate | 0.34x | LEFT JOIN was already semi-join |
| MAJOR | union_cte_split | 0.49x | Original CTE kept → double materialization |
| MAJOR | date_cte_isolate | 0.50x | 3-way fact join locked optimizer order |
| MAJOR | or_to_union | 0.51x | Self-join re-executed per branch |
| MAJOR | semantic_rewrite | 0.54x | Correlated EXISTS pairs broken |
| MODERATE | or_to_union | 0.59x | Split same-column OR |
| MODERATE | union_cte_split | 0.68x | Original CTE kept alongside split |
| MODERATE | decorrelate | 0.71x | Pre-aggregated ALL stores when only subset needed |
| MODERATE | prefetch_fact_join | 0.78x | 3rd cascading CTE chain |
| MINOR | multi_dimension_prefetch | 0.77x | Forced suboptimal join order |
| MINOR | date_cte_isolate | 0.85x | CTE blocked ROLLUP pushdown |



## §IV. CONSTRAINTS

- **COMPLETE_OUTPUT**: The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original.
- **CTE_COLUMN_COMPLETENESS**: CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.
- **LITERAL_PRESERVATION**: CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.
- **SEMANTIC_EQUIVALENCE**: The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set — even by one row, one column, or a different sort order — is WRONG and will be REJECTED.

**Aggregation:** This query uses COUNT (safe) and AVG (grouping-sensitive). Verify aggregation equivalence for any restructuring.

## §V. INVESTIGATE

Work in `<reasoning>`. Follow this investigation process:

**Step 1: Analyze the Current Plan.** Read the cost spine and EXPLAIN in §II.B. Identify the red flags: where is time going? What's the running rowcount at each stage? Where does it fail to decrease?

**Step 2: Read the Map.** Use the query map (§II.C) to understand the data shape. Identify the driving table, best entry point, filter ratios, join ratios, and join directions.

**Step 3: Deduce the Optimal Path.** From the map, work out the ideal join order:

- Start from the best entry point (most selective filter)
- Follow reducing joins first (downward/semi)
- Pick up filters early to shrink the running rowcount at every step
- Defer expanding joins and pure attribute lookups until last
- Compute the running rowcount at each step of your optimal path

**Step 4: Diagnose the Gap.** Compare your optimal path (Step 3) to the actual plan (Step 1). For each divergence:

- Name the violated goal (§I)
- Check if an engine blind spot from §III explains it. If yes, name it. If no, you've found a novel blind spot — describe the mechanism: what information is the optimizer missing or what structural pattern is it failing to optimize?
- Quantify: how many excess rows flow because of this divergence?

This diagnosis is complete and actionable on its own. Steps 1–4 give you everything you need to design an intervention, even for problems you've never seen before.

**Step 5: Match Gold Examples.** This is the highest-leverage step. For each blind spot and goal violation identified in Step 4, search the Example Catalog (§VII.B) for gold examples with matching query structure.

- **Match found**: Use the matching examples as structural templates. Adapt the gold example's before/after SQL pattern to this query — don't invent from scratch when a proven template exists.
- **No match**: Design the intervention from your diagnosis. You know the goal violation, the mechanism, and the excess rowcount — that's sufficient to reason about restructuring. Select the structurally closest examples as partial templates even if no exact match exists.

**Step 6: Select Examples.** For your strategy, select 1–3 examples from the catalog:

*Matching criteria* (in priority order):
1. **Structural similarity** — Does the example's original query have the same shape? (same join pattern, same subquery type, same fact/dim relationship). A multi-channel EXISTS query needs a multi-channel example, not a single-table aggregation example.
2. **Transform relevance** — Does the example demonstrate the specific restructuring this strategy needs? If the strategy is "build keysets per channel," pick examples that build keysets, not examples that push predicates.
3. **Hazard coverage** — Does the example show a pitfall this strategy could hit? An example that failed by materializing EXISTS is MORE valuable for a strategy that's tempted to do that than a safe example.

*Adaptation guidance* — For each assigned example, you MUST specify:
- **APPLY**: Which structural pattern from the example maps to this query (e.g., "the date_dim CTE pattern — isolate qualifying dates first, then join to fact")
- **IGNORE**: Which parts of the example don't apply and WHY (e.g., "ignore the ROLLUP handling — this query has no ROLLUP"). Without this, irrelevant complexity gets copied into the rewrite.
- **ADAPT**: What's different between the example's query and this query that requires modification (e.g., "example has 2 channels, this query has 3 — extend the pattern but don't exceed 2 CTE chains")

*Anti-patterns*:
- Don't assign an example just because it matches the same blind spot if the query structure is fundamentally different
- Don't pad with 3 examples when 1 is a strong match — irrelevant examples dilute attention
- Don't assign examples that demonstrate transforms the strategy ISN'T using

**Step 7: Implement.** Design and implement the single best strategy as working SQL.

Selection rules:
- If the EXPLAIN shows the optimizer already handles something, don't re-do it
- Verify structural prerequisites before assigning transforms

## §VI. OUTPUT FORMAT

```
=== SHARED BRIEFING ===

SEMANTIC_CONTRACT: (80-150 tokens)
(a) Business intent.
(b) JOIN semantics.
(c) Aggregation traps.
(d) Filter dependencies.

OPTIMAL_PATH:
[Your deduced ideal join order from Step 3, with running rowcount at each step.
This is the destination — what every worker is trying to get the optimizer to execute.]

CURRENT_PLAN_GAP:
[Where the actual plan diverges from optimal. Per divergence: which goal violated,
which blind spot causes it, how many excess rows result.]

ACTIVE_CONSTRAINTS:
- [ID]: [1-line relevance]

REGRESSION_WARNINGS:
- [Pattern] ([result]):
  CAUSE: [...]
  RULE: [...]


=== OPTIMIZED SQL ===

STRATEGY: strategy_name
TRANSFORM: transform_names

```sql
SELECT ...
```

```

## §VII. REFERENCE APPENDIX (DuckDB)

Case files and gold examples from past investigations, organized by engine blind spot (matching §III). Consult during Step 5 when your diagnosis identifies a matching blind spot.

### B. Gold Example Catalog (DuckDB)

Each example is a proven before/after SQL pair with measured speedups. Workers receive the full SQL for assigned examples. You select based on structural similarity to this query.

| Example ID | Family | Match | Query Shape | Result | Key Feature |
|---|---|---|---|---|---|
| aggregate_pushdown | C | 100% | Pre-aggregate fact table by join key before dimension joi... | 42.90x | Principle: Aggregate Pushdown — pre-aggregate the fact table (inventory) by t... |
| single_pass_aggregation | C | 100% | Consolidate multiple subqueries scanning the same table i... | 4.47x | Principle: Single-Pass Aggregation — consolidate multiple scalar subqueries o... |
| shared_dimension_multi_channel | A | 73% | Extract shared dimension filters (date, item, promotion) ... | 1.30x | Principle: Shared Dimension Extraction — when multiple channel CTEs (store/ca... |
| channel_bitmap_aggregation | C | 64% | Consolidate repeated scans of the same fact table (one pe... | 6.24x | The original query scans store_sales 8 times (once per time bucket), each wit... |
| materialize_cte | E | 64% | Extract repeated subquery patterns into a CTE to avoid re... | 1.37x | Principle: Shared Materialization — extract repeated subquery patterns into C... |
| early_filter | A | 64% | Filter dimension tables FIRST, then join to fact tables t... | 4.00x | Principle: Early Selection — filter small dimension tables first, then join t... |
| inner_join_conversion | F | 64% | Convert LEFT JOIN + right-table WHERE filter to INNER JOI... | 3.44x | Principle: Inner Join Conversion — when a LEFT JOIN is followed by a WHERE fi... |
| intersect_to_exists | D | 64% | Convert INTERSECT subquery pattern to multiple EXISTS cla... | 1.83x | Principle: Semi-Join Short-Circuit — replace INTERSECT with EXISTS to avoid f... |
| multi_intersect_exists_cte | D | 64% | Convert cascading INTERSECT operations into correlated EX... | 2.39x | INTERSECT materializes full intermediate result sets (brand_id, class_id, cat... |
| self_join_decomposition | F | 55% | Split self-joined CTE with different filter values into s... | 4.76x | Principle: Self-Join Decomposition — when a CTE is self-joined with different... |
| date_cte_isolate | A | 55% | Extract date filtering into a separate CTE to enable pred... | 4.00x | Principle: Dimension Isolation — extract small dimension lookups into CTEs so... |
| deferred_window_aggregation | C | 55% | When multiple CTEs each perform GROUP BY + WINDOW (cumula... | 1.36x | Principle: Deferred Aggregation — delay expensive operations (window function... |
| multi_date_range_cte | A | 46% | When query uses multiple date_dim aliases with different ... | 2.35x | Principle: Early Selection per Alias — when a query joins the same dimension ... |
| union_cte_split | D | 46% | Split a generic UNION ALL CTE into specialized CTEs when ... | 1.36x | Principle: CTE Specialization — when a generic CTE is scanned multiple times ... |
| SELF_JOIN_TO_WINDOW | ? | 46% | Replace self-joins used to access group-level values with... | unknown | Self-join retrieves aggregate values or rankings within a group. |
| composite_decorrelate_union | B | 36% | Decorrelate multiple correlated EXISTS subqueries into pr... | 2.42x | Principle: Composite Decorrelation — when multiple correlated EXISTS share co... |
| decorrelate | B | 36% | Convert correlated subquery to separate CTE with GROUP BY... | 2.92x | Principle: Decorrelation — convert correlated subqueries to standalone CTEs w... |
| CORRELATED_SUBQUERY_TO_WINDOW | ? | 36% | Rewrite scalar subqueries computing group aggregates to w... | High - single scan vs N scans | Correlated subquery calculates aggregate for current row's group
      withou... |
| CORRELATED_WHERE_TO_DERIVED_TABLE | ? | 36% | Convert correlated subqueries in WHERE clause to derived ... | unknown | Queries comparing row values against group aggregates. Common pattern
      f... |
| TOP_N_PER_GROUP_ROW_NUMBER | ? | 36% | Use ROW_NUMBER() window function instead of correlated su... | unknown | Retrieving multiple rows per group based on ranking. |

### D. Structural Matches for This Query

Transforms ranked by structural feature overlap with this query. The gap tag shows the example's target blind spot — verify it applies to THIS query's EXPLAIN before using.

- **pushdown** (100%) [targets: CROSS_CTE_PREDICATE_BLINDNESS] — AGG_AVG, AGG_COUNT, BETWEEN, CASE_EXPR, SCALAR_SUB_5+, TABLE_REPEAT_8+
- **single_pass_aggregation** (100%) [targets: REDUNDANT_SCAN_ELIMINATION] — AGG_AVG, AGG_COUNT, SCALAR_SUB_2+, TABLE_REPEAT_3+
- **channel_bitmap_aggregation** (100%) [targets: REDUNDANT_SCAN_ELIMINATION] — AGG_COUNT, SCALAR_SUB_5+, TABLE_REPEAT_8+
- **multi_date_range_cte** (50%) [targets: CROSS_CTE_PREDICATE_BLINDNESS] — AGG_AVG, BETWEEN, TABLE_REPEAT_3+
- **date_cte_isolate** (43%) [targets: CROSS_CTE_PREDICATE_BLINDNESS] — AGG_AVG, AGG_COUNT, SCALAR_SUB_2+
  ⚠ Skip if baseline <100ms — CTE overhead exceeds filter savings
  ⚠ CTE may prevent optimizer from pushing ROLLUP/window down through join tree

### E. What Doesn't Apply

No LEFT JOINs, No INTERSECT, No WINDOW/OVER, No CTE chain in original, No OR predicates, No GROUP BY, No nested loops in EXPLAIN, No correlated subqueries.

**Skip**: P5 (INNER conversion), P6 (set rewrite), P8 (deferred window), P4 (OR decomposition), P3 (aggregate pushdown), P2 (decorrelation).
