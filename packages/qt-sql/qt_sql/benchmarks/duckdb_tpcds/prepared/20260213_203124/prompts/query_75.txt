## §1. ROLE & MISSION

You are a senior query optimization architect. Your job is to deeply analyze a SQL query and produce a structured briefing for 4 specialist workers who will each write a different optimized version.

You are the ONLY call that sees all the data: EXPLAIN plans, logical-tree costs, full constraint list, global knowledge, and the complete example catalog. The workers will only see what YOU put in their briefings. Your output quality directly determines their success.

## §2a. Original Query: query_75 (duckdb)

```sql
 1 | WITH all_sales AS (
 2 |  SELECT d_year
 3 |        ,i_brand_id
 4 |        ,i_class_id
 5 |        ,i_category_id
 6 |        ,i_manufact_id
 7 |        ,SUM(sales_cnt) AS sales_cnt
 8 |        ,SUM(sales_amt) AS sales_amt
 9 |  FROM (SELECT d_year
10 |              ,i_brand_id
11 |              ,i_class_id
12 |              ,i_category_id
13 |              ,i_manufact_id
14 |              ,cs_quantity - COALESCE(cr_return_quantity,0) AS sales_cnt
15 |              ,cs_ext_sales_price - COALESCE(cr_return_amount,0.0) AS sales_amt
16 |        FROM catalog_sales JOIN item ON i_item_sk=cs_item_sk
17 |                           JOIN date_dim ON d_date_sk=cs_sold_date_sk
18 |                           LEFT JOIN catalog_returns ON (cs_order_number=cr_order_number 
19 |                                                     AND cs_item_sk=cr_item_sk)
20 |        WHERE i_category='Home'
21 |        UNION
22 |        SELECT d_year
23 |              ,i_brand_id
24 |              ,i_class_id
25 |              ,i_category_id
26 |              ,i_manufact_id
27 |              ,ss_quantity - COALESCE(sr_return_quantity,0) AS sales_cnt
28 |              ,ss_ext_sales_price - COALESCE(sr_return_amt,0.0) AS sales_amt
29 |        FROM store_sales JOIN item ON i_item_sk=ss_item_sk
30 |                         JOIN date_dim ON d_date_sk=ss_sold_date_sk
31 |                         LEFT JOIN store_returns ON (ss_ticket_number=sr_ticket_number 
32 |                                                 AND ss_item_sk=sr_item_sk)
33 |        WHERE i_category='Home'
34 |        UNION
35 |        SELECT d_year
36 |              ,i_brand_id
37 |              ,i_class_id
38 |              ,i_category_id
39 |              ,i_manufact_id
40 |              ,ws_quantity - COALESCE(wr_return_quantity,0) AS sales_cnt
41 |              ,ws_ext_sales_price - COALESCE(wr_return_amt,0.0) AS sales_amt
42 |        FROM web_sales JOIN item ON i_item_sk=ws_item_sk
43 |                       JOIN date_dim ON d_date_sk=ws_sold_date_sk
44 |                       LEFT JOIN web_returns ON (ws_order_number=wr_order_number 
45 |                                             AND ws_item_sk=wr_item_sk)
46 |        WHERE i_category='Home') sales_detail
47 |  GROUP BY d_year, i_brand_id, i_class_id, i_category_id, i_manufact_id)
48 |  select prev_yr.d_year AS prev_year
49 |                           ,curr_yr.d_year AS year
50 |                           ,curr_yr.i_brand_id
51 |                           ,curr_yr.i_class_id
52 |                           ,curr_yr.i_category_id
53 |                           ,curr_yr.i_manufact_id
54 |                           ,prev_yr.sales_cnt AS prev_yr_cnt
55 |                           ,curr_yr.sales_cnt AS curr_yr_cnt
56 |                           ,curr_yr.sales_cnt-prev_yr.sales_cnt AS sales_cnt_diff
57 |                           ,curr_yr.sales_amt-prev_yr.sales_amt AS sales_amt_diff
58 |  FROM all_sales curr_yr, all_sales prev_yr
59 |  WHERE curr_yr.i_brand_id=prev_yr.i_brand_id
60 |    AND curr_yr.i_class_id=prev_yr.i_class_id
61 |    AND curr_yr.i_category_id=prev_yr.i_category_id
62 |    AND curr_yr.i_manufact_id=prev_yr.i_manufact_id
63 |    AND curr_yr.d_year=1999
64 |    AND prev_yr.d_year=1999-1
65 |    AND CAST(curr_yr.sales_cnt AS DECIMAL(17,2))/CAST(prev_yr.sales_cnt AS DECIMAL(17,2))<0.9
66 |  ORDER BY sales_cnt_diff,sales_amt_diff
67 |  LIMIT 100;
```

## §2b. EXPLAIN ANALYZE Plan

```
Total execution time: 21822ms

CTE [0 rows, 0.2ms]
  HASH_GROUP_BY [9,818 rows, 83.7ms]
    Aggregates: sum(#5), sum(#6)
    HASH_GROUP_BY [1.9M rows, 342.0ms, 2%]
      UNION [0 rows]
        HASH_GROUP_BY [1.6M rows, 320.5ms, 1%]
          UNION [0 rows]
            HASH_JOIN RIGHT on cr_order_number = cs_order_number, cr_item_sk = cs_item_sk [563K rows, 76.7ms]
              SEQ_SCAN  catalog_returns [573K of 17.3M rows, 43.8ms]
              HASH_JOIN INNER on cs_sold_date_sk = d_date_sk [563K rows, 5.7ms]
                HASH_JOIN INNER on cs_item_sk = i_item_sk [563K rows, 15.1ms]
                  SEQ_SCAN  catalog_sales [5.7M of 403.2M rows, 2604.5ms, 12%]
                  SEQ_SCAN  item [10K of 102K rows, 6.6ms]  Filters: i_category='Home'
                FILTER [730 rows, 0.1ms]
                  Expression: ((d_date_sk BETWEEN 2450815 AND 2452653) AND ((d_year = 1999) OR (d_year = 1998)))
                  SEQ_SCAN  date_dim [73K rows, 1.4ms]  Filters: optional: d_year=1999 OR d_year=1998
            HASH_JOIN RIGHT on sr_ticket_number = ss_ticket_number, sr_item_sk = ss_item_sk [1.1M rows, 336.1ms, 2%]
              SEQ_SCAN  store_returns [2.9M of 69.1M rows, 824.9ms, 4%]
              HASH_JOIN INNER on ss_sold_date_sk = d_date_sk [1.1M rows, 25.4ms]
                HASH_JOIN INNER on ss_item_sk = i_item_sk [1.1M rows, 57.8ms]
                  SEQ_SCAN  store_sales [10.9M of 806.4M rows, 12579.3ms, 58%]
                  SEQ_SCAN  item [10K of 102K rows, 6.6ms]  Filters: i_category='Home'
                FILTER [729 rows, 0.1ms]
                  Expression: ((d_date_sk BETWEEN 2450816 AND 2452642) AND ((d_year = 1999) OR (d_year = 1998)))
                  SEQ_SCAN  date_dim [73K rows, 1.5ms]  Filters: optional: d_year=1999 OR d_year=1998
        HASH_JOIN RIGHT on wr_order_number = ws_order_number, wr_item_sk = ws_item_sk [282K rows, 79.2ms]
          SEQ_SCAN  web_returns [719K of 4.3M rows, 117.6ms]
          HASH_JOIN INNER on ws_sold_date_sk = d_date_sk [282K rows, 9.8ms]
            HASH_JOIN INNER on ws_item_sk = i_item_sk [282K rows, 22.2ms]
              SEQ_SCAN  web_sales [2.9M of 201.5M rows, 4226.2ms, 19%]
              SEQ_SCAN  item [10K of 102K rows, 6.6ms]  Filters: i_category='Home'
            FILTER [729 rows, 0.1ms]
              Expression: ((d_date_sk BETWEEN 2450816 AND 2452642) AND ((d_year = 1999) OR (d_year = 1998)))
              SEQ_SCAN  date_dim [73K rows, 1.5ms]  Filters: optional: d_year=1999 OR d_year=1998
  TOP_N [100 rows, 0.2ms]
    Top: 100
    Order By: (curr_yr.sales_cnt - prev_yr.sales_cnt) ASC, (curr_yr.sales_amt - prev_yr.sales_amt) ASC
    FILTER [877 rows, 0.7ms]
      Expression: ((CAST(CAST(sales_cnt AS DECIMAL(17,2)) AS DOUBLE) / CAST(CAST(sales_cnt AS DECIMAL(17,2)) AS DOU...
      HASH_JOIN INNER on i_brand_id = i_brand_id, i_class_id = i_class_id, i_categ... [4,895 rows, 1.1ms]
        FILTER [4,909 rows]
          Expression: (d_year = 1999)
          CTE_SCAN [9,818 rows]
        FILTER [4,909 rows]
          Expression: (d_year = 1998)
          CTE_SCAN [9,818 rows]
```

**NOTE:** EXPLAIN shows PHYSICAL execution — ground truth when it disagrees with the logical tree (optimizer may already split CTEs, push predicates, reorder joins).
DuckDB times are **operator-exclusive** (children excluded). Sum siblings for pipeline cost. Use EXPLAIN timings, not logical-tree %.

### §2b-i. Cardinality Estimation Routing (Q-Error)

Direction: OVER_EST (estimated >> actual — planner over-provisions, redundant work likely)
Locus: PROJECTION — worst mismatch at PROJECTION (est=3.1M, act=877)

Pathology routing: P7, P0, P4, P9, P5
(Locus+Direction routing is 85% accurate at predicting where the winning transform operates)

## §2c. Query Structure (Logic Tree)

```
QUERY: (single statement)
├── [CTE] all_sales  [=]  Cost: 97%  Rows: ~10.9M  — Build channel-neutral yearly sales count and sales amount metrics by brand/class/category/manufacturer using sales minus returns from catalog, store, and web.
│   ├── SCAN (web_sales, item, date_dim, web_returns, catalog_sales, catalog_returns, store_sales, store_returns)
│   ├── FILTER (i_category = 'Home')
│   ├── AGG (GROUP BY)
│   ├── UNION
│   └── OUTPUT (d_year, i_brand_id, i_class_id, i_category_id, i_manufact_id, sales_cnt, sales_amt)
└── [MAIN] main_query  [=]  Cost: 2%  Rows: ~9K  — Join 1999 metrics to 1998 metrics on product keys, compute year-over-year differences, filter to curr/prev sales_cnt ratio below 0.9, and order by declines.
    ├── SCAN (all_sales AS curr_yr (join), all_sales AS prev_yr (join))
    ├── JOIN (curr_yr.i_brand_id = prev_yr.i_brand_id)
    ├── JOIN (curr_yr.i_class_id = prev_yr.i_class_id)
    ├── JOIN (+2 more)
    ├── FILTER (curr_yr.d_year = 1999)
    ├── FILTER (prev_yr.d_year = 1999 - 1)
    ├── FILTER (+1 more)
    ├── AGG (GROUP BY)
    ├── SORT (sales_cnt_diff ASC, sales_amt_diff ASC)
    └── OUTPUT (prev_year, year, i_brand_id, i_class_id, i_category_id, i_manufact_id, prev_yr_cnt, curr_yr_cnt, ...)
```

### Node Details

### 1. all_sales
**Role**: CTE (Definition Order: 0)
**Intent**: Build channel-neutral yearly sales count and sales amount metrics by brand/class/category/manufacturer using sales minus returns from catalog, store, and web.
**Stats**: 97% Cost | ~10.9M rows
**Flags**: GROUP_BY, UNION_ALL
**Outputs**: [d_year, i_brand_id, i_class_id, i_category_id, i_manufact_id, sales_cnt, sales_amt]
**Dependencies**: web_sales, item, date_dim, web_returns, catalog_sales, catalog_returns, store_sales, store_returns
**Filters**: i_category = 'Home'
**Operators**: SEQ_SCAN[catalog_returns], SEQ_SCAN[catalog_sales], SEQ_SCAN[item], SEQ_SCAN[date_dim], SEQ_SCAN[store_returns]
**Key Logic (SQL)**:
```sql
SELECT
  d_year,
  i_brand_id,
  i_class_id,
  i_category_id,
  i_manufact_id,
  SUM(sales_cnt) AS sales_cnt,
  SUM(sales_amt) AS sales_amt
FROM (
  SELECT
    d_year,
    i_brand_id,
    i_class_id,
    i_category_id,
    i_manufact_id,
    cs_quantity - COALESCE(cr_return_quantity, 0) AS sales_cnt,
    cs_ext_sales_price - COALESCE(cr_return_amount, 0.0) AS sales_amt
  FROM catalog_sales
  JOIN item
    ON i_item_sk = cs_item_sk
...
```

### 2. main_query
**Role**: Root / Output (Definition Order: 1)
**Intent**: Join 1999 metrics to 1998 metrics on product keys, compute year-over-year differences, filter to curr/prev sales_cnt ratio below 0.9, and order by declines.
**Stats**: 2% Cost | ~9k rows processed → 100 rows output
**Flags**: GROUP_BY, ORDER_BY, LIMIT(100)
**Outputs**: [prev_year, year, i_brand_id, i_class_id, i_category_id, i_manufact_id, prev_yr_cnt, curr_yr_cnt, sales_cnt_diff, sales_amt_diff] — ordered by sales_cnt_diff ASC, sales_amt_diff ASC
**Dependencies**: all_sales AS curr_yr (join), all_sales AS prev_yr (join)
**Joins**: curr_yr.i_brand_id = prev_yr.i_brand_id | curr_yr.i_class_id = prev_yr.i_class_id | curr_yr.i_category_id = prev_yr.i_category_id | curr_yr.i_manufact_id = prev_yr.i_manufact_id
**Filters**: curr_yr.d_year = 1999 | prev_yr.d_year = 1999 - 1 | CAST(curr_yr.sales_cnt AS DECIMAL(17, 2)) / CAST(prev_yr.sales_cnt AS DECIMAL(17, 2)) < 0.9
**Operators**: CTE_SCAN, CTE_SCAN, HASH_JOIN
**Key Logic (SQL)**:
```sql
SELECT
  prev_yr.d_year AS prev_year,
  curr_yr.d_year AS year,
  curr_yr.i_brand_id,
  curr_yr.i_class_id,
  curr_yr.i_category_id,
  curr_yr.i_manufact_id,
  prev_yr.sales_cnt AS prev_yr_cnt,
  curr_yr.sales_cnt AS curr_yr_cnt,
  curr_yr.sales_cnt - prev_yr.sales_cnt AS sales_cnt_diff,
  curr_yr.sales_amt - prev_yr.sales_amt AS sales_amt_diff
FROM all_sales AS curr_yr, all_sales AS prev_yr
WHERE
  curr_yr.i_brand_id = prev_yr.i_brand_id
  AND curr_yr.i_class_id = prev_yr.i_class_id
  AND curr_yr.i_category_id = prev_yr.i_category_id
  AND curr_yr.i_manufact_id = prev_yr.i_manufact_id
  AND curr_yr.d_year = 1999
  AND prev_yr.d_year = 1999 - 1
  AND CAST(curr_yr.sales_cnt AS DECIMAL(17, 2)) / CAST(prev_yr.sales_cnt AS DECIMAL(17, 2)) < 0.9
...
```

### Edges
- all_sales → main_query
- all_sales → main_query


## §2d. Pre-Computed Semantic Intent

**Query intent:** Compare 1999 versus 1998 net unit and sales amount performance for Home-category brand/class/manufacturer combinations across all channels after subtracting returns, and keep combinations with at least 10% unit decline.

START from this pre-computed intent. In your SEMANTIC_CONTRACT output, ENRICH it with: intersection/union semantics from JOIN types, aggregation function traps, NULL propagation paths, and filter dependencies. Do NOT re-derive what is already stated above.

## §3a. Correctness Constraints (4 — NEVER violate)

**[CRITICAL] COMPLETE_OUTPUT**: The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original.

**[CRITICAL] CTE_COLUMN_COMPLETENESS**: CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.
  - Failure: prefetched_inventory CTE omits i_item_id but main query references it in SELECT and GROUP BY
  - Failure: filtered_store_dates CTE omits d_year and d_qoy but aggregation CTE uses them in GROUP BY

**[CRITICAL] LITERAL_PRESERVATION**: CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

**[CRITICAL] SEMANTIC_EQUIVALENCE**: The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set — even by one row, one column, or a different sort order — is WRONG and will be REJECTED.

## §3b. Aggregation Equivalence Rules

You MUST verify aggregation equivalence for any proposed restructuring:

- **STDDEV_SAMP(x)** requires >=2 non-NULL values per group. Returns NULL for 0-1 values. Changing group membership changes the result.
- `STDDEV_SAMP(x) FILTER (WHERE year=1999)` over a combined (1999,2000) group is NOT equivalent to `STDDEV_SAMP(x)` over only 1999 rows — FILTER still uses the combined group's membership for the stddev denominator.
- **AVG and STDDEV are NOT duplicate-safe**: if a join introduces row duplication, the aggregate result changes.
- When splitting a UNION ALL CTE with GROUP BY + aggregate, each split branch must preserve the exact GROUP BY columns and filter to the exact same row set as the original.
- **SAFE ALTERNATIVE**: If GROUP BY includes the discriminator column (e.g., d_year), each group is already partitioned. STDDEV_SAMP computed per-group is correct. You can then pivot using `MAX(CASE WHEN year = 1999 THEN year_total END) AS year_total_1999` because the GROUP BY guarantees exactly one row per (customer, year) — the MAX is just a row selector, not a real aggregation.

## §4. Exploit Algorithm: Evidence-Based Gap Intelligence

The following describes known optimizer gaps with detection rules, procedural exploit steps, and evidence. Use DETECT rules to match structural features of the query, then follow EXPLOIT_STEPS.

# DuckDB Rewrite Playbook
# TPC-DS SF1–SF10 field intelligence

## HOW TO USE THIS DOCUMENT

Work in phase order. Each phase changes the plan shape — re-evaluate later phases after each.

  Phase 1: Reduce scan volume (P0) — always first. Every other optimization benefits from smaller input.
  Phase 2: Eliminate redundant work (P1, P3)
  Phase 3: Fix structural inefficiencies (P2, P4–P9)

## EXPLAIN ANALYSIS PROCEDURE

Before choosing any strategy, execute this procedure on the EXPLAIN plan:

1. IDENTIFY THE COST SPINE — which sequence of nodes accounts for >70% of total cost?
   The spine is your optimization target. Everything else is noise.
2. CLASSIFY EACH SPINE NODE:
   - SEQ_SCAN: how many rows? Is there a filter? Is the filter selective (>5:1)?
   - HASH_JOIN: what's the build side cardinality? Is it the smaller table?
   - AGGREGATE: input rows vs output rows ratio? >10:1 = pushdown candidate.
   - NESTED_LOOP: ALWAYS suspicious — check if decorrelation is possible.
   - WINDOW: is it computed before or after a join? Could it be deferred?
3. TRACE DATA FLOW: row counts should decrease monotonically through the plan.
   Where do they stay flat or increase? That transition point is the bottleneck.
4. CHECK THE SYMPTOM ROUTING TABLE: match your observations to primary hypotheses.
5. FORM BOTTLENECK HYPOTHESIS: "The optimizer is doing X, but Y would be better
   because Z." This hypothesis drives both pathology matching AND novel reasoning.

## SYMPTOM ROUTING — from EXPLAIN to hypothesis

Two routing paths exist and should agree. If they disagree, trust Q-Error (quantitative).

### Path A: Q-Error routing (quantitative — from §2b-i when available)

Q-Error = max(estimated/actual, actual/estimated) per operator.
The operator with the highest Q-Error is where the planner's worst decision lives.

| Q-Error Locus | Direction  | Primary hypothesis     | Why                                      |
|---------------|------------|------------------------|------------------------------------------|
| JOIN          | UNDER_EST  | P2 (decorrelate)       | Planner thinks join is cheap, it's not    |
| JOIN          | ZERO_EST   | P0, P2                 | Planner has no join estimate at all       |
| JOIN          | OVER_EST   | P5 (LEFT→INNER)        | Planner over-provisions for NULLs         |
| SCAN          | OVER_EST   | P1, P4                 | Redundant scans or missed pruning         |
| SCAN          | ZERO_EST   | P2                     | DELIM_SCAN = correlated subquery          |
| AGGREGATE     | OVER_EST   | P3 (agg below join)    | Fan-out before GROUP BY                   |
| CTE           | ZERO_EST   | P0, P7                 | Planner blind to CTE statistics           |
| CTE           | UNDER_EST  | P2, P0                 | CTE output larger than expected           |
| PROJECTION    | OVER_EST   | P7, P0, P4             | Redundant computation                     |
| PROJECTION    | UNDER_EST  | P6, P5, P0             | Set operation or join underestimate       |
| FILTER        | OVER_EST   | P9, P0                 | Shared expression or missed pushdown      |

Structural flags (free, no execution needed):
- DELIM_SCAN → P2 (correlated subquery the optimizer couldn't decorrelate)
- EST_ZERO → P0/P7 (planner gave up — CTE boundary blocks stats)
- EST_ONE_NONLEAF → P2/P0 (planner guessing on non-leaf node)
- REPEATED_TABLE → P1 (single-pass consolidation opportunity)

### Path B: Structural routing (qualitative — from EXPLAIN tree inspection)

| EXPLAIN symptom                          | Primary hypothesis   | Verify           |
|------------------------------------------|---------------------|------------------|
| Row counts flat through CTEs, late drop  | P0 (predicate push) | Filter ratio, chain depth |
| Same table scanned N times               | P1 (repeated scans) | Join structure identical? |
| Nested loop with inner aggregate         | P2 (correlated sub)  | Already hash join? |
| Aggregate input >> output after join     | P3 (agg below join)  | Key alignment    |
| Full scan, OR across DIFFERENT columns   | P4 (cross-col OR)    | Same column? → STOP |
| LEFT JOIN + WHERE on right column        | P5 (LEFT→INNER)      | COALESCE check   |
| INTERSECT node, large inputs             | P6 (INTERSECT)       | Row count >1K?   |
| CTE self-joined with discriminators      | P7 (self-join CTE)   | 2-4 values?      |
| Window in CTE before join                | P8 (deferred window) | LAG/LEAD check   |
| Identical subtrees in different branches | P9 (shared expr)     | EXISTS check     |
| None of the above                        | FIRST-PRINCIPLES     | See NO MATCH     |

## ENGINE STRENGTHS — do NOT rewrite

1. **Predicate pushdown**: filter inside scan node → leave it.
2. **Same-column OR**: handled natively in one scan. Splitting = lethal (0.23x observed).
3. **Hash join selection**: sound for 2–4 tables. Reduce inputs, not order.
4. **CTE inlining**: single-ref CTEs inlined automatically (zero overhead).
5. **Columnar projection**: only referenced columns read.
6. **Parallel aggregation**: scans and aggregations parallelized across threads.
7. **EXISTS semi-join**: early termination. **Never materialize** (0.14x observed).

## CORRECTNESS RULES

- Identical rows, columns, ordering as original.
- Copy ALL literals exactly (strings, numbers, dates).
- Every CTE must SELECT all columns referenced downstream.
- Never drop, rename, or reorder output columns.

## GLOBAL GUARDS

1. EXISTS/NOT EXISTS → never materialize (0.14x, 0.54x — semi-join destroyed)
2. Same-column OR → never split to UNION (0.23x, 0.59x — native OR handling)
3. Baseline < 100ms → skip CTE-based rewrites (overhead exceeds savings)
4. 3+ fact table joins → do not pre-materialize facts (locks join order)
5. Every CTE MUST have a WHERE clause (0.85x observed)
6. No orphaned CTEs — remove original after splitting (0.49x, 0.68x — double materialization)
7. No cross-joining 3+ dimension CTEs (0.0076x — Cartesian product)
8. Max 2 cascading fact-table CTE chains (0.78x observed)
9. Convert comma joins to explicit JOIN...ON
10. NOT EXISTS → NOT IN breaks with NULLs — preserve EXISTS form

---

## PATHOLOGIES

### P0: Predicate chain pushback [Phase 1 — always first, ~35% of wins]

  Gap: CROSS_CTE_PREDICATE_BLINDNESS — DuckDB plans each CTE independently.
  Predicates in the outer query or later CTEs cannot propagate backward into
  earlier CTE definitions. The CTE materializes blind to how its output will
  be consumed.

  This is the general case. date_cte_isolate, early_filter, prefetch_fact_join,
  multi_dimension_prefetch are all specific instances where the pushed predicate
  is a dimension filter. The principle applies to ANY selective predicate:
  dimension filters, HAVING thresholds, JOIN conditions, subquery results.
  The rule: find the most selective predicate, find the earliest CTE where it
  CAN apply, put it there.

  Signal: row counts stay flat through CTE chain stages then drop sharply at a
  late filter. Target state: monotonically decreasing rows through the chain.

  Decision gates:
  - Structural: 2+ stage CTE chain + late predicate with columns available earlier
  - Cardinality: filter ratio >5:1 strong, 2:1–5:1 moderate if baseline >200ms, <2:1 skip
  - Multi-fact: 1 fact = safe, 2 = careful, 3+ = STOP (0.50x on 3-fact query)
  - ROLLUP/WINDOW downstream: CAUTION (0.85x observed)
  - CTE already filtered on this predicate: skip (0.71x observed)

  Transform selection (lightest sufficient):
  - Single dim, ≤2 stages → date_cte_isolate (12 wins, 1.34x avg)
  - Single dim, ≥3 stages → prefetch_fact_join (4 wins, 1.89x avg)
  - Multiple dims → multi_dimension_prefetch (3 wins, 1.55x avg)
  - date_dim 3+ aliases → multi_date_range_cte (3 wins, 1.42x avg)
  - Multi-channel shared dims → shared_dimension_multi_channel (1 win, 1.40x)
  - CTE self-join with literal discriminators → self_join_decomposition (1 win, 4.76x)

  Ordering: push most selective predicate first. Selectivity compounds —
  once the first filter reduces 7M to 50K, everything downstream operates on 50K.
  Composition: often combines with aggregate_pushdown (P3) or decorrelation (P2).
  After applying: re-evaluate P1 (scans may now be small enough to skip),
  P2 (outer set may be small enough that nested loop is fine),
  P3 (pre-agg on smaller set may now be more valuable).

  Wins: 8 validated (1.9x–4.8x, avg 3.3x)
  Regressions: 0.0076x (dim cross-join), 0.50x (3-fact join lock), 0.85x (ROLLUP blocked), 0.71x (over-decomposed)

### P1: Repeated scans of same table [Phase 2 — ZERO REGRESSIONS]

  Gap: REDUNDANT_SCAN_ELIMINATION — the optimizer cannot detect that N subqueries
  all scan the same table with the same joins. Each subquery is an independent plan
  unit with no Common Subexpression Elimination across boundaries.

  Signal: N separate SEQ_SCAN nodes on same table, identical joins, different bucket filters.
  Decision: consolidate to single scan with CASE WHEN / FILTER (WHERE ...).
  Gates: identical join structure across all subqueries, max 8 branches,
  COUNT/SUM/AVG/MIN/MAX only (not STDDEV/VARIANCE/PERCENTILE).

  Transforms: single_pass_aggregation (8 wins, 1.88x avg), channel_bitmap_aggregation (1 win, 6.24x)
  Wins: 6 validated (1.5x–6.2x, avg 2.9x)

### P2: Correlated subquery nested loop [Phase 3]

  Gap: CORRELATED_SUBQUERY_PARALYSIS — the optimizer cannot decorrelate correlated
  aggregate subqueries into GROUP BY + hash join. It falls back to nested-loop
  re-execution instead of recognizing the equivalence.

  Signal: nested loop, inner re-executes aggregate per outer row.
  If EXPLAIN shows hash join on correlation key → already decorrelated → STOP.
  Decision: extract correlated aggregate into CTE with GROUP BY on correlation key, JOIN back.
  Gates: NEVER decorrelate EXISTS (0.34x, 0.14x — semi-join destroyed), preserve ALL WHERE filters,
  check if Phase 1 reduced outer to <1000 rows (nested loop may be fast enough).

  Transforms: decorrelate (3 wins, 2.45x avg), composite_decorrelate_union (1 win, 2.42x)
  Wins: 2 validated (2.4x–2.9x, avg 2.7x)
  Regressions: 0.34x (semi-join destroyed), 0.71x (already decorrelated)

### P3: Aggregation after join — fan-out before GROUP BY [Phase 2 — ZERO REGRESSIONS]

  Gap: AGGREGATE_BELOW_JOIN_BLINDNESS — the optimizer cannot push GROUP BY below
  joins even when aggregation keys align with join keys. It always joins first
  (producing M rows), then aggregates (reducing to K groups, K << M).

  Signal: GROUP BY input rows >> distinct keys, aggregate node sits after join.
  Decision: pre-aggregate fact by join key BEFORE dimension join.
  Gates: GROUP BY keys ⊇ join keys (CORRECTNESS — wrong results if violated),
  reconstruct AVG from SUM/COUNT when pre-aggregating for ROLLUP.

  Transforms: aggregate_pushdown, star_join_prefetch
  Wins: 3 validated (1.3x–42.9x, avg 15.3x)

### P4: Cross-column OR forcing full scan [Phase 3 — HIGHEST VARIANCE]

  Gap: CROSS_COLUMN_OR_DECOMPOSITION — the optimizer handles same-column OR
  efficiently (single scan range) but OR across different columns forces a full
  scan evaluating all conditions for every row.

  Signal: single scan, OR across DIFFERENT columns, 70%+ rows discarded.
  CRITICAL: same column in all OR arms → STOP (engine handles natively).
  Decision: split into UNION ALL branches + shared dim CTE.
  Gates: max 3 branches, cross-column only, no self-join, no nested OR (multiplicative expansion).

  Transforms: or_to_union
  Wins: 4 validated (1.4x–6.3x, avg 3.1x)
  Regressions: 0.23x (9 branches from nested OR), 0.41x (nested OR expansion), 0.59x (same-col split), 0.51x (self-join re-executed per branch)

### P5: LEFT JOIN + NULL-eliminating WHERE [Phase 3 — ZERO REGRESSIONS]

  Gap: LEFT_JOIN_FILTER_ORDER_RIGIDITY — the optimizer cannot infer that WHERE on
  a right-table column makes LEFT JOIN semantically equivalent to INNER. LEFT JOIN
  also blocks join reordering (not commutative).

  Signal: LEFT JOIN + WHERE on right-table column (proves right non-null).
  Decision: convert to INNER JOIN, optionally pre-filter right table into CTE.
  Gate: no CASE WHEN IS NULL / COALESCE on right-table column.

  Transforms: inner_join_conversion
  Wins: 2 validated (1.9x–3.4x, avg 2.7x)

### P6: INTERSECT materializing both sides [Phase 3 — ZERO REGRESSIONS]

  Gap: INTERSECT is implemented as set materialization + comparison. The optimizer
  doesn't recognize that EXISTS semi-join is algebraically equivalent and can
  short-circuit at first match per row.

  Signal: INTERSECT between 10K+ row result sets.
  Decision: replace with EXISTS semi-join.
  Gate: both sides >1K rows.
  Related: semi_join_exists — replace full JOIN with EXISTS when joined columns not in output (1.67x).

  Transforms: intersect_to_exists, multi_intersect_exists_cte
  Wins: 1 validated (2.7x)

### P7: Self-joined CTE materialized for all values [Phase 3]

  Gap: UNION_CTE_SELF_JOIN_DECOMPOSITION + CROSS_CTE_PREDICATE_BLINDNESS — the
  optimizer materializes the CTE once for all values. Self-join discriminator
  filters cannot propagate backward into the CTE definition. Each arm post-filters
  the full materialized result instead of computing only its needed partition.

  Signal: CTE joined to itself with different WHERE per arm (e.g., period=1 vs period=2).
  Decision: split into per-partition CTEs, each embedding its discriminator.
  Gates: 2–4 discriminator values, MUST remove original combined CTE after splitting.

  Transforms: self_join_decomposition (1 win, 4.76x), union_cte_split (2 wins, 1.72x avg),
  rollup_to_union_windowing (1 win, 2.47x)
  Wins: 3 validated (1.6x–4.8x, avg 2.9x)
  Regressions: 0.49x (orphaned CTE — double materialization), 0.68x (orphaned variant)

### P8: Window functions in CTEs before join [Phase 3 — ZERO REGRESSIONS]

  Gap: the optimizer cannot defer window computation past a join when
  partition/ordering is preserved. It computes the window in the CTE because
  that's where the SQL places it.

  Signal: N WINDOW nodes inside CTEs, same ORDER BY key, CTEs then joined.
  Decision: remove windows from CTEs, compute once on joined result.
  Gates: not LAG/LEAD (depends on pre-join row order), not ROWS BETWEEN with specific frame.
  Note: SUM() OVER() naturally skips NULLs — handles FULL OUTER JOIN gaps.

  Transforms: deferred_window_aggregation
  Wins: 1 validated (1.4x)

### P9: Shared subexpression executed multiple times [Phase 3]

  Gap: the optimizer may not CSE identical subqueries across different query branches.
  When it doesn't, cost is N× what single execution would be.
  HARD STOP: EXISTS/NOT EXISTS → NEVER materialize (0.14x observed). Semi-join
  short-circuit is destroyed by CTE materialization.

  Signal: identical subtrees with identical costs scanning same tables.
  Decision: extract shared subexpression into CTE.
  Gates: NOT EXISTS, subquery is expensive (joins/aggregates), CTE must have WHERE.

  Transforms: materialize_cte
  Wins: 1 validated (1.4x)
  Regressions: 0.14x (EXISTS materialized — semi-join destroyed), 0.54x (correlated EXISTS pairs broken)

### NO MATCH — First-Principles Reasoning

If no pathology matches this query, do NOT stop.

1. **Check §2b-i Q-Error routing first.** Even when no pathology gate passes,
   the Q-Error direction+locus still points to where the planner is wrong.
   Use it as a starting hypothesis for novel intervention design.
2. Identify the single largest cost node. What operation dominates? Can it be restructured?
3. Count scans per base table. Repeated scans are always a consolidation opportunity.
4. Trace row counts through the plan. Where do they stay flat or increase?
5. Look for operations the optimizer DIDN'T optimize that it could have:
   - Subqueries not flattened
   - Predicates not pushed through CTE boundaries
   - CTEs re-executed instead of materialized
6. Use the transform catalog (§5a) as a menu. For each transform, check: does the
   EXPLAIN show the optimizer already handles this? If not → candidate.

Record: which pathologies checked, which gates failed, nearest miss, structural
features present. This data seeds pathology discovery for future updates.

---

## SAFETY RANKING

| Rank | Pathology | Regr. | Worst | Action |
|------|-----------|-------|-------|--------|
| 1 | P1: Repeated scans | 0 | — | Always fix |
| 2 | P3: Agg after join | 0 | — | Always fix (verify keys) |
| 3 | P5: LEFT→INNER | 0 | — | Always fix |
| 4 | P6: INTERSECT | 0 | — | Always fix |
| 5 | P8: Pre-join windows | 0 | — | Always fix |
| 6 | P7: Self-join CTE | 1 | 0.49x | Check orphan CTE |
| 7 | P0: Predicate pushback | 4 | 0.0076x | All gates must pass |
| 8 | P2: Correlated loop | 2 | 0.34x | Check EXPLAIN first |
| 9 | P9: Shared expr | 3 | 0.14x | Never on EXISTS |
| 10 | P4: Cross-col OR | 4 | 0.23x | Max 3, cross-column only |

## VERIFICATION CHECKLIST

Before finalizing any rewrite:
- [ ] Row counts decrease monotonically through CTE chain
- [ ] No orphaned CTEs (every CTE referenced downstream)
- [ ] No unfiltered CTEs (every CTE has WHERE)
- [ ] No cross-joined dimension CTEs (each dim joins to fact)
- [ ] EXISTS still uses EXISTS (not materialized)
- [ ] Same-column ORs still intact (not split)
- [ ] All original WHERE filters preserved in CTEs
- [ ] Max 2 cascading fact-table CTE chains
- [ ] Comma joins converted to explicit JOIN...ON
- [ ] Rewrite doesn't match any known regression pattern

## PRUNING GUIDE

Skip pathologies the plan rules out:

| Plan shows | Skip |
|---|---|
| No nested loops | P2 (decorrelation) |
| Each table appears once | P1 (repeated scans) |
| No LEFT JOIN | P5 (INNER conversion) |
| No OR predicates | P4 (OR decomposition) |
| No GROUP BY | P3 (aggregate pushdown) |
| No WINDOW/OVER | P8 (deferred window) |
| No INTERSECT/EXCEPT | P6 (set rewrite) |
| Baseline < 50ms | ALL CTE-based transforms |
| Row counts monotonically decreasing | P0 (predicate pushback) |

## REGRESSION REGISTRY

| Severity | Transform | Result | Root cause |
|----------|-----------|--------|------------|
| CATASTROPHIC | dimension_cte_isolate | 0.0076x | Cross-joined 3 dim CTEs: Cartesian product |
| CATASTROPHIC | materialize_cte | 0.14x | Materialized EXISTS → semi-join destroyed |
| SEVERE | or_to_union | 0.23x | 9 UNION branches from nested OR |
| SEVERE | decorrelate | 0.34x | LEFT JOIN was already semi-join |
| MAJOR | union_cte_split | 0.49x | Original CTE kept → double materialization |
| MAJOR | date_cte_isolate | 0.50x | 3-way fact join locked optimizer order |
| MAJOR | or_to_union | 0.51x | Self-join re-executed per branch |
| MAJOR | semantic_rewrite | 0.54x | Correlated EXISTS pairs broken |
| MODERATE | or_to_union | 0.59x | Split same-column OR |
| MODERATE | union_cte_split | 0.68x | Original CTE kept alongside split |
| MODERATE | decorrelate | 0.71x | Pre-aggregated ALL stores when only subset needed |
| MODERATE | prefetch_fact_join | 0.78x | 3rd cascading CTE chain |
| MINOR | multi_dimension_prefetch | 0.77x | Forced suboptimal join order |
| MINOR | date_cte_isolate | 0.85x | CTE blocked ROLLUP pushdown |


## §5a. Transform Catalog

Select 4 transforms that are applicable to THIS query, maximizing structural diversity (each must attack a different part of the execution plan).

### Predicate Movement
- **global_predicate_pushdown**: Trace selective predicates from late in the CTE chain back to the earliest scan via join equivalences. Biggest win when a dimension filter is applied after a large intermediate materialization.
  Maps to examples: pushdown, early_filter, date_cte_isolate
- **transitive_predicate_propagation**: Infer predicates through join equivalence chains (A.key = B.key AND B.key = 5 -> A.key = 5). Especially across CTE boundaries where optimizers stop propagating.
  Maps to examples: early_filter, dimension_cte_isolate
- **null_rejecting_join_simplification**: When downstream WHERE rejects NULLs from the outer side of a LEFT JOIN, convert to INNER. Enables reordering and predicate pushdown. CHECK: does the query actually have LEFT/OUTER joins before assigning this.
  Maps to examples: (no direct gold example — novel transform)

### Join Restructuring
- **self_join_elimination**: When a UNION ALL CTE is self-joined N times with each join filtering to a different discriminator, split into N pre-partitioned CTEs. Eliminates discriminator filtering and repeated hash probes on rows that don't match.
  Maps to examples: union_cte_split, shared_dimension_multi_channel
- **decorrelation**: Convert correlated EXISTS/IN/scalar subqueries to CTE + JOIN. CHECK: does the query actually have correlated subqueries before assigning this.
  Maps to examples: decorrelate, composite_decorrelate_union
- **aggregate_pushdown**: When GROUP BY follows a multi-table join but aggregation only uses columns from one side, push the GROUP BY below the join. CHECK: verify the join doesn't change row multiplicity for the aggregate (one-to-many breaks AVG/STDDEV).
  Maps to examples: (no direct gold example — novel transform)
- **late_attribute_binding**: When a dimension table is joined only to resolve display columns (names, descriptions) that aren't used in filters, aggregations, or join conditions, defer that join until after all filtering and aggregation is complete. Join on the surrogate key once against the final reduced result set. This eliminates N-1 dimension scans when the CTE references the dimension N times. CHECK: verify the deferred columns aren't used in WHERE, GROUP BY, or JOIN ON — only in the final SELECT.
  Maps to examples: dimension_cte_isolate (partial pattern), early_filter

### Scan Optimization
- **star_join_prefetch**: Pre-filter ALL dimension tables into CTEs, then probe fact table with the combined key intersection.
  Maps to examples: dimension_cte_isolate, multi_dimension_prefetch, prefetch_fact_join, date_cte_isolate
- **single_pass_aggregation**: Merge N subqueries on the same fact table into 1 scan with CASE/FILTER inside aggregates. CHECK: STDDEV_SAMP/VARIANCE are grouping-sensitive — FILTER over a combined group != separate per-group computation.
  Maps to examples: single_pass_aggregation, channel_bitmap_aggregation
- **scan_consolidation_pivot**: When a CTE is self-joined N times with each reference filtering to a different discriminator (e.g., year, channel), consolidate into fewer scans that GROUP BY the discriminator, then pivot rows to columns using MAX(CASE WHEN discriminator = X THEN agg_value END). This halves the fact scans and dimension joins. SAFE when GROUP BY includes the discriminator — each group is naturally partitioned, so aggregates like STDDEV_SAMP are computed correctly per-partition. The pivot MAX is just a row selector (one row per group), not a real aggregation.
  Maps to examples: single_pass_aggregation, union_cte_split

### Structural Transforms
- **union_consolidation**: Share dimension lookups across UNION ALL branches that scan different fact tables with the same dim joins.
  Maps to examples: shared_dimension_multi_channel
- **window_optimization**: Push filters before window functions when they don't affect the frame. Convert ROW_NUMBER + filter to LATERAL + LIMIT. Merge same-PARTITION windows into one sort pass.
  Maps to examples: deferred_window_aggregation
- **exists_restructuring**: Convert INTERSECT to EXISTS for semi-join short-circuit, or restructure complex EXISTS with shared CTEs. CHECK: does the query actually have INTERSECT or complex EXISTS.
  Maps to examples: intersect_to_exists, multi_intersect_exists_cte

## §6. REASONING PROCESS

First, use a `<reasoning>` block for your internal analysis. This will be stripped before parsing. Work through these steps IN ORDER:

1. **CLASSIFY**: What structural archetype is this query?
   (channel-comparison self-join / correlated-aggregate filter / star-join with late dim filter / repeated fact scan / multi-channel UNION ALL / EXISTS-set operations / other)

2. **EXPLAIN PLAN ANALYSIS**: From the EXPLAIN ANALYZE output, identify:
   - Compute wall-clock ms per EXPLAIN node. Sum repeated operations (e.g., 2x store_sales joins = total cost). The EXPLAIN is ground truth, not the logical-tree cost percentages.
   - Which nodes consume >10% of runtime and WHY
   - Where row counts drop sharply (existing selectivity)
   - Where row counts DON'T drop (missed optimization opportunity)
   - Whether the optimizer already splits CTEs, pushes predicates, or performs transforms you might otherwise assign
   - Count scans per base table. If a fact table is scanned N times, a restructuring that reduces it to 1 scan saves (N-1)/N of that table's I/O cost. Prioritize transforms that reduce scan count on the largest tables.
   - Whether the CTE is materialized once and probed multiple times, or re-executed per reference

   **Q-ERROR ROUTING** (§2b-i): The cardinality estimation routing above identifies WHERE the planner is wrong (locus) and HOW (direction). This routing is 85% accurate at predicting where the winning transform operates.
   - **Direction + Locus → Pathology routing**: This is the primary signal. Start your hypothesis from the routed pathologies.
   - **Structural flags** (DELIM_SCAN, EST_ZERO, etc.) are direct transform triggers. DELIM_SCAN = correlated subquery → P2. EST_ZERO = CTE stats blind → P0/P7.
   - **Ignore magnitude/severity** — Q-Error size does NOT predict optimization opportunity (win rate is flat across all severity levels).

3. **BOTTLENECK HYPOTHESIS**: From your EXPLAIN observations in Step 2, reason
   about WHY each bottleneck exists and what intervention could fix it.

   **Start from Q-Error routing.** The §2b-i routing identified the planner's
   worst mismatch direction+locus and mapped it to candidate pathologies.
   Use this as your primary hypothesis anchor, then verify against the plan structure:

   For the top 2-3 cost centers identified on the cost spine:

   a) DIAGNOSE: What optimizer behavior causes this cost?
      - What operation dominates? (scan, join, sort, aggregate, window)
      - Is the input to this node larger than it needs to be? Why?
      - Is the optimizer executing operations in a suboptimal order?
      - Is work being repeated that could be done once?

   b) HYPOTHESIZE: What SQL restructuring would change the physical plan?
      - Scan dominates + low pruning ratio → predicate not reaching scan layer
      - Same table scanned N times → consolidate into single scan + conditional agg
      - Large intermediate + selective late filter → push predicate earlier in chain
      - Nested loop on large table → decorrelate to CTE + hash join
      - Aggregate input >> output after join → pre-aggregate before join
      - CTE materialized but referenced once → inline as subquery
      - Window computed in CTE before join → defer window to post-join
      - OR across different columns + full scan → decompose into UNION ALL branches

   c) CALIBRATE against engine knowledge (§4):
      - If a documented gap matches your diagnosis: USE its evidence
        (what_worked, what_didnt_work, field_notes, decision gates)
        to sharpen your intervention. Follow its gates — they encode failures.
      - If a strength matches what you'd rewrite: STOP — the optimizer already
        handles it. Your rewrite adds overhead or destroys an optimization.
      - If no gap matches: your hypothesis is novel — tag as UNVERIFIED_HYPOTHESIS
        and proceed with structural reasoning only. Design a control variant
        that tests the opposite assumption.

4. **AGGREGATION TRAP CHECK**: For every aggregate function in the query, verify: does my proposed restructuring change which rows participate in each group? STDDEV_SAMP, VARIANCE, PERCENTILE_CONT, CORR are grouping-sensitive. SUM, COUNT, MIN, MAX are grouping-insensitive (modulo duplicates). If the query uses FILTER clauses or conditional aggregation, verify equivalence explicitly.

5. **INTERVENTION DESIGN**: For each hypothesized bottleneck from Step 3,
   design a transform:

   a) Match the diagnosed optimizer behavior to a transform category in §5a
      (missed pushdown → Predicate Movement, redundant scans → Scan Consolidation, etc.)
   b) If engine evidence exists for the matched transform:
      - Prefer the proven approach and follow documented gates
      - Apply the transform's structural preconditions as hard constraints
      - Use documented regressions as REJECTION criteria
   c) If no evidence exists (UNVERIFIED_HYPOTHESIS):
      - Design the intervention from the transform description + structural preconditions
      - RANK by estimated impact: (scan reduction × table size) > (join reordering)
        > (aggregation restructuring) > (window deferral)
      - Include a rollback path — explain what makes this rewrite reversible
   d) Assign 4 structurally diverse interventions. Each worker attacks a DIFFERENT
      bottleneck or a different approach to the same bottleneck.
      No two workers should apply the same transform to the same query region.

6. **LOGICAL TREE DESIGN**: For each worker's strategy, define the target logical tree topology. Verify that every node contract has exhaustive output columns by checking downstream references.
   CTE materialization matters for your design: a CTE referenced by 2+ consumers will likely be materialized (good — computed once, probed many). A CTE referenced once may be inlined (no materialization benefit from 'sharing'). Design shared CTEs only when multiple downstream nodes consume them. See CTE_INLINING in Engine Profile strengths.

### Strategy Selection Rules

1. **CHECK APPLICABILITY**: Each transform has a structural prerequisite (correlated subquery, UNION ALL CTE, LEFT JOIN, etc.). Verify the query actually has the prerequisite before assigning a transform. DO NOT assign decorrelation if there are no correlated subqueries.
2. **CHECK OPTIMIZER OVERLAP**: Read the EXPLAIN plan. If the optimizer already performs a transform (e.g., already splits a UNION CTE, already pushes a predicate), that transform will have marginal benefit. Note this in your reasoning and prefer transforms the optimizer is NOT already doing.
3. **MAXIMIZE DIVERSITY**: Each worker must attack a different part of the execution plan. Do not assign 'pushdown variant A' and 'pushdown variant B'. Assign transforms from different categories above.
4. **ASSESS RISK PER-QUERY**: Risk is a function of (transform x query complexity), not an inherent property of the transform. Decorrelation is low-risk on a simple EXISTS and high-risk on nested correlation inside a CTE. Assess per-assignment.
5. **COMPOSITION IS ALLOWED AND ENCOURAGED**: A strategy can combine 2-3 transforms from different categories (e.g., star_join_prefetch + scan_consolidation_pivot, or date_cte_isolate + early_filter + decorrelate). The TARGET_LOGICAL_TREE should reflect the combined structure. Compound strategies are often the source of the biggest wins.
6. **MINIMAL-CHANGE BASELINE**: If the EXPLAIN shows the optimizer already handles the primary bottleneck (e.g., already splits CTEs, already pushes predicates), consider assigning one worker as a minimal-change baseline: explicit JOINs only, no structural changes. This provides a regression-safe fallback.

Each worker gets 1-3 examples from the 'Maps to examples' notes in the Transform Catalog. The system auto-loads full before/after SQL for each assigned example. Do NOT pad with irrelevant examples — an irrelevant example is worse than no example.

For TARGET_LOGICAL_TREE: Define the CTE structure you want produced. For NODE_CONTRACTS: Be exhaustive with OUTPUT columns — missing columns cause semantic breaks.

## §7a. Output Format

Then produce the structured briefing in EXACTLY this format:

```
=== SHARED BRIEFING ===

SEMANTIC_CONTRACT: (80-150 tokens, cover ONLY:)
(a) One sentence of business intent (start from pre-computed intent if available).
(b) JOIN type semantics that constrain rewrites (INNER = intersection = all sides must match).
(c) Any aggregation function traps specific to THIS query.
(d) Any filter dependencies that a rewrite could break.
Do NOT repeat information already in ACTIVE_CONSTRAINTS or REGRESSION_WARNINGS.

BOTTLENECK_DIAGNOSIS:
[Which operation dominates cost and WHY (not just '50% cost').
Scan-bound vs join-bound vs aggregation-bound.
Cardinality flow (how many rows at each stage).
What the optimizer already handles well (don't re-optimize).
Whether logical-tree cost percentages are misleading.]

ACTIVE_CONSTRAINTS:
- [CORRECTNESS_CONSTRAINT_ID]: [Why it applies to this query, 1 line]
- [ENGINE_GAP_ID]: [Evidence from EXPLAIN that this gap is active]
(List all 4 correctness constraints + the 1-3 engine gaps that
are active for THIS query based on your EXPLAIN analysis.)

REGRESSION_WARNINGS:
1. [Pattern name] ([observed regression]):
   CAUSE: [What happened mechanistically]
   RULE: [Actionable avoidance rule for THIS query]
(If no regression warnings are relevant, write 'None applicable.')

NODE_CONTRACTS: Write all fields as SQL fragments, not natural language. Example: `WHERE: d_year IN (1999, 2000)` not `WHERE: filter to target years`. Workers use these as specifications to code against.

=== WORKER 1 BRIEFING ===

STRATEGY: [strategy_name]
TARGET_LOGICAL_TREE:
  [node] -> [node] -> [node]
NODE_CONTRACTS:
  [node_name]:
    FROM: [tables/CTEs]
    JOIN: [join conditions]
    WHERE: [filters]
    GROUP BY: [columns] (if applicable)
    AGGREGATE: [functions] (if applicable)
    OUTPUT: [exhaustive column list]
    EXPECTED_ROWS: [approximate row count from EXPLAIN analysis]
    CONSUMERS: [downstream nodes]
EXAMPLES: [ex1], [ex2], [ex3]
EXAMPLE_ADAPTATION:
  [For each: what to apply, what to IGNORE for this strategy.]
HAZARD_FLAGS:
- [Specific risk for this approach on this query]

=== WORKER 2 BRIEFING ===

STRATEGY: [strategy_name]
TARGET_LOGICAL_TREE:
  [node] -> [node] -> [node]
NODE_CONTRACTS:
  [node_name]:
    FROM: [tables/CTEs]
    JOIN: [join conditions]
    WHERE: [filters]
    GROUP BY: [columns] (if applicable)
    AGGREGATE: [functions] (if applicable)
    OUTPUT: [exhaustive column list]
    EXPECTED_ROWS: [approximate row count from EXPLAIN analysis]
    CONSUMERS: [downstream nodes]
EXAMPLES: [ex1], [ex2], [ex3]
EXAMPLE_ADAPTATION:
  [For each: what to apply, what to IGNORE for this strategy.]
HAZARD_FLAGS:
- [Specific risk for this approach on this query]

=== WORKER 3 BRIEFING ===

STRATEGY: [strategy_name]
TARGET_LOGICAL_TREE:
  [node] -> [node] -> [node]
NODE_CONTRACTS:
  [node_name]:
    FROM: [tables/CTEs]
    JOIN: [join conditions]
    WHERE: [filters]
    GROUP BY: [columns] (if applicable)
    AGGREGATE: [functions] (if applicable)
    OUTPUT: [exhaustive column list]
    EXPECTED_ROWS: [approximate row count from EXPLAIN analysis]
    CONSUMERS: [downstream nodes]
EXAMPLES: [ex1], [ex2], [ex3]
EXAMPLE_ADAPTATION:
  [For each: what to apply, what to IGNORE for this strategy.]
HAZARD_FLAGS:
- [Specific risk for this approach on this query]

=== WORKER 4 BRIEFING === (EXPLORATION WORKER)

STRATEGY: [strategy_name]
TARGET_LOGICAL_TREE:
  [node] -> [node] -> [node]
NODE_CONTRACTS:
  [node_name]:
    FROM: [tables/CTEs]
    JOIN: [join conditions]
    WHERE: [filters]
    GROUP BY: [columns] (if applicable)
    AGGREGATE: [functions] (if applicable)
    OUTPUT: [exhaustive column list]
    EXPECTED_ROWS: [approximate row count from EXPLAIN analysis]
    CONSUMERS: [downstream nodes]
EXAMPLES: [ex1], [ex2], [ex3]
EXAMPLE_ADAPTATION:
  [For each: what to apply, what to IGNORE for this strategy.]
HAZARD_FLAGS:
- [Specific risk for this approach on this query]
CONSTRAINT_OVERRIDE: [CONSTRAINT_ID or 'None']
OVERRIDE_REASONING: [Why this query's structure differs from the observed failure, or 'N/A']
EXPLORATION_TYPE: [constraint_relaxation | compound_strategy | novel_combination]
HYPOTHESIS_TAG: [H1_CTE_PREDICATE_FENCE | H2_JOIN_ORDER | ... | NOVEL_<description>]

```

## Section Validation Checklist (MUST pass before final output)

### SHARED BRIEFING
- `SEMANTIC_CONTRACT`: 30-250 tokens covering business intent, JOIN semantics, aggregation trap, filter dependency.
- `BOTTLENECK_DIAGNOSIS`: dominant mechanism, bound type (`scan-bound`/`join-bound`/`aggregation-bound`), what optimizer already handles.
- `ACTIVE_CONSTRAINTS`: all 4 correctness IDs + 0-3 engine gap or hypothesis IDs with EXPLAIN evidence.
- `REGRESSION_WARNINGS`: `None applicable.` or entries with `CAUSE:` and `RULE:`.

### WORKER N BRIEFING (N=1..4)
- `STRATEGY`: non-empty, unique across workers.
- `TARGET_LOGICAL_TREE`: explicit node chain. `NODE_CONTRACTS`: every logical tree node has a contract with FROM, OUTPUT, CONSUMERS.
- `EXAMPLES`: 1-3 IDs. `EXAMPLE_ADAPTATION`: what to adapt/ignore per example.
- `HAZARD_FLAGS`: query-specific risks, not generic cautions.

### WORKER 4 EXPLORATION FIELDS
- Includes `CONSTRAINT_OVERRIDE`, `OVERRIDE_REASONING`, `EXPLORATION_TYPE`, and `HYPOTHESIS_TAG`.

## §7c. Worker 4 Exploration Rules

Workers 1-3 follow the engine profile's proven patterns. **Worker 4 is the EXPLORATION worker** with a different mandate:

Worker 4 MAY (in priority order — prefer higher-value exploration):
  (c) **PREFERRED**: Attempt a novel technique not listed in the engine profile, if the EXPLAIN plan reveals an optimizer blind spot not yet documented. This is the highest-value exploration — new discoveries expand the engine profile for all future queries.
  (b) Combine 2-3 transforms from different engine gaps into a compound strategy that hasn't been tested before. Medium value — tests interaction effects between known patterns.
  (a) Retry a technique from 'what_didnt_work', IF the structural context of THIS query differs materially from the observed failure — explain the structural difference in HAZARD_FLAGS. Lowest priority — only when the query structure clearly diverges from the failed case.

Worker 4 may NEVER violate correctness constraints (LITERAL_PRESERVATION, SEMANTIC_EQUIVALENCE, COMPLETE_OUTPUT, CTE_COLUMN_COMPLETENESS).

The exploration worker's output is tagged EXPLORATORY and tracked separately. Past failures documented in the engine profile are context-specific — they happened on specific queries with specific structures. Worker 4's job is to test whether those failures generalize or not. If Worker 4 discovers a new win, it becomes field intelligence for the engine profile.

## §7d. Output Consumption Spec

Each worker receives: SHARED BRIEFING + their WORKER N BRIEFING + full before/after SQL for assigned examples + original SQL + output format.
Workers do NOT see other workers' briefings.