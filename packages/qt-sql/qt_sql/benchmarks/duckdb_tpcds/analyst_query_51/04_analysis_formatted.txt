## Expert Analysis

### Query Structure
**web_v1**: Computes running cumulative sales by item and date for web sales over a 12-month period. Scans web_sales (fact table) joined with date_dim (dimension), filters to 12 months of data. Outputs ~1k rows with (item_sk, d_date, cume_sales).

**store_v1**: Identical computation for store sales over same 12-month period. Scans store_sales joined with date_dim. Outputs ~1k rows with same schema.

**main_query**: Performs full outer join between web_v1 and store_v1 on (item_sk, d_date), then computes running maximums of both sales streams (which are redundant since inputs are already cumulative), filters where web cumulative exceeds store cumulative, orders, and limits to 100 rows. Processes ~1k rows from the join.

### Performance Bottleneck
The dominant cost mechanism is **redundant window function computation** combined with **inefficient join pattern**:

1. **Redundant window operations**: Both CTEs compute `SUM(SUM(...)) OVER (PARTITION BY item_sk ORDER BY d_date)` - a cumulative sum. Then the main query computes `MAX(...) OVER (PARTITION BY item_sk ORDER BY d_date)` on these already cumulative values. Since cumulative values are non-decreasing by definition, the running maximum equals the current value, making this window function unnecessary.

2. **Inefficient full outer join**: The FULL OUTER JOIN produces NULL rows for dates where only one channel has sales, but these are later filtered out by `web_cumulative > store_cumulative` (NULL comparisons yield NULL/false). This wastes compute on rows that won't survive the filter.

3. **Multiple scans of date_dim**: Both CTEs independently scan and filter the same 12-month range from date_dim, potentially duplicating work.

The cost distribution (33% each for CTEs, 33% for main) suggests the main query is disproportionately expensive given it only processes ~1k rows - indicating the window functions in the main query are the bottleneck.

### Proposed Optimization Strategy
**Change 1: Eliminate redundant window functions in main query**
- **What**: Replace the `MAX(...) OVER (...)` window functions with direct references to web_sales and store_sales, since they're already cumulative.
- **Why**: Eliminates unnecessary sorting/partitioning of ~1k rows. The running max of a cumulative value equals the current value.
- **Risk**: Must verify cumulative values are truly non-decreasing (they are by SQL's `SUM() OVER (ORDER BY d_date ROWS UNBOUNDED PRECEDING)`).
- **Estimated impact**: Significant (removes ~33% of query cost).

**Change 2: Convert FULL OUTER JOIN to INNER JOIN**
- **What**: Change `FULL OUTER JOIN` to `INNER JOIN` since `web_cumulative > store_cumulative` filter removes NULL rows.
- **Why**: Reduces join complexity and avoids generating rows that will be filtered out.
- **Risk**: Must ensure semantics are identical - NULL comparisons yield NULL, which fails the filter, so INNER JOIN is equivalent.
- **Estimated impact**: Moderate (reduces join output size).

**Change 3: Share date_dim filtering via CTE**
- **What**: Extract `SELECT d_date_sk, d_date FROM date_dim WHERE d_month_seq BETWEEN 1216 AND 1216+11` into a CTE and reference it in both web_v1 and store_v1.
- **Why**: Avoids scanning/filtering date_dim twice. DuckDB may not automatically cache this.
- **Risk**: Could interfere with join ordering optimizations (as seen in previous failure).
- **Estimated impact**: Minor to moderate.

### Lessons from Previous Failures
**Previous attempt: date_cte_isolate (REGRESSION 0.87x)**
- **Why it failed**: Likely because DuckDB's optimizer already pushes the date filter efficiently, and materializing the date subset into a CTE prevented join reordering or introduced unnecessary materialization overhead.
- **Lesson**: DuckDB may optimize dimension table joins better when left inline. Explicit CTEs for small dimension tables can inhibit optimizations.

### Recommended Approach
Implement optimizations 1 and 2 together, as they're semantically safe and synergistic:
1. Rewrite the main query to use direct column references instead of window functions
2. Change FULL OUTER JOIN to INNER JOIN
3. Keep date_dim joins inline (don't extract to CTE) based on previous failure

Resulting query structure:
```sql
WITH web_v1 AS (...),  -- unchanged
     store_v1 AS (...)  -- unchanged
SELECT
  COALESCE(web.item_sk, store.item_sk) AS item_sk,
  COALESCE(web.d_date, store.d_date) AS d_date,
  web.cume_sales AS web_sales,
  store.cume_sales AS store_sales,
  web.cume_sales AS web_cumulative,      -- Direct reference, not window
  store.cume_sales AS store_cumulative   -- Direct reference, not window
FROM web_v1 AS web
INNER JOIN store_v1 AS store            -- Changed from FULL OUTER
  ON web.item_sk = store.item_sk AND web.d_date = store.d_date
WHERE web.cume_sales > store.cume_sales
ORDER BY item_sk, d_date
LIMIT 100
```

## 6. EXAMPLE SELECTION

The FAISS selections are partially relevant:
- **deferred_window_aggregation**: Relevant for eliminating redundant windows
- **early_filter**: Relevant but previous failure suggests caution
- **shared_dimension_multi_channel**: Relevant for sharing date_dim

Better examples for this query:
- **pushdown**: For pushing the cumulative comparison into the join
- **deferred_window_aggregation**: For eliminating redundant window computations
- **materialize_cte**: Though previous failure suggests avoiding date CTE

EXAMPLES: deferred_window_aggregation, pushdown, materialize_cte

Apply the recommended strategy above. The analysis has already identified the bottleneck and the specific structural change needed. Focus on implementing it correctly while preserving semantic equivalence.