## Role

You are **W1 "Reducer"** — Cardinality reduction — WHERE filters, set operations, early pruning. Reduce row counts early: push predicates into CTEs, convert set operations to EXISTS/NOT EXISTS, apply early filtering before expensive joins.

Transform this SQL query from its CURRENT IR structure to a TARGET IR structure using patch operations. Output a single PatchPlan JSON.

**Family**: A — dimension_cte_isolate
**Hypothesis**: Late store filter (s_state='SD') forces processing of irrelevant stores. Pre-filtering store_returns using SD stores reduces CTE cardinality.

## Original SQL

```sql
-- start query 1 in stream 0 using template query1.tpl
with customer_total_return as
(select sr_customer_sk as ctr_customer_sk
,sr_store_sk as ctr_store_sk
,sum(SR_FEE) as ctr_total_return
from store_returns
,date_dim
where sr_returned_date_sk = d_date_sk
and d_year =2000
group by sr_customer_sk
,sr_store_sk)
 select c_customer_id
from customer_total_return ctr1
,store
,customer
where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2
from customer_total_return ctr2
where ctr1.ctr_store_sk = ctr2.ctr_store_sk)
and s_store_sk = ctr1.ctr_store_sk
and s_state = 'SD'
and ctr1.ctr_customer_sk = c_customer_sk
order by c_customer_id
 LIMIT 100;

-- end query 1 in stream 0 using template query1.tpl
```

## Current IR Node Map

```
S0 [SELECT]
  CTE: customer_total_return  (via CTE_Q_S0_customer_total_return)
    FROM: store_returns, date_dim
    WHERE [eb0f6bc97f7168d4]: sr_returned_date_sk = d_date_sk AND d_year = 2000
    GROUP BY: sr_customer_sk, sr_store_sk
  MAIN QUERY (via Q_S0)
    FROM: customer_total_return ctr1, store, customer
    WHERE [e5b7485395ff5a80]: ctr1.ctr_total_return > (SELECT AVG(ctr_total_return) * 1.2 FROM customer_total_return AS ctr2 WH...
    ORDER BY: c_customer_id
S1 [OTHER_DDL]

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Target IR (what the optimized query should look like)

```
S0 [SELECT]
  CTE: sd_stores  (new)
    FROM: store
    WHERE: s_state='SD'
    SELECT: s_store_sk
  CTE: customer_total_return  (modified)
    FROM: store_returns, date_dim, sd_stores
    WHERE: 
        sr_returned_date_sk = d_date_sk
        AND d_year = 2000
        AND sr_store_sk = s_store_sk
    GROUP BY: sr_customer_sk, sr_store_sk
  MAIN QUERY (via Q_S0)
    FROM: customer_total_return ctr1, customer
    WHERE [e5b7485395ff5a80]: 
        ctr1.ctr_total_return > (SELECT AVG(ctr_total_return)*1.2 FROM customer_total_return ctr2 WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk)
        AND ctr1.ctr_customer_sk = c_customer_sk
    ORDER BY: c_customer_id
    LIMIT 100
```

## Patch Operations

| Op | Description | Payload |
|----|-------------|---------|
| insert_cte | Add a new CTE to the WITH clause | cte_name, cte_query_sql |
| replace_from | Replace the FROM clause | from_sql |
| replace_where_predicate | Replace the WHERE clause | expr_sql |
| replace_body | Replace entire query body (SELECT, FROM, WHERE, GROUP BY) | sql_fragment |
| replace_expr_subtree | Replace a specific expression | expr_sql (+ by_anchor_hash) |
| delete_expr_subtree | Remove a specific expression | (target only, no payload) |

## Gold Patch Example (reference pattern)

```json
{
  "plan_id": "gold_duckdb_date_cte_isolate",
  "dialect": "duckdb",
  "description": "Extract date filtering into a separate CTE to enable predicate pushdown and reduce scans",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "target_month",
        "cte_query_sql": "SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2002 AND d_moy = 3"
      },
      "description": "Insert CTE 'target_month' for date dimension filtering"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "category_avg",
        "cte_query_sql": "SELECT i_category, AVG(i_current_price) * 1.2 AS price_threshold FROM item GROUP BY i_category"
      },
      "description": "Insert CTE 'category_avg' for pre-aggregated computation"
    },
    {
      "step_id": "s3",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "customer_address AS a JOIN customer AS c ON a.ca_address_sk = c.c_current_addr_sk JOIN store_sales AS s ON c.c_customer_sk = s.ss_customer_sk JOIN date_dim AS d ON s.ss_sold_date_sk = d.d_date_sk JOIN target_month AS tm ON d.d_month_seq = tm.d_month_seq JOIN item AS i ON s.ss_item_sk = i.i_item_sk JOIN category_avg AS ca ON i.i_category = ca.i_category"
      },
      "description": "Replace comma-join FROM with explicit JOINs"
    },
    {
      "step_id": "s4",
      "op": "replace_where_predicate",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "2837aea03aa52676"
      },
      "payload": {
        "expr_sql": "i.i_current_price > ca.price_threshold"
      },
      "description": "Replace WHERE predicate with optimized version"
    }
  ]
}
```

## Instructions

Adapt the gold example pattern to match the ORIGINAL SQL above.
Use the TARGET IR as your structural guide — create CTEs matching the target's CTE names and structure.
Preferred approach: insert_cte (x2-3) + replace_from or replace_body.
All SQL in payloads must be complete, executable fragments (no ellipsis).
Use dialect: "duckdb" in the output.
Target all steps at by_node_id: "S0" (the main statement).

Output ONLY the JSON object (no markdown, no explanation):