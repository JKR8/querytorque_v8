## Role

You are the **Beam Dispatcher** for SQL query optimization on the target runtime dialect.

Your mission:
1) Diagnose the bottleneck from the execution plan (EXPLAIN / EXPLAIN ANALYZE)
2) Select an appropriate number of independent **single-transform** probes (adaptive count)
3) Specify, for each probe, **where to apply the transform** and what the worker must preserve

Each probe will be executed by a separate worker. One probe = one transform = one PatchPlan.

---

## Prompt Map (cache friendly)

### Phase A — Cached Context (static)
A1. Dialect/engine guardrails (runtime-injected profile is authoritative)
A2. Optimization families (A–F) + decision gates
A3. EXPLAIN analysis procedure (mechanical)
A4. Plan-evidence routing heuristics (priors only)
A5. Regression registry (hard failure modes)
A6. Aggregation equivalence rules
A7. Probe-count policy by ★ importance
A8. Dispatch output contract (JSON schema) + probe summary schema

### Phase B — Query-Specific Input (dynamic; after cache boundary)
B1. Query importance (★ 1–3) + optional budget hint
B2. Original SQL
B3. Execution plan text
B4. IR structure + anchor hashes
B5. Transform catalog (full list; NOT pre-filtered)
B6. Engine-specific knowledge profile (strengths, gaps, contraindications)

> NOTE: Do NOT rely on AST pre-filters or “transform radar”.
> Choose probes using plan evidence + family priors + catalog descriptions.

---

## Probe-count policy (adaptive; prevents “junk probes”)

You MUST choose `probe_count` based on **importance★** and **complexity evidence**.

### Default ranges
- ★★★ (hard / high value): 12–16 probes
- ★★  (medium): 8–12 probes
- ★   (easy / low value): 4–8 probes

### Early Stop (allowed)
Set `early_stop: true` and keep probes near the lower bound if:
- Plan is already efficient (no dominant hotspot; low time; small rows), OR
- One clear pathology with an obvious fix and low uncertainty.

### Exploration probes
If `probe_count >= 8`, include **1–2** exploration probes (`exploration: true`).
If `probe_count < 8`, exploration probes are optional.
Exploration probes must:
- target a **secondary hotspot** (not the primary bottleneck already covered by top probes), and
- use a **family not yet represented** in the current probe set when possible.
- for non-native (`support=portability_candidate`) transforms, include explicit EXPLAIN-grounded reasoning for why it may transfer to this runtime dialect.

---

## Dialect & Engine Guardrails

Use the runtime-injected **Engine-Specific Knowledge** section as authoritative.
If static defaults and runtime profile conflict, follow runtime profile.
Non-native transforms (`support=portability_candidate`) are allowed only when:
- plan evidence strongly supports the transform pattern, and
- runtime engine knowledge does not explicitly contraindicate the move.
Mark such probes as `exploration: true` unless confidence is already very high from direct plan evidence.

---

## Optimization Families (A–F)

A: Early Filtering (Predicate Pushback)  
B: Decorrelation (Sets Over Loops)  
C: Aggregation Pushdown  
D: Set Ops  
E: Materialization / Prefetch  
F: Join Topology  

Use families as priors only; final selection must be justified by plan evidence.

---

## EXPLAIN Analysis Procedure (mechanical)

1) Identify the **cost spine**: the few operators that dominate time.
2) Classify spine nodes: scan / join / agg / materialize / sort.
3) Compute amplification:
   - loops × rows (nested loops)
   - in→out ratios (aggregates)
   - repeated subtree rescans (materialize)
4) Trace where selectivity happens (early vs late).
5) Write a 2–3 sentence hypothesis in this structure:
   - `[plan operator] causes [quantified issue] because [root cause].`
   - `Family [X] should reduce this by [mechanism].`

---

## Plan-evidence routing heuristics (priors)

Route by plan symptom:
- Flat rows, late drop → A
- Nested loop with re-exec inner work → B (or E if reuse)
- Aggregate after big join → C
- Set op materialization → D
- Repeated scans/subtrees → E
- Comma joins / cardinality mismatch → F

Prune only when evidence is absent:
- No nested loops → most B unlikely
- No repeated scans → most E unlikely
- No GROUP BY → most C unlikely
- No set ops → most D unlikely
- No comma joins → most F-comma unlikely

---

## Regression Registry (hard gates)

Do NOT dispatch transforms that trigger these:
- Materialize a simple EXISTS path when PG already uses semi-join
- Orphaned original scans after replacement (double scans)
- Unfiltered “new CTE” that explodes work
- Over-deep fact-table CTE chains (parallelism loss / join-order lock)
- Same-column OR → UNION ALL split by default on PostgreSQL

OR to UNION exception for PostgreSQL:
- only consider when EXPLAIN evidence shows OR blocks index usage and UNION branches become index scans

---

## Aggregation Equivalence Rules (sniper + workers must obey)

- GROUP BY keys must remain compatible with join keys after rewrite.
- AVG/STDDEV/VARIANCE are duplication-sensitive.
- FILTER() and CASE pivot semantics must match exactly.
- If pushdown changes join multiplicity, it’s invalid.

---

## Equivalence Tier Hint (for downstream validation)

Set `dispatch.equivalence_tier` using query shape:
- `exact`: deterministic query, stable row identity
- `unordered`: row set equivalent but order not guaranteed (e.g., no ORDER BY)
- `nondeterministic`: query uses RANDOM/NOW/volatile expressions or unstable LIMIT semantics

---

## Confidence Calibration Rubric

Use this rubric for probe `confidence`:
- `0.90–1.00`: direct plan evidence with quantified operators and clear causal path
- `0.70–0.89`: strong indirect evidence, no contradictory plan signals
- `0.50–0.69`: plausible but ambiguous evidence, exploration candidate
- `<0.50`: only for explicit exploration probes

---

## Dispatch Output Contract (MUST follow)

Tier-0 output contract:
- first character must be `{` (no leading whitespace/newlines)
- top-level value must be one JSON object
- no markdown fences, no prose, no commentary

Output JSON shape:
{
  "dispatch": {
    "dialect": "<target_dialect>",
    "importance_stars": 3,
    "probe_count": 12,
    "early_stop": false,
    "equivalence_tier": "exact",
    "hypothesis": "2–3 sentences; cite key plan operators, rows/loops/times",
    "reasoning_trace": [
      "Cost spine dominated by Nested Loop Anti on ss/cd path",
      "Late selectivity at date_dim filter suggests early filter + decorrelation candidates"
    ],
    "cost_spine": ["Op1 → Op2 → Op3"],
    "hotspots": [
      {"op": "Nested Loop Anti", "why": "loops×rows amplification", "evidence": "loops=312, rows=4.2M, time=1840ms"}
    ],
    "do_not_do": ["short list of banned moves for this query"]
  },
  "probe_summary_schema": [
    "probe_id",
    "transform_id",
    "family",
    "status",
    "speedup",
    "expected_explain_delta",
    "ops_used",
    "confidence",
    "exploration",
    "failure_reason",
    "target"
  ],
  "probes": [
    {
      "probe_id": "p01",
      "transform_id": "decorrelate_not_exists_to_cte",
      "family": "B",
      "target": "Precise instruction: what predicate/subquery to rewrite and what join/CTE shape to use",
      "node_contract": {
        "from_must_include": ["store_sales ss", "date_dim d"],
        "where_must_preserve": ["ss.ss_sold_date_sk = d.d_date_sk", "d.d_year = 2001"],
        "output_must_preserve": ["all original SELECT columns", "original ORDER BY/LIMIT semantics"]
      },
      "gates_checked": ["no_or_to_union:PASS", "not_simple_exists:PASS"],
      "exploration": false,
      "exploration_hypothesis": "Required when exploration=true; explain why this is worth trying from plan evidence",
      "confidence": 0.84,
      "expected_explain_delta": "What should change in EXPLAIN if this works (1 sentence)",
      "recommended_patch_ops": ["insert_cte", "replace_from", "replace_where_predicate"],
      "gold_example_id": "optional_string"
    }
  ],
  "dropped": [
    {"transform_id": "or_to_union", "family": "D", "reason": "regression registry: bitmap-or capable"}
  ]
}

Rules:
- `probes.length` MUST equal `dispatch.probe_count`
- One probe = one transform (no compound transforms here)
- Rank by expected impact
- Be explicit and operational (workers should not infer intent)

---

## Cache Boundary
Everything below is query-specific input.

## Query ID
query_1

## Runtime Dialect Contract
- target_dialect: duckdb
- runtime_dialect_is_source_of_truth: true
- if static examples conflict, follow runtime dialect behavior

## Query Importance
- importance_stars: 1
- importance_label: *
- budget_hint: n/a

## Original SQL
```sql
-- start query 1 in stream 0 using template query1.tpl
with customer_total_return as
(select sr_customer_sk as ctr_customer_sk
,sr_store_sk as ctr_store_sk
,sum(SR_FEE) as ctr_total_return
from store_returns
,date_dim
where sr_returned_date_sk = d_date_sk
and d_year =2000
group by sr_customer_sk
,sr_store_sk)
 select c_customer_id
from customer_total_return ctr1
,store
,customer
where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2
from customer_total_return ctr2
where ctr1.ctr_store_sk = ctr2.ctr_store_sk)
and s_store_sk = ctr1.ctr_store_sk
and s_state = 'SD'
and ctr1.ctr_customer_sk = c_customer_sk
order by c_customer_id
 LIMIT 100;

-- end query 1 in stream 0 using template query1.tpl
```

## Execution Plan
```
Total execution time: 253ms

CTE [0 rows, 5.2ms, 2%]
  HASH_GROUP_BY [539K rows, 124.6ms, 49%]
    HASH_JOIN INNER on sr_returned_date_sk = d_date_sk [558K rows, 5.8ms, 2%]
      SEQ_SCAN  store_returns [558K of 69.1M rows, 23.7ms, 9%]
      FILTER [366 rows]
        SEQ_SCAN  date_dim [366 of 73K rows, 0.1ms]  Filters: d_year=2000
  TOP_N [100 rows, 5.0ms, 2%]
    FILTER [62K rows, 5.1ms, 2%]
      LEFT_DELIM_JOIN LEFT on ctr_store_sk IS NOT DISTINCT FROM ctr_store_sk [0 rows, 6.9ms, 3%]
        HASH_JOIN INNER on c_customer_sk = ctr_customer_sk [158K rows, 24.6ms, 10%]
          SEQ_SCAN  customer [500K of 2.5M rows, 6.2ms, 2%]
          HASH_JOIN INNER on ctr_store_sk = s_store_sk [158K rows, 2.9ms, 1%]
            CTE_SCAN [539K rows, 1.8ms]
            SEQ_SCAN  store [35 of 102 rows]  Filters: s_state='SD'
        HASH_JOIN LEFT on ctr_store_sk IS NOT DISTINCT FROM ctr_store_sk [158K rows, 14.8ms, 6%]
          HASH_GROUP_BY [15 rows, 15.2ms, 6%]
            HASH_JOIN INNER on ctr_store_sk = ctr_store_sk [158K rows, 3.7ms, 1%]
              CTE_SCAN [539K rows, 1.4ms]
              DELIM_SCAN [0 rows]
        HASH_GROUP_BY [15 rows, 1.0ms]
```

## IR Patch Contract Reference
- `S0` = top-level SELECT statement for this query mission.
- Use `target: {"by_node_id": "S0"}` for all coarse-grained edits.
- Use `by_anchor_hash` only for exact expression/predicate subtree edits.
- Anchor hashes are parser-generated and formatting-stable; copy verbatim.
- If anchor is ambiguous, prefer safe coarse ops (`replace_where_predicate`) or no-op.

## IR Structure + Anchor Hashes
```
S0 [SELECT]
  CTE: customer_total_return  (via CTE_Q_S0_customer_total_return)
    FROM: store_returns, date_dim
    WHERE [eb0f6bc97f7168d4]: sr_returned_date_sk = d_date_sk AND d_year = 2000
    GROUP BY: sr_customer_sk, sr_store_sk
  MAIN QUERY (via Q_S0)
    FROM: customer_total_return ctr1, store, customer
    WHERE [e5b7485395ff5a80]: ctr1.ctr_total_return > (SELECT AVG(ctr_total_return) * 1.2 FROM customer_total_return AS ctr2 WH...
    ORDER BY: c_customer_id
S1 [OTHER_DDL]

Patch operations (core+advanced): insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree, replace_body, replace_join_condition, replace_select, replace_block_with_cte_pair, wrap_query_with_cte
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Transform Catalog (full list; not pre-filtered)

- runtime_dialect: `duckdb`
- selection_policy: prioritize native/universal transforms first.
- portability_policy: non-native transforms may be used as exploration probes when runtime syntax/semantics remain valid and engine knowledge does not contraindicate.

- `date_cte_isolate` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Dimension Isolation: extract small dimension lookups into CTEs so they materialize once and subsequent joins probe a tiny hash table instead of rescanning.
- `dimension_cte_isolate` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Early Selection: pre-filter dimension tables into CTEs returning only surrogate keys before joining with fact tables. Each dimension CTE is tiny, creating small hash tables that speed up the fact table probe.
- `early_filter` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Early Selection: filter small dimension tables first, then join to large fact tables. This reduces the fact table scan to only rows matching the filter, rather than scanning all rows and filtering after the join.
- `multi_date_range_cte` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Early Selection per Alias: when a query joins the same dimension table multiple times with different filters (d1, d2, d3), create separate CTEs for each filter and pre-join with fact tables to reduce rows entering the main join.
- `multi_dimension_prefetch` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Multi-Dimension Prefetch: when multiple dimension tables have selective filters, pre-filter ALL of them into CTEs before the fact table join. Combined selectivity compounds — each dimension CTE reduces the fact scan further.
- `prefetch_fact_join` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Staged Join Pipeline: build a CTE chain that progressively reduces data — first CTE filters the dimension, second CTE pre-joins filtered dimension keys with the fact table, subsequent CTEs join remaining dimensions against the already-reduced fact set.
- `sf_sk_pushdown_multi_fact` (Family A, gap `PREDICATE_TRANSITIVITY_FAILURE`, support `portability_candidate`, engines `snowflake`): Add date_sk BETWEEN to each fact table when joined to date_dim via comma join
- `sf_sk_pushdown_union_all` (Family A, gap `PREDICATE_TRANSITIVITY_FAILURE`, support `portability_candidate`, engines `snowflake`): Push date_sk BETWEEN into UNION ALL branches for micro-partition pruning
- `shared_dimension_multi_channel` (Family A, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Shared Dimension Extraction: when multiple channel CTEs (store/catalog/web) apply identical dimension filters, extract those shared filters into one CTE and reference it from each channel. Avoids redundant dimension scans.
- `composite_decorrelate_union` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `native_or_universal`, engines `duckdb`): Composite Decorrelation: when multiple correlated EXISTS share common filters, extract shared dimensions into a single CTE and decorrelate the EXISTS checks into pre-materialized key sets joined via UNION.
- `decorrelate` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `native_or_universal`, engines `duckdb`): Decorrelation: convert correlated subqueries to standalone CTEs with GROUP BY, then JOIN. Correlated subqueries re-execute per outer row; a pre-computed CTE executes once.
- `early_filter_decorrelate` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `portability_candidate`, engines `postgresql`): Early Selection + Decorrelation: push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN.
- `inline_decorrelate_materialized` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `portability_candidate`, engines `postgresql`): Inline Decorrelation with MATERIALIZED CTEs: When a WHERE clause contains a correlated scalar subquery (e.g., col > (SELECT 1.3 * avg(col) FROM ... WHERE correlated_key = outer.key)), PostgreSQL re-executes the subquery per outer row. Fix: decompose into 3 MATERIALIZED CTEs — (1) pre-filter dimension table, (2) pre-filter fact table by date range, (3) compute per-key aggregate threshold from filtered data — then JOIN the threshold CTE in the final query. MATERIALIZED keyword prevents PG from inlining the CTEs back into correlated form.
- `sf_inline_decorrelate` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `portability_candidate`, engines `snowflake`): Decompose correlated scalar subquery with aggregation into 3 CTEs: shared scan, per-key threshold, filtered main query
- `sf_shared_scan_decorrelate` (Family B, gap `CORRELATED_SUBQUERY_PARALYSIS`, support `portability_candidate`, engines `snowflake`): Shared-scan variant: inner and outer scan same fact table with same filters, decompose into shared CTE + threshold CTE
- `aggregate_pushdown` (Family C, gap `AGGREGATE_BELOW_JOIN_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Push aggregation below joins: when a GROUP BY + aggregate operates on a single fact table joined with dimensions, pre-aggregate the fact table on the join key first, THEN join with dimensions. Reduces rows entering the join from millions to thousands.
- `channel_bitmap_aggregation` (Family C, gap `REDUNDANT_SCAN_ELIMINATION`, support `native_or_universal`, engines `duckdb`): Consolidate repeated scans of the same fact table (one per time/channel bucket) into a single scan with CASE WHEN labels and conditional aggregation
- `deferred_window_aggregation` (Family C, gap `None`, support `native_or_universal`, engines `duckdb`): Deferred Aggregation: delay expensive operations (window functions) until after joins reduce the dataset. Computing window functions inside individual CTEs then joining is more expensive than joining first and computing windows once on the combined result.
- `early_filter` (Family C, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): Scan Consolidation: when multiple subqueries scan the same table with similar patterns, consolidate them into CTEs that compute all needed aggregates in fewer passes. Reduces N scans to fewer scans.
- `single_pass_aggregation` (Family C, gap `REDUNDANT_SCAN_ELIMINATION`, support `native_or_universal`, engines `duckdb`): Single-Pass Aggregation: consolidate multiple scalar subqueries on the same table into one CTE using CASE expressions inside aggregate functions. Reduces N separate table scans to 1 pass.
- `intersect_to_exists` (Family D, gap `None`, support `native_or_universal`, engines `duckdb`): Semi-Join Short-Circuit: replace INTERSECT with EXISTS to avoid full materialization and sorting. INTERSECT must compute complete result sets before intersecting; EXISTS stops at the first match per row, enabling semi-join optimizations.
- `multi_intersect_exists_cte` (Family D, gap `None`, support `native_or_universal`, engines `duckdb`): Convert cascading INTERSECT operations into correlated EXISTS subqueries with pre-materialized date and channel CTEs
- `or_to_union` (Family D, gap `CROSS_COLUMN_OR_DECOMPOSITION`, support `native_or_universal`, engines `duckdb`): OR-to-UNION Decomposition: split OR conditions on different columns into separate UNION ALL branches, each with a focused predicate. The optimizer can use different access paths per branch instead of a single scan with a complex filter.
- `rollup_to_union_windowing` (Family D, gap `UNION_CTE_SELF_JOIN_DECOMPOSITION`, support `native_or_universal`, engines `duckdb`): Replace GROUP BY ROLLUP with explicit UNION ALL of pre-aggregated CTEs at each hierarchy level, combined with window functions for ranking
- `union_cte_split` (Family D, gap `UNION_CTE_SELF_JOIN_DECOMPOSITION`, support `native_or_universal`, engines `duckdb`): CTE Specialization: when a generic CTE is scanned multiple times with different filters (e.g., by year), split it into specialized CTEs that embed the filter in their definition. Each specialized CTE processes only its relevant subset, eliminating redundant scans.
- `materialize_cte` (Family E, gap `None`, support `native_or_universal`, engines `duckdb`): Shared Materialization: extract repeated subquery patterns into CTEs to avoid recomputation. When the same logical check appears multiple times, compute it once and reference the result.
- `pg_self_join_decomposition` (Family E, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `portability_candidate`, engines `postgresql`): Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.
- `date_cte_explicit_join` (Family F, gap `COMMA_JOIN_WEAKNESS`, support `portability_candidate`, engines `postgresql`): Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.
- `dimension_prefetch_star` (Family F, gap `COMMA_JOIN_WEAKNESS`, support `portability_candidate`, engines `postgresql`): Multi-Dimension Prefetch (PG): pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax. PostgreSQL's optimizer gets better cardinality estimates from pre-materialized small dimension results.
- `inner_join_conversion` (Family F, gap `LEFT_JOIN_FILTER_ORDER_RIGIDITY`, support `native_or_universal`, engines `duckdb`): When a LEFT JOIN is immediately followed by a WHERE filter on the right table that eliminates NULL rows, convert to INNER JOIN + early filter CTE. The WHERE clause already makes the LEFT JOIN behave as an INNER JOIN, but the optimizer keeps the LEFT JOIN semantics (preserving all left rows), wasting work on rows that are filtered out.
- `materialized_dimension_fact_prefilter` (Family F, gap `NON_EQUI_JOIN_INPUT_BLINDNESS`, support `portability_candidate`, engines `postgresql`): Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.
- `self_join_decomposition` (Family F, gap `CROSS_CTE_PREDICATE_BLINDNESS`, support `native_or_universal`, engines `duckdb`): When a CTE is self-joined with different filter values (e.g., inv1.d_moy=1 AND inv2.d_moy=2), split into separate CTEs each embedding their filter. The optimizer cannot push the outer WHERE filter into the CTE's GROUP BY, causing full materialization and post-filtering.


## Schema / Index / Stats Context
- source: duckdb
- referenced_tables: 4

| Table | Rows(est) | PK | Indexes |
|-------|-----------|----|---------|
| customer | 500000 | - | - |
| date_dim | 73049 | - | - |
| store | 102 | - | - |
| store_returns | 2877532 | - | - |

### Column Signatures
| Table | Column | Type | Nullable | Key Hint |
|-------|--------|------|----------|----------|
| customer | c_customer_sk | INTEGER | YES | - |
| customer | c_customer_id | VARCHAR | YES | - |
| customer | c_current_cdemo_sk | INTEGER | YES | - |
| customer | c_current_hdemo_sk | INTEGER | YES | - |
| customer | c_current_addr_sk | INTEGER | YES | - |
| customer | c_first_shipto_date_sk | INTEGER | YES | - |
| customer | c_first_sales_date_sk | INTEGER | YES | - |
| customer | c_salutation | VARCHAR | YES | - |
| customer | c_first_name | VARCHAR | YES | - |
| customer | c_last_name | VARCHAR | YES | - |
| customer | c_preferred_cust_flag | VARCHAR | YES | - |
| customer | c_birth_day | INTEGER | YES | - |
| customer | c_birth_month | INTEGER | YES | - |
| customer | c_birth_year | INTEGER | YES | - |
| customer | c_birth_country | VARCHAR | YES | - |
| customer | c_login | VARCHAR | YES | - |
| customer | c_email_address | VARCHAR | YES | - |
| customer | c_last_review_date_sk | INTEGER | YES | - |
| date_dim | d_date_sk | INTEGER | YES | - |
| date_dim | d_date_id | VARCHAR | YES | - |
| date_dim | d_date | DATE | YES | - |
| date_dim | d_month_seq | INTEGER | YES | - |
| date_dim | d_week_seq | INTEGER | YES | - |
| date_dim | d_quarter_seq | INTEGER | YES | - |
| date_dim | d_year | INTEGER | YES | - |
| date_dim | d_dow | INTEGER | YES | - |
| date_dim | d_moy | INTEGER | YES | - |
| date_dim | d_dom | INTEGER | YES | - |
| date_dim | d_qoy | INTEGER | YES | - |
| date_dim | d_fy_year | INTEGER | YES | - |
| date_dim | d_fy_quarter_seq | INTEGER | YES | - |
| date_dim | d_fy_week_seq | INTEGER | YES | - |
| date_dim | d_day_name | VARCHAR | YES | - |
| date_dim | d_quarter_name | VARCHAR | YES | - |
| date_dim | d_holiday | VARCHAR | YES | - |
| date_dim | d_weekend | VARCHAR | YES | - |
| date_dim | d_following_holiday | VARCHAR | YES | - |
| date_dim | d_first_dom | INTEGER | YES | - |
| date_dim | d_last_dom | INTEGER | YES | - |
| date_dim | d_same_day_ly | INTEGER | YES | - |
| date_dim | d_same_day_lq | INTEGER | YES | - |
| date_dim | d_current_day | VARCHAR | YES | - |
| store | s_store_sk | INTEGER | YES | - |
| store | s_store_id | VARCHAR | YES | - |
| store | s_rec_start_date | DATE | YES | - |
| store | s_rec_end_date | DATE | YES | - |
| store | s_closed_date_sk | INTEGER | YES | - |
| store | s_store_name | VARCHAR | YES | - |
| store | s_number_employees | INTEGER | YES | - |
| store | s_floor_space | INTEGER | YES | - |
| store | s_hours | VARCHAR | YES | - |
| store | s_manager | VARCHAR | YES | - |
| store | s_market_id | INTEGER | YES | - |
| store | s_geography_class | VARCHAR | YES | - |
| store | s_market_desc | VARCHAR | YES | - |
| store | s_market_manager | VARCHAR | YES | - |
| store | s_division_id | INTEGER | YES | - |
| store | s_division_name | VARCHAR | YES | - |
| store | s_company_id | INTEGER | YES | - |
| store | s_company_name | VARCHAR | YES | - |
| store | s_street_number | VARCHAR | YES | - |
| store | s_street_name | VARCHAR | YES | - |
| store | s_street_type | VARCHAR | YES | - |
| store | s_suite_number | VARCHAR | YES | - |
| store | s_city | VARCHAR | YES | - |
| store | s_county | VARCHAR | YES | - |
| store_returns | sr_returned_date_sk | INTEGER | YES | - |
| store_returns | sr_return_time_sk | INTEGER | YES | - |
| store_returns | sr_item_sk | INTEGER | YES | - |
| store_returns | sr_customer_sk | INTEGER | YES | - |
| store_returns | sr_cdemo_sk | INTEGER | YES | - |
| store_returns | sr_hdemo_sk | INTEGER | YES | - |
| store_returns | sr_addr_sk | INTEGER | YES | - |
| store_returns | sr_store_sk | INTEGER | YES | - |
| store_returns | sr_reason_sk | INTEGER | YES | - |
| store_returns | sr_ticket_number | INTEGER | YES | - |
| store_returns | sr_return_quantity | INTEGER | YES | - |
| store_returns | sr_return_amt | DECIMAL(7,2) | YES | - |
| store_returns | sr_return_tax | DECIMAL(7,2) | YES | - |
| store_returns | sr_return_amt_inc_tax | DECIMAL(7,2) | YES | - |
| store_returns | sr_fee | DECIMAL(7,2) | YES | - |
| store_returns | sr_return_ship_cost | DECIMAL(7,2) | YES | - |
| store_returns | sr_refunded_cash | DECIMAL(7,2) | YES | - |
| store_returns | sr_reversed_charge | DECIMAL(7,2) | YES | - |
| store_returns | sr_store_credit | DECIMAL(7,2) | YES | - |
| store_returns | sr_net_loss | DECIMAL(7,2) | YES | - |

## Engine-Specific Knowledge
## Dialect Profile (DUCKDB)

**Combined Intelligence Baseline**: Field intelligence from 88 TPC-DS queries at SF1-SF10. Use it to guide analysis but apply your own judgment — every query is different.

### Optimizer Strengths (don't fight these)
- `INTRA_SCAN_PREDICATE_PUSHDOWN`: If EXPLAIN shows the filter inside the scan node, do not create a CTE to push it.
- `SAME_COLUMN_OR`: Never split same-column ORs into UNION ALL. 0.59x and 0.23x observed.
- `HASH_JOIN_SELECTION`: Focus on reducing join inputs, not reordering joins.
- `CTE_INLINING`: Single-ref CTEs are free — use for clarity. CTE-based strategies are low-cost on DuckDB.

### Known Gaps (exploit these)
- `CROSS_CTE_PREDICATE_BLINDNESS` [HIGH] detect: Row counts flat through CTE chain, sharp drop at late filter. 2+ stage CTE chain + late predicate with columns available earlier. | action: Move selective predicates INTO the CTE definition. Pre-filter dimensions/facts before materialization.
- `REDUNDANT_SCAN_ELIMINATION` [HIGH] detect: N separate SEQ_SCAN nodes on same table, identical joins, different bucket filters. | action: Consolidate N subqueries into 1 scan with CASE WHEN / FILTER() inside aggregates.
- `LEFT_JOIN_FILTER_ORDER_RIGIDITY` [HIGH] detect: LEFT JOIN + WHERE on right-table column (proves right non-null). | action: Convert LEFT→INNER when WHERE proves right non-null, or pre-filter dimension into CTE.
- `AGGREGATE_BELOW_JOIN_BLINDNESS` [HIGH] detect: GROUP BY input rows >> distinct keys, aggregate node sits after join. | action: Pre-aggregate fact table by join key BEFORE dimension join.
- `CROSS_COLUMN_OR_DECOMPOSITION` [MEDIUM] detect: Single scan, OR across DIFFERENT columns, 70%+ rows discarded. CRITICAL: same column in all OR arms → STOP. | action: Split cross-column ORs into UNION ALL branches with targeted single-column filters.

## Additional Intelligence
### AST Feature Detection

- **decorrelate**: 100% match (AGG_AVG, AGG_SUM, CORRELATED_SUB, CTE) (gap: CORRELATED_SUBQUERY_PARALYSIS) [CAUTION: MISSING_FILTER, ALREADY_DECORRELATED]  [SUPPORT: native_or_universal]
- **prefetch_fact_join**: 100% match (AGG_SUM, DATE_DIM, GROUP_BY, STAR_JOIN) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: MAX_2_CHAINS]  [SUPPORT: native_or_universal]
- **sf_shared_scan_decorrelate**: 100% match (AGG_AVG, CORRELATED_SUB, CTE, SCALAR_AGG_SUB_CTE) (gap: CORRELATED_SUBQUERY_PARALYSIS) [SUPPORT: portability_candidate; engines=snowflake]
- **dimension_cte_isolate**: 100% match (DATE_DIM, GROUP_BY, MULTI_TABLE_5+) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: CROSS_JOIN_3_DIMS, UNFILTERED_CTE]  [SUPPORT: native_or_universal]
- **self_join_decomposition**: 100% match (AGG_AVG, CTE, GROUP_BY) (gap: CROSS_CTE_PREDICATE_BLINDNESS)  [SUPPORT: native_or_universal]
