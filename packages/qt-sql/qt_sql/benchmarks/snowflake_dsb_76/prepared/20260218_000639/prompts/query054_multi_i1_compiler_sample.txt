## Role

You are the **Beam Compiler** for SQL optimization on the target runtime dialect.

You receive Battle Damage Assessment (BDA) from 4-16 workers.
Your job is to synthesize the best final DAG attempt(s) from measured outcomes.

Success condition:
- produce semantically safe, executable attempt(s)
- maximize expected plan improvement from proven evidence
- return strict JSON only

Failure behavior:
- if evidence is insufficient for a safe rewrite, return one safe no-change attempt

---

## Prompt Map (cache friendly)

### Phase A — Cached Context (static)
A1. Terminology and decision policy
A2. Dialect reminders and regression registry
A3. Combination hazards
A4. Evidence-first compiler procedure
A5. DAG output contract + validation rules
A6. Worked valid and invalid examples

### Phase B — Query-Specific Input (dynamic; after cache boundary)
B1. Importance stars (1-3)
B2. Original SQL and original plan
B3. IR structure and anchor hashes
B4. BDA table (all probes: status, failure_category, speedup, explain delta, failure reasons)
B5. Worker outputs (full SQL and DAG evidence)
B6. Schema excerpt (tables, columns, keys, indexes)
B7. Engine-specific knowledge profile

---

## Terminology (normative)

- **winner**: probe with status `WIN` and validated semantics.
- **near_miss**: probe with strong plan impact signal but failed a fixable structural gate.
- **foundation_shape**: the primary candidate shape used as merge base.
- **distinct_pathway**: candidate with materially different mechanism from another candidate.
  Different transform family OR different changed-node set OR different join topology.
- **semantic_drift**: any change to result rows, multiplicity, grouping semantics, literals, aliases, order, or limit behavior.

---

## Input Contract

Required Phase B inputs:
- B2 original SQL
- B4 BDA table
- B5 worker outputs

Optional but useful:
- B3 IR map
- B6 schema context
- B7 engine profile

Missing-input handling:
- if any required input is missing or contradictory, return one safe no-change attempt
- set `confidence` to `0.20` or lower
- explain the missing input in `hypothesis`

---

## Decision Priority Ladder

Resolve conflicts in this strict order:
1. semantic safety
2. executability
3. dialect compliance
4. expected speedup

Never trade higher-priority constraints for lower-priority gains.

---

## Regression Registry (hard bans)

Do not emit a compiler attempt that:
- duplicates base scans after replacement
- introduces unfiltered massive CTEs
- builds over-deep fact chains that lock join order
- changes semantics of EXISTS or NOT EXISTS or aggregation multiplicity
- applies same-column OR to UNION ALL by default on PostgreSQL

OR to UNION exception for PostgreSQL:
- only when EXPLAIN evidence shows OR blocks index usage and UNION branches become index scans

---

## Combination Hazards

- Duplicate source introduction when merging candidates.
- Join multiplicity drift from EXISTS to JOIN rewrites.
- CTE fences blocking pushdown and reorder.
- Overlapping predicate edits that must be unified.
- Alias drift where a referenced alias is not defined in scope.

---

## Evidence-First Compiler Procedure

1) Parse BDA and rank candidates by validated evidence.
2) Select one foundation shape from strongest safe evidence.
3) Attempt improvement by adding one compatible tactic only when hazards remain controlled.
4) Consider two-attempt output only if there are two distinct pathways.
5) Run semantic and structural self-check before finalizing JSON.

Checkpoint rules:
- reject any merge that introduces multiplicity risk without explicit guard.
- reject any merge where changed nodes conflict on the same predicate scope.
- prefer fewer changed nodes when expected gains are similar.

Tie-break rules when candidates are close:
1. lower semantic risk
2. fewer changed nodes
3. cleaner dependency graph
4. higher expected explain delta

---

## Distinct Pathway Decision Matrix

Output one attempt when:
- one clearly dominant safe pathway exists, or
- alternatives differ only cosmetically.

Output two attempts when all conditions hold:
- both attempts are semantically safe and executable,
- pathways are distinct by mechanism,
- each has non-overlapping justification from BDA evidence,
- each specifies separate `based_on` evidence.

---

## DAG Output Contract (MUST follow)

Tier-0 output contract:
- response must be valid JSON
- first character must be `{` or `[` (no leading whitespace/newlines)
- top-level value may be:
  - one object (single attempt), or
  - an array of exactly two objects (two attempts)
- no markdown fences, no prose, no commentary

Per-attempt schema:

| key | type | required | constraints |
|---|---|---|---|
| `plan_id` | string | yes | non-empty, unique across attempts |
| `dialect` | string | yes | runtime dialect |
| `hypothesis` | string | yes | evidence-grounded, one to three sentences |
| `target_ir` | string | yes | structural intent summary |
| `dag` | object | yes | must satisfy DAG validation rules |
| `confidence` | number | recommended | range 0.0 to 1.0 |
| `based_on` | string | recommended | comma-separated probe ids |
| `strategy` | string | recommended | concise mechanism summary |
| `expected_explain_delta` | string | recommended | operator-level expected change |

DAG validation rules:
- `dag.order` must be a non-empty array of unique node ids
- `dag.final_node_id` must exist and must appear in `dag.order`
- `dag.nodes` must be a non-empty array
- each node must include `node_id`, `deps`, `outputs`, and `changed`
- changed nodes MUST include full executable SQL in `sql`
- unchanged nodes MUST omit `sql`
- every dependency in `deps` must resolve to a node in `dag.nodes` or a valid base source from runtime context
- preserve literals and output semantics exactly
- preserve final output columns, aliases, order, and limit behavior

---

## Worked Valid Example (single attempt object)

{
  "plan_id": "compile_p1",
  "dialect": "duckdb",
  "confidence": 0.84,
  "based_on": "p03",
  "strategy": "Keep winning decorrelation shape and add multiplicity guard.",
  "hypothesis": "Winning probe removed repeated correlated work. Distinct keyset guard preserves multiplicity and keeps output contract stable.",
  "expected_explain_delta": "Nested-loop correlation operators disappear and one hash join over keyset remains.",
  "target_ir": "Add store_averages node and update final_select join graph.",
  "dag": {
    "order": ["customer_total_return", "store_averages", "final_select"],
    "final_node_id": "final_select",
    "nodes": [
      {
        "node_id": "store_averages",
        "deps": ["customer_total_return"],
        "outputs": ["ctr_store_sk", "avg_return"],
        "changed": true,
        "sql": "SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return FROM customer_total_return GROUP BY ctr_store_sk"
      },
      {
        "node_id": "final_select",
        "deps": ["customer_total_return", "store_averages", "store", "customer"],
        "outputs": ["c_customer_id"],
        "changed": true,
        "sql": "SELECT c_customer_id FROM customer_total_return ctr1 JOIN store_averages sa ON ctr1.ctr_store_sk = sa.ctr_store_sk JOIN store s ON s.s_store_sk = ctr1.ctr_store_sk JOIN customer c ON c.c_customer_sk = ctr1.ctr_customer_sk WHERE s.s_state = 'SD' AND ctr1.ctr_total_return > sa.avg_return ORDER BY c_customer_id LIMIT 100"
      }
    ]
  }
}

---

## Worked Valid Example (two-attempt array)

[
  {
    "plan_id": "compile_p1",
    "dialect": "duckdb",
    "confidence": 0.81,
    "based_on": "p03,p09",
    "strategy": "Decorrelation-first with early aggregate support.",
    "hypothesis": "Primary hotspot is repeated correlated work. This pathway removes repeated scans before aggregation.",
    "expected_explain_delta": "Loop amplification removed and aggregate input reduced.",
    "target_ir": "Update final_select and keep aggregate support node.",
    "dag": {
      "order": ["customer_total_return", "store_averages", "final_select"],
      "final_node_id": "final_select",
      "nodes": [
        {
          "node_id": "customer_total_return",
          "deps": ["store_returns", "date_dim"],
          "outputs": ["ctr_customer_sk", "ctr_store_sk", "ctr_total_return"],
          "changed": false
        },
        {
          "node_id": "store_averages",
          "deps": ["customer_total_return"],
          "outputs": ["ctr_store_sk", "avg_return"],
          "changed": true,
          "sql": "SELECT ctr_store_sk, AVG(ctr_total_return) * 1.2 AS avg_return FROM customer_total_return GROUP BY ctr_store_sk"
        },
        {
          "node_id": "final_select",
          "deps": ["customer_total_return", "store_averages", "store", "customer"],
          "outputs": ["c_customer_id"],
          "changed": true,
          "sql": "SELECT c_customer_id FROM customer_total_return ctr1 JOIN store_averages sa ON ctr1.ctr_store_sk = sa.ctr_store_sk JOIN store s ON s.s_store_sk = ctr1.ctr_store_sk JOIN customer c ON c.c_customer_sk = ctr1.ctr_customer_sk WHERE s.s_state = 'SD' AND ctr1.ctr_total_return > sa.avg_return ORDER BY c_customer_id LIMIT 100"
        }
      ]
    }
  },
  {
    "plan_id": "compile_p2",
    "dialect": "duckdb",
    "confidence": 0.76,
    "based_on": "p11",
    "strategy": "Aggregate-first pathway with safe join topology.",
    "hypothesis": "Secondary pathway pre-aggregates earlier to reduce rows entering the final join spine.",
    "expected_explain_delta": "Aggregate input shrinks before final join operators.",
    "target_ir": "Change customer_total_return shape and keep final_select projection contract.",
    "dag": {
      "order": ["customer_total_return", "final_select"],
      "final_node_id": "final_select",
      "nodes": [
        {
          "node_id": "customer_total_return",
          "deps": ["store_returns", "date_dim"],
          "outputs": ["ctr_customer_sk", "ctr_store_sk", "ctr_total_return"],
          "changed": true,
          "sql": "SELECT sr.sr_customer_sk AS ctr_customer_sk, sr.sr_store_sk AS ctr_store_sk, SUM(sr.sr_fee) AS ctr_total_return FROM store_returns sr JOIN date_dim d ON sr.sr_returned_date_sk = d.d_date_sk WHERE d.d_year = 2000 GROUP BY sr.sr_customer_sk, sr.sr_store_sk"
        },
        {
          "node_id": "final_select",
          "deps": ["customer_total_return", "store", "customer"],
          "outputs": ["c_customer_id"],
          "changed": false
        }
      ]
    }
  }
]

---

## Worked Invalid Example (do not produce)

{
  "plan_id": "compile_bad",
  "dialect": "duckdb",
  "hypothesis": "Fast result",
  "target_ir": "mixed",
  "dag": {
    "order": ["final_select", "final_select"],
    "final_node_id": "missing_node",
    "nodes": [
      {
        "node_id": "final_select",
        "deps": ["unknown_node"],
        "outputs": ["c_customer_id"],
        "changed": true
      }
    ]
  }
}

Why invalid:
- duplicate ids in `dag.order`
- `final_node_id` does not resolve
- unresolved dependency `unknown_node`
- changed node missing required `sql`

Corrective action:
- emit a structurally valid DAG
- include full SQL for each changed node
- resolve all dependencies

---

## Safe No-Change Fallback (required capability)

If evidence is insufficient or required inputs are missing, output one valid no-change attempt:
- keep all nodes `changed: false`
- preserve executable graph structure
- explain missing evidence in `hypothesis`

---

## Cache Boundary
Everything below is query-specific input.

## Query ID
query054_multi_i1

## Runtime Dialect Contract
- target_dialect: snowflake
- runtime_dialect_is_source_of_truth: true
- if static examples conflict, follow runtime dialect behavior

## Importance
- importance_stars: 2
- importance_label: **

## Original SQL
```sql
with my_customers as (
 select distinct c_customer_sk
        , c_current_addr_sk
 from
        ( select cs_sold_date_sk sold_date_sk,
                 cs_bill_customer_sk customer_sk,
                 cs_item_sk item_sk,
                 cs_wholesale_cost wholesale_cost
          from   catalog_sales
          union all
          select ws_sold_date_sk sold_date_sk,
                 ws_bill_customer_sk customer_sk,
                 ws_item_sk item_sk,
                 ws_wholesale_cost wholesale_cost
          from   web_sales
         ) cs_or_ws_sales,
         item,
         date_dim,
         customer
 where   sold_date_sk = d_date_sk
         and item_sk = i_item_sk
         and i_category = 'Electronics'
         and i_class = 'personal'
         and c_customer_sk = cs_or_ws_sales.customer_sk
         and d_moy = 1
         and d_year = 1998
         and wholesale_cost BETWEEN 35 AND 65
         and c_birth_year BETWEEN 1928 AND 1941
 )
 , my_revenue as (
 select c_customer_sk,
        sum(ss_ext_sales_price) as revenue
 from   my_customers,
        store_sales,
        customer_address,
        store,
        date_dim
 where  c_current_addr_sk = ca_address_sk
        and ca_county = s_county
        and ca_state = s_state
        and ss_sold_date_sk = d_date_sk
        and c_customer_sk = ss_customer_sk
        and ss_wholesale_cost BETWEEN 35 AND 65
        and s_state in ('AR','CO','IA'
                    ,'IL','KY','NC'
                    ,'NM','NY','PA'
                    ,'TX')
        and d_month_seq between (select distinct d_month_seq+1
                                 from   date_dim where d_year = 1998 and d_moy = 1)
                           and  (select distinct d_month_seq+3
                                 from   date_dim where d_year = 1998 and d_moy = 1)
 group by c_customer_sk
 )
 , segments as
 (select cast((revenue/50) as int) as segment
  from   my_revenue
 )
  select  segment, count(*) as num_customers, segment*50 as segment_base
 from segments
 group by segment
 order by segment, num_customers
 limit 100;
```

## Original Plan
```
{'GlobalStats': {'partitionsTotal': 155743, 'partitionsAssigned': 153231, 'bytesAssigned': 2596906613760}, 'Operations': [[{'id': 0, 'operation': 'Result', 'expressions': ['DATE_DIM.D_MONTH_SEQ + 1']}, {'id': 3, 'operation': 'Aggregate', 'expressions': ['groupKeys: [DATE_DIM.D_MONTH_SEQ + 1]'], 'parentOperators': [2]}, {'id': 4, 'operation': 'Filter', 'expressions': ['(DATE_DIM.D_YEAR = 1998) AND (DATE_DIM.D_MOY = 1)'], 'parentOperators': [3]}, {'id': 5, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.DATE_DIM'], 'expressions': ['D_MONTH_SEQ', 'D_YEAR', 'D_MOY'], 'partitionsAssigned': 1, 'partitionsTotal': 1, 'bytesAssigned': 2138624, 'parentOperators': [4]}], [{'id': 0, 'operation': 'Result', 'expressions': ['DATE_DIM.D_MONTH_SEQ + 3']}, {'id': 3, 'operation': 'Aggregate', 'expressions': ['groupKeys: [DATE_DIM.D_MONTH_SEQ + 3]'], 'parentOperators': [2]}, {'id': 4, 'operation': 'Filter', 'expressions': ['(DATE_DIM.D_YEAR = 1998) AND (DATE_DIM.D_MOY = 1)'], 'parentOperators': [3]}, {'id': 5, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.DATE_DIM'], 'expressions': ['D_MONTH_SEQ', 'D_YEAR', 'D_MOY'], 'partitionsAssigned': 1, 'partitionsTotal': 1, 'bytesAssigned': 2138624, 'parentOperators': [4]}], [{'id': 0, 'operation': 'Result', 'expressions': ['(SUM(SUM(SUM_INTERNAL(SUM(STORE_SALES.SS_EXT_SALES_PRICE), COUNT(*))))) / 50', 'COUNT(*)', '((SUM(SUM(SUM_INTERNAL(SUM(STORE_SALES.SS_EXT_SALES_PRICE), COUNT(*))))) / 50) * 50']}, {'id': 1, 'operation': 'SortWithLimit', 'expressions': ['sortKey: [(MY_REVENUE.REVENUE) / 50 ASC NULLS LAST, COUNT(*) ASC NULLS LAST]', 'rowCount: 100'], 'parentOperators': [0]}, {'id': 2, 'operation': 'Aggregate', 'expressions': ['aggExprs: [COUNT(*)]', 'groupKeys: [(SUM(SUM(SUM_INTERNAL(SUM(STORE_SALES.SS_EXT_SALES_PRICE), COUNT(*))))) / 50]'], 'parentOperators': [1]}, {'id': 3, 'operation': 'Aggregate', 'expressions': ['aggExprs: [SUM(SUM(SUM_INTERNAL(SUM(STORE_SALES.SS_EXT_SALES_PRICE), COUNT(*))))]', 'groupKeys: [CUSTOMER.C_CUSTOMER_SK]'], 'parentOperators': [2]}, {'id': 4, 'operation': 'Aggregate', 'expressions': ['aggExprs: [SUM(SUM_INTERNAL(SUM(STORE_SALES.SS_EXT_SALES_PRICE), COUNT(*)))]', 'groupKeys: [CUSTOMER.C_CUSTOMER_SK]'], 'parentOperators': [3]}, {'id': 5, 'operation': 'InnerJoin', 'expressions': ['joinKey: (DATE_DIM.D_DATE_SK = STORE_SALES.SS_SOLD_DATE_SK)'], 'parentOperators': [4]}, {'id': 6, 'operation': 'Filter', 'expressions': ['(DATE_DIM.D_MONTH_SEQ >= Subquery(Step1)) AND (DATE_DIM.D_MONTH_SEQ <= Subquery(Step2))'], 'parentOperators': [5]}, {'id': 7, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.DATE_DIM'], 'expressions': ['D_DATE_SK', 'D_MONTH_SEQ'], 'partitionsAssigned': 1, 'partitionsTotal': 1, 'bytesAssigned': 2138624, 'parentOperators': [6]}, {'id': 8, 'operation': 'Aggregate', 'expressions': ['aggExprs: [SUM_INTERNAL(SUM(STORE_SALES.SS_EXT_SALES_PRICE), COUNT(*))]', 'groupKeys: [CUSTOMER.C_CUSTOMER_SK, STORE_SALES.SS_SOLD_DATE_SK]'], 'parentOperators': [5]}, {'id': 9, 'operation': 'InnerJoin', 'expressions': ['joinKey: (CUSTOMER.C_CUSTOMER_SK = STORE_SALES.SS_CUSTOMER_SK)'], 'parentOperators': [8]}, {'id': 10, 'operation': 'Aggregate', 'expressions': ['aggExprs: [COUNT(*)]', 'groupKeys: [CUSTOMER.C_CUSTOMER_SK]'], 'parentOperators': [9]}, {'id': 11, 'operation': 'InnerJoin', 'expressions': ['joinKey: (STORE.S_COUNTY = CUSTOMER_ADDRESS.CA_COUNTY) AND (STORE.S_STATE = CUSTOMER_ADDRESS.CA_STATE)'], 'parentOperators': [10]}, {'id': 12, 'operation': 'Filter', 'expressions': ["(STORE.S_STATE IN 'AR' IN 'CO' IN 'IA' IN 'IL' IN 'KY' IN 'NC' IN 'NM' IN 'NY' IN 'PA' IN 'TX') AND (STORE.S_COUNTY IS NOT NULL) AND (STORE.S_STATE IS NOT NULL)"], 'parentOperators': [11]}, {'id': 13, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.STORE'], 'expressions': ['S_COUNTY', 'S_STATE'], 'partitionsAssigned': 1, 'partitionsTotal': 1, 'bytesAssigned': 135680, 'parentOperators': [12]}, {'id': 14, 'operation': 'Aggregate', 'expressions': ['aggExprs: [COUNT(*)]', 'groupKeys: [CUSTOMER.C_CUSTOMER_SK, CUSTOMER_ADDRESS.CA_COUNTY, CUSTOMER_ADDRESS.CA_STATE]'], 'parentOperators': [11]}, {'id': 15, 'operation': 'InnerJoin', 'expressions': ['joinKey: (CUSTOMER.C_CURRENT_ADDR_SK = CUSTOMER_ADDRESS.CA_ADDRESS_SK)'], 'parentOperators': [14]}, {'id': 16, 'operation': 'Aggregate', 'expressions': ['groupKeys: [CUSTOMER.C_CUSTOMER_SK, CUSTOMER.C_CURRENT_ADDR_SK]'], 'parentOperators': [15]}, {'id': 17, 'operation': 'Aggregate', 'expressions': ['groupKeys: [CUSTOMER.C_CUSTOMER_SK, CUSTOMER.C_CURRENT_ADDR_SK]'], 'parentOperators': [16]}, {'id': 18, 'operation': 'SemiJoin', 'expressions': ['joinKey: (UNION_ALL(CATALOG_SALES.CS_BILL_CUSTOMER_SK, WEB_SALES.WS_BILL_CUSTOMER_SK) = CUSTOMER.C_CUSTOMER_SK)'], 'parentOperators': [17]}, {'id': 19, 'operation': 'Aggregate', 'expressions': ['groupKeys: [UNION_ALL(CATALOG_SALES.CS_BILL_CUSTOMER_SK, WEB_SALES.WS_BILL_CUSTOMER_SK)]'], 'parentOperators': [18]}, {'id': 20, 'operation': 'SemiJoin', 'expressions': ['joinKey: (DATE_DIM.D_DATE_SK = UNION_ALL(CATALOG_SALES.CS_SOLD_DATE_SK, WEB_SALES.WS_SOLD_DATE_SK))'], 'parentOperators': [19]}, {'id': 21, 'operation': 'Aggregate', 'expressions': ['groupKeys: [DATE_DIM.D_DATE_SK]'], 'parentOperators': [20]}, {'id': 22, 'operation': 'Filter', 'expressions': ['(DATE_DIM.D_MOY = 1) AND (DATE_DIM.D_YEAR = 1998)'], 'parentOperators': [21]}, {'id': 23, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.DATE_DIM'], 'expressions': ['D_DATE_SK', 'D_YEAR', 'D_MOY'], 'partitionsAssigned': 1, 'partitionsTotal': 1, 'bytesAssigned': 2138624, 'parentOperators': [22]}, {'id': 24, 'operation': 'Aggregate', 'expressions': ['groupKeys: [UNION_ALL(CATALOG_SALES.CS_BILL_CUSTOMER_SK, WEB_SALES.WS_BILL_CUSTOMER_SK), UNION_ALL(CATALOG_SALES.CS_SOLD_DATE_SK, WEB_SALES.WS_SOLD_DATE_SK)]'], 'parentOperators': [20]}, {'id': 25, 'operation': 'SemiJoin', 'expressions': ['joinKey: (ITEM.I_ITEM_SK = UNION_ALL(CATALOG_SALES.CS_ITEM_SK, WEB_SALES.WS_ITEM_SK))'], 'parentOperators': [24]}, {'id': 26, 'operation': 'Aggregate', 'expressions': ['groupKeys: [ITEM.I_ITEM_SK]'], 'parentOperators': [25]}, {'id': 27, 'operation': 'Filter', 'expressions': ["(ITEM.I_CATEGORY = 'Electronics') AND (ITEM.I_CLASS = 'personal')"], 'parentOperators': [26]}, {'id': 28, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.ITEM'], 'expressions': ['I_ITEM_SK', 'I_CLASS', 'I_CATEGORY'], 'partitionsAssigned': 2, 'partitionsTotal': 2, 'bytesAssigned': 23811584, 'parentOperators': [27]}, {'id': 29, 'operation': 'Aggregate', 'expressions': ['groupKeys: [UNION_ALL(CATALOG_SALES.CS_BILL_CUSTOMER_SK, WEB_SALES.WS_BILL_CUSTOMER_SK), UNION_ALL(CATALOG_SALES.CS_SOLD_DATE_SK, WEB_SALES.WS_SOLD_DATE_SK), UNION_ALL(CATALOG_SALES.CS_ITEM_SK, WEB_SALES.WS_ITEM_SK)]'], 'parentOperators': [25]}, {'id': 30, 'operation': 'UnionAll', 'parentOperators': [29]}, {'id': 31, 'operation': 'Filter', 'expressions': ['(CATALOG_SALES.CS_WHOLESALE_COST >= 35) AND (CATALOG_SALES.CS_WHOLESALE_COST <= 65) AND (CATALOG_SALES.CS_BILL_CUSTOMER_SK IS NOT NULL) AND (CATALOG_SALES.CS_SOLD_DATE_SK IS NOT NULL)'], 'parentOperators': [30]}, {'id': 32, 'operation': 'JoinFilter', 'expressions': ['joinKey: (DATE_DIM.D_DATE_SK = UNION_ALL(CATALOG_SALES.CS_SOLD_DATE_SK, WEB_SALES.WS_SOLD_DATE_SK))'], 'parentOperators': [31]}, {'id': 33, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CATALOG_SALES'], 'expressions': ['CS_SOLD_DATE_SK', 'CS_BILL_CUSTOMER_SK', 'CS_ITEM_SK', 'CS_WHOLESALE_COST'], 'partitionsAssigned': 54721, 'partitionsTotal': 54922, 'bytesAssigned': 920184101376, 'parentOperators': [32]}, {'id': 34, 'operation': 'Filter', 'expressions': ['(WEB_SALES.WS_WHOLESALE_COST >= 35) AND (WEB_SALES.WS_WHOLESALE_COST <= 65) AND (WEB_SALES.WS_BILL_CUSTOMER_SK IS NOT NULL) AND (WEB_SALES.WS_SOLD_DATE_SK IS NOT NULL)'], 'parentOperators': [30]}, {'id': 35, 'operation': 'JoinFilter', 'expressions': ['joinKey: (DATE_DIM.D_DATE_SK = UNION_ALL(CATALOG_SALES.CS_SOLD_DATE_SK, WEB_SALES.WS_SOLD_DATE_SK))'], 'parentOperators': [34]}, {'id': 36, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.WEB_SALES'], 'expressions': ['WS_SOLD_DATE_SK', 'WS_ITEM_SK', 'WS_BILL_CUSTOMER_SK', 'WS_WHOLESALE_COST'], 'partitionsAssigned': 27574, 'partitionsTotal': 27579, 'bytesAssigned': 460956759040, 'parentOperators': [35]}, {'id': 37, 'operation': 'Aggregate', 'expressions': ['groupKeys: [CUSTOMER.C_CUSTOMER_SK, CUSTOMER.C_CURRENT_ADDR_SK]'], 'parentOperators': [18]}, {'id': 38, 'operation': 'Filter', 'expressions': ['(CUSTOMER.C_BIRTH_YEAR >= 1928) AND (CUSTOMER.C_BIRTH_YEAR <= 1941)'], 'parentOperators': [37]}, {'id': 39, 'operation': 'JoinFilter', 'expressions': ['joinKey: (UNION_ALL(CATALOG_SALES.CS_BILL_CUSTOMER_SK, WEB_SALES.WS_BILL_CUSTOMER_SK) = CUSTOMER.C_CUSTOMER_SK)'], 'parentOperators': [38]}, {'id': 40, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CUSTOMER'], 'expressions': ['C_CUSTOMER_SK', 'C_CURRENT_ADDR_SK', 'C_BIRTH_YEAR'], 'partitionsAssigned': 261, 'partitionsTotal': 261, 'bytesAssigned': 2328538624, 'parentOperators': [39]}, {'id': 41, 'operation': 'Aggregate', 'expressions': ['aggExprs: [COUNT(*)]', 'groupKeys: [CUSTOMER_ADDRESS.CA_COUNTY, CUSTOMER_ADDRESS.CA_STATE, CUSTOMER_ADDRESS.CA_ADDRESS_SK]'], 'parentOperators': [15]}, {'id': 42, 'operation': 'Filter', 'expressions': ["(CUSTOMER_ADDRESS.CA_STATE IN 'AR' IN 'CO' IN 'IA' IN 'IL' IN 'KY' IN 'NC' IN 'NM' IN 'NY' IN 'PA' IN 'TX') AND (CUSTOMER_ADDRESS.CA_COUNTY IS NOT NULL) AND (CUSTOMER_ADDRESS.CA_STATE IS NOT NULL)"], 'parentOperators': [41]}, {'id': 43, 'operation': 'JoinFilter', 'expressions': ['joinKey: (STORE.S_COUNTY = CUSTOMER_ADDRESS.CA_COUNTY) AND (STORE.S_STATE = CUSTOMER_ADDRESS.CA_STATE)'], 'parentOperators': [42]}, {'id': 44, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CUSTOMER_ADDRESS'], 'expressions': ['CA_ADDRESS_SK', 'CA_COUNTY', 'CA_STATE'], 'partitionsAssigned': 256, 'partitionsTotal': 256, 'bytesAssigned': 776454656, 'parentOperators': [43]}, {'id': 45, 'operation': 'Aggregate', 'expressions': ['aggExprs: [SUM(STORE_SALES.SS_EXT_SALES_PRICE)]', 'groupKeys: [STORE_SALES.SS_SOLD_DATE_SK, STORE_SALES.SS_CUSTOMER_SK]'], 'parentOperators': [9]}, {'id': 46, 'operation': 'Filter', 'expressions': ['(STORE_SALES.SS_WHOLESALE_COST >= 35) AND (STORE_SALES.SS_WHOLESALE_COST <= 65) AND (STORE_SALES.SS_SOLD_DATE_SK IS NOT NULL) AND (STORE_SALES.SS_CUSTOMER_SK IS NOT NULL)'], 'parentOperators': [45]}, {'id': 47, 'operation': 'JoinFilter', 'expressions': ['joinKey: (DATE_DIM.D_DATE_SK = STORE_SALES.SS_SOLD_DATE_SK)'], 'parentOperators': [46]}, {'id': 48, 'operation': 'TableScan', 'objects': ['SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.STORE_SALES'], 'expressions': ['SS_SOLD_DATE_SK', 'SS_CUSTOMER_SK', 'SS_WHOLESALE_COST', 'SS_EXT_SALES_PRICE'], 'partitionsAssigned': 70412, 'partitionsTotal': 72718, 'bytesAssigned': 1212628258304, 'parentOperators': [47]}]]}
```

## IR Structure + Anchor Hashes
```
S0 [SELECT]
  CTE: my_customers  (via CTE_Q_S0_my_customers)
    FROM: (subquery) cs_or_ws_sales, item, date_dim, customer
    WHERE [39569bb4425260fb]: sold_date_sk = d_date_sk AND item_sk = i_item_sk AND i_category = 'Electronics' AND i_class = 'pe...
  CTE: my_revenue  (via CTE_Q_S0_my_revenue)
    FROM: my_customers, store_sales, customer_address, store, date_dim
    WHERE [da5ee871ab9d7894]: c_current_addr_sk = ca_address_sk AND ca_county = s_county AND ca_state = s_state AND ss_sold_dat...
    GROUP BY: c_customer_sk
  CTE: segments  (via CTE_Q_S0_segments)
    FROM: my_revenue
  MAIN QUERY (via Q_S0)
    FROM: segments
    GROUP BY: segment
    ORDER BY: segment, num_customers

Patch operations (core+advanced): insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree, replace_body, replace_join_condition, replace_select, replace_block_with_cte_pair, wrap_query_with_cte
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Engine-Specific Knowledge
## Dialect Profile (SNOWFLAKE)

**Combined Intelligence Baseline**: P3 (correlated scalar decorrelation) 2/2 (100%) — 23.17x and 7.82x wins on SF10TCL MEDIUM, 3x3 validated.

### Optimizer Strengths (don't fight these)
- `MICRO_PARTITION_PRUNING`: Snowflake's #1 optimization. Functions on filter columns kill pruning. Runtime pruning from CTE values invisible in static EXPLAIN.
- `COLUMN_PRUNING`: Automatic unless final SELECT is *.
- `PREDICATE_PUSHDOWN`: Also does predicate mirroring across join sides.
- `CORRELATED_DECORRELATION`: Do NOT decorrelate simple EXISTS/IN. DOES NOT handle correlated scalar subqueries with aggregation (see gap).

### Known Gaps (exploit these)
- `CORRELATED_SUBQUERY_PARALYSIS` [HIGH] detect: WHERE col > (SELECT agg(col) FROM fact WHERE key = outer.key). Correlated scalar subquery with AVG/SUM/COUNT that re-scans fact table per o… | action: Decompose into CTEs: (1) dimension filter, (2) date-filtered fact rows, (3) per-key aggregate threshold via GROUP BY. JOIN threshold CTE in final query. If inn…

## Analyst Hypothesis
Primary hotspot likely responds to a single-transform rewrite (materialize_cte) based on detected features.

## Analyst Reasoning Trace
- materialize_cte selected as top detected sample transform.

## Equivalence Tier
- exact

## Additional Intelligence
### AST Feature Detection

- **materialize_cte**: 100% match (AGG_COUNT, AGG_SUM, BETWEEN, CTE) [SUPPORT: portability_candidate; engines=duckdb]
- **prefetch_fact_join**: 100% match (AGG_SUM, DATE_DIM, GROUP_BY, STAR_JOIN) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: MAX_2_CHAINS] [SUPPORT: portability_candidate; engines=duckdb]
- **dimension_cte_isolate**: 100% match (DATE_DIM, GROUP_BY, MULTI_TABLE_5+) (gap: CROSS_CTE_PREDICATE_BLINDNESS) [CAUTION: CROSS_JOIN_3_DIMS, UNFILTERED_CTE] [SUPPORT: portability_candidate; engines=duckdb]
- **sf_sk_pushdown_union_all**: 100% match (DATE_DIM, MULTI_CHANNEL, UNION) (gap: PREDICATE_TRANSITIVITY_FAILURE)  [SUPPORT: native_or_universal]
- **sf_sk_pushdown_multi_fact**: 100% match (DATE_DIM, MULTI_TABLE_5+) (gap: PREDICATE_TRANSITIVITY_FAILURE)  [SUPPORT: native_or_universal]


## Probe Summary
1 probes fired, 1 passed validation, 0 showed speedup.

## BDA Table (all probes)

| Probe | Transform | Family | Status | Failure Category | Speedup | Top EXPLAIN Nodes | Model Description | SQL Patch | Error/Notes |
|-------|-----------|--------|--------|------------------|---------|-------------------|-------------------|-----------|-------------|
| sample_p01 | materialize_cte | E | PASS | none | - | - | Shared Materialization: extract repeated subquery patterns into CTEs to avoid recomputation. When the same logical check appears multiple times, compute it once and reference the result. | sample_p01 |  |

## Worker SQL Patches

### sample_p01: materialize_cte (PASS, n/a)
```sql
with my_customers as (
 select distinct c_customer_sk
        , c_current_addr_sk
 from
        ( select cs_sold_date_sk sold_date_sk,
                 cs_bill_customer_sk customer_sk,
                 cs_item_sk item_sk,
                 cs_wholesale_cost wholesale_cost
          from   catalog_sales
          union all
          select ws_sold_date_sk sold_date_sk,
                 ws_bill_customer_sk customer_sk,
                 ws_item_sk item_sk,
                 ws_wholesale_cost wholesale_cost
          from   web_sales
         ) cs_or_ws_sales,
         item,
         date_dim,
         customer
 where   sold_date_sk = d_date_sk
         and item_sk = i_item_sk
         and i_category = 'Electronics'
         and i_class = 'personal'
         and c_customer_sk = cs_or_ws_sales.customer_sk
         and d_moy = 1
         and d_year = 1998
         and wholesale_cost BETWEEN 35 AND 65
         and c_birth_year BETWEEN 1928 AND 1941
 )
 , my_revenue as (
 select c_customer_sk,
        sum(ss_ext_sales_price) as revenue
 from   my_customers,
        store_sales,
        customer_address,
        store,
        date_dim
 where  c_current_addr_sk = ca_address_sk
        and ca_county = s_county
        and ca_state = s_state
        and ss_sold_date_sk = d_date_sk
        and c_customer_sk = ss_customer_sk
        and ss_wholesale_cost BETWEEN 35 AND 65
        and s_state in ('AR','CO','IA'
                    ,'IL','KY','NC'
                    ,'NM','NY','PA'
                    ,'TX')
        and d_month_seq between (select distinct d_month_seq+1
                                 from   date_dim where d_year = 1998 and d_moy = 1)
                           and  (select distinct d_month_seq+3
                                 from   date_dim where d_year = 1998 and d_moy = 1)
 group by c_customer_sk
 )
 , segments as
 (select cast((revenue/50) as int) as segment
  from   my_revenue
 )
  select  segment, count(*) as num_customers, segment*50 as segment_base
 from segments
 group by segment
 order by segment, num_customers
 limit 100;
```
