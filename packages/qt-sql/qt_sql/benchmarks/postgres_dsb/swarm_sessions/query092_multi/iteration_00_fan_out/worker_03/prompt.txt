## Optimization Strategy: aggressive_prefetch_materialize

**Your approach**: Materialize all filtered dimension and fact tables into CTEs first, then join; decompose the self-join pattern by computing the subquery aggregation once and reusing it.

**Focus**: Apply the examples below in service of this strategy. Prioritize this specific approach over generic optimizations.

---

You are a SQL query rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1).

Your goal: rewrite the complete SQL query to maximize execution speed
while preserving exact semantic equivalence (same rows, same columns,
same ordering).

You will receive the full query, its DAG structure showing how CTEs and
subqueries connect, cost analysis per node, and reference examples of
proven rewrites on structurally similar queries.
You may restructure the query freely: create new CTEs, merge existing ones,
push filters across node boundaries, or decompose subqueries.

## Query: query092_multi_w3

```sql
SELECT
  SUM(ws_ext_discount_amt) AS "Excess Discount Amount"
FROM web_sales, item, date_dim
WHERE
  (
    i_manufact_id BETWEEN 341 AND 540 OR i_category IN ('Home', 'Men', 'Music')
  )
  AND i_item_sk = ws_item_sk
  AND d_date BETWEEN '1998-03-13' AND CAST('1998-03-13' AS DATE) + INTERVAL '90 DAY'
  AND d_date_sk = ws_sold_date_sk
  AND ws_wholesale_cost BETWEEN 26 AND 46
  AND ws_ext_discount_amt > (
    SELECT
      1.3 * AVG(ws_ext_discount_amt)
    FROM web_sales, date_dim
    WHERE
      ws_item_sk = i_item_sk
      AND d_date BETWEEN '1998-03-13' AND CAST('1998-03-13' AS DATE) + INTERVAL '90 DAY'
      AND d_date_sk = ws_sold_date_sk
      AND ws_wholesale_cost BETWEEN 26 AND 46
      AND ws_sales_price / ws_list_price BETWEEN 34 * 0.01 AND 49 * 0.01
  )
ORDER BY
  SUM(ws_ext_discount_amt)
LIMIT 100
```

## Query Structure (DAG)

### 1. main_query
**Role**: Root / Output (Definition Order: 0)
**Intent**: Sum web discounts over a 90-day 1998 window for targeted manufacturer/category conditions where discount exceeds an item-specific 1.3x baseline under cost/price-ratio filters.
**Stats**: 100% Cost | ~1k rows processed → 100 rows output
**Flags**: ORDER_BY, LIMIT(100)
**Outputs**: [Excess Discount Amount] — ordered by SUM(ws_ext_discount_amt) ASC
**Dependencies**: web_sales, item (join), date_dim (join)
**Joins**: i_item_sk = ws_item_sk | d_date_sk = ws_sold_date_sk
**Filters**: (i_manufact_id BETWEEN 341 AND 540 OR i_category IN ('Home', 'Men', 'Music')) | d_date BETWEEN '1998-03-13' AND CAST('1998-03-13' AS DATE) + INTERVAL '90 DAY' | ws_wholesale_cost BETWEEN 26 AND 46 | ws_ext_discount_amt > 1.3 * AVG(ws_ext_discount_amt) (per d_date_sk)
**Operators**: SEQ_SCAN[web_sales], SEQ_SCAN[item], SEQ_SCAN[date_dim]
**Key Logic (SQL)**:
```sql
SELECT
  SUM(ws_ext_discount_amt) AS "Excess Discount Amount"
FROM web_sales, item, date_dim
WHERE
  (
    i_manufact_id BETWEEN 341 AND 540 OR i_category IN ('Home', 'Men', 'Music')
  )
  AND i_item_sk = ws_item_sk
  AND d_date BETWEEN '1998-03-13' AND CAST('1998-03-13' AS DATE) + INTERVAL '90 DAY'
  AND d_date_sk = ws_sold_date_sk
  AND ws_wholesale_cost BETWEEN 26 AND 46
  AND ws_ext_discount_amt > (
    SELECT
      1.3 * AVG(ws_ext_discount_amt)
    FROM web_sales, date_dim
    WHERE
      ws_item_sk = i_item_sk
      AND d_date BETWEEN '1998-03-13' AND CAST('1998-03-13' AS DATE) + INTERVAL '90 DAY'
      AND d_date_sk = ws_sold_date_sk
      AND ws_wholesale_cost BETWEEN 26 AND 46
...
```


## Benchmark Learnings

### Effective Transforms
- **materialize_cte**: 50% success rate, 1.80x avg speedup (2 attempts)

### Example Effectiveness
- **pg_dimension_prefetch_star**: 50% led to success (2 recommendations)
- **early_filter_decorrelate**: 33% led to success (3 recommendations)
- **pg_self_join_decomposition**: 0% led to success (2 recommendations)

### Common Error Patterns
- **None**: 1 occurrences
- **execution**: 1 occurrences


## Reference Examples

The following examples are for **pattern reference only**. Do not copy their table names, column names, or literal values into your rewrite. Use only the schema and tables from the target query above.

### 1. pg_materialized_dimension_fact_prefilter (2.68x)

**Principle:** Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.

**BEFORE (slow):**
```sql
select  i_item_desc
      ,w_warehouse_name
      ,d1.d_week_seq
      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo
      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo
      ,count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity
  and d3.d_date > d1.d_date + interval '3 day'
  and hd_buy_potential = '501-1000'
  and d1.d_year = 1998
  and cd_marital_status = 'M'
  and cd_dep_count between 9 and 11
  and i_category IN ('Home', 'Men', 'Music')
  and cs_wholesale_cost BETWEEN 34 AND 54
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk, d_date, d_week_seq FROM date_dim WHERE d_year = 1998
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc FROM item WHERE i_category IN ('Home', 'Men', 'Music')
```
[filtered_cd]:
```sql
SELECT cd_demo_sk FROM customer_demographics WHERE cd_marital_status = 'M' AND cd_dep_count BETWEEN 9 AND 11
```
[filtered_hd]:
```sql
SELECT hd_demo_sk FROM household_demographics WHERE hd_buy_potential = '501-1000'
```
[cs_filtered]:
```sql
SELECT cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_sold_date_sk, cs_ship_date_sk, cs_promo_sk, cs_quantity, cs_wholesale_cost, cs_order_number FROM catalog_sales WHERE cs_wholesale_cost BETWEEN 34 AND 54
```
[main_query]:
```sql
SELECT i.i_item_desc, w.w_warehouse_name, d1.d_week_seq, SUM(CASE WHEN p.p_promo_sk IS NULL THEN 1 ELSE 0 END) AS no_promo, SUM(CASE WHEN p.p_promo_sk IS NOT NULL THEN 1 ELSE 0 END) AS promo, COUNT(*) AS total_cnt FROM cs_filtered cs JOIN inventory inv ON cs.cs_item_sk = inv.inv_item_sk JOIN warehouse w ON w.w_warehouse_sk = inv.inv_warehouse_sk JOIN filtered_item i ON i.i_item_sk = cs.cs_item_sk JOIN filtered_cd cd ON cs.cs_bill_cdemo_sk = cd.cd_demo_sk JOIN filtered_hd hd ON cs.cs_bill_hdemo_sk = hd.hd_demo_sk JOIN filtered_date d1 ON cs.cs_sold_date_sk = d1.d_date_sk JOIN date_dim d2 ON inv.inv_date_sk = d2.d_date_sk JOIN date_dim d3 ON cs.cs_ship_date_sk = d3.d_date_sk LEFT OUTER JOIN promotion p ON cs.cs_promo_sk = p.p_promo_sk LEFT OUTER JOIN catalog_returns cr ON cr.cr_item_sk = cs.cs_item_sk AND cr.cr_order_number = cs.cs_order_number WHERE d1.d_week_seq = d2.d_week_seq AND inv.inv_quantity_on_hand < cs.cs_quantity AND d3.d_date > d1.d_date + INTERVAL '3 day' GROUP BY i.i_item_desc, w.w_warehouse_name, d1.d_week_seq ORDER BY total_cnt DESC, i.i_item_desc, w.w_warehouse_name, d1.d_week_seq LIMIT 100
```

### 2. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

### 3. inline_decorrelate_materialized (timeout_rescue)

**Principle:** Inline Decorrelation with MATERIALIZED CTEs: When a WHERE clause contains a correlated scalar subquery (e.g., col > (SELECT 1.3 * avg(col) FROM ... WHERE correlated_key = outer.key)), PostgreSQL re-executes the subquery per outer row. Fix: decompose into 3 MATERIALIZED CTEs — (1) pre-filter dimension table, (2) pre-filter fact table by date range, (3) compute per-key aggregate threshold from filtered data — then JOIN the threshold CTE in the final query. MATERIALIZED keyword prevents PG from inlining the CTEs back into correlated form.

**BEFORE (slow):**
```sql
select  sum(cs_ext_discount_amt)  as "excess discount amount"
from
   catalog_sales
   ,item
   ,date_dim
where
(i_manufact_id in (1, 78, 97, 516, 521)
or i_manager_id BETWEEN 25 and 54)
and i_item_sk = cs_item_sk
and d_date between '1999-03-07' and
        cast('1999-03-07' as date) + interval '90 day'
and d_date_sk = cs_sold_date_sk
and cs_ext_discount_amt
     > (
         select
            1.3 * avg(cs_ext_discount_amt)
         from
            catalog_sales
           ,date_dim
         where
              cs_item_sk = i_item_sk
          and d_date between '1999-03-07' and
                             cast('1999-03-07' as date) + interval '90 day'
          and d_date_sk = cs_sold_date_sk
          and cs_list_price between 16 and 45
          and cs_sales_price / cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01
      )
order by sum(cs_ext_discount_amt)
limit 100;
```

**AFTER (fast):**
```sql
WITH filtered_items AS MATERIALIZED (
    SELECT i_item_sk
    FROM item
    WHERE i_manufact_id IN (1, 78, 97, 516, 521)
       OR i_manager_id BETWEEN 25 AND 54
),
date_filtered_sales AS MATERIALIZED (
    SELECT cs.cs_item_sk, cs.cs_ext_discount_amt,
           cs.cs_list_price, cs.cs_sales_price
    FROM catalog_sales cs
    JOIN date_dim d ON d.d_date_sk = cs.cs_sold_date_sk
    WHERE d.d_date BETWEEN '1999-03-07' AND cast('1999-03-07' as date) + interval '90 day'
),
item_avg_discount AS MATERIALIZED (
    SELECT dfs.cs_item_sk,
           1.3 * avg(dfs.cs_ext_discount_amt) AS threshold
    FROM date_filtered_sales dfs
    JOIN filtered_items fi ON fi.i_item_sk = dfs.cs_item_sk
    WHERE dfs.cs_list_price BETWEEN 16 AND 45
      AND dfs.cs_sales_price / dfs.cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01
    GROUP BY dfs.cs_item_sk
)
SELECT sum(dfs.cs_ext_discount_amt) AS "excess discount amount"
FROM date_filtered_sales dfs
JOIN item_avg_discount iad ON iad.cs_item_sk = dfs.cs_item_sk
WHERE dfs.cs_ext_discount_amt > iad.threshold
ORDER BY 1
LIMIT 100;
```

## Filter Pushdown Heuristic

SQL optimizers CANNOT push filters through multi-level CTEs, window functions, DISTINCT, GROUP BY, or UNION ALL boundaries. You must move them manually. Apply these rules:

1. **Static filter on CTE output → move inside CTE**
   If the final SELECT (or an outer CTE) filters on a column produced by an inner CTE with a literal/constant value, move that WHERE clause inside the CTE definition. This reduces the intermediate result set.

2. **Date/dimension filter → push to earliest scan**
   If a date or dimension filter appears in the final query, push it into the CTE that first joins with the dimension table. Pre-filtering the dimension table into a small CTE and joining early is even better.

3. **Repeated filter across CTEs → extract shared CTE**
   If the same filter predicate (e.g., `d_year = 2001`) appears in multiple subqueries or CTEs, extract the filtered result into one shared CTE and reference it everywhere.

4. **Filter after GROUP BY → push before GROUP BY**
   If a HAVING clause or post-aggregation filter can be expressed as a pre-aggregation WHERE, move it before GROUP BY to reduce rows entering the aggregation.

5. **Filter after window function → cannot push through**
   Window functions require the full partition to compute. Do NOT push filters before window functions unless the filter is on partition columns only (which narrows partitions without changing results).

## Constraints

### CRITICAL — Correctness Guards

**COMPLETE_OUTPUT**
The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original.

**CTE_COLUMN_COMPLETENESS**
CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.

**KEEP_EXISTS_AS_EXISTS**
Preserve EXISTS/NOT EXISTS subqueries as-is. Do NOT convert them to IN/NOT IN or to JOINs — this risks NULL-handling semantic changes and can introduce duplicate rows.

**LITERAL_PRESERVATION**
CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

**NO_CROSS_JOIN_DIMENSIONS**
NEVER combine multiple dimension tables into a single CTE via CROSS JOIN, Cartesian product, or JOIN ON TRUE. Even small dimensions (30 dates × 200 items × 20 promos = 120K rows) create huge intermediate results that prevent index use on fact tables. Always keep each dimension as a SEPARATE CTE: filtered_date AS (...), filtered_item AS (...), filtered_promotion AS (...). This was validated at 3.32x with separate CTEs vs 0.0076x with a merged CROSS JOIN CTE.

**NO_MATERIALIZE_EXISTS**
Keep EXISTS and NOT EXISTS as-is — they use semi-join short-circuiting that stops scanning after the first match. Converting them to materialized CTEs (e.g., WITH cte AS (SELECT DISTINCT ... FROM large_table)) forces a full table scan, which is catastrophically slower (0.14x observed on Q16). When you see EXISTS, preserve it.

**OR_TO_UNION_SELF_JOIN**
Never apply or_to_union when the query contains a self-join (the same table appears twice with different aliases). Splitting self-join queries into UNION branches forces each branch to independently perform the self-join, doubling or tripling execution time. Observed 0.51x regression on Q23.

**PG_OR_TO_UNION_BLOCK**
POSTGRESQL RULE: NEVER use OR→UNION on PostgreSQL. PostgreSQL handles OR conditions efficiently via BitmapOr index scans in a single pass. Converting OR to UNION ALL forces multiple scans of fact tables and causes catastrophic regressions (0.21x-0.26x observed on DSB benchmark). Keep the original OR structure.

**SEMANTIC_EQUIVALENCE**
The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set — even by one row, one column, or a different sort order — is WRONG and will be REJECTED.

### HIGH — Performance and Style Rules

**MIN_BASELINE_THRESHOLD**
If the query execution plan shows very fast runtime (under 100ms), be conservative with CTE-based transforms. Each CTE adds materialization overhead (hash table creation, intermediate result storage). On fast queries, this overhead can exceed the filtering benefit. Prefer minimal changes or no change over adding multiple CTEs to an already-fast query.

**NO_MATERIALIZED_KEYWORD_PG**
Do NOT use the AS MATERIALIZED keyword on CTEs. Write plain CTEs: 'name AS (SELECT ...)'. PostgreSQL automatically materializes CTEs when beneficial. Forcing materialization on small dimension CTEs (< 1000 rows) adds temp-table I/O overhead that causes regressions (0.69x observed). The proven gold examples use plain CTEs without MATERIALIZED.

**NO_UNFILTERED_DIMENSION_CTE**
Every CTE you create must include a WHERE clause that actually reduces row count. Selecting fewer columns is not filtering — the CTE still materializes every row. If a dimension table has no predicate to push down, leave it as a direct join in the main query instead of wrapping it in a CTE.

**OR_TO_UNION_GUARD**
Only apply or_to_union when (a) the OR branches involve different tables or fundamentally different access paths — never when all branches filter the same column (e.g., t_hour ranges), since the optimizer already handles same-column ORs efficiently in a single scan — and (b) the result is 3 or fewer UNION ALL branches. Nested ORs that would expand into 4+ branches (e.g., 3 conditions x 3 values = 9 combinations) must be left as-is. Violating these rules causes 0.23x–0.59x regressions from multiplied fact table scans.

**PG_CTE_DUPLICATION_BLOCK**
POSTGRESQL RULE: NEVER duplicate a CTE body to push a single-column filter inside. If the original has one CTE referenced multiple times, keep it as one CTE and filter in the WHERE clause. PostgreSQL materializes CTEs, so computing an expensive multi-table join twice is always worse than computing once and filtering. Observed 0.65x regression on 18-table CTE duplication.

**PG_EXISTS_TO_IN_BLOCK**
POSTGRESQL RULE: NEVER convert EXISTS/NOT EXISTS to IN/NOT IN with materialized CTEs. PostgreSQL uses efficient semi-join with early termination for EXISTS. Materializing DISTINCT keys from fact tables forces full scans and loses the early-termination benefit. Observed 0.50x-0.86x regressions.

**PREFETCH_MULTI_FACT_CHAIN**
When using prefetch_fact_join, do not create more than 2 cascading CTEs that each reference a fact table (store_sales, catalog_sales, web_sales, etc.). Each CTE in the chain materializes a large intermediate result. Observed 0.78x regression on Q4 from 3 cascading fact CTEs.

**REMOVE_REPLACED_CTES**
When creating replacement CTEs, overwrite the original by using the same node_id in your rewrite_sets, or ensure the original is removed from the WITH clause. Every CTE in the final query should be actively used — dead CTEs still get materialized and waste resources (caused 0.49x on Q31, 0.68x on Q74).

**SINGLE_PASS_AGGREGATION_LIMIT**
When applying single_pass_aggregation (consolidating repeated scans into CASE WHEN aggregates), use at most 8 CASE branches. Beyond 8 branches, the per-row CASE evaluation overhead can negate the benefit of reducing table scans. If the original query has more than 8 distinct filter conditions, keep some scans separate rather than forcing all into one pass.

**UNION_CTE_SPLIT_MUST_REPLACE**
When applying union_cte_split (splitting UNION into CTEs), the original UNION must be eliminated from the main query. The main query should reference the split CTEs, not duplicate the UNION branches. If the rewritten query has more UNION ALL operations than the original, the rewrite is incorrect.

**DECORRELATE_MUST_FILTER_FIRST**
When decorrelating a correlated subquery into a JOIN, ensure all original WHERE filters are preserved in the replacement CTE or JOIN condition. A decorrelation without selective filters creates a cross-product that is larger than the original per-row correlated execution. The replacement CTE must filter to at most the same cardinality as the original subquery.

**DIMENSION_CTE_SAME_COLUMN_OR**
Do not create dimension CTEs to isolate OR conditions that filter the same column. The optimizer handles same-column ORs efficiently in a single scan. Only apply dimension_cte_isolate when filters span different columns or different dimension tables.

**EARLY_FILTER_CTE_BEFORE_CHAIN**
When creating an early_filter CTE, ensure it is actually referenced in the main query chain. The original unfiltered table reference must be replaced with the CTE reference. Do not create CTEs that filter a table if the main query still joins the original unfiltered table — this adds overhead without benefit.

**EXPLICIT_JOINS**
Convert comma-separated implicit joins to explicit JOIN ... ON syntax. This gives the optimizer better join-order freedom.

**PG_DATE_CTE_CAUTION**
POSTGRESQL RULE: date_cte_isolate is ONLY beneficial when combined with converting comma-joins to explicit JOINs on star-schema queries. DO NOT use it on queries with EXISTS/NOT EXISTS (kills semi-join), INTERSECT/EXCEPT (adds CTE overhead per branch), or when the query already has efficient CTEs. If applying to UNION ALL branches, apply to ALL or NONE.

**PG_LOOSE_PREFILTER_BLOCK**
POSTGRESQL RULE: Do NOT pre-filter fact tables into CTEs when the WHERE has correlated OR conditions (the union/superset filter materializes too many rows, 0.79x regression). BUT DO pre-filter fact tables when the query has expensive non-equi joins (quantity comparisons, date arithmetic) - reducing the fact table before these joins is highly effective (2.68x win on Q072).

### CRITICAL — Correctness Guards (repeated for emphasis)

**COMPLETE_OUTPUT**
The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original.

**CTE_COLUMN_COMPLETENESS**
CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.

**KEEP_EXISTS_AS_EXISTS**
Preserve EXISTS/NOT EXISTS subqueries as-is. Do NOT convert them to IN/NOT IN or to JOINs — this risks NULL-handling semantic changes and can introduce duplicate rows.

**LITERAL_PRESERVATION**
CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

**NO_CROSS_JOIN_DIMENSIONS**
NEVER combine multiple dimension tables into a single CTE via CROSS JOIN, Cartesian product, or JOIN ON TRUE. Even small dimensions (30 dates × 200 items × 20 promos = 120K rows) create huge intermediate results that prevent index use on fact tables. Always keep each dimension as a SEPARATE CTE: filtered_date AS (...), filtered_item AS (...), filtered_promotion AS (...). This was validated at 3.32x with separate CTEs vs 0.0076x with a merged CROSS JOIN CTE.

**NO_MATERIALIZE_EXISTS**
Keep EXISTS and NOT EXISTS as-is — they use semi-join short-circuiting that stops scanning after the first match. Converting them to materialized CTEs (e.g., WITH cte AS (SELECT DISTINCT ... FROM large_table)) forces a full table scan, which is catastrophically slower (0.14x observed on Q16). When you see EXISTS, preserve it.

**OR_TO_UNION_SELF_JOIN**
Never apply or_to_union when the query contains a self-join (the same table appears twice with different aliases). Splitting self-join queries into UNION branches forces each branch to independently perform the self-join, doubling or tripling execution time. Observed 0.51x regression on Q23.

**PG_OR_TO_UNION_BLOCK**
POSTGRESQL RULE: NEVER use OR→UNION on PostgreSQL. PostgreSQL handles OR conditions efficiently via BitmapOr index scans in a single pass. Converting OR to UNION ALL forces multiple scans of fact tables and causes catastrophic regressions (0.21x-0.26x observed on DSB benchmark). Keep the original OR structure.

**SEMANTIC_EQUIVALENCE**
The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set — even by one row, one column, or a different sort order — is WRONG and will be REJECTED.

## Output

Return the complete rewritten SQL query. The query must be syntactically
valid and ready to execute.

### Column Completeness Contract

Your rewritten query MUST produce **exactly** these output columns (same names, same order):

  1. `Excess Discount Amount`

Do NOT add, remove, or rename any columns. The result set schema must be identical to the original query.

```sql
-- Your rewritten query here
```

After the SQL, briefly explain what you changed:

```
Changes: <1-2 sentence summary of the rewrite>
Expected speedup: <estimate>
```

Now output your rewritten SQL: