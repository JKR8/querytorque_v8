## Optimization Strategy: novel_intersect_transform

**Your approach**: Transform the INTERSECT operations to EXISTS or IN subqueries, restructure the cross_items CTE to reduce set operations, and apply structural transforms to the year comparison logic.

**Focus**: Apply the examples below in service of this strategy. Prioritize this specific approach over generic optimizations.

---

You are a SQL query rewrite engine for PostgreSQL v16.11-0ubuntu0.24.04.1).

Your goal: rewrite the complete SQL query to maximize execution speed
while preserving exact semantic equivalence (same rows, same columns,
same ordering).

You will receive the full query, its DAG structure showing how CTEs and
subqueries connect, cost analysis per node, and reference examples of
proven rewrites on structurally similar queries.
You may restructure the query freely: create new CTEs, merge existing ones,
push filters across node boundaries, or decompose subqueries.

## Query: query014_multi_w4

```sql
WITH cross_items AS (
  SELECT
    i_item_sk AS ss_item_sk
  FROM item, (
    SELECT
      iss.i_brand_id AS brand_id,
      iss.i_class_id AS class_id,
      iss.i_category_id AS category_id
    FROM store_sales, item AS iss, date_dim AS d1
    WHERE
      ss_item_sk = iss.i_item_sk
      AND ss_sold_date_sk = d1.d_date_sk
      AND d1.d_year BETWEEN 2000 AND 2000 + 2
      AND i_category IN ('Electronics', 'Home', 'Men')
      AND i_manager_id BETWEEN 25 AND 34
      AND ss_wholesale_cost BETWEEN 34 AND 54
    INTERSECT
    SELECT
      ics.i_brand_id,
      ics.i_class_id,
      ics.i_category_id
    FROM catalog_sales, item AS ics, date_dim AS d2
    WHERE
      cs_item_sk = ics.i_item_sk
      AND cs_sold_date_sk = d2.d_date_sk
      AND d2.d_year BETWEEN 2000 AND 2000 + 2
      AND i_category IN ('Electronics', 'Home', 'Men')
      AND i_manager_id BETWEEN 25 AND 34
      AND cs_wholesale_cost BETWEEN 34 AND 54
    INTERSECT
    SELECT
      iws.i_brand_id,
      iws.i_class_id,
      iws.i_category_id
    FROM web_sales, item AS iws, date_dim AS d3
    WHERE
      ws_item_sk = iws.i_item_sk
      AND ws_sold_date_sk = d3.d_date_sk
      AND ws_wholesale_cost BETWEEN 34 AND 54
      AND d3.d_year BETWEEN 2000 AND 2000 + 2
  ) AS x
  WHERE
    i_brand_id = brand_id
    AND i_class_id = class_id
    AND i_category_id = category_id
    AND i_category IN ('Electronics', 'Home', 'Men')
    AND i_manager_id BETWEEN 25 AND 34
), avg_sales AS (
  SELECT
    AVG(quantity * list_price) AS average_sales
  FROM (
    SELECT
      ss_quantity AS quantity,
      ss_list_price AS list_price
    FROM store_sales, date_dim
    WHERE
      ss_sold_date_sk = d_date_sk
      AND d_year BETWEEN 2000 AND 2000 + 2
      AND ss_wholesale_cost BETWEEN 34 AND 54
    UNION ALL
    SELECT
      cs_quantity AS quantity,
      cs_list_price AS list_price
    FROM catalog_sales, date_dim
    WHERE
      cs_sold_date_sk = d_date_sk
      AND d_year BETWEEN 2000 AND 2000 + 2
      AND cs_wholesale_cost BETWEEN 34 AND 54
    UNION ALL
    SELECT
      ws_quantity AS quantity,
      ws_list_price AS list_price
    FROM web_sales, date_dim
    WHERE
      ws_sold_date_sk = d_date_sk
      AND ws_wholesale_cost BETWEEN 34 AND 54
      AND d_year BETWEEN 2000 AND 2000 + 2
  ) AS x
)
SELECT
  this_year.channel AS ty_channel,
  this_year.i_brand_id AS ty_brand,
  this_year.i_class_id AS ty_class,
  this_year.i_category_id AS ty_category,
  this_year.sales AS ty_sales,
  this_year.number_sales AS ty_number_sales,
  last_year.channel AS ly_channel,
  last_year.i_brand_id AS ly_brand,
  last_year.i_class_id AS ly_class,
  last_year.i_category_id AS ly_category,
  last_year.sales AS ly_sales,
  last_year.number_sales AS ly_number_sales
FROM (
  SELECT
    'store' AS channel,
    i_brand_id,
    i_class_id,
    i_category_id,
    SUM(ss_quantity * ss_list_price) AS sales,
    COUNT(*) AS number_sales
  FROM store_sales, item, date_dim
  WHERE
    ss_item_sk IN (
      SELECT
        ss_item_sk
      FROM cross_items
    )
    AND ss_item_sk = i_item_sk
    AND ss_sold_date_sk = d_date_sk
    AND d_week_seq = (
      SELECT
        d_week_seq
      FROM date_dim
      WHERE
        d_year = 2000 + 1 AND d_moy = 12 AND d_dom = 17
    )
    AND i_category IN ('Electronics', 'Home', 'Men')
    AND i_manager_id BETWEEN 25 AND 34
    AND ss_wholesale_cost BETWEEN 34 AND 54
  GROUP BY
    i_brand_id,
    i_class_id,
    i_category_id
  HAVING
    SUM(ss_quantity * ss_list_price) > (
      SELECT
        average_sales
      FROM avg_sales
    )
) AS this_year, (
  SELECT
    'store' AS channel,
    i_brand_id,
    i_class_id,
    i_category_id,
    SUM(ss_quantity * ss_list_price) AS sales,
    COUNT(*) AS number_sales
  FROM store_sales, item, date_dim
  WHERE
    ss_item_sk IN (
      SELECT
        ss_item_sk
      FROM cross_items
    )
    AND ss_item_sk = i_item_sk
    AND ss_sold_date_sk = d_date_sk
    AND d_week_seq = (
      SELECT
        d_week_seq
      FROM date_dim
      WHERE
        d_year = 2000 AND d_moy = 12 AND d_dom = 17
    )
    AND i_category IN ('Electronics', 'Home', 'Men')
    AND ss_wholesale_cost BETWEEN 34 AND 54
    AND i_manager_id BETWEEN 25 AND 34
  GROUP BY
    i_brand_id,
    i_class_id,
    i_category_id
  HAVING
    SUM(ss_quantity * ss_list_price) > (
      SELECT
        average_sales
      FROM avg_sales
    )
) AS last_year
WHERE
  this_year.i_brand_id = last_year.i_brand_id
  AND this_year.i_class_id = last_year.i_class_id
  AND this_year.i_category_id = last_year.i_category_id
ORDER BY
  this_year.channel,
  this_year.i_brand_id,
  this_year.i_class_id,
  this_year.i_category_id
LIMIT 100
```

## Query Structure (DAG)

### 1. cross_items
**Role**: CTE (Definition Order: 0)
**Intent**: Build the shared item key set that satisfies cross-channel product constraints before downstream year-over-year comparisons.
**Stats**: 33% Cost | ~1k rows
**Outputs**: [ss_item_sk]
**Dependencies**: item, web_sales (join), item AS iws (join), date_dim AS d3 (join), store_sales (join), item AS iss (join), date_dim AS d1 (join), catalog_sales (join), item AS ics (join), date_dim AS d2 (join)
**Joins**: i_brand_id = brand_id | i_class_id = class_id | i_category_id = category_id
**Filters**: i_category IN ('Electronics', 'Home', 'Men') | i_manager_id BETWEEN 25 AND 34
**Operators**: SEQ_SCAN[item], SEQ_SCAN[web_sales], SEQ_SCAN[item]
**Key Logic (SQL)**:
```sql
SELECT
  i_item_sk AS ss_item_sk
FROM item, (
  SELECT
    iss.i_brand_id AS brand_id,
    iss.i_class_id AS class_id,
    iss.i_category_id AS category_id
  FROM store_sales, item AS iss, date_dim AS d1
  WHERE
    ss_item_sk = iss.i_item_sk
    AND ss_sold_date_sk = d1.d_date_sk
    AND d1.d_year BETWEEN 2000 AND 2000 + 2
    AND i_category IN ('Electronics', 'Home', 'Men')
    AND i_manager_id BETWEEN 25 AND 34
    AND ss_wholesale_cost BETWEEN 34 AND 54
  INTERSECT
  SELECT
    ics.i_brand_id,
    ics.i_class_id,
    ics.i_category_id
...
```

### 2. avg_sales
**Role**: CTE (Definition Order: 0)
**Intent**: Compute a multi-channel average sales baseline used as a threshold for qualifying grouped results.
**Stats**: 33% Cost | ~1k rows
**Flags**: UNION_ALL
**Outputs**: [average_sales]
**Dependencies**: web_sales, date_dim, store_sales, catalog_sales
**Joins**: ws_sold_date_sk = d_date_sk
**Filters**: ws_wholesale_cost BETWEEN 34 AND 54 | d_year BETWEEN 2000 AND 2000 + 2
**Operators**: SEQ_SCAN[web_sales], SEQ_SCAN[date_dim], SEQ_SCAN[store_sales]
**Key Logic (SQL)**:
```sql
SELECT
  AVG(quantity * list_price) AS average_sales
FROM (
  SELECT
    ss_quantity AS quantity,
    ss_list_price AS list_price
  FROM store_sales, date_dim
  WHERE
    ss_sold_date_sk = d_date_sk
    AND d_year BETWEEN 2000 AND 2000 + 2
    AND ss_wholesale_cost BETWEEN 34 AND 54
  UNION ALL
  SELECT
    cs_quantity AS quantity,
    cs_list_price AS list_price
  FROM catalog_sales, date_dim
  WHERE
    cs_sold_date_sk = d_date_sk
    AND d_year BETWEEN 2000 AND 2000 + 2
    AND cs_wholesale_cost BETWEEN 34 AND 54
...
```

### 3. main_query
**Role**: Root / Output (Definition Order: 1)
**Intent**: Find product hierarchies sold across all three channels under shared category/manager/cost filters, then compare store sales and counts between matched December weeks in 2000 and 2001.
**Stats**: 33% Cost | ~1k rows processed → 100 rows output
**Flags**: GROUP_BY, ORDER_BY, LIMIT(100)
**Outputs**: [ty_channel, ty_brand, ty_class, ty_category, ty_sales, ty_number_sales, ly_channel, ly_brand, ly_class, ly_category, ...] — ordered by this_year.channel ASC, this_year.i_brand_id ASC, this_year.i_class_id ASC, this_year.i_category_id ASC
**Dependencies**: store_sales, item, date_dim, avg_sales, cross_items
**Joins**: this_year.i_brand_id = last_year.i_brand_id | this_year.i_class_id = last_year.i_class_id | this_year.i_category_id = last_year.i_category_id
**Operators**: HASH_GROUP_BY, HASH_JOIN, SEQ_SCAN[store_sales], SEQ_SCAN[item], SEQ_SCAN[date_dim]
**Key Logic (SQL)**:
```sql
SELECT
  this_year.channel AS ty_channel,
  this_year.i_brand_id AS ty_brand,
  this_year.i_class_id AS ty_class,
  this_year.i_category_id AS ty_category,
  this_year.sales AS ty_sales,
  this_year.number_sales AS ty_number_sales,
  last_year.channel AS ly_channel,
  last_year.i_brand_id AS ly_brand,
  last_year.i_class_id AS ly_class,
  last_year.i_category_id AS ly_category,
  last_year.sales AS ly_sales,
  last_year.number_sales AS ly_number_sales
FROM (
  SELECT
    'store' AS channel,
    i_brand_id,
    i_class_id,
    i_category_id,
    SUM(ss_quantity * ss_list_price) AS sales,
...
```

### Edges
- avg_sales → main_query
- avg_sales → main_query
- cross_items → main_query
- cross_items → main_query


## Benchmark Learnings

### Effective Transforms
- **materialize_cte**: 50% success rate, 1.80x avg speedup (2 attempts)

### Example Effectiveness
- **early_filter_decorrelate**: 50% led to success (2 recommendations)
- **pg_dimension_prefetch_star**: 50% led to success (2 recommendations)

### Common Error Patterns
- **None**: 1 occurrences


## Reference Examples

The following examples are for **pattern reference only**. Do not copy their table names, column names, or literal values into your rewrite. Use only the schema and tables from the target query above.

### 1. pg_self_join_decomposition (3.93x)

**Principle:** Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.

**BEFORE (slow):**
```sql
select 
	s_store_name,
	i_item_desc,
	sc.revenue,
	i_current_price,
	i_wholesale_cost,
	i_brand
 from store, item,
     (select ss_store_sk, avg(revenue) as ave
	from
	    (select  ss_store_sk, ss_item_sk,
		     sum(ss_sales_price) as revenue
		from store_sales, date_dim
		where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
   and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
		group by ss_store_sk, ss_item_sk) sa
	group by ss_store_sk) sb,
     (select  ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
	from store_sales, date_dim
	where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1213+11
  and ss_sales_price / ss_list_price BETWEEN 38 * 0.01 AND 48 * 0.01
	group by ss_store_sk, ss_item_sk) sc
 where sb.ss_store_sk = sc.ss_store_sk and
       sc.revenue <= 0.1 * sb.ave and
       s_store_sk = sc.ss_store_sk and
       i_item_sk = sc.ss_item_sk
       and i_manager_id BETWEEN 32 and 36
       and s_state in ('TN','TX','VA')
 order by s_store_name, i_item_desc
limit 100;
```

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

### 2. early_filter_decorrelate (1.13x)

**Principle:** Early Selection + Decorrelation: push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN.

**BEFORE (slow):**
```sql
WITH customer_total_return AS (
  SELECT sr_customer_sk AS ctr_customer_sk,
         sr_store_sk AS ctr_store_sk,
         sr_reason_sk AS ctr_reason_sk,
         SUM(SR_REFUNDED_CASH) AS ctr_total_return
  FROM store_returns, date_dim
  WHERE sr_returned_date_sk = d_date_sk
    AND d_year = 2001
    AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295
  GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1, store, customer, customer_demographics
WHERE ctr1.ctr_total_return > (
    SELECT AVG(ctr_total_return) * 1.2
    FROM customer_total_return ctr2
    WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk
  )
  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31
  AND s_store_sk = ctr1.ctr_store_sk
  AND s_state IN ('MI', 'NC', 'WI')
  AND ctr1.ctr_customer_sk = c_customer_sk
  AND c_current_cdemo_sk = cd_demo_sk
  AND cd_marital_status IN ('W', 'W')
  AND cd_education_status IN ('4 yr Degree', 'College')
  AND cd_gender = 'M'
  AND c_birth_month = 5
  AND c_birth_year BETWEEN 1950 AND 1956
ORDER BY c_customer_id
LIMIT 100
```

**AFTER (fast):**
```sql
WITH customer_total_return AS (
    SELECT sr_customer_sk AS ctr_customer_sk,
           sr_store_sk AS ctr_store_sk,
           sr_reason_sk AS ctr_reason_sk,
           SUM(SR_REFUNDED_CASH) AS ctr_total_return
    FROM store_returns
    JOIN date_dim ON sr_returned_date_sk = d_date_sk
    JOIN store ON sr_store_sk = s_store_sk
    WHERE d_year = 2001
      AND s_state IN ('MI', 'NC', 'WI')
      AND sr_return_amt / sr_return_quantity BETWEEN 236 AND 295
    GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
),
store_thresholds AS (
    SELECT ctr_store_sk,
           AVG(ctr_total_return) * 1.2 AS avg_limit
    FROM customer_total_return
    GROUP BY ctr_store_sk
)
SELECT c_customer_id
FROM customer_total_return ctr1
JOIN store_thresholds st ON ctr1.ctr_store_sk = st.ctr_store_sk
JOIN customer ON ctr1.ctr_customer_sk = c_customer_sk
JOIN customer_demographics ON c_current_cdemo_sk = cd_demo_sk
JOIN store s ON ctr1.ctr_store_sk = s.s_store_sk
WHERE ctr1.ctr_total_return > st.avg_limit
  AND ctr1.ctr_reason_sk BETWEEN 28 AND 31
  AND s.s_state IN ('MI', 'NC', 'WI')
  AND cd_marital_status = 'W'
  AND cd_education_status IN ('4 yr Degree', 'College')
  AND cd_gender = 'M'
  AND c_birth_month = 5
  AND c_birth_year BETWEEN 1950 AND 1956
ORDER BY c_customer_id
LIMIT 100
```

### 3. pg_dimension_prefetch_star (3.32x)

**Principle:** Multi-Dimension Prefetch (PG): pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax. PostgreSQL's optimizer gets better cardinality estimates from pre-materialized small dimension results.

**BEFORE (slow):**
```sql
with ssr as
 (select  s_store_id as store_id,
          sum(ss_ext_sales_price) as sales,
          sum(coalesce(sr_return_amt, 0)) as returns,
          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit
  from store_sales left outer join store_returns on
         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),
     date_dim,
     store,
     item,
     promotion
 where ss_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
       and ss_store_sk = s_store_sk
       and ss_item_sk = i_item_sk
       and i_current_price > 50
       and ss_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ss_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
 group by s_store_id)
 ,
 csr as
 (select  cp_catalog_page_id as catalog_page_id,
          sum(cs_ext_sales_price) as sales,
          sum(coalesce(cr_return_amount, 0)) as returns,
          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit
  from catalog_sales left outer join catalog_returns on
         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),
     date_dim,
     catalog_page,
     item,
     promotion
 where cs_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and cs_catalog_page_sk = cp_catalog_page_sk
       and cs_item_sk = i_item_sk
       and i_current_price > 50
       and cs_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and cs_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by cp_catalog_page_id)
 ,
 wsr as
 (select  web_site_id,
          sum(ws_ext_sales_price) as sales,
          sum(coalesce(wr_return_amt, 0)) as returns,
          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit
  from web_sales left outer join web_returns on
         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),
     date_dim,
     web_site,
     item,
     promotion
 where ws_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and ws_web_site_sk = web_site_sk
       and ws_item_sk = i_item_sk
       and i_current_price > 50
       and ws_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ws_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by web_site_id)
  select  channel
        , id
        , sum(sales) as sales
        , sum(returns) as returns
        , sum(profit) as profit
 from
 (select 'store channel' as channel
        , 'store' || store_id as id
        , sales
        , returns
        , profit
 from   ssr
 union all
 select 'catalog channel' as channel
        , 'catalog_page' || catalog_page_id as id
        , sales
        , returns
        , profit
 from  csr
 union all
 select 'web channel' as channel
        , 'web_site' || web_site_id as id
        , sales
        , returns
        , profit
 from   wsr
 ) x
 group by rollup (channel, id)
 order by channel
         ,id
 limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-23' AS DATE) AND CAST('1998-08-23' AS DATE) + INTERVAL '30 DAY'
```
[filtered_item]:
```sql
SELECT i_item_sk FROM item WHERE i_current_price > 50 AND i_category IN ('Jewelry', 'Music')
```
[filtered_promotion]:
```sql
SELECT p_promo_sk FROM promotion WHERE p_channel_email = 'Y' AND p_channel_tv = 'Y' AND p_channel_radio = 'N' AND p_channel_press = 'N' AND p_channel_event = 'Y'
```
[ssr]:
```sql
SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS returns, SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) INNER JOIN filtered_date ON ss_sold_date_sk = filtered_date.d_date_sk INNER JOIN store ON ss_store_sk = s_store_sk INNER JOIN filtered_item ON ss_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ss_promo_sk = filtered_promotion.p_promo_sk WHERE ss_wholesale_cost BETWEEN 63 AND 78 GROUP BY s_store_id
```

## Constraints

### CRITICAL — Correctness Guards

**COMPLETE_OUTPUT**
The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original.

**CTE_COLUMN_COMPLETENESS**
CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.

**KEEP_EXISTS_AS_EXISTS**
Preserve EXISTS/NOT EXISTS subqueries as-is. Do NOT convert them to IN/NOT IN or to JOINs — this risks NULL-handling semantic changes and can introduce duplicate rows.

**LITERAL_PRESERVATION**
CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

**NO_CROSS_JOIN_DIMENSIONS**
NEVER combine multiple dimension tables into a single CTE via CROSS JOIN, Cartesian product, or JOIN ON TRUE. Even small dimensions (30 dates × 200 items × 20 promos = 120K rows) create huge intermediate results that prevent index use on fact tables. Always keep each dimension as a SEPARATE CTE: filtered_date AS (...), filtered_item AS (...), filtered_promotion AS (...). This was validated at 3.32x with separate CTEs vs 0.0076x with a merged CROSS JOIN CTE.

**NO_MATERIALIZE_EXISTS**
Keep EXISTS and NOT EXISTS as-is — they use semi-join short-circuiting that stops scanning after the first match. Converting them to materialized CTEs (e.g., WITH cte AS (SELECT DISTINCT ... FROM large_table)) forces a full table scan, which is catastrophically slower (0.14x observed on Q16). When you see EXISTS, preserve it.

**SEMANTIC_EQUIVALENCE**
The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set — even by one row, one column, or a different sort order — is WRONG and will be REJECTED.

### HIGH — Performance and Style Rules

**MIN_BASELINE_THRESHOLD**
If the query execution plan shows very fast runtime (under 100ms), be conservative with CTE-based transforms. Each CTE adds materialization overhead (hash table creation, intermediate result storage). On fast queries, this overhead can exceed the filtering benefit. Prefer minimal changes or no change over adding multiple CTEs to an already-fast query.

**NO_MATERIALIZED_KEYWORD_PG**
Do NOT use the AS MATERIALIZED keyword on CTEs. Write plain CTEs: 'name AS (SELECT ...)'. PostgreSQL automatically materializes CTEs when beneficial. Forcing materialization on small dimension CTEs (< 1000 rows) adds temp-table I/O overhead that causes regressions (0.69x observed). The proven gold examples use plain CTEs without MATERIALIZED.

**NO_UNFILTERED_DIMENSION_CTE**
Every CTE you create must include a WHERE clause that actually reduces row count. Selecting fewer columns is not filtering — the CTE still materializes every row. If a dimension table has no predicate to push down, leave it as a direct join in the main query instead of wrapping it in a CTE.

**OR_TO_UNION_GUARD**
Only apply or_to_union when (a) the OR branches involve different tables or fundamentally different access paths — never when all branches filter the same column (e.g., t_hour ranges), since the optimizer already handles same-column ORs efficiently in a single scan — and (b) the result is 3 or fewer UNION ALL branches. Nested ORs that would expand into 4+ branches (e.g., 3 conditions x 3 values = 9 combinations) must be left as-is. Violating these rules causes 0.23x–0.59x regressions from multiplied fact table scans.

**REMOVE_REPLACED_CTES**
When creating replacement CTEs, overwrite the original by using the same node_id in your rewrite_sets, or ensure the original is removed from the WITH clause. Every CTE in the final query should be actively used — dead CTEs still get materialized and waste resources (caused 0.49x on Q31, 0.68x on Q74).

**EXPLICIT_JOINS**
Convert comma-separated implicit joins to explicit JOIN ... ON syntax. This gives the optimizer better join-order freedom.

### CRITICAL — Correctness Guards (repeated for emphasis)

**COMPLETE_OUTPUT**
The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original.

**CTE_COLUMN_COMPLETENESS**
CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.

**KEEP_EXISTS_AS_EXISTS**
Preserve EXISTS/NOT EXISTS subqueries as-is. Do NOT convert them to IN/NOT IN or to JOINs — this risks NULL-handling semantic changes and can introduce duplicate rows.

**LITERAL_PRESERVATION**
CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

**NO_CROSS_JOIN_DIMENSIONS**
NEVER combine multiple dimension tables into a single CTE via CROSS JOIN, Cartesian product, or JOIN ON TRUE. Even small dimensions (30 dates × 200 items × 20 promos = 120K rows) create huge intermediate results that prevent index use on fact tables. Always keep each dimension as a SEPARATE CTE: filtered_date AS (...), filtered_item AS (...), filtered_promotion AS (...). This was validated at 3.32x with separate CTEs vs 0.0076x with a merged CROSS JOIN CTE.

**NO_MATERIALIZE_EXISTS**
Keep EXISTS and NOT EXISTS as-is — they use semi-join short-circuiting that stops scanning after the first match. Converting them to materialized CTEs (e.g., WITH cte AS (SELECT DISTINCT ... FROM large_table)) forces a full table scan, which is catastrophically slower (0.14x observed on Q16). When you see EXISTS, preserve it.

**SEMANTIC_EQUIVALENCE**
The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set — even by one row, one column, or a different sort order — is WRONG and will be REJECTED.

## Output

Return the complete rewritten SQL query. The query must be syntactically
valid and ready to execute.

### Column Completeness Contract

Your rewritten query MUST produce **exactly** these output columns (same names, same order):

  1. `ty_channel`
  2. `ty_brand`
  3. `ty_class`
  4. `ty_category`
  5. `ty_sales`
  6. `ty_number_sales`
  7. `ly_channel`
  8. `ly_brand`
  9. `ly_class`
  10. `ly_category`
  11. `ly_sales`
  12. `ly_number_sales`

Do NOT add, remove, or rename any columns. The result set schema must be identical to the original query.

```sql
-- Your rewritten query here
```

After the SQL, briefly explain what you changed:

```
Changes: <1-2 sentence summary of the rewrite>
Expected speedup: <estimate>
```

Now output your rewritten SQL: