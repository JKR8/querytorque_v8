{
  "query_id": "query050_spj_spj",
  "worker_id": 1,
  "run_name": "swarm_batch_20260208_142643",
  "timestamp": "2026-02-08T20:24:42.375807",
  "query_intent": "",
  "query_fingerprint": "",
  "examples_used": [
    "early_filter_decorrelate",
    "pg_date_cte_explicit_join",
    "pg_dimension_prefetch_star"
  ],
  "strategy": "early_filter_pushdown",
  "status": "REGRESSION",
  "speedup": 0.9044077078672319,
  "transforms_applied": [
    "date_cte_isolate",
    "dimension_cte_isolate",
    "multi_date_range_cte"
  ],
  "error_category": null,
  "error_messages": [],
  "what_worked": null,
  "why_it_worked": null,
  "what_failed": "Regression: 0.90x slower than baseline",
  "why_it_failed": "All attempts failed because they focused on syntactic reorganization (CTEs, explicit joins) without addressing the core physical execution bottlenecks. PostgreSQL's optimizer often inlines CTEs, making them optimization fences that prevent join reordering and predicate pushdown. The real bottleneck is the massive Cartesian product between date_dim self-join and fact tables before applying the 120-day range filter, causing explosive intermediate results. Worker 3's 0.13x slowdown demonstrates cat",
  "principle": null,
  "reviewed": true
}