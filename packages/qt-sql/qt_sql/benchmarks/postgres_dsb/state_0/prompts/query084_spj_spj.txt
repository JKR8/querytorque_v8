You are a SQL query rewrite engine.

Your goal: rewrite the complete SQL query to maximize execution speed
while preserving exact semantic equivalence (same rows, same columns,
same ordering).

You will receive the full query, its DAG structure showing how CTEs and
subqueries connect, cost analysis per node, and suggested rewrite patterns.
You may restructure the query freely: create new CTEs, merge existing ones,
push filters across node boundaries, or decompose subqueries.

## Query: query084_spj_spj

```sql
SELECT
  MIN(c_customer_id),
  MIN(sr_ticket_number),
  MIN(sr_item_sk)
FROM customer, customer_address, customer_demographics, household_demographics, income_band, store_returns
WHERE
  ca_city = 'Lakeview'
  AND c_current_addr_sk = ca_address_sk
  AND ib_lower_bound >= 7 * 10000
  AND ib_upper_bound <= 7 * 10000 + 50000
  AND ib_income_band_sk = hd_income_band_sk
  AND cd_demo_sk = c_current_cdemo_sk
  AND hd_demo_sk = c_current_hdemo_sk
  AND sr_cdemo_sk = cd_demo_sk
```

## DAG Topology

```sql
-- DAG TOPOLOGY
-- Depth 0:
--   main_query (main, 100% cost)
--     outputs: [MIN(c_customer_id), MIN(sr_ticket_number), MIN(sr_item_sk)]
```

## Performance Profile

**main_query**: 100% of total cost, ~1,000 rows
  operators: SEQ_SCAN[customer], SEQ_SCAN[customer_address], SEQ_SCAN[customer_demographics]

## Suggested Rewrite Strategy

No specific patterns identified. Use your judgment.

## Reference Examples

### 1. pg_self_join_decomposition (3.93x)

**BEFORE (slow):**
```sql
select s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand
from store, item,
  (select ss_store_sk, avg(revenue) as ave
   from (select ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
         from store_sales, date_dim
         where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1224
           and ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48
         group by ss_store_sk, ss_item_sk) sa
   group by ss_store_sk) sb,
  (select ss_store_sk, ss_item_sk, sum(ss_sales_price) as revenue
   from store_sales, date_dim
   where ss_sold_date_sk = d_date_sk and d_month_seq between 1213 and 1224
     and ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48
   group by ss_store_sk, ss_item_sk) sc
where sb.ss_store_sk = sc.ss_store_sk
  and sc.revenue <= 0.1 * sb.ave
  and s_store_sk = sc.ss_store_sk
  and i_item_sk = sc.ss_item_sk
  and i_manager_id BETWEEN 32 AND 36
  and s_state in ('TN','TX','VA')
order by s_store_name, i_item_desc
limit 100
```

**Key insight:** The original scans store_sales+date_dim TWICE with identical predicates (sa/sc subqueries). On PostgreSQL, CTE materialization computes the fact table aggregation ONCE and reuses it for both per-item revenue and per-store averages. Combined with dimension pre-filtering (store, item), this eliminates the dominant I/O cost.

**AFTER (fast):**
[date_filter]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1213 AND 1224
```
[store_sales_revenue]:
```sql
SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM store_sales JOIN date_filter ON ss_sold_date_sk = d_date_sk WHERE ss_sales_price / ss_list_price BETWEEN 0.38 AND 0.48 GROUP BY ss_store_sk, ss_item_sk
```
[store_avg_revenue]:
```sql
SELECT ss_store_sk, AVG(revenue) AS ave FROM store_sales_revenue GROUP BY ss_store_sk
```
[filtered_store]:
```sql
SELECT s_store_sk, s_store_name FROM store WHERE s_state IN ('TN', 'TX', 'VA')
```
[filtered_item]:
```sql
SELECT i_item_sk, i_item_desc, i_current_price, i_wholesale_cost, i_brand FROM item WHERE i_manager_id BETWEEN 32 AND 36
```
[main_query]:
```sql
SELECT s_store_name, i_item_desc, sc.revenue, i_current_price, i_wholesale_cost, i_brand FROM store_avg_revenue AS sb JOIN store_sales_revenue AS sc ON sb.ss_store_sk = sc.ss_store_sk JOIN filtered_store AS s ON sc.ss_store_sk = s.s_store_sk JOIN filtered_item AS i ON sc.ss_item_sk = i.i_item_sk WHERE sc.revenue <= 0.1 * sb.ave ORDER BY s_store_name, i_item_desc LIMIT 100
```

## Constraints

### CRITICAL — Correctness Guards (top of sandwich)

**SEMANTIC_EQUIVALENCE**
The rewritten query MUST return exactly the same rows, columns, and
ordering as the original. This is the prime directive.

**LITERAL_PRESERVATION**
Keep all literal values (dates, strings, numbers) exactly as they appear in
the original SQL. Do not round, truncate, or reformat them.

### HIGH — Performance and Style Rules (middle of sandwich)

**NO_UNFILTERED_DIM_CTE**
When creating a new CTE that scans a dimension table, include at least one
filter predicate. Never materialize an entire dimension without a WHERE clause.

**OR_TO_UNION_LIMIT**
When converting OR predicates to UNION ALL, limit to 4 branches maximum.
Beyond 4, the UNION overhead exceeds the OR scan cost for most planners.

**EXPLICIT_JOINS**
Convert comma-separated implicit joins to explicit JOIN ... ON syntax.
This gives the optimizer better join-order freedom.

### CRITICAL — Correctness Guards (bottom of sandwich)

**KEEP_EXISTS_AS_EXISTS**
Preserve EXISTS/NOT EXISTS subqueries as-is. Do not convert them to
IN/NOT IN or to JOINs — this risks NULL-handling semantic changes.

**COMPLETE_OUTPUT**
The rewritten query must output ALL columns from the original SELECT.
Never drop, rename, or reorder output columns.

## Output

Return the complete rewritten SQL query. The query must be syntactically
valid and ready to execute.

```sql
-- Your rewritten query here
```

After the SQL, briefly explain what you changed:

```
Changes: <1-2 sentence summary of the rewrite>
Expected speedup: <estimate>
```

Now output your rewritten SQL: