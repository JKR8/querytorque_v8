## Modified Logic Tree

```
[=] Original: 8 subqueries cross-joined
  [~] s1: COUNT(*) for 8:30-9:00 → Replaced with single-pass conditional aggregation
  [~] s2: COUNT(*) for 9:00-9:30 → Replaced with single-pass conditional aggregation
  [~] s3: COUNT(*) for 9:30-10:00 → Replaced with single-pass conditional aggregation
  [~] s4: COUNT(*) for 10:00-10:30 → Replaced with single-pass conditional aggregation
  [~] s5: COUNT(*) for 10:30-11:00 → Replaced with single-pass conditional aggregation
  [~] s6: COUNT(*) for 11:00-11:30 → Replaced with single-pass conditional aggregation
  [~] s7: COUNT(*) for 11:30-12:00 → Replaced with single-pass conditional aggregation
  [~] s8: COUNT(*) for 12:00-12:30 → Replaced with single-pass conditional aggregation
  [+] filtered_store: Early filter for store='ese'
  [+] filtered_household: Early filter for household conditions
  [+] time_buckets: Precomputed time intervals
  [+] sales_joined: Single join with all filters applied
  [~] main_query: Single conditional COUNT_IF aggregation
```

## Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "snowflake",
  "rewrite_rules": [
    {"id": "R1", "type": "single_pass_aggregation", "description": "Replaced 8 subqueries with conditional aggregation in a single pass", "applied_to": ["main_query"]},
    {"id": "R2", "type": "predicate_pushdown", "description": "Pushed store/household filters to dimension tables before join", "applied_to": ["filtered_store", "filtered_household"]},
    {"id": "R3", "type": "time_bucket_precompute", "description": "Precomputed time intervals to avoid repeated calculations", "applied_to": ["time_buckets"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "filtered_store": {
        "type": "cte",
        "change": "new",
        "sql": "SELECT s_store_sk FROM store WHERE s_store_name = 'ese'",
        "interfaces": {"outputs": ["s_store_sk"], "consumes": []}
      },
      "filtered_household": {
        "type": "cte",
        "change": "new",
        "sql": "SELECT hd_demo_sk FROM household_demographics WHERE (hd_dep_count = -1 AND hd_vehicle_count <= 1) OR (hd_dep_count = 4 AND hd_vehicle_count <= 6) OR (hd_dep_count = 3 AND hd_vehicle_count <= 5)",
        "interfaces": {"outputs": ["hd_demo_sk"], "consumes": []}
      },
      "time_buckets": {
        "type": "cte",
        "change": "new",
        "sql": "SELECT t_time_sk, t_hour, t_minute FROM time_dim WHERE (t_hour = 8 AND t_minute >= 30) OR (t_hour = 9 AND t_minute < 30) OR (t_hour = 9 AND t_minute >= 30) OR (t_hour = 10 AND t_minute < 30) OR (t_hour = 10 AND t_minute >= 30) OR (t_hour = 11 AND t_minute < 30) OR (t_hour = 11 AND t_minute >= 30) OR (t_hour = 12 AND t_minute < 30)",
        "interfaces": {"outputs": ["t_time_sk", "t_hour", "t_minute"], "consumes": []}
      },
      "sales_joined": {
        "type": "cte",
        "change": "new",
        "sql": "SELECT t.t_hour, t.t_minute FROM store_sales ss JOIN filtered_store s ON ss.ss_store_sk = s.s_store_sk JOIN filtered_household h ON ss.ss_hdemo_sk = h.hd_demo_sk JOIN time_buckets t ON ss.ss_sold_time_sk = t.t_time_sk",
        "interfaces": {"outputs": ["t_hour", "t_minute"], "consumes": ["filtered_store", "filtered_household", "time_buckets"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "SELECT COUNT_IF(t_hour=8 AND t_minute>=30) AS h8_30_to_9, COUNT_IF(t_hour=9 AND t_minute<30) AS h9_to_9_30, COUNT_IF(t_hour=9 AND t_minute>=30) AS h9_30_to_10, COUNT_IF(t_hour=10 AND t_minute<30) AS h10_to_10_30, COUNT_IF(t_hour=10 AND t_minute>=30) AS h10_30_to_11, COUNT_IF(t_hour=11 AND t_minute<30) AS h11_to_11_30, COUNT_IF(t_hour=11 AND t_minute>=30) AS h11_30_to_12, COUNT_IF(t_hour=12 AND t_minute<30) AS h12_to_12_30 FROM sales_joined",
        "interfaces": {"outputs": ["h8_30_to_9", "h9_to_9_30", "h9_30_to_10", "h10_to_10_30", "h10_30_to_11", "h11_to_11_30", "h11_30_to_12", "h12_to_12_30"], "consumes": ["sales_joined"]}
      }
    },
    "reconstruction_order": ["filtered_store", "filtered_household", "time_buckets", "sales_joined", "main_query"],
    "assembly_template": "WITH filtered_store AS ({filtered_store}), filtered_household AS ({filtered_household}), time_buckets AS ({time_buckets}), sales_joined AS ({sales_joined}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "validation_checks": []
}
```

## Optimized SQL

```sql
WITH filtered_store AS (
  SELECT s_store_sk 
  FROM store 
  WHERE s_store_name = 'ese'
), 
filtered_household AS (
  SELECT hd_demo_sk 
  FROM household_demographics 
  WHERE 
    (hd_dep_count = -1 AND hd_vehicle_count <= 1) OR
    (hd_dep_count = 4 AND hd_vehicle_count <= 6) OR
    (hd_dep_count = 3 AND hd_vehicle_count <= 5)
), 
time_buckets AS (
  SELECT t_time_sk, t_hour, t_minute 
  FROM time_dim 
  WHERE 
    (t_hour = 8 AND t_minute >= 30) OR
    (t_hour = 9 AND t_minute < 30) OR
    (t_hour = 9 AND t_minute >= 30) OR
    (t_hour = 10 AND t_minute < 30) OR
    (t_hour = 10 AND t_minute >= 30) OR
    (t_hour = 11 AND t_minute < 30) OR
    (t_hour = 11 AND t_minute >= 30) OR
    (t_hour = 12 AND t_minute < 30)
), 
sales_joined AS (
  SELECT t.t_hour, t.t_minute 
  FROM store_sales ss
  JOIN filtered_store s ON ss.ss_store_sk = s.s_store_sk
  JOIN filtered_household h ON ss.ss_hdemo_sk = h.hd_demo_sk
  JOIN time_buckets t ON ss.ss_sold_time_sk = t.t_time_sk
)
SELECT
  COUNT_IF(t_hour=8 AND t_minute>=30) AS h8_30_to_9,
  COUNT_IF(t_hour=9 AND t_minute<30) AS h9_to_9_30,
  COUNT_IF(t_hour=9 AND t_minute>=30) AS h9_30_to_10,
  COUNT_IF(t_hour=10 AND t_minute<30) AS h10_to_10_30,
  COUNT_IF(t_hour=10 AND t_minute>=30) AS h10_30_to_11,
  COUNT_IF(t_hour=11 AND t_minute<30) AS h11_to_11_30,
  COUNT_IF(t_hour=11 AND t_minute>=30) AS h11_30_to_12,
  COUNT_IF(t_hour=12 AND t_minute<30) AS h12_to_12_30
FROM sales_joined;
```

## Mechanism and Expected Speedup

Changes: Replaced 8 repeated subqueries with single-pass aggregation using COUNT_IF, while pushing store and household filters to dimension tables before joining. Precomputed time intervals to avoid repeated calculations during joins.

Expected speedup: 3.0-5.0x by:
1. Eliminating 7 redundant store_sales scans (1.25TB → 1.25TB total scan)
2. Reducing join cardinality via early dimension filtering
3. Leveraging COUNT_IF for vectorized conditional aggregation
4. Minimizing data movement through CTE pipelining