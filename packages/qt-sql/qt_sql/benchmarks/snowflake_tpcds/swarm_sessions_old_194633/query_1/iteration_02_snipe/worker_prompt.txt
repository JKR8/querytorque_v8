You are a senior SQL optimization architect for snowflake. You have FULL FREEDOM to design your own approach — you are NOT constrained to any specific logical tree topology or CTE structure. Your job: diagnose WHY previous workers failed to reach 2.0x, identify unexplored optimization angles, and produce an optimized SQL rewrite that reaches the target.

Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — guards prevent silent breakage. Strip benchmark comments (-- start query, -- end query) from output.

## Target: >=2.0x speedup

Your target is >=2.0x speedup on this query. This is the bar. Anything below 2.0x is a miss.

## PREVIOUS RETRY ATTEMPT — Learn from this

Your previous retry achieved **0.0x** against a target of **2.0x**.
**Error**: Benchmark failed: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
**Strategy**: retry_1

Diagnose why this approach fell short and try a fundamentally different angle.

## Previous Optimization Attempts
Target: **>=2.0x** | 5 workers tried | none reached target

### W1: global_predicate_pushdown → 0.0x ★ BEST [ERROR]
- **Examples**: early_filter, date_cte_isolate
- **Transforms**: pushdown
- **Approach**: Apply early_filter's predicate pushdown but ignore date isolation. Use date_cte_
- **Error**: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
- **Optimized SQL:**
```sql
WITH filtered_store AS (SELECT s_store_sk FROM store WHERE s_state = 'SD'), customer_total_return AS (SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, SUM(SR_FEE) AS ctr_total_return FROM store_returns INNER JOIN date_dim ON store_returns.sr_returned_date_sk = date_dim.d_date_sk INNER JOIN filtered_store ON store_returns.sr_store_sk = filtered_store.s_store_sk WHERE date_dim.d_year = 2000 GROUP BY sr_customer_sk, sr_store_sk) SELECT c_customer_id FROM customer_total_return ctr1 INNER JOIN customer ON ctr1.ctr_customer_sk = customer.c_customer_sk WHERE ctr1.ctr_total_return > (SELECT AVG(ctr2.ctr_total_return) * 1.2 FROM customer_total_return ctr2 WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk) ORDER BY c_customer_id LIMIT 100
```
- **Planner Diagnosis:**
```
[EXPLAIN failed — planner rejected this SQL]
Error: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
```

### W2: aggregate_pushdown → 0.0x ★ BEST [ERROR]
- **Examples**: decorrelate, composite_decorrelate_union
- **Transforms**: decorrelate
- **Approach**: Use decorrelate's subquery-to-join pattern. Ignore UNION aspects from composite 
- **Error**: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
- **Optimized SQL:**
```sql
WITH store_returns_agg AS (SELECT
    sr_customer_sk,
    sr_store_sk,
    SUM(SR_FEE) AS ctr_total_return
FROM store_returns
JOIN date_dim ON sr_returned_date_sk = d_date_sk
WHERE d_year = 2000
GROUP BY sr_customer_sk, sr_store_sk),
store_avg AS (SELECT
    sr_store_sk,
    AVG(ctr_total_return) * 1.2 AS store_avg
FROM store_returns_agg
GROUP BY sr_store_sk)
SELECT
    c_customer_id
FROM store_returns_agg ctr1
JOIN store ON ctr1.sr_store_sk = store.s_store_sk
JOIN store_avg ON ctr1.sr_store_sk = store_avg.sr_store_sk
JOIN customer ON ctr1.sr_customer_sk = customer.c_customer_sk
WHERE store.s_state = 'SD'
  AND ctr1.ctr_total_return > store_avg.store_avg
ORDER BY c_customer_id
LIMIT 100
```
- **Planner Diagnosis:**
```
[EXPLAIN failed — planner rejected this SQL]
Error: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
```

### W3: single_pass_aggregation → 0.0x ★ BEST [ERROR]
- **Examples**: single_pass_aggregation, channel_bitmap_aggregation
- **Transforms**: decorrelate
- **Approach**: Apply single_pass_aggregation's window technique. Ignore bitmap aspects.
- **Error**: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
- **Optimized SQL:**
```sql
WITH enhanced_ctr AS (SELECT
  sr_customer_sk,
  sr_store_sk,
  SUM(SR_FEE) AS ctr_total_return,
  AVG(SUM(SR_FEE)) OVER (PARTITION BY sr_store_sk) AS store_avg
FROM store_returns
INNER JOIN date_dim ON sr_returned_date_sk = d_date_sk
WHERE d_year = 2000
GROUP BY sr_customer_sk, sr_store_sk) SELECT c_customer_id
FROM enhanced_ctr ctr1
INNER JOIN store ON ctr1.sr_store_sk = store.s_store_sk
INNER JOIN customer ON ctr1.sr_customer_sk = customer.c_customer_sk
WHERE store.s_state = 'SD'
  AND ctr1.ctr_total_return > (ctr1.store_avg * 1.2)
ORDER BY c_customer_id
LIMIT 100
```
- **Planner Diagnosis:**
```
[EXPLAIN failed — planner rejected this SQL]
Error: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
```

### W4: star_join_prefetch → 0.0x ★ BEST [ERROR]
- **Examples**: dimension_cte_isolate, prefetch_fact_join
- **Transforms**: dimension_cte_isolate
- **Approach**: Use dimension_cte_isolate's early dim filtering. Keep LATERAL for subquery equiv
- **Error**: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
- **Optimized SQL:**
```sql
WITH sd_stores AS (SELECT s_store_sk FROM store WHERE s_state = 'SD'), store_returns_filtered AS (SELECT sr_customer_sk, sr_store_sk, SUM(SR_FEE) AS ctr_total_return FROM store_returns INNER JOIN date_dim ON sr_returned_date_sk = d_date_sk INNER JOIN sd_stores ON sr_store_sk = s_store_sk WHERE d_year = 2000 GROUP BY sr_customer_sk, sr_store_sk) SELECT c_customer_id FROM store_returns_filtered ctr1, customer, LATERAL (SELECT AVG(ctr_total_return) * 1.2 AS avg_threshold FROM store_returns_filtered ctr2 WHERE ctr1.sr_store_sk = ctr2.sr_store_sk) WHERE ctr1.sr_customer_sk = c_customer_sk AND ctr_total_return > avg_threshold ORDER BY c_customer_id LIMIT 100
```
- **Planner Diagnosis:**
```
[EXPLAIN failed — planner rejected this SQL]
Error: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
```

### W5: retry_1 → 0.0x ★ BEST [ERROR]
- **Transforms**: decorrelate
- **Error**: Benchmark failed: IO Error: Cannot open database "/mnt/c/Users/jakc9/Documents/QueryTorque_V8/snowflake://JKDL:YourNewPassword123!@CVRYJTF-AW47074/SNOWFLAKE_SAMPLE_DATA/TPCDS_SF10TCL?warehouse=COMPUTE_WH&role=ACCOUNTADMIN" in read-only mode: database does not exist
- **Optimized SQL:**
```sql
WITH store_returns_prefilter AS (
  SELECT 
    sr_customer_sk,
    sr_store_sk,
    SUM(SR_FEE) AS ctr_total_return,
    AVG(SUM(SR_FEE)) OVER (PARTITION BY sr_store_sk) * 1.2 AS store_avg_threshold
  FROM store_returns
  JOIN date_dim ON sr_returned_date_sk = d_date_sk
  JOIN store ON sr_store_sk = s_store_sk
  WHERE d_year = 2000
    AND s_state = 'SD'
  GROUP BY sr_customer_sk, sr_store_sk
)
SELECT 
  c_customer_id
FROM store_returns_prefilter
JOIN customer ON sr_customer_sk = c_customer_sk
WHERE ctr_total_return > store_avg_threshold
ORDER BY c_customer_id
LIMIT 100;
```


## Semantic Contract (MUST preserve)

Identify customers in South Dakota (SD) stores whose total return fees in 2000 exceeded 120% of their store's average. Output customer IDs ordered by ID. Joins are INNER: all tables must match. Aggregations use SUM and AVG - verify AVG reconstruction from SUM/COUNT if pre-aggregating. The state filter ('SD') depends on store table, not present in initial CTE.

## Bottleneck Diagnosis

The query is scan-bound (store_returns + date_dim scan dominates 50% cost) and join-bound (correlated subquery forces repeated CTE scans). Cardinality: store_returns (large) → CTE (~1K rows) → main query filters to SD stores → correlated subquery rescans CTE per store. Optimizer handles column pruning automatically but misses predicate pushdown into multi-ref CTE and decorrelation opportunity.

## Engine Profile

*Discovery mode — 10 strengths from docs/research, 9 hypothesized gaps in playbook. Collecting empirical evidence.*

### Optimizer Strengths (DO NOT fight these)
- **MICRO_PARTITION_PRUNING**: Filters on clustered columns skip micro-partitions at scan level
- **COLUMN_PRUNING**: Reads only columns referenced by final query, even through CTEs
- **PREDICATE_PUSHDOWN**: Filters pushed to storage layer including through single-ref CTEs
- **CORRELATED_DECORRELATION**: Correlated subqueries automatically decorrelated to hash joins
- **SEMI_JOIN**: EXISTS → SemiJoin with early termination
- **JOIN_FILTER**: Bloom filter pushdown from build side to probe-side TableScan
- **COST_BASED_JOIN_ORDER**: Evaluates multiple join orders, selects lowest cost
- **METADATA_SCAN_ELIMINATION**: MIN/MAX/COUNT served from micro-partition metadata without scan
- **QUALIFY_OPTIMIZATION**: Native window-function filtering, more efficient than nested subquery
- **DISTRIBUTED_AGGREGATION**: Multi-level partial aggregation for parallel warehouse execution

## Correctness Invariants (HARD STOPS — non-negotiable)

These 4 constraints are absolute. Even with full creative freedom, you may NEVER violate these:

- **COMPLETE_OUTPUT**: The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original.
- **CTE_COLUMN_COMPLETENESS**: CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.
- **LITERAL_PRESERVATION**: CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.
- **SEMANTIC_EQUIVALENCE**: The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set — even by one row, one column, or a different sort order — is WRONG and will be REJECTED.

## Aggregation Semantics Check (HARD STOP)

- STDDEV_SAMP/VARIANCE are grouping-sensitive — changing group membership changes the result.
- AVG and STDDEV are NOT duplicate-safe.
- FILTER over a combined group != separate per-group computation.
- Verify aggregation equivalence for ANY proposed restructuring.

## Original SQL

```sql
with customer_total_return as
(select sr_customer_sk as ctr_customer_sk
,sr_store_sk as ctr_store_sk
,sum(SR_FEE) as ctr_total_return
from store_returns
,date_dim
where sr_returned_date_sk = d_date_sk
and d_year =2000
group by sr_customer_sk
,sr_store_sk)
 select c_customer_id
from customer_total_return ctr1
,store
,customer
where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2
from customer_total_return ctr2
where ctr1.ctr_store_sk = ctr2.ctr_store_sk)
and s_store_sk = ctr1.ctr_store_sk
and s_state = 'SD'
and ctr1.ctr_customer_sk = c_customer_sk
order by c_customer_id
 LIMIT 100;
```

## Your Task — Self-Directed Retry

Work through these 3 steps in a `<reasoning>` block, then output your optimized SQL:

1. **DIAGNOSE**: Why did the best worker achieve 0.0x instead of the 2.0x target? What do the EXPLAIN plans reveal about the actual execution bottleneck?
2. **IDENTIFY**: What optimization angles are still unexplored? What did the empirical results reveal that couldn't have been known before seeing the execution plans?
3. **REWRITE**: Produce optimized SQL that exploits the angles you identified. You may build on the best foundation or start fresh.

## Rewrite Checklist (must pass before final SQL)

- Verify output schema matches the Column Completeness Contract (same columns, same names, same order).
- Keep all semantic invariants from `Correctness Invariants` (including join/null behavior).
- Verify aggregation equivalence: same rows participate in each group, same aggregate semantics.
- Preserve all literals exactly (numbers, strings, date values).
- Apply `Hazard Flags` as hard guards against known failure modes.

### Column Completeness Contract

Your `main_query` component MUST produce **exactly** these output columns (same names, same order):

  1. `c_customer_id`

Do NOT add, remove, or rename any output columns. The result set schema must be identical to the original query.

## Output Format

Your response has **two parts** in order:

### Part 1: Modified Logic Tree

Show what changed using change markers. Generate the tree BEFORE writing SQL.

Change markers:
- `[+]` — New component added
- `[-]` — Component removed
- `[~]` — Component modified (describe what changed)
- `[=]` — Unchanged (no children needed)
- `[!]` — Structural change (e.g. CTE → subquery)

### Part 2: Component Payload JSON

```json
{
  "spec_version": "1.0",
  "dialect": "<dialect>",
  "rewrite_rules": [
    {"id": "R1", "type": "<transform_name>", "description": "<what changed>", "applied_to": ["<component_id>"]}
  ],
  "statements": [{
    "target_table": null,
    "change": "modified",
    "components": {
      "<cte_name>": {
        "type": "cte",
        "change": "modified",
        "sql": "<complete SQL for this CTE body>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<upstream_id>"]}
      },
      "main_query": {
        "type": "main_query",
        "change": "modified",
        "sql": "<final SELECT>",
        "interfaces": {"outputs": ["col1", "col2"], "consumes": ["<cte_name>"]}
      }
    },
    "reconstruction_order": ["<cte_name>", "main_query"],
    "assembly_template": "WITH <cte_name> AS ({<cte_name>}) {main_query}"
  }],
  "macros": {},
  "frozen_blocks": [],
  "validation_checks": []
}
```

### Rules
- **Tree first, always.** Generate the Logic Tree before writing any SQL
- **One component at a time.** When writing SQL for component X, treat others as opaque interfaces
- **No ellipsis.** Every `sql` value must be complete, executable SQL
- **Frozen blocks are copy-paste.** Large CASE-WHEN lookups must be verbatim
- **Validate interfaces.** Verify every `consumes` reference exists in upstream `outputs`
- Only include components you **changed or added** — set unchanged components to `"change": "unchanged"` with `"sql": ""`
- `main_query` output columns must match the Column Completeness Contract above
- `reconstruction_order`: topological order of components for assembly

After the JSON, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
Expected speedup: <estimate>
```

Now output your Logic Tree and Component Payload JSON: