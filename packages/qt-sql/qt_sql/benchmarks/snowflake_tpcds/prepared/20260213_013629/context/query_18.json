{
  "explain_plan_text": "GlobalStats | 55444 | 55243 | 923329937920\n1 | 0 | Result | ITEM.I_ITEM_ID, CUSTOMER_ADDRESS.CA_COUNTRY, CUSTOMER_ADDRESS.CA_STATE, CUSTOMER_ADDRESS.CA_COUNTY, (SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_QUANTITY))), COUNT(*))))) / (COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_QUANTITY))), COUNT(*))))), (SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_LIST_PRICE))), COUNT(*))))) / (COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_LIST_PRICE))), COUNT(*))))), (SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_COUPON_AMT))), COUNT(*))))) / (COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_COUPON_AMT))), COUNT(*))))), (SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_SALES_PRICE))), COUNT(*))))) / (COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_SALES_PRICE))), COUNT(*))))), (SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_NET_PROFIT))), COUNT(*))))) / (COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_NET_PROFIT))), COUNT(*))))), (SUM(SUM(SUM_INTERNAL(SUM_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT(*))))) / (COUNT(COUNT(COUNT_INTERNAL(COUNT_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT(*))))), (SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CD1.CD_DEP_COUNT))), COUNT(*))))) / (COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CD1.CD_DEP_COUNT))), COUNT(*)))))\n1 | 1 | [0] | SortWithLimit | sortKey: [CUSTOMER_ADDRESS.CA_COUNTRY ASC NULLS LAST, CUSTOMER_ADDRESS.CA_STATE ASC NULLS LAST, CUSTOMER_ADDRESS.CA_COUNTY ASC NULLS LAST, ITEM.I_ITEM_ID ASC NULLS LAST], rowCount: 100\n1 | 2 | [1] | GroupingSets | SUM(CATALOG_SALES.CS_QUANTITY), COUNT(CATALOG_SALES.CS_QUANTITY), SUM(CATALOG_SALES.CS_LIST_PRICE), COUNT(CATALOG_SALES.CS_LIST_PRICE), SUM(CATALOG_SALES.CS_COUPON_AMT), COUNT(CATALOG_SALES.CS_COUPON_AMT), SUM(CATALOG_SALES.CS_SALES_PRICE), COUNT(CATALOG_SALES.CS_SALES_PRICE), SUM(CATALOG_SALES.CS_NET_PROFIT), COUNT(CATALOG_SALES.CS_NET_PROFIT), SUM(CUSTOMER.C_BIRTH_YEAR), COUNT(CUSTOMER.C_BIRTH_YEAR), SUM(CD1.CD_DEP_COUNT), COUNT(CD1.CD_DEP_COUNT)\n1 | 3 | [2] | Aggregate | aggExprs: [SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_QUANTITY))), COUNT(*)))), COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_QUANTITY))), COUNT(*)))), SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_LIST_PRICE))), COUNT(*)))), COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_LIST_PRICE))), COUNT(*)))), SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_COUPON_AMT))), COUNT(*)))), COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_COUPON_AMT))), COUNT(*)))), SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_SALES_PRICE))), COUNT(*)))), COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_SALES_PRICE))), COUNT(*)))), SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_NET_PROFIT))), COUNT(*)))), COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_NET_PROFIT))), COUNT(*)))), SUM(SUM(SUM_INTERNAL(SUM_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT(*)))), COUNT(COUNT(COUNT_INTERNAL(COUNT_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT(*)))), SUM(SUM(SUM_INTERNAL(SUM(SUM(SUM(CD1.CD_DEP_COUNT))), COUNT(*)))), COUNT(COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CD1.CD_DEP_COUNT))), COUNT(*))))], groupKeys: [ITEM.I_ITEM_ID, CUSTOMER_ADDRESS.CA_COUNTRY, CUSTOMER_ADDRESS.CA_STATE, CUSTOMER_ADDRESS.CA_COUNTY]\n1 | 4 | [3] | Aggregate | aggExprs: [SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_QUANTITY))), COUNT(*))), COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_QUANTITY))), COUNT(*))), SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_LIST_PRICE))), COUNT(*))), COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_LIST_PRICE))), COUNT(*))), SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_COUPON_AMT))), COUNT(*))), COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_COUPON_AMT))), COUNT(*))), SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_SALES_PRICE))), COUNT(*))), COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_SALES_PRICE))), COUNT(*))), SUM(SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_NET_PROFIT))), COUNT(*))), COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_NET_PROFIT))), COUNT(*))), SUM(SUM_INTERNAL(SUM_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT(*))), COUNT(COUNT_INTERNAL(COUNT_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT(*))), SUM(SUM_INTERNAL(SUM(SUM(SUM(CD1.CD_DEP_COUNT))), COUNT(*))), COUNT(COUNT_INTERNAL(COUNT(COUNT(COUNT(CD1.CD_DEP_COUNT))), COUNT(*)))], groupKeys: [ITEM.I_ITEM_ID, CUSTOMER_ADDRESS.CA_COUNTRY, CUSTOMER_ADDRESS.CA_STATE, CUSTOMER_ADDRESS.CA_COUNTY]\n1 | 5 | [4] | InnerJoin | joinKey: (CD2.CD_DEMO_SK = CUSTOMER.C_CURRENT_CDEMO_SK)\n1 | 6 | [5] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CUSTOMER_DEMOGRAPHICS | CD2 | CD_DEMO_SK | 1 | 1 | 7446528\n1 | 7 | [5] | Aggregate | aggExprs: [SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_QUANTITY))), COUNT(*)), COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_QUANTITY))), COUNT(*)), SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_LIST_PRICE))), COUNT(*)), COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_LIST_PRICE))), COUNT(*)), SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_COUPON_AMT))), COUNT(*)), COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_COUPON_AMT))), COUNT(*)), SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_SALES_PRICE))), COUNT(*)), COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_SALES_PRICE))), COUNT(*)), SUM_INTERNAL(SUM(SUM(SUM(CATALOG_SALES.CS_NET_PROFIT))), COUNT(*)), COUNT_INTERNAL(COUNT(COUNT(COUNT(CATALOG_SALES.CS_NET_PROFIT))), COUNT(*)), SUM_INTERNAL(SUM_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT(*)), COUNT_INTERNAL(COUNT_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT(*)), SUM_INTERNAL(SUM(SUM(SUM(CD1.CD_DEP_COUNT))), COUNT(*)), COUNT_INTERNAL(COUNT(COUNT(COUNT(CD1.CD_DEP_COUNT))), COUNT(*))], groupKeys: [ITEM.I_ITEM_ID, CUSTOMER_ADDRESS.CA_COUNTRY, CUSTOMER_ADDRESS.CA_STATE, CUSTOMER_ADDRESS.CA_COUNTY, CUSTOMER.C_CURRENT_CDEMO_SK]\n1 | 8 | [7] | InnerJoin | joinKey: (CUSTOMER_ADDRESS.CA_ADDRESS_SK = CUSTOMER.C_CURRENT_ADDR_SK)\n1 | 9 | [8] | Aggregate | aggExprs: [COUNT(*)], groupKeys: [CUSTOMER_ADDRESS.CA_COUNTRY, CUSTOMER_ADDRESS.CA_STATE, CUSTOMER_ADDRESS.CA_COUNTY, CUSTOMER_ADDRESS.CA_ADDRESS_SK]\n1 | 10 | [9] | Filter | CUSTOMER_ADDRESS.CA_STATE IN 'WA' IN 'GA' IN 'NC' IN 'ME' IN 'WY' IN 'OK' IN 'IN'\n1 | 11 | [10] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CUSTOMER_ADDRESS | CA_ADDRESS_SK, CA_COUNTY, CA_STATE, CA_COUNTRY | 256 | 256 | 776454656\n1 | 12 | [8] | Aggregate | aggExprs: [SUM(SUM(SUM(CATALOG_SALES.CS_QUANTITY))), COUNT(COUNT(COUNT(CATALOG_SALES.CS_QUANTITY))), SUM(SUM(SUM(CATALOG_SALES.CS_LIST_PRICE))), COUNT(COUNT(COUNT(CATALOG_SALES.CS_LIST_PRICE))), SUM(SUM(SUM(CATALOG_SALES.CS_COUPON_AMT))), COUNT(COUNT(COUNT(CATALOG_SALES.CS_COUPON_AMT))), SUM(SUM(SUM(CATALOG_SALES.CS_SALES_PRICE))), COUNT(COUNT(COUNT(CATALOG_SALES.CS_SALES_PRICE))), SUM(SUM(SUM(CATALOG_SALES.CS_NET_PROFIT))), COUNT(COUNT(COUNT(CATALOG_SALES.CS_NET_PROFIT))), SUM_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), COUNT_INTERNAL(CUSTOMER.C_BIRTH_YEAR, COUNT(*)), SUM(SUM(SUM(CD1.CD_DEP_COUNT))), COUNT(COUNT(COUNT(CD1.CD_DEP_COUNT)))], groupKeys: [ITEM.I_ITEM_ID, CUSTOMER.C_CURRENT_CDEMO_SK, CUSTOMER.C_CURRENT_ADDR_SK]\n1 | 13 | [12] | InnerJoin | joinKey: (CUSTOMER.C_CUSTOMER_SK = CATALOG_SALES.CS_BILL_CUSTOMER_SK)\n1 | 14 | [13] | Filter | (CUSTOMER.C_BIRTH_MONTH IN 10 IN 7 IN 8 IN 4 IN 1 IN 2) AND (CUSTOMER.C_CURRENT_CDEMO_SK IS NOT NULL)\n1 | 15 | [14] | JoinFilter | joinKey: (CD2.CD_DEMO_SK = CUSTOMER.C_CURRENT_CDEMO_SK)\n1 | 16 | [15] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CUSTOMER | C_CUSTOMER_SK, C_CURRENT_CDEMO_SK, C_CURRENT_ADDR_SK, C_BIRTH_MONTH, C_BIRTH_YEAR | 261 | 261 | 2328538624\n1 | 17 | [13] | Aggregate | aggExprs: [SUM(SUM(CATALOG_SALES.CS_QUANTITY)), COUNT(COUNT(CATALOG_SALES.CS_QUANTITY)), SUM(SUM(CATALOG_SALES.CS_LIST_PRICE)), COUNT(COUNT(CATALOG_SALES.CS_LIST_PRICE)), SUM(SUM(CATALOG_SALES.CS_COUPON_AMT)), COUNT(COUNT(CATALOG_SALES.CS_COUPON_AMT)), SUM(SUM(CATALOG_SALES.CS_SALES_PRICE)), COUNT(COUNT(CATALOG_SALES.CS_SALES_PRICE)), SUM(SUM(CATALOG_SALES.CS_NET_PROFIT)), COUNT(COUNT(CATALOG_SALES.CS_NET_PROFIT)), SUM(SUM(CD1.CD_DEP_COUNT)), COUNT(COUNT(CD1.CD_DEP_COUNT)), COUNT(*)], groupKeys: [ITEM.I_ITEM_ID, CATALOG_SALES.CS_BILL_CUSTOMER_SK]\n1 | 18 | [17] | InnerJoin | joinKey: (ITEM.I_ITEM_SK = CATALOG_SALES.CS_ITEM_SK)\n1 | 19 | [18] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.ITEM | I_ITEM_SK, I_ITEM_ID | 2 | 2 | 23811584\n1 | 20 | [18] | Aggregate | aggExprs: [SUM(CATALOG_SALES.CS_QUANTITY), COUNT(CATALOG_SALES.CS_QUANTITY), SUM(CATALOG_SALES.CS_LIST_PRICE), COUNT(CATALOG_SALES.CS_LIST_PRICE), SUM(CATALOG_SALES.CS_COUPON_AMT), COUNT(CATALOG_SALES.CS_COUPON_AMT), SUM(CATALOG_SALES.CS_SALES_PRICE), COUNT(CATALOG_SALES.CS_SALES_PRICE), SUM(CATALOG_SALES.CS_NET_PROFIT), COUNT(CATALOG_SALES.CS_NET_PROFIT), SUM(CD1.CD_DEP_COUNT), COUNT(CD1.CD_DEP_COUNT), COUNT(*)], groupKeys: [CATALOG_SALES.CS_BILL_CUSTOMER_SK, CATALOG_SALES.CS_ITEM_SK]\n1 | 21 | [20] | InnerJoin | joinKey: (CD1.CD_DEMO_SK = CATALOG_SALES.CS_BILL_CDEMO_SK)\n1 | 22 | [21] | Filter | (CD1.CD_GENDER = 'F') AND (CD1.CD_EDUCATION_STATUS = 'Advanced Degree')\n1 | 23 | [22] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CUSTOMER_DEMOGRAPHICS | CD1 | CD_DEMO_SK, CD_GENDER, CD_EDUCATION_STATUS, CD_DEP_COUNT | 1 | 1 | 7446528\n1 | 24 | [21] | InnerJoin | joinKey: (DATE_DIM.D_DATE_SK = CATALOG_SALES.CS_SOLD_DATE_SK)\n1 | 25 | [24] | Filter | DATE_DIM.D_YEAR = 1998\n1 | 26 | [25] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.DATE_DIM | D_DATE_SK, D_YEAR | 1 | 1 | 2138624\n1 | 27 | [24] | Filter | (CATALOG_SALES.CS_BILL_CDEMO_SK IS NOT NULL) AND (CATALOG_SALES.CS_SOLD_DATE_SK IS NOT NULL) AND (CATALOG_SALES.CS_BILL_CUSTOMER_SK IS NOT NULL)\n1 | 28 | [27] | JoinFilter | joinKey: (CUSTOMER.C_CUSTOMER_SK = CATALOG_SALES.CS_BILL_CUSTOMER_SK)\n1 | 29 | [28] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CATALOG_SALES | CS_SOLD_DATE_SK, CS_BILL_CUSTOMER_SK, CS_BILL_CDEMO_SK, CS_ITEM_SK, CS_QUANTITY, CS_LIST_PRICE, CS_SALES_PRICE, CS_COUPON_AMT, CS_NET_PROFIT | 54922 | 54721 | 920184101376",
  "plan_scanner_text": null,
  "global_knowledge": {
    "engine": "snowflake",
    "benchmark": "tpcds",
    "scale_factor": 10,
    "source": "bootstrap \u2014 no empirical data yet",
    "principles": [
      {
        "id": "reduce_scan_volume",
        "description": "Pre-filter dimension tables before joining to fact tables. Snowflake's micro-partition pruning benefits from smaller join inputs.",
        "confidence": "hypothesized",
        "evidence": "Proven on DuckDB (35% of wins) and PostgreSQL. Expected high-value on Snowflake due to remote storage I/O costs."
      },
      {
        "id": "consolidate_repeated_scans",
        "description": "Replace multiple subqueries scanning the same table with single-pass CASE WHEN aggregation. Reduces remote I/O.",
        "confidence": "hypothesized",
        "evidence": "Proven on DuckDB (Q88 5.25x, Q9 4.47x). Remote storage makes this even more important on Snowflake."
      },
      {
        "id": "decorrelate_subqueries",
        "description": "Convert correlated subqueries to JOIN + GROUP BY for parallel MPP execution.",
        "confidence": "hypothesized",
        "evidence": "Proven on both DuckDB and PostgreSQL. Snowflake may auto-decorrelate some patterns."
      },
      {
        "id": "minimize_cte_count",
        "description": "Snowflake materializes CTEs by default. Use only when genuinely shared (2+ references) or for dimension pre-filtering.",
        "confidence": "hypothesized",
        "evidence": "Unlike DuckDB which inlines single-ref CTEs, Snowflake always materializes. Excessive CTEs increase memory pressure."
      }
    ],
    "anti_patterns": [
      {
        "id": "never_materialize_exists",
        "description": "EXISTS/NOT EXISTS uses semi-join with early termination. Converting to materializing CTEs kills this optimization.",
        "severity": "HIGH",
        "evidence": "Proven regression on DuckDB (0.14x Q16) and PostgreSQL (0.50x Q069). Same applies to Snowflake."
      },
      {
        "id": "limit_union_branches",
        "description": "UNION ALL creates separate execution branches, each scanning independently. Limit to 3 branches max.",
        "severity": "HIGH",
        "evidence": "Proven regression on DuckDB (0.23x Q13 with 9 branches). Each branch = separate scan pipeline on Snowflake."
      },
      {
        "id": "avoid_excessive_ctes",
        "description": "Each CTE materializes a temporary result. Too many CTEs increase memory pressure and may cause spilling to remote storage.",
        "severity": "MEDIUM",
        "evidence": "Snowflake-specific concern. DuckDB inlines single-ref CTEs; Snowflake does not."
      }
    ]
  },
  "semantic_intents": null,
  "matched_examples": [
    {
      "id": "snowflake_date_cte_isolate",
      "engine": "snowflake",
      "transform": "date_cte_isolate",
      "speedup": null,
      "status": "hypothesized",
      "description": "Pre-filter date_dim in a CTE to reduce fact table join input. Helps Snowflake's micro-partition pruning on date-clustered fact tables.",
      "signal": "date_dim joined to fact table with year/month filter applied late",
      "before_sql": "SELECT c_customer_id\nFROM customer_total_return ctr1, store, customer\nWHERE ctr1.ctr_total_return > (\n  SELECT avg(ctr_total_return)*1.2\n  FROM customer_total_return ctr2\n  WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk\n)",
      "after_sql": "WITH date_filter AS (\n  SELECT d_date_sk FROM date_dim WHERE d_year = 2000\n),\ncustomer_total_return AS (\n  SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk,\n         SUM(sr_fee) AS ctr_total_return\n  FROM store_returns\n  JOIN date_filter ON sr_returned_date_sk = d_date_sk\n  GROUP BY sr_customer_sk, sr_store_sk\n)\nSELECT c_customer_id\nFROM customer_total_return ctr1\nJOIN store ON s_store_sk = ctr1.ctr_store_sk\nJOIN customer ON ctr1.ctr_customer_sk = c_customer_sk\nWHERE s_state = 'SD'\n  AND ctr1.ctr_total_return > (\n    SELECT avg(ctr_total_return)*1.2\n    FROM customer_total_return ctr2\n    WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk\n  )\nORDER BY c_customer_id\nLIMIT 100",
      "tags": [
        "date_dim",
        "store_returns",
        "customer",
        "store",
        "cte",
        "date_filter",
        "year"
      ]
    },
    {
      "id": "snowflake_decorrelate",
      "engine": "snowflake",
      "transform": "decorrelate",
      "speedup": null,
      "status": "hypothesized",
      "description": "Convert correlated subquery to JOIN + GROUP BY for parallel MPP execution on Snowflake.",
      "signal": "Correlated subquery in WHERE clause comparing aggregate to outer row",
      "before_sql": "SELECT c_customer_id\nFROM customer_total_return ctr1, store, customer\nWHERE ctr1.ctr_total_return > (\n  SELECT avg(ctr_total_return)*1.2\n  FROM customer_total_return ctr2\n  WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk\n)",
      "after_sql": "WITH store_avg AS (\n  SELECT ctr_store_sk, avg(ctr_total_return)*1.2 AS avg_return\n  FROM customer_total_return\n  GROUP BY ctr_store_sk\n)\nSELECT c_customer_id\nFROM customer_total_return ctr1\nJOIN store_avg ON ctr1.ctr_store_sk = store_avg.ctr_store_sk\n  AND ctr1.ctr_total_return > store_avg.avg_return\nJOIN store ON s_store_sk = ctr1.ctr_store_sk\nJOIN customer ON ctr1.ctr_customer_sk = c_customer_sk\nWHERE s_state = 'SD'\nORDER BY c_customer_id\nLIMIT 100",
      "tags": [
        "correlated",
        "subquery",
        "avg",
        "group_by",
        "customer",
        "store"
      ]
    },
    {
      "id": "snowflake_single_pass_aggregation",
      "name": "Single Pass Aggregation",
      "description": "Replace N subqueries scanning the same fact table with a single scan using CASE WHEN conditional aggregation. Reduces remote I/O on Snowflake.",
      "benchmark_queries": [
        "Q88",
        "Q9"
      ],
      "verified_speedup": "hypothesized",
      "principle": "Scan Consolidation: scan large fact table once with conditional aggregation instead of N times with N subqueries. Critical for Snowflake where each scan hits remote storage.",
      "example": {
        "opportunity": "SINGLE_PASS_AGGREGATION",
        "input_slice": "[main_query]:\nSELECT *\nFROM\n (SELECT count(*) h8_30_to_9\n FROM store_sales, household_demographics, time_dim, store\n WHERE ss_sold_time_sk = time_dim.t_time_sk\n   AND ss_hdemo_sk = household_demographics.hd_demo_sk\n   AND ss_store_sk = s_store_sk\n   AND time_dim.t_hour = 8\n   AND time_dim.t_minute >= 30\n   AND store.s_store_name = 'ese') s1,\n (SELECT count(*) h9_to_9_30\n FROM store_sales, household_demographics, time_dim, store\n WHERE ss_sold_time_sk = time_dim.t_time_sk\n   AND ss_hdemo_sk = household_demographics.hd_demo_sk\n   AND ss_store_sk = s_store_sk\n   AND time_dim.t_hour = 9\n   AND time_dim.t_minute < 30\n   AND store.s_store_name = 'ese') s2",
        "output": {
          "rewrite_sets": [
            {
              "id": "rs_01",
              "transform": "single_pass_aggregation",
              "sql": "WITH time_filtered AS (\n  SELECT t_time_sk, t_hour, t_minute\n  FROM time_dim\n  WHERE t_hour BETWEEN 8 AND 12\n),\nhd_filtered AS (\n  SELECT hd_demo_sk\n  FROM household_demographics\n  WHERE (hd_dep_count = -1 AND hd_vehicle_count <= 1)\n     OR (hd_dep_count = 4 AND hd_vehicle_count <= 6)\n     OR (hd_dep_count = 3 AND hd_vehicle_count <= 5)\n),\nstore_filtered AS (\n  SELECT s_store_sk FROM store WHERE s_store_name = 'ese'\n)\nSELECT\n  COUNT(CASE WHEN tf.t_hour = 8 AND tf.t_minute >= 30 THEN 1 END) AS h8_30_to_9,\n  COUNT(CASE WHEN tf.t_hour = 9 AND tf.t_minute < 30 THEN 1 END) AS h9_to_9_30\nFROM store_sales ss\nJOIN time_filtered tf ON ss.ss_sold_time_sk = tf.t_time_sk\nJOIN hd_filtered hd ON ss.ss_hdemo_sk = hd.hd_demo_sk\nJOIN store_filtered sf ON ss.ss_store_sk = sf.s_store_sk"
            }
          ]
        }
      }
    }
  ],
  "all_available_examples": [
    {
      "id": "snowflake_date_cte_isolate",
      "speedup": "?",
      "description": "Pre-filter date_dim in a CTE to reduce fact table join input. Helps Snowflake's "
    },
    {
      "id": "snowflake_decorrelate",
      "speedup": "?",
      "description": "Convert correlated subquery to JOIN + GROUP BY for parallel MPP execution on Sno"
    },
    {
      "id": "snowflake_single_pass_aggregation",
      "speedup": "hypothesized",
      "description": "Replace N subqueries scanning the same fact table with a single scan using CASE "
    }
  ],
  "engine_profile": {
    "engine": "snowflake",
    "version_tested": "8.x (cloud)",
    "profile_type": "engine_profile",
    "briefing_note": "Initial profile based on Snowflake optimizer documentation and known MPP warehouse behavior. No empirical TPC-DS data yet \u2014 treat all gaps as hypotheses to validate.",
    "strengths": [
      {
        "id": "MICRO_PARTITION_PRUNING",
        "summary": "Snowflake prunes micro-partitions using min/max metadata on clustering keys. Filters on clustering columns skip irrelevant partitions entirely.",
        "field_note": "If the query already filters on the clustering key, the scan is already efficient. Don't wrap in CTEs for pushdown \u2014 the engine handles it. Focus on getting selective filters to execute BEFORE joins."
      },
      {
        "id": "MPP_PARALLEL_EXECUTION",
        "summary": "Queries execute across all nodes in the warehouse. Scans, joins, and aggregations are parallelized automatically.",
        "field_note": "Simple aggregation queries are already fast. Restructuring them rarely helps unless you're reducing the number of rows or partitions scanned."
      },
      {
        "id": "SEMI_JOIN_OPTIMIZATION",
        "summary": "EXISTS/NOT EXISTS uses semi-join with early termination.",
        "field_note": "Never materialize EXISTS patterns into CTEs or subqueries. Semi-join is always faster."
      },
      {
        "id": "RESULT_SET_CACHING",
        "summary": "Identical queries return cached results within 24 hours. Cache is per-warehouse.",
        "field_note": "Don't optimize for cache hits \u2014 we measure cold-run performance. But be aware that benchmarking needs cache warming or bypassing."
      },
      {
        "id": "ADAPTIVE_JOIN_SELECTION",
        "summary": "Hash join, merge join, and nested loop selected automatically based on table statistics.",
        "field_note": "Don't manually restructure join order for simple 2-4 table joins. Focus on reducing input sizes instead."
      },
      {
        "id": "PREDICATE_PUSHDOWN",
        "summary": "Simple WHERE predicates pushed into scan operators.",
        "field_note": "Single-table predicates are already pushed down. CTE-based pushdown only helps for cross-table predicates that the optimizer misses."
      }
    ],
    "gaps": [
      {
        "id": "CROSS_CTE_PREDICATE_BLINDNESS",
        "priority": "HIGH",
        "what": "Selective filters on dimension tables are not pushed through joins to reduce fact table scans.",
        "why": "Snowflake's optimizer may not propagate dimension predicates to prune fact table partitions when the filter is applied after the join.",
        "opportunity": "Pre-filter dimensions in CTEs, then join to fact tables. Reduces partition scanning on fact tables.",
        "what_worked": "Hypothesized: date_cte_isolate, dimension_cte_isolate for queries with date/store/customer filters.",
        "what_didnt_work": "Unknown \u2014 no empirical data yet.",
        "field_notes": "This is the #1 gap on both DuckDB (35% of wins) and PostgreSQL. Likely high-value on Snowflake too."
      },
      {
        "id": "REDUNDANT_SCAN_ELIMINATION",
        "priority": "HIGH",
        "what": "Same large table scanned N times in correlated or parallel subqueries.",
        "why": "Each subquery reference generates a separate scan pipeline. On Snowflake, each scan hits remote storage.",
        "opportunity": "Consolidate into single-pass aggregation with CASE WHEN. Reduces I/O which is Snowflake's bottleneck.",
        "what_worked": "Hypothesized: single_pass_aggregation for queries like Q9, Q88 (8 subqueries each scanning store_sales).",
        "what_didnt_work": "Unknown \u2014 no empirical data yet.",
        "field_notes": "Remote storage I/O is expensive on Snowflake. Reducing scan count should have outsized impact vs local engines."
      },
      {
        "id": "CORRELATED_SUBQUERY_PARALYSIS",
        "priority": "MEDIUM",
        "what": "Correlated subqueries in WHERE/SELECT may prevent optimal parallel execution.",
        "why": "Snowflake may execute correlated subqueries as nested loops, which scales linearly with outer row count.",
        "opportunity": "Decorrelate to JOIN + GROUP BY for parallel execution.",
        "what_worked": "Hypothesized: decorrelate pattern from DuckDB/PG wins.",
        "what_didnt_work": "Unknown \u2014 Snowflake may already decorrelate some patterns automatically.",
        "field_notes": "Check query profile \u2014 if Snowflake already shows a join, decorrelation won't help."
      },
      {
        "id": "CTE_MATERIALIZATION_OVERHEAD",
        "priority": "MEDIUM",
        "what": "CTEs in Snowflake are materialized by default, creating temporary results that may spill to remote storage.",
        "why": "Unlike DuckDB (which inlines single-ref CTEs), Snowflake always materializes. Large CTEs increase memory pressure.",
        "opportunity": "Use CTEs only for genuinely shared computations (referenced 2+ times). For single-use, prefer inline subqueries.",
        "what_worked": "Hypothesized: minimize CTE count, only use for pre-filtered dimensions.",
        "what_didnt_work": "Unknown.",
        "field_notes": "This is the OPPOSITE of DuckDB where CTEs are cheap. Be conservative with CTE-heavy rewrites on Snowflake."
      },
      {
        "id": "NETWORK_SHUFFLE_COST",
        "priority": "MEDIUM",
        "what": "Joins on non-co-located data require network shuffle between warehouse nodes.",
        "why": "MPP architecture distributes data across nodes. Joins on non-distribution keys require data movement.",
        "opportunity": "Pre-aggregate before joining to reduce shuffle volume. Pre-filter dimensions to reduce join inputs.",
        "what_worked": "Hypothesized: early_filter patterns that reduce rows before joins.",
        "what_didnt_work": "Unknown.",
        "field_notes": "Shuffle cost is invisible in query text but visible in query profile. Look for 'Bytes sent over the network' in EXPLAIN."
      }
    ]
  },
  "constraints": [
    {
      "id": "COMPLETE_OUTPUT",
      "severity": "CRITICAL",
      "description": "The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns.",
      "constraint_rules": [
        {
          "rule": "ALL_COLUMNS_PRESENT",
          "description": "Every column in the original SELECT list must appear in the rewritten SELECT list."
        },
        {
          "rule": "NO_COLUMN_RENAME",
          "description": "Column aliases must be preserved exactly. If the original says 'AS total_sales', the rewrite must use the same alias."
        },
        {
          "rule": "PRESERVE_COLUMN_ORDER",
          "description": "Columns must appear in the same order as the original SELECT list."
        }
      ],
      "prompt_instruction": "The rewritten query must output ALL columns from the original SELECT. Never drop, rename, or reorder output columns. Every column alias must be preserved exactly as in the original."
    },
    {
      "id": "CTE_COLUMN_COMPLETENESS",
      "severity": "CRITICAL",
      "description": "When creating or modifying a CTE, its SELECT list MUST include ALL columns that downstream nodes reference. Check the Node Contracts and Downstream Usage sections before writing any CTE.",
      "failure_rate": "Caused 54% of all execution errors (7 of 13 failures)",
      "observed_failures": [
        {
          "query": "Q21",
          "error": "prefetched_inventory CTE omits i_item_id but main query references it in SELECT and GROUP BY",
          "type": "MISSING_COLUMN_IN_CTE"
        },
        {
          "query": "Q76",
          "error": "filtered_store_dates CTE omits d_year and d_qoy but aggregation CTE uses them in GROUP BY",
          "type": "MISSING_COLUMN_IN_CTE"
        },
        {
          "query": "Q24",
          "error": "filtered_base CTE omits s_state, i_current_price, i_manager_id, i_units, i_size needed by downstream CTEs",
          "type": "MISSING_COLUMN_IN_CTE"
        },
        {
          "query": "Q64",
          "error": "filtered_store_sales CTE omits ss_sold_date_sk needed for JOIN in cross_sales CTE",
          "type": "MISSING_COLUMN_IN_CTE"
        },
        {
          "query": "Q60",
          "error": "ss/ws/cs CTEs reference item.i_item_sk and item.i_category in WHERE but item table not joined in CTE",
          "type": "MISSING_TABLE_IN_CTE"
        },
        {
          "query": "Q13",
          "error": "filtered_store_sales CTE references hd_demo_sk, cd_demo_sk from tables not joined in the CTE",
          "type": "MISSING_TABLE_IN_CTE"
        },
        {
          "query": "Q2",
          "error": "Ambiguous d_date_sk and d_week_seq columns between CTE and re-joined date_dim",
          "type": "AMBIGUOUS_COLUMN_REF"
        }
      ],
      "constraint_rules": [
        {
          "rule": "CHECK_DOWNSTREAM_REFS",
          "description": "Before writing a CTE, check the Downstream Usage section. Every column listed in downstream_refs for that node MUST appear in the CTE's SELECT list."
        },
        {
          "rule": "CHECK_JOIN_COLUMNS",
          "description": "If a downstream node JOINs on a column from this CTE (e.g., ON cte.d_date_sk = ...), that column MUST be in the CTE's SELECT."
        },
        {
          "rule": "CHECK_TABLE_PRESENCE",
          "description": "If a CTE's WHERE clause references columns from a table, that table MUST be in the CTE's FROM/JOIN clause."
        }
      ],
      "prompt_instruction": "CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error."
    },
    {
      "id": "LITERAL_PRESERVATION",
      "severity": "CRITICAL",
      "description": "All literal values (strings, numbers, dates) from the original query MUST be preserved EXACTLY in the rewrite",
      "failure_rate": "100% of Q2-Q16 failures were caused by hallucinated literals",
      "observed_failures": [
        {
          "query": "Q2",
          "original": "d_year = 2001, d_year = 2002",
          "hallucinated": "d_year = 1998, d_year = 1999",
          "type": "YEAR_HALLUCINATION"
        },
        {
          "query": "Q7",
          "original": "cd_gender = 'M', cd_marital_status = 'S', d_year = 2000",
          "hallucinated": "cd_gender = 'F', cd_marital_status = 'W', d_year = 2001",
          "type": "MULTIPLE_LITERAL_HALLUCINATION"
        },
        {
          "query": "Q10",
          "original": "d_year = 2002, ca_county IN ('Rush County', 'Toole County', 'Jefferson County', 'Dona Ana County', 'La Porte County')",
          "hallucinated": "d_year = 2001, ca_county IN ('Storey County', 'Marquette County', 'Warren County', 'Cochran County', 'Kandiyohi County')",
          "type": "YEAR_AND_STRING_HALLUCINATION"
        },
        {
          "query": "Q13",
          "original": "cd_marital_status = 'M', cd_education_status = 'Advanced Degree'",
          "hallucinated": "cd_marital_status = 'D', cd_education_status = 'Unknown'",
          "type": "STRING_HALLUCINATION"
        },
        {
          "query": "Q16",
          "original": "ca_state = 'GA', cc_county = 'Williamson County', d_date BETWEEN '2002-02-01' AND '2002-04-02'",
          "hallucinated": "ca_state = 'WV', cc_county IN ('Ziebach County', ...), d_date BETWEEN '2002-4-01' AND ...",
          "type": "STATE_COUNTY_DATE_HALLUCINATION"
        }
      ],
      "constraint_rules": [
        {
          "rule": "EXACT_STRING_MATCH",
          "description": "String literals in WHERE clauses must be copied character-for-character",
          "examples": [
            "'M' not 'F'",
            "'GA' not 'WV'",
            "'Rush County' not 'Storey County'"
          ]
        },
        {
          "rule": "EXACT_NUMBER_MATCH",
          "description": "Numeric literals (years, amounts, counts) must be copied exactly",
          "examples": [
            "2000 not 2001",
            "2002 not 2001",
            "100.00 not 150.00"
          ]
        },
        {
          "rule": "EXACT_DATE_MATCH",
          "description": "Date literals must be copied exactly, including format",
          "examples": [
            "'2002-02-01' not '2002-4-01'"
          ]
        },
        {
          "rule": "EXACT_LIST_MATCH",
          "description": "IN lists must contain the exact same values in the same order",
          "examples": [
            "IN ('TX', 'OH', 'TX') not IN ('SD', 'KS', 'MI')"
          ]
        }
      ],
      "prompt_instruction": "CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED."
    },
    {
      "id": "SEMANTIC_EQUIVALENCE",
      "severity": "CRITICAL",
      "description": "The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive.",
      "constraint_rules": [
        {
          "rule": "SAME_ROWS",
          "description": "The rewritten query must produce the same set of rows as the original. No rows may be added or removed."
        },
        {
          "rule": "SAME_COLUMNS",
          "description": "The rewritten query must return the same columns in the same order with the same names and data types."
        },
        {
          "rule": "SAME_ORDERING",
          "description": "If the original query has an ORDER BY clause, the rewritten query must preserve the same ordering."
        }
      ],
      "prompt_instruction": "The rewritten query MUST return exactly the same rows, columns, and ordering as the original. This is the prime directive. Any rewrite that changes the result set \u2014 even by one row, one column, or a different sort order \u2014 is WRONG and will be REJECTED."
    },
    {
      "id": "KEEP_EXISTS_AS_EXISTS",
      "severity": "HIGH",
      "overridable": true,
      "description": "Prefer preserving EXISTS/NOT EXISTS subqueries. Converting to IN/NOT IN risks NULL-handling changes; converting to JOINs risks duplicate rows.",
      "observed_failures": [
        {
          "problem": "Converting NOT EXISTS to NOT IN changes behavior when the subquery column contains NULLs. NOT IN with NULLs returns no rows.",
          "type": "NULL_SEMANTIC_CHANGE"
        },
        {
          "problem": "Converting EXISTS to JOIN can produce duplicate rows when the subquery matches multiple rows per outer row.",
          "type": "DUPLICATE_ROW_INTRODUCTION"
        }
      ],
      "constraint_rules": [
        {
          "rule": "AVOID_EXISTS_TO_IN",
          "description": "Avoid converting EXISTS/NOT EXISTS to IN/NOT IN unless the subquery column is provably NOT NULL (has a NOT NULL constraint or is a primary key)."
        },
        {
          "rule": "EXISTS_TO_JOIN_NEEDS_DISTINCT",
          "description": "Converting EXISTS to JOIN requires SELECT DISTINCT or GROUP BY to prevent row duplication when the subquery matches multiple rows per outer row."
        }
      ],
      "override_conditions": [
        "The subquery join column has a NOT NULL constraint or is a primary key (safe for IN conversion)",
        "The subquery returns at most 1 row per outer row (1:1 relationship, safe for JOIN)",
        "EXISTS is converted to JOIN + DISTINCT/GROUP BY to explicitly handle duplicates"
      ],
      "prompt_instruction": "DEFAULT: Preserve EXISTS/NOT EXISTS as-is. NOT EXISTS\u2192NOT IN breaks with NULLs; EXISTS\u2192JOIN can duplicate rows. HOWEVER: if the join column is NOT NULL (PK or explicit constraint), EXISTS\u2192IN is safe. If the subquery is 1:1 with the outer query, EXISTS\u2192JOIN is safe. The exploration worker MAY convert EXISTS with written proof of NULL safety or 1:1 cardinality."
    },
    {
      "id": "NO_CROSS_JOIN_DIMENSIONS",
      "severity": "HIGH",
      "overridable": true,
      "description": "Avoid CROSS JOINing dimension tables into a single CTE. The Cartesian product can explode row counts and prevent index use on fact tables.",
      "failure_rate": "Caused 0.0076x regression on Q080 (132x slower) when 3 dimensions were cross-joined",
      "observed_failures": [
        {
          "query": "Q080_multi",
          "regression": "0.0076x (57ms -> 7500ms)",
          "broken_rewrite": "filtered_dims AS (SELECT d_date_sk, i_item_sk, p_promo_sk FROM date_dim CROSS JOIN item CROSS JOIN promotion WHERE ...)",
          "problem": "CROSS JOIN created 120K-row CTE (30 \u00d7 200 \u00d7 20), then 3-key join prevented index use on fact tables.",
          "type": "CROSS_JOIN_DIMENSION_EXPLOSION"
        }
      ],
      "constraint_rules": [
        {
          "rule": "PREFER_SEPARATE_DIMENSION_CTES",
          "description": "Each dimension table should generally be its own CTE with its own filter. Combining via CROSS JOIN risks Cartesian explosion."
        }
      ],
      "override_conditions": [
        "Only 2 dimensions are joined (not 3+) AND the product is <1000 rows",
        "The dimensions share a foreign key (not a true Cartesian \u2014 it's a filtered JOIN)",
        "The combined CTE replaces N separate semi-joins with 1 multi-key join on the fact table"
      ],
      "prompt_instruction": "DEFAULT: Keep each dimension as a SEPARATE CTE (filtered_date, filtered_item, etc.). Cross-joining 3 dimensions caused 0.0076x on Q080 (30\u00d7200\u00d720 = 120K rows). HOWEVER: joining exactly 2 small dimensions (<1000 row product) via a foreign key (not Cartesian) may be acceptable if it reduces total join count on the fact table. The exploration worker MAY attempt a 2-dimension join with size estimate. Never cross-join 3+ dimensions."
    },
    {
      "id": "NO_MATERIALIZE_EXISTS",
      "severity": "HIGH",
      "overridable": true,
      "description": "Avoid converting EXISTS/NOT EXISTS subqueries into materialized CTEs with full table scans. EXISTS uses semi-join short-circuiting which is typically more efficient.",
      "failure_rate": "Caused 0.14x and 0.54x regressions (7x and 2x slowdowns)",
      "observed_failures": [
        {
          "query": "Q16",
          "regression": "0.14x (18ms -> 126ms)",
          "original": "EXISTS (SELECT * FROM catalog_sales cs2 WHERE cs1.cs_order_number = cs2.cs_order_number AND cs1.cs_warehouse_sk <> cs2.cs_warehouse_sk)",
          "broken_rewrite": "WITH multi_warehouse_orders AS (SELECT DISTINCT cs_order_number FROM catalog_sales GROUP BY cs_order_number HAVING MIN(cs_warehouse_sk) <> MAX(cs_warehouse_sk))",
          "type": "EXISTS_TO_FULL_SCAN_CTE"
        },
        {
          "query": "Q95",
          "regression": "0.54x (390ms -> 728ms)",
          "original": "EXISTS(SELECT 1 FROM ws_wh WHERE ws_wh.ws_order_number = ws1.ws_order_number)",
          "broken_rewrite": "WITH multi_warehouse_orders AS (SELECT DISTINCT ws_order_number FROM ws_wh)",
          "type": "EXISTS_TO_MATERIALIZED_DISTINCT"
        }
      ],
      "observed_successes": [
        {
          "query": "Q14",
          "speedup": "1.83x",
          "context": "intersect_to_exists: INTERSECT converted to EXISTS for semi-join short-circuit. Shows EXISTS restructuring CAN help when applied in the right direction."
        }
      ],
      "constraint_rules": [
        {
          "rule": "PREFER_EXISTS_SEMI_JOIN",
          "description": "EXISTS and NOT EXISTS use semi-join optimization that short-circuits after finding the first match. Converting to materialized CTEs usually forces a full scan."
        },
        {
          "rule": "AVOID_FULL_TABLE_DISTINCT_CTE",
          "description": "Avoid creating CTEs like SELECT DISTINCT key FROM large_table to replace EXISTS. The CTE scans the entire table; EXISTS can stop after one match."
        }
      ],
      "override_conditions": [
        "The EXISTS subquery is correlated and executed many times (optimizer fails to decorrelate it)",
        "The CTE would be small (<10K rows) and probed multiple times, amortizing materialization cost",
        "The EXISTS is inside a UNION ALL branch where each branch re-executes the same correlated subquery"
      ],
      "prompt_instruction": "DEFAULT: Keep EXISTS/NOT EXISTS as-is \u2014 semi-join short-circuiting is usually faster than materialization. Converting to CTEs caused 0.14x on Q16 and 0.54x on Q95. HOWEVER: if the correlated EXISTS is executed many times and the optimizer fails to decorrelate it, materializing into a small CTE (<10K rows) probed via JOIN may help. The exploration worker MAY attempt this with reasoning about correlation frequency and CTE size."
    },
    {
      "id": "NO_UNFILTERED_DIMENSION_CTE",
      "severity": "HIGH",
      "description": "Never create a 'filtered' dimension CTE that has no WHERE clause. A CTE that selects all rows from a dimension table is pure materialization overhead with zero filtering benefit.",
      "failure_rate": "Caused 0.85x regression on Q67",
      "observed_failures": [
        {
          "query": "Q67",
          "regression": "0.85x (4509ms -> 5291ms)",
          "broken_rewrite": "filtered_stores AS (SELECT s_store_sk, s_store_id FROM store), filtered_items AS (SELECT i_item_sk, i_category, i_class, i_brand, i_product_name FROM item)",
          "problem": "Both CTEs select ALL rows - no WHERE clause, no filtering. Pure overhead.",
          "type": "UNFILTERED_DIMENSION_CTE"
        }
      ],
      "constraint_rules": [
        {
          "rule": "CTE_MUST_FILTER",
          "description": "Every dimension CTE you create MUST have a WHERE clause that reduces the row count. If a dimension table has no filter to apply, do NOT extract it into a CTE."
        },
        {
          "rule": "COLUMN_PROJECTION_IS_NOT_FILTERING",
          "description": "Selecting a subset of columns (SELECT a, b FROM table) is NOT filtering. The CTE still materializes all rows. Only a WHERE clause reduces rows."
        }
      ],
      "prompt_instruction": "Every CTE you create must include a WHERE clause that actually reduces row count. Selecting fewer columns is not filtering \u2014 the CTE still materializes every row. If a dimension table has no predicate to push down, leave it as a direct join in the main query instead of wrapping it in a CTE."
    },
    {
      "id": "OR_TO_UNION_GUARD",
      "severity": "HIGH",
      "overridable": true,
      "description": "Guard rails for or_to_union: branches should have different access paths (not same column) and be limited to 3 or fewer.",
      "observed_failures": [
        {
          "query": "Q90",
          "regression": "0.59x (16ms -> 27ms)",
          "original": "WHERE t.t_hour BETWEEN 10 AND 11 OR t.t_hour BETWEEN 16 AND 17",
          "broken_rewrite": "UNION ALL of two separate web_sales scans (one for AM hours, one for PM hours)",
          "problem": "Doubles the fact table scan. The OR on t_hour is trivial for the optimizer - it just checks two ranges on one column.",
          "type": "UNION_SAME_COLUMN_OR"
        },
        {
          "query": "Q13",
          "regression": "0.23x",
          "problem": "9 UNION branches from nested OR expansion (3 conditions x 3 values) caused 9x fact table scans.",
          "type": "UNION_BRANCH_EXPLOSION"
        },
        {
          "query": "Q48",
          "regression": "0.41x",
          "problem": "9 UNION branches from nested OR expansion caused severe regression from multiplied fact table scans.",
          "type": "UNION_BRANCH_EXPLOSION"
        }
      ],
      "observed_successes": [
        {
          "query": "Q88",
          "speedup": "6.28x",
          "context": "8 time-bucket subqueries on store_sales, each filtering distinct hour ranges via different WHERE clauses. Branches access genuinely different row subsets."
        },
        {
          "query": "Q10",
          "speedup": "1.49x",
          "context": "OR across different dimension table lookups creating distinct access paths."
        },
        {
          "query": "Q45",
          "speedup": "1.35x",
          "context": "OR conditions reference different tables/subqueries."
        }
      ],
      "constraint_rules": [
        {
          "rule": "OR_TO_UNION_REQUIRES_DIFFERENT_PATHS",
          "description": "or_to_union is most beneficial when OR conditions create fundamentally different access paths (e.g., across different tables or between a correlated subquery and a direct filter). Same-column ORs on trivial ranges are usually handled efficiently by the optimizer as a single scan."
        },
        {
          "rule": "OR_TO_UNION_PREFER_3_OR_FEWER",
          "description": "Prefer 3 or fewer UNION ALL branches. Nested ORs that expand into 9+ combinations are almost always harmful. 4-5 branches may be acceptable if each accesses genuinely different row subsets."
        }
      ],
      "override_conditions": [
        "Branches access genuinely different row subsets (different WHERE predicates, not just same-column ranges)",
        "Total branch count stays at 4-5 or fewer (not Cartesian expansion of nested ORs)",
        "EXPLAIN shows the fact table is already scanned N times in baseline, so splitting does not increase scan count",
        "Each branch filters to <20% of fact table rows (high selectivity per branch)"
      ],
      "prompt_instruction": "DEFAULT: Prefer 3 or fewer UNION ALL branches with different access paths per branch. Same-column ORs on simple ranges are usually handled efficiently by the optimizer. Nested ORs that expand into 4+ branches (e.g., 3 x 3 = 9 combinations) caused 0.23x-0.41x regressions. HOWEVER: or_to_union achieved 6.28x on Q88 where branches had genuinely different row subsets. The exploration worker MAY try 4-5 branches if each branch has distinct access paths and high selectivity. Provide reasoning."
    },
    {
      "id": "OR_TO_UNION_SELF_JOIN",
      "severity": "HIGH",
      "overridable": true,
      "description": "Avoid or_to_union on queries with self-joins. Splitting OR conditions on self-joined tables can create multiple independent scans that cannot share the self-join optimization.",
      "observed_failures": [
        {
          "query": "Q23",
          "regression": "0.51x",
          "problem": "Self-join on store_sales was split into separate UNION branches, each requiring its own full self-join, doubling execution time.",
          "type": "SELF_JOIN_SPLIT"
        }
      ],
      "constraint_rules": [
        {
          "rule": "AVOID_OR_TO_UNION_ON_SELF_JOINS",
          "description": "If a query contains a self-join (same table aliased twice), or_to_union is risky because the self-join must typically remain in a single query block to share the scan."
        }
      ],
      "override_conditions": [
        "The OR conditions are on a column NOT involved in the self-join predicate",
        "The self-join aliases have independent WHERE filters that make each branch selective",
        "EXPLAIN shows the self-join is already executed multiple times in baseline"
      ],
      "prompt_instruction": "DEFAULT: Avoid or_to_union when the query contains a self-join (same table with different aliases). Splitting forces each branch to independently perform the self-join (observed 0.51x on Q23). HOWEVER: if the OR conditions target a column not involved in the self-join predicate, or if each alias already has independent selective filters, splitting may still help. The exploration worker MAY attempt this with written reasoning about why the structural context differs from Q23."
    },
    {
      "id": "REMOVE_REPLACED_CTES",
      "severity": "HIGH",
      "description": "When creating replacement CTEs, always remove the original CTEs from the WITH clause. Leaving dead/unused CTEs causes unnecessary materialization overhead.",
      "failure_rate": "Contributed to 0.49x and 0.68x regressions",
      "observed_failures": [
        {
          "query": "Q31",
          "regression": "0.49x (99ms -> 201ms)",
          "problem": "Created new store_sales_agg and web_sales_agg CTEs but left the original ss and ws CTEs in the WITH clause. Both old and new CTEs coexist, wasting materialization.",
          "type": "DEAD_CTE_OVERHEAD"
        },
        {
          "query": "Q74",
          "regression": "0.68x (493ms -> 724ms)",
          "problem": "Created 4 new year-specific CTEs but left the original year_total, year_total_store, year_total_web CTEs. Total of 8 CTEs instead of 4.",
          "type": "DEAD_CTE_OVERHEAD"
        }
      ],
      "constraint_rules": [
        {
          "rule": "REPLACE_NOT_APPEND",
          "description": "When your rewrite replaces a CTE with a new version, the original CTE node must be removed or overwritten. Do not define both the old and new CTE."
        }
      ],
      "prompt_instruction": "When creating replacement CTEs, overwrite the original by using the same node_id in your rewrite_sets, or ensure the original is removed from the WITH clause. Every CTE in the final query should be actively used \u2014 dead CTEs still get materialized and waste resources (caused 0.49x on Q31, 0.68x on Q74)."
    },
    {
      "id": "UNION_CTE_SPLIT_MUST_REPLACE",
      "severity": "HIGH",
      "description": "When splitting a UNION into separate CTEs, the original UNION must be eliminated. Creating CTEs that duplicate the UNION branches while keeping the original UNION doubles the work.",
      "observed_failures": [
        {
          "query": "multiple",
          "problem": "UNION branches were extracted into CTEs but the original UNION ALL remained in the main query, causing each branch to be computed twice.",
          "type": "DUPLICATE_UNION"
        }
      ],
      "constraint_rules": [
        {
          "rule": "CTE_SPLIT_REPLACES_UNION",
          "description": "When applying union_cte_split, the final query must reference the CTEs instead of the original UNION. The total number of UNION ALL operations should not increase."
        }
      ],
      "prompt_instruction": "When applying union_cte_split (splitting UNION into CTEs), the original UNION must be eliminated from the main query. The main query should reference the split CTEs, not duplicate the UNION branches. If the rewritten query has more UNION ALL operations than the original, the rewrite is incorrect."
    },
    {
      "id": "DECORRELATE_MUST_FILTER_FIRST",
      "severity": "MEDIUM",
      "description": "When decorrelating a subquery into a JOIN, the replacement JOIN must include a selective filter. A decorrelation that produces an unfiltered cross-product is worse than the original correlated subquery.",
      "observed_failures": [
        {
          "query": "multiple",
          "problem": "Correlated subquery was converted to JOIN without carrying over the original WHERE filters, producing a much larger intermediate result than the correlated version.",
          "type": "UNFILTERED_DECORRELATION"
        }
      ],
      "constraint_rules": [
        {
          "rule": "DECORRELATE_PRESERVES_FILTERS",
          "description": "When converting a correlated subquery to a JOIN + GROUP BY CTE, all WHERE conditions from the original subquery must be preserved in the CTE or JOIN condition. The replacement must not produce more rows than the original correlated subquery."
        }
      ],
      "prompt_instruction": "When decorrelating a correlated subquery into a JOIN, ensure all original WHERE filters are preserved in the replacement CTE or JOIN condition. A decorrelation without selective filters creates a cross-product that is larger than the original per-row correlated execution. The replacement CTE must filter to at most the same cardinality as the original subquery."
    },
    {
      "id": "DIMENSION_CTE_SAME_COLUMN_OR",
      "severity": "MEDIUM",
      "description": "Do not extract dimension CTE filters when the WHERE clause has OR conditions on the same column. Same-column ORs are efficiently handled by the optimizer in a single scan; CTE extraction adds overhead without benefit.",
      "observed_failures": [
        {
          "query": "Q37",
          "regression": "0.89x",
          "problem": "OR conditions on item.i_current_price ranges were extracted into separate CTEs, adding CTE materialization overhead without improving selectivity.",
          "type": "SAME_COLUMN_OR_CTE"
        }
      ],
      "constraint_rules": [
        {
          "rule": "KEEP_SAME_COLUMN_OR_INLINE",
          "description": "When OR conditions filter the same column (e.g., i_current_price BETWEEN X AND Y OR i_current_price BETWEEN A AND B), keep them inline in WHERE. Only extract dimension CTEs when filters span different columns or tables."
        }
      ],
      "prompt_instruction": "Do not create dimension CTEs to isolate OR conditions that filter the same column. The optimizer handles same-column ORs efficiently in a single scan. Only apply dimension_cte_isolate when filters span different columns or different dimension tables."
    },
    {
      "id": "EARLY_FILTER_CTE_BEFORE_CHAIN",
      "severity": "MEDIUM",
      "description": "Early filter CTEs must be referenced by the main query chain. An orphaned CTE that pre-filters data but is never joined back into the main query wastes materialization effort.",
      "observed_failures": [
        {
          "query": "multiple",
          "problem": "Early filter CTEs were created but not referenced in subsequent JOINs, resulting in wasted CTE materialization plus the original unfiltered joins remaining.",
          "type": "ORPHANED_FILTER_CTE"
        }
      ],
      "constraint_rules": [
        {
          "rule": "FILTER_CTE_MUST_BE_REFERENCED",
          "description": "Every early_filter CTE must be referenced by at least one downstream CTE or the main query. If a filter CTE is created, the original unfiltered table reference must be replaced with the CTE reference."
        }
      ],
      "prompt_instruction": "When creating an early_filter CTE, ensure it is actually referenced in the main query chain. The original unfiltered table reference must be replaced with the CTE reference. Do not create CTEs that filter a table if the main query still joins the original unfiltered table \u2014 this adds overhead without benefit."
    },
    {
      "id": "EXPLICIT_JOINS",
      "severity": "MEDIUM",
      "description": "Convert comma-separated implicit joins to explicit JOIN ... ON syntax. This gives the optimizer better join-order freedom.",
      "constraint_rules": [
        {
          "rule": "PREFER_EXPLICIT_JOIN",
          "description": "When the original query uses comma-separated tables with WHERE conditions for joining, convert to explicit JOIN ... ON syntax."
        }
      ],
      "prompt_instruction": "Convert comma-separated implicit joins to explicit JOIN ... ON syntax. This gives the optimizer better join-order freedom."
    },
    {
      "id": "MIN_BASELINE_THRESHOLD",
      "severity": "MEDIUM",
      "overridable": true,
      "description": "Be conservative with CTE-based transforms on queries with very short baseline runtimes. CTE materialization overhead can dominate when the query is already fast.",
      "failure_rate": "Caused 0.14x-0.59x regressions on queries under 50ms",
      "observed_failures": [
        {
          "query": "Q25",
          "regression": "0.50x (31ms -> 62ms)",
          "baseline_ms": 31,
          "transform": "prefetch_fact_join with 6 CTEs",
          "type": "CTE_OVERHEAD_ON_FAST_QUERY"
        },
        {
          "query": "Q90",
          "regression": "0.59x (16ms -> 27ms)",
          "baseline_ms": 16,
          "transform": "multi_dimension_prefetch with 4 CTEs + UNION ALL",
          "type": "CTE_OVERHEAD_ON_FAST_QUERY"
        },
        {
          "query": "Q16",
          "regression": "0.14x (18ms -> 126ms)",
          "baseline_ms": 18,
          "transform": "materialize_cte with 2 full-scan CTEs",
          "type": "CTE_OVERHEAD_ON_FAST_QUERY"
        }
      ],
      "constraint_rules": [
        {
          "rule": "CHECK_BASELINE_RUNTIME",
          "description": "If the Execution Plan shows estimated or actual runtime under 50ms, prefer minimal rewrites. DuckDB already optimizes simple star-join patterns efficiently."
        }
      ],
      "override_conditions": [
        "The transform reduces scan count (e.g., 3 scans \u2192 1 scan) even on a fast query",
        "The query is a component of a larger pipeline where cumulative savings matter",
        "The transform simplifies the query structure without adding CTEs (e.g., pushdown, decorrelate)"
      ],
      "prompt_instruction": "DEFAULT: If baseline is under 100ms, prefer minimal rewrites. CTE materialization overhead (hash tables, intermediate storage) can exceed filtering benefit on fast queries. HOWEVER: transforms that reduce scan count without adding CTEs (pushdown, decorrelate) may still help. The exploration worker MAY attempt structural changes on fast queries if the transform is scan-reducing, not CTE-adding."
    },
    {
      "id": "PREFETCH_MULTI_FACT_CHAIN",
      "severity": "MEDIUM",
      "overridable": true,
      "description": "Prefer limiting cascading fact-table CTEs to 2. Each additional CTE materializes a large intermediate result.",
      "observed_failures": [
        {
          "query": "Q4",
          "regression": "0.78x",
          "problem": "3 cascading fact-table CTEs (store_sales -> catalog_sales -> web_sales) created excessive intermediate materialization.",
          "type": "FACT_CHAIN_OVERHEAD"
        }
      ],
      "constraint_rules": [
        {
          "rule": "PREFER_2_OR_FEWER_FACT_CTES",
          "description": "When pre-joining fact tables with filtered dimensions in CTEs, 2 cascading fact CTEs is safe. A third adds risk of excessive materialization."
        }
      ],
      "override_conditions": [
        "Each fact CTE has highly selective filters (<5% of rows survive), keeping intermediate sizes small",
        "The 3rd CTE reads from a dimension-filtered result, not a raw fact table",
        "The query already has 3+ separate fact table scans in baseline \u2014 chaining cannot be worse"
      ],
      "prompt_instruction": "DEFAULT: Limit to 2 cascading fact-table CTEs. A 3rd CTE caused 0.78x on Q4 from excessive materialization. HOWEVER: if each CTE applies highly selective filters (<5% row survival), the intermediate results stay small. The exploration worker MAY try a 3-CTE chain if filters are selective and baseline already has 3+ separate scans."
    },
    {
      "id": "SINGLE_PASS_AGGREGATION_LIMIT",
      "severity": "MEDIUM",
      "overridable": true,
      "description": "Prefer limiting single-pass aggregation to 8 CASE branches. Beyond 8, CASE evaluation overhead may reduce benefit.",
      "observed_failures": [
        {
          "query": "Q88",
          "note": "8 CASE branches (time slices) was the maximum tested that still showed improvement (6.28x). More branches are untested, not proven harmful.",
          "type": "CASE_BRANCH_LIMIT"
        }
      ],
      "observed_successes": [
        {
          "query": "Q88",
          "speedup": "6.28x",
          "context": "8 CASE branches consolidating 8 separate time-bucket subqueries into a single scan."
        },
        {
          "query": "Q9",
          "speedup": "4.47x",
          "context": "5 CASE branches consolidating repeated store_sales scans."
        }
      ],
      "constraint_rules": [
        {
          "rule": "PREFER_8_OR_FEWER_CASE_BRANCHES",
          "description": "When consolidating repeated scans into CASE WHEN aggregates, 8 or fewer branches is well-tested. More branches are untested territory."
        }
      ],
      "override_conditions": [
        "The original query has 9-12 repeated scans on the same fact table (high consolidation value)",
        "Each CASE branch is a simple equality check (low per-row overhead)",
        "The fact table is large (>1M rows) so scan reduction dominates CASE evaluation cost"
      ],
      "prompt_instruction": "DEFAULT: Use at most 8 CASE branches for single_pass_aggregation (tested up to 8 at 6.28x on Q88). HOWEVER: 9-12 branches with simple equality checks on large fact tables may still net positive. The exploration worker MAY try 9-12 branches if the scan reduction value is high. Beyond 12 branches is not recommended."
    }
  ],
  "regression_warnings": [],
  "strategy_leaderboard": null,
  "query_archetype": null,
  "resource_envelope": null,
  "exploit_algorithm_text": "# Snowflake Rewrite Playbook\n# INITIAL \u2014 no empirical wins/regressions yet | TPC-DS SF10TCL\n\n## HOW TO USE THIS DOCUMENT\n\nWork in phase order. Each phase changes the plan shape \u2014 re-evaluate later phases after each.\n\n  Phase 1: Reduce scan volume (P1, P2) \u2014 always first. Micro-partition pruning is Snowflake's #1 lever.\n  Phase 2: Eliminate redundant work (P3, P4)\n  Phase 3: Fix structural inefficiencies (P5, P6, P7)\n\nBefore choosing any strategy, scan the query profile for:\n- Partitions scanned vs total: high ratio = pruning opportunity (add clustering key filters).\n- Spilling to disk: bytes spilled > 0 = memory pressure, reduce intermediate sizes.\n- Repeated table access: same table N times = consolidation candidate.\n- Remote I/O vs cache: low cache hit = partition pruning or clustering issue.\n- Join explosion: output rows >> input rows = join fanout, pre-aggregate.\n- Subquery type: correlated subquery = decorrelation candidate (Snowflake handles well but not always optimally).\n\n## ENGINE STRENGTHS \u2014 do NOT rewrite these patterns\n\n1. **Micro-partition pruning**: Snowflake prunes partitions based on min/max metadata on clustering keys. If a filter matches the clustering key, pruning is automatic \u2014 do NOT restructure.\n2. **Automatic clustering**: Snowflake re-clusters data in the background. Manual sort-based CTEs are unnecessary.\n3. **Result set caching**: Identical queries return cached results in <100ms. Don't optimize for cache \u2014 focus on cold-run performance.\n4. **MPP parallel execution**: Queries execute across warehouse nodes. Simple scans and aggregations are already parallelized.\n5. **Semi-join optimization**: EXISTS/NOT EXISTS uses semi-join. Never materialize these patterns.\n6. **Predicate pushdown**: Simple WHERE predicates pushed into scan. Don't wrap in CTEs for pushdown.\n7. **Adaptive join selection**: Hash join vs merge join vs nested loop chosen automatically based on statistics.\n\n## CORRECTNESS RULES\n\n- Identical rows, columns, ordering as original.\n- Copy ALL literals exactly (strings, numbers, dates).\n- Preserve NULL semantics \u2014 NOT IN with NULLs behaves differently than NOT EXISTS.\n- Every CTE must SELECT all columns referenced downstream.\n- Never drop, rename, or reorder output columns.\n- Preserve LIMIT semantics \u2014 no result set expansion.\n\n## GLOBAL GUARDS (check always, before any rewrite)\n\n1. EXISTS/NOT EXISTS \u2192 never materialize into CTEs (kills semi-join optimization)\n2. Clustering key filters \u2192 never restructure (breaks micro-partition pruning)\n3. Simple OR conditions \u2192 don't split to UNION ALL unless proven beneficial\n4. Baseline < 500ms \u2192 skip CTE rewrites (network/compilation overhead on Snowflake > DuckDB)\n5. CTEs are materialized by default \u2014 each CTE creates a temp result. Use sparingly.\n6. UNION ALL creates separate execution branches \u2014 each scans independently. Limit to \u22643 branches.\n7. Avoid creating more intermediate results than necessary \u2014 Snowflake spills large intermediates to remote storage.\n8. Don't over-decompose \u2014 Snowflake's MPP engine handles large joins well if inputs are pruned.\n9. Preserve window function partitioning \u2014 Snowflake optimizes PARTITION BY with sort-based execution.\n10. QUALIFY clause is native to Snowflake \u2014 prefer over subquery-based row filtering.\n\n## PATHOLOGY P1: CROSS_CTE_PREDICATE_BLINDNESS\n**Signal**: Filter applied late (after join), large intermediate before filter.\n**Transform**: date_cte_isolate, dimension_cte_isolate, early_filter\n**Gate**: Original must scan > 1M rows before applying the selective filter.\n**Strategy**: Pre-filter dimension tables in CTEs, join to fact table. Reduces partition scanning.\n**Risk**: LOW \u2014 Snowflake CTEs are materialized, but small dimension CTEs are cheap.\n**Example pattern**:\n```sql\n-- BEFORE: filter buried in WHERE after large join\nSELECT ... FROM fact JOIN dim ON ... WHERE dim.col = 'value'\n-- AFTER: pre-filter dimension, then join\nWITH dim_filtered AS (SELECT ... FROM dim WHERE col = 'value')\nSELECT ... FROM fact JOIN dim_filtered ON ...\n```\n\n## PATHOLOGY P2: REDUNDANT_SCAN_ELIMINATION\n**Signal**: Same large table scanned multiple times in subqueries.\n**Transform**: single_pass_aggregation, consolidate_scans\n**Gate**: Table appears 3+ times in query, each scan > 100K rows.\n**Strategy**: Scan once with CASE WHEN aggregation or a single CTE, then reference multiple times.\n**Risk**: LOW \u2014 reduces I/O which is Snowflake's bottleneck.\n**Example pattern**:\n```sql\n-- BEFORE: 8 subqueries each scanning store_sales\nSELECT (SELECT count(*) FROM store_sales WHERE ...) as s1,\n       (SELECT count(*) FROM store_sales WHERE ...) as s2\n-- AFTER: single scan with conditional aggregation\nSELECT count(CASE WHEN ... THEN 1 END) as s1,\n       count(CASE WHEN ... THEN 1 END) as s2\nFROM store_sales WHERE ...\n```\n\n## PATHOLOGY P3: CORRELATED_SUBQUERY_PARALYSIS\n**Signal**: Correlated subquery in WHERE or SELECT list. EXPLAIN shows nested loop.\n**Transform**: decorrelate, lateral_to_join\n**Gate**: Outer query returns > 10K rows (correlation cost scales linearly).\n**Strategy**: Convert correlated subquery to JOIN + GROUP BY.\n**Risk**: MEDIUM \u2014 Snowflake handles some correlated subqueries well. Check if EXPLAIN already shows a join.\n\n## PATHOLOGY P4: COMMA_JOIN_TO_EXPLICIT\n**Signal**: FROM a, b, c WHERE a.x = b.x AND b.y = c.y (implicit cross joins).\n**Transform**: explicit_join\n**Gate**: 3+ tables in comma-join style.\n**Strategy**: Convert to explicit JOIN...ON. Snowflake optimizer may handle both, but explicit joins provide clearer join ordering hints.\n**Risk**: LOW \u2014 semantically equivalent, may help optimizer.\n\n## PATHOLOGY P5: REPEATED_DIMENSION_PREFETCH\n**Signal**: Same dimension table joined to multiple fact subqueries.\n**Transform**: dimension_cte_isolate, multi_dimension_prefetch\n**Gate**: Dimension joined 2+ times with same filter.\n**Strategy**: Pre-filter dimension once in CTE, reuse across subqueries.\n**Risk**: LOW \u2014 reduces redundant dimension scans.\n\n## PATHOLOGY P6: SET_OPERATION_OPTIMIZATION\n**Signal**: INTERSECT, EXCEPT used where EXISTS/NOT EXISTS would suffice.\n**Transform**: intersect_to_exists, except_to_not_exists\n**Gate**: Set operation on large result sets (> 100K rows per side).\n**Strategy**: Convert to EXISTS/NOT EXISTS for semi-join optimization.\n**Risk**: LOW \u2014 preserves semantics, enables semi-join.\n\n## PATHOLOGY P7: WINDOW_FUNCTION_PUSHDOWN\n**Signal**: Window function computed over large dataset, then filtered.\n**Transform**: qualify_pushdown, pre_filter_window\n**Gate**: Window function input > 1M rows, post-filter keeps < 10%.\n**Strategy**: Use QUALIFY clause (Snowflake-native) or pre-filter input.\n**Risk**: MEDIUM \u2014 QUALIFY changes execution order.\n\n## VERIFICATION CHECKLIST\n\nBefore submitting any rewrite:\n1. Row count: must match original exactly.\n2. Column count and names: must match original exactly.\n3. NULL handling: NOT IN/NOT EXISTS semantics preserved.\n4. ORDER BY: must match original if present.\n5. LIMIT: must match original if present.\n6. No new tables introduced.\n7. No columns removed from output.\n\n## PRUNING GUIDE\n\nSkip optimization if:\n- Query baseline < 500ms (Snowflake overhead makes marginal gains invisible).\n- Query is a simple point lookup (micro-partition pruning already optimal).\n- Query uses only indexed/clustered columns in WHERE (already pruned).\n- Only 1 table in FROM (nothing to restructure).\n\n## REGRESSION REGISTRY\n\n*No regressions recorded yet \u2014 this section will be populated after initial benchmark.*\n\n| Query | Rewrite | Regression | Root Cause |\n|-------|---------|------------|------------|\n| \u2014 | \u2014 | \u2014 | \u2014 |\n",
  "detected_transforms": []
}