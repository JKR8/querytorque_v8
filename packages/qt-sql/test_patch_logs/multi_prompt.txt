You are a SQL rewrite engine for PostgreSQL v14.3.
Preserve exact semantic equivalence (same rows, same columns, same ordering).

## Original SQL

```sql
with customer_total_return as
(select sr_customer_sk as ctr_customer_sk
,sr_store_sk as ctr_store_sk
,sr_reason_sk as ctr_reason_sk
,sum(SR_RETURN_AMT_INC_TAX) as ctr_total_return
from store_returns
,date_dim
where sr_returned_date_sk = d_date_sk
and d_year =2002
and sr_return_amt / sr_return_quantity between 108 and 167
group by sr_customer_sk
,sr_store_sk, sr_reason_sk)
 select  c_customer_id
from customer_total_return ctr1
,store
,customer
,customer_demographics
where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2
from customer_total_return ctr2
where ctr1.ctr_store_sk = ctr2.ctr_store_sk
)
and ctr1.ctr_reason_sk BETWEEN 43 AND 46
and s_store_sk = ctr1.ctr_store_sk
and s_state IN ('IL', 'KY', 'TX')
and ctr1.ctr_customer_sk = c_customer_sk
and c_current_cdemo_sk = cd_demo_sk
and cd_marital_status IN ('M', 'M')
and cd_education_status IN ('Advanced Degree', 'College')
and cd_gender = 'F'
and c_birth_month = 2
and c_birth_year BETWEEN 1965 AND 1971
order by c_customer_id
limit 100;
```

## IR Node Map

```
S0 [SELECT]
  CTE: customer_total_return  (via CTE_Q_S0_customer_total_return)
    FROM: store_returns, date_dim
    WHERE [ddc05012d854ff26]: sr_returned_date_sk = d_date_sk AND d_year = 2002 AND sr_return_amt / sr_return_quantity BETWEEN ...
    GROUP BY: sr_customer_sk, sr_store_sk, sr_reason_sk
  MAIN QUERY (via Q_S0)
    FROM: customer_total_return ctr1, store, customer, customer_demographics
    WHERE [a05952426f9ba20b]: ctr1.ctr_total_return > (SELECT AVG(ctr_total_return) * 1.2 FROM customer_total_return AS ctr2 WH...
    ORDER BY: c_customer_id

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

## Task

Produce **4 independent patch plans** â€” each a different optimization strategy.
Each plan is a self-contained JSON object. Emit them as a JSON array.

Strategies to try (one per plan):
1. **Decorrelate**: Pre-compute the correlated subquery avg into a CTE
2. **Explicit JOINs**: Convert comma-joins to explicit JOIN...ON syntax for better plan selection
3. **Early filter**: Push selective filters (birth_month, birth_year, marital_status) into a CTE to reduce join input
4. **Combined**: Decorrelate + explicit JOINs together

## Available Operations

| op | target fields | payload fields |
|---|---|---|
| `insert_cte` | `by_node_id` | `cte_name`, `cte_query_sql` |
| `replace_expr_subtree` | `by_node_id` + `by_anchor_hash` | `expr_sql` |
| `replace_where_predicate` | `by_node_id` + `by_anchor_hash` | `expr_sql` |
| `delete_expr_subtree` | `by_node_id` + `by_anchor_hash` | _(none)_ |

## Targeting

- `by_node_id`: Statement ID (e.g. `"S0"`). Required for all ops.
- `by_anchor_hash`: Copy the 16-char hex hash from the IR Node Map `[...]` brackets. Do NOT compute your own.

## Output Format

```json
[
  {"plan_id": "P1_decorrelate", "dialect": "postgres", "steps": [...]},
  {"plan_id": "P2_explicit_joins", "dialect": "postgres", "steps": [...]},
  {"plan_id": "P3_early_filter", "dialect": "postgres", "steps": [...]},
  {"plan_id": "P4_combined", "dialect": "postgres", "steps": [...]}
]
```

Rules:
- Every `cte_query_sql` and `expr_sql` must be complete, executable SQL.
- Each plan is independent (applied to the original IR, not chained).
- After the JSON array, write a brief summary of each plan's expected speedup.

Now output the JSON array of 4 patch plans: