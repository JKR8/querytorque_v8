% ============================================================================
% QueryTorque Figure Include Snippets
% Copy-paste these into querytorque.tex to replace placeholders.
% ============================================================================

% --- FIGURE 1: System Overview (replaces placeholder at line ~246) ---
% Replace the entire \begin{figure*}...\end{figure*} block
\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{figures/fig1_system_overview.pdf}
\caption{End-to-end \sysname{} pipeline. The analyst LLM performs dynamic
gap matching (Section~\ref{sec:gap_selection}), then dispatches workers
with structurally diverse strategies. Only the best validated candidate
survives. Winners are promoted as baselines for subsequent rounds.}
\label{fig:overview}
\end{figure*}


% --- FIGURE 2: DuckDB Per-Query Speedup (NEW - add after Table 2) ---
\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig2_duckdb_perquery.pdf}
\caption{Per-query speedup on DuckDB TPC-DS SF10 (43 validated queries).
17 queries achieve WIN status ($\geq$1.10$\times$), with top speedups
of 6.28$\times$ (Q88, OR decomposition) and 4.47$\times$ (Q9, scan
consolidation). 9 regressions indicate that not all LLM rewrites are
beneficial, validating the importance of execution-based validation.}
\label{fig:duckdb_perquery}
\end{figure}


% --- FIGURE 3: Gap Profile Contribution (NEW - add in Section 4) ---
\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig3_gap_contribution.pdf}
\caption{Optimizer gap contribution to DuckDB wins. Three root
causes---cross-CTE predicate blindness, redundant scan elimination,
and correlated subquery paralysis---account for 70\% of all wins,
demonstrating that a small number of well-characterized blind spots
enable focused, high-yield optimization.}
\label{fig:gap_contribution}
\end{figure}


% --- FIGURE 4: Worker Coverage (NEW - add in Section 5.5) ---
\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig4_worker_coverage.pdf}
\caption{Worker win attribution on DuckDB TPC-DS SF10. 80\% of winning
queries (24/30) are \emph{uniquely} discovered by a single worker---no
other worker finds a valid improvement. The best single worker (W2)
captures only 30\% of wins, directly validating the swarm design.}
\label{fig:worker_coverage}
\end{figure}


% --- FIGURE 5: R-Bot Scatter (replaces placeholder at line ~1209) ---
% ⚠️ TEMPLATE - update fig_rbot_scatter.py data[] with real results first
\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/fig5_rbot_scatter_TEMPLATE.pdf}
\caption{Per-query speedup comparison on DSB SF10 (PostgreSQL~14.3).
Points above the diagonal are queries where \sysname{} outperforms
R-Bot. Red squares indicate wins from transforms outside Calcite's
rule vocabulary (CTE isolation, scan consolidation, single-pass
aggregation). Timeout recoveries (Q092: 4{,}428$\times$, Q032: 391$\times$)
are off-scale and annotated separately.}
\label{fig:rbot_scatter}
\end{figure}


% --- FIGURE 6: Cross-Engine Comparison (NEW - add in Section 5.6) ---
\begin{figure*}[t]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig6_cross_engine.pdf}
\caption{Cross-engine generalization with zero retraining. \sysname{}
achieves ${\sim}$37--39\% win rates on both DuckDB (columnar, TPC-DS)
and PostgreSQL (row-oriented, DSB) using the same pipeline, prompt
structure, and validation protocol. Only the engine gap profiles and
correctness constraints are engine-specific.}
\label{fig:cross_engine}
\end{figure*}
