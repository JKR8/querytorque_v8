[
  {
    "input_slice": "[main_query]:\nSELECT a.ca_state state, count(*) cnt\nFROM customer_address a, customer c, store_sales s, date_dim d, item i\nWHERE a.ca_address_sk = c.c_current_addr_sk\n  AND c.c_customer_sk = s.ss_customer_sk\n  AND s.ss_sold_date_sk = d.d_date_sk\n  AND s.ss_item_sk = i.i_item_sk\n  AND d.d_month_seq = (SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1)\n  AND i.i_current_price > 1.2 * (SELECT avg(j.i_current_price) FROM item j WHERE j.i_category = i.i_category)\nGROUP BY a.ca_state HAVING count(*) >= 10\nORDER BY cnt, a.ca_state LIMIT 100",
    "opportunity": "DATE_CTE_ISOLATE + CATEGORY_AVG",
    "output": {
      "rewrite_sets": [
        {
          "id": "rs_01",
          "transform": "date_cte_isolate",
          "nodes": {
            "target_month": "SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1",
            "category_avg_price": "SELECT i_category, AVG(i_current_price) * 1.2 AS avg_threshold FROM item GROUP BY i_category",
            "filtered_dates": "SELECT d_date_sk FROM date_dim JOIN target_month ON d_month_seq = target_month.d_month_seq",
            "filtered_sales": "SELECT ss_customer_sk, ss_item_sk FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk",
            "main_query": "SELECT a.ca_state AS state, COUNT(*) AS cnt FROM customer_address a JOIN customer c ON a.ca_address_sk = c.c_current_addr_sk JOIN filtered_sales s ON c.c_customer_sk = s.ss_customer_sk JOIN item i ON s.ss_item_sk = i.i_item_sk JOIN category_avg_price cap ON i.i_category = cap.i_category WHERE i.i_current_price > cap.avg_threshold GROUP BY a.ca_state HAVING COUNT(*) >= 10 ORDER BY cnt, a.ca_state LIMIT 100"
          },
          "invariants_kept": [
            "same result rows",
            "same ordering",
            "same column output",
            "same grouping and aggregation"
          ],
          "expected_speedup": "2.0x",
          "risk": "low"
        }
      ]
    },
    "key_insight": "Extract date month_seq subquery into CTE. Extract category average into separate CTE with GROUP BY. Join instead of correlated subquery. This allows each CTE to be scanned once."
  },
  {
    "input_slice": "[main_query]:\nSELECT ca_zip, sum(cs_sales_price)\nFROM catalog_sales, customer, customer_address, date_dim\nWHERE cs_bill_customer_sk = c_customer_sk\n  AND c_current_addr_sk = ca_address_sk\n  AND (substr(ca_zip,1,5) IN ('85669', '86197', ...)\n       OR ca_state IN ('CA','WA','GA')\n       OR cs_sales_price > 500)\n  AND cs_sold_date_sk = d_date_sk\n  AND d_qoy = 1 AND d_year = 2001\nGROUP BY ca_zip ORDER BY ca_zip LIMIT 100",
    "opportunity": "OR_TO_UNION + EARLY_FILTER",
    "output": {
      "rewrite_sets": [
        {
          "id": "rs_01",
          "transform": "or_to_union",
          "nodes": {
            "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_qoy = 1 AND d_year = 2001",
            "filtered_sales": "SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE substr(ca_zip,1,5) IN ('85669', '86197', '88274', '83405', '86475', '85392', '85460', '80348', '81792') UNION ALL SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE ca_state IN ('CA','WA','GA') UNION ALL SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE cs_sales_price > 500",
            "main_query": "SELECT ca_zip, SUM(cs_sales_price) FROM filtered_sales GROUP BY ca_zip ORDER BY ca_zip LIMIT 100"
          },
          "invariants_kept": [
            "output columns unchanged",
            "same rows after aggregation"
          ],
          "expected_speedup": "2.98x",
          "risk": "low"
        }
      ]
    },
    "key_insight": "Each OR branch becomes a separate query with focused predicates. Date filter is extracted as CTE and joined into each branch."
  },
  {
    "input_slice": "[quantity_range_1]:\nSELECT ss_item_sk, SUM(ss_quantity) AS qty\nFROM store_sales\nWHERE ss_quantity BETWEEN 1 AND 10\nGROUP BY ss_item_sk\n\n[quantity_range_2]:\nSELECT ss_item_sk, SUM(ss_quantity) AS qty\nFROM store_sales\nWHERE ss_quantity BETWEEN 11 AND 20\nGROUP BY ss_item_sk\n\n[main_query]:\nSELECT i_item_id, q1.qty, q2.qty\nFROM quantity_range_1 q1\nJOIN quantity_range_2 q2 ON q1.ss_item_sk = q2.ss_item_sk\nJOIN item i ON i_item_sk = q1.ss_item_sk\nWHERE i_item_id BETWEEN 'A' AND 'Z'\n  AND ss_sold_date_sk BETWEEN 2450816 AND 2450846",
    "opportunity": "PUSHDOWN",
    "output": {
      "rewrite_sets": [
        {
          "id": "rs_01",
          "transform": "pushdown",
          "nodes": {
            "quantity_range_1": "SELECT ss_item_sk, SUM(ss_quantity) AS qty FROM store_sales JOIN item ON ss_item_sk = i_item_sk WHERE ss_quantity BETWEEN 1 AND 10 AND i_item_id BETWEEN 'A' AND 'Z' AND ss_sold_date_sk BETWEEN 2450816 AND 2450846 GROUP BY ss_item_sk",
            "quantity_range_2": "SELECT ss_item_sk, SUM(ss_quantity) AS qty FROM store_sales JOIN item ON ss_item_sk = i_item_sk WHERE ss_quantity BETWEEN 11 AND 20 AND i_item_id BETWEEN 'A' AND 'Z' AND ss_sold_date_sk BETWEEN 2450816 AND 2450846 GROUP BY ss_item_sk",
            "main_query": "SELECT i_item_id, q1.qty, q2.qty FROM quantity_range_1 q1 JOIN quantity_range_2 q2 ON q1.ss_item_sk = q2.ss_item_sk JOIN item i ON i_item_sk = q1.ss_item_sk"
          },
          "invariants_kept": [
            "same result rows",
            "same aggregation results",
            "same output columns"
          ],
          "expected_speedup": "2.11x",
          "risk": "low"
        }
      ]
    },
    "key_insight": "When multiple quantity-range branches repeat the same dimensional filters, push those filters into each branch to reduce scan and aggregation cost."
  }
]