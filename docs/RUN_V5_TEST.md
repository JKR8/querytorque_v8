# V5 Single Query Test - Quick Start

## Test One Query with Full Output Recording

This test script will:
- âœ… Run v5 optimization on a single query
- âœ… Save ALL worker outputs incrementally (nothing lost if interrupted)
- âœ… Record all prompts, responses, and SQL from each worker
- âœ… Save execution plans, metadata, and summaries
- âœ… Handle interruptions gracefully (Ctrl+C safe)

---

## Quick Run

```bash
cd /mnt/c/Users/jakc9/Documents/QueryTorque_V8

# Test query 1 (default)
./scripts/run_v5_test.sh

# Test specific query
./scripts/run_v5_test.sh 15
```

**API Key**: Auto-loaded from `DeepseekV3.txt`

---

## What Gets Saved

Output directory: `research/experiments/v5_test_runs/q{N}_YYYYMMDD_HHMMSS/`

### Directory Structure

```
q1_20260204_143022/
â”œâ”€â”€ config.json                    # Test configuration
â”œâ”€â”€ original.sql                   # Original query
â”œâ”€â”€ plan_summary.txt               # Compact plan summary
â”œâ”€â”€ plan_full.txt                  # Full EXPLAIN output
â”œâ”€â”€ plan.json                      # Plan JSON
â”œâ”€â”€ base_prompt.txt                # Base DAG prompt
â”œâ”€â”€ summary.json                   # Machine-readable results
â”œâ”€â”€ summary.txt                    # Human-readable results
â”‚
â”œâ”€â”€ worker_1/                      # Worker 1 outputs
â”‚   â”œâ”€â”€ sample_optimized.sql       # Generated SQL
â”‚   â”œâ”€â”€ sample_metadata.json       # Status, speedup, error
â”‚   â”œâ”€â”€ sample_prompt.txt          # Full prompt sent to LLM
â”‚   â”œâ”€â”€ sample_response.txt        # LLM response (rewrites JSON)
â”‚   â”œâ”€â”€ full_metadata.json         # Full DB validation results
â”‚
â”œâ”€â”€ worker_2/                      # Worker 2 outputs
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ worker_3/                      # Worker 3 outputs
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ worker_4/                      # Worker 4 outputs
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ worker_5/                      # Worker 5 outputs (explore mode)
    â””â”€â”€ ...
```

### Incremental Saving

**Workers save immediately when they complete** - no data loss if:
- Process is interrupted (Ctrl+C)
- Connection drops
- System crashes
- LLM API timeouts

Even if only 2 of 5 workers finish, their outputs are fully saved.

---

## Output Files Explained

### Per-Worker Files

| File | Content |
|------|---------|
| `sample_optimized.sql` | Optimized SQL generated by this worker |
| `sample_metadata.json` | Status (pass/fail), speedup, error message |
| `sample_prompt.txt` | Complete prompt sent to LLM (includes DAG, plan, examples) |
| `sample_response.txt` | Raw LLM response (rewrites JSON) |
| `full_metadata.json` | Full DB validation results (if validated) |

### Global Files

| File | Content |
|------|---------|
| `config.json` | Test parameters (query #, DBs, workers, target speedup) |
| `original.sql` | Original TPC-DS query |
| `plan_summary.txt` | Compact execution plan (operators, scans, joins) |
| `plan_full.txt` | Full EXPLAIN ANALYZE output |
| `plan.json` | Parsed execution plan JSON |
| `base_prompt.txt` | DAG-based base prompt |
| `summary.json` | Results summary (valid workers, speedups, winner) |
| `summary.txt` | Human-readable results |

---

## Example Output

### Console Output

```
======================================================================
V5 Robust Test - Query 1
======================================================================

Output directory: research/experiments/v5_test_runs/q1_20260204_143022

Loading query 1...
âœ… Query loaded (1234 chars)

Sample DB: /mnt/d/TPC-DS/tpcds_sf100_sampled_1pct.duckdb
Full DB: /mnt/d/TPC-DS/tpcds_sf100.duckdb

Running v5 optimization with incremental saving...

Analyzing execution plan...
âœ… Plan analyzed

Running 5 workers in parallel on sample DB...
  âœ… Saved worker 2 (sample): pass, 1.23x
  âœ… Saved worker 4 (sample): pass, 1.87x
  âœ… Saved worker 1 (sample): validation_failed, 0.00x
  âœ… Saved worker 5 (sample): pass, 0.98x
  âœ… Saved worker 3 (sample): pass, 2.15x

âœ… Sample phase complete: 5/5 workers finished

Running full DB validation on 4 valid candidates...

Validating worker 2 on full DB...
  âœ… Saved worker 2 (full): pass, 1.18x
Validating worker 4 on full DB...
  âœ… Saved worker 4 (full): pass, 2.05x
  ğŸ† Winner found! Breaking early.

======================================================================
RESULTS
======================================================================

Elapsed: 145.3s
Output: research/experiments/v5_test_runs/q1_20260204_143022

Sample valid: 4/5
  Best speedup: 2.15x

Full validated: 2/4
  Best speedup: 2.05x

ğŸ† WINNER FOUND
   Worker: 4
   Sample: 1.87x
   Full: 2.05x

======================================================================
âœ… Test completed successfully
======================================================================

All outputs saved to: research/experiments/v5_test_runs/q1_20260204_143022
```

### Summary File

```
======================================================================
V5 Test - Query 1
======================================================================

Timestamp: 2026-02-04T14:32:45.123456
Elapsed: 145.3s

Sample Phase (1% DB)
----------------------------------------------------------------------
Valid workers: 4/5
Best speedup: 2.15x
Per-worker speedups:
  Worker 3: 2.15x (pass)
  Worker 4: 1.87x (pass)
  Worker 2: 1.23x (pass)
  Worker 5: 0.98x (pass)

Full Phase (SF100)
----------------------------------------------------------------------
Validated: 2/4
Best speedup: 2.05x
Per-worker speedups:
  Worker 4: 2.05x (pass)
  Worker 2: 1.18x (pass)

ğŸ† Winner Found
----------------------------------------------------------------------
Worker: 4
Sample speedup: 1.87x
Full speedup: 2.05x

======================================================================
```

---

## Viewing Results

### Quick Summary

```bash
# View summary
cat research/experiments/v5_test_runs/q1_*/summary.txt

# View JSON results
cat research/experiments/v5_test_runs/q1_*/summary.json | jq
```

### Explore Worker Outputs

```bash
# List all workers
ls -la research/experiments/v5_test_runs/q1_*/

# View worker 4's optimized SQL
cat research/experiments/v5_test_runs/q1_*/worker_4/sample_optimized.sql

# View worker 4's prompt (what was sent to LLM)
cat research/experiments/v5_test_runs/q1_*/worker_4/sample_prompt.txt

# View worker 4's response (LLM output)
cat research/experiments/v5_test_runs/q1_*/worker_4/sample_response.txt

# View worker 4's metadata
cat research/experiments/v5_test_runs/q1_*/worker_4/sample_metadata.json | jq
```

### Compare Workers

```bash
# Compare speedups
for w in research/experiments/v5_test_runs/q1_*/worker_*/sample_metadata.json; do
    echo "$w: $(jq -r '.speedup' $w)x"
done

# Find winner
grep -r "winner_worker" research/experiments/v5_test_runs/q1_*/summary.json
```

---

## Interruption Handling

### Safe to Interrupt

Press `Ctrl+C` at any time. Already-completed workers are fully saved.

**Example**: If you interrupt after 3 workers complete:
```
research/experiments/v5_test_runs/q1_20260204_143022/
â”œâ”€â”€ worker_1/     âœ… Fully saved
â”œâ”€â”€ worker_2/     âœ… Fully saved
â””â”€â”€ worker_3/     âœ… Fully saved
```

Workers 4 and 5 won't have directories (not started or incomplete).

### Resume From Saved Results

You can analyze partial results:

```bash
# View what completed
ls -la research/experiments/v5_test_runs/q1_*/

# Check summary (will show partial results)
cat research/experiments/v5_test_runs/q1_*/summary.txt
```

---

## Testing Different Queries

### Easy Queries (Good for Testing)
```bash
./scripts/run_v5_test.sh 1    # Simple aggregation
./scripts/run_v5_test.sh 3    # Basic joins
./scripts/run_v5_test.sh 7    # Medium complexity
```

### Complex Queries
```bash
./scripts/run_v5_test.sh 23   # Many CTEs
./scripts/run_v5_test.sh 39   # Complex subqueries
./scripts/run_v5_test.sh 74   # Advanced joins
```

### Known Winners (from prefills)
```bash
./scripts/run_v5_test.sh 9    # Previously achieved 2.05x
```

---

## Expected Timing

- **Sample phase**: 30-60s (5 workers in parallel)
- **Full phase**: 60-300s per candidate (sequential)
- **Total**: 1-5 minutes for typical query

**Early stopping**: Stops when first â‰¥2.0x candidate found on full DB.

---

## Manual Run (Without Script)

```bash
cd /mnt/c/Users/jakc9/Documents/QueryTorque_V8

# Set API key
export DEEPSEEK_API_KEY=$(cat DeepseekV3.txt)

# Install packages if needed
pip install -e packages/qt-shared packages/qt-sql

# Run test
python3 scripts/test_v5_single_query_robust.py 1
```

---

## Troubleshooting

### Import Error

```bash
pip install -e packages/qt-shared packages/qt-sql
```

### Database Not Found

```bash
# Verify databases exist
ls -lh /mnt/d/TPC-DS/*.duckdb
ls /mnt/d/TPC-DS/queries_duckdb_converted/*.sql | wc -l
```

### API Key Issues

```bash
# Check API key
cat DeepseekV3.txt
echo $DEEPSEEK_API_KEY
```

### Memory Issues

Reduce workers or use smaller sample DB:
```bash
# Edit script to use 5% sample instead of 1%
# or reduce max_workers from 5 to 3
```

---

## Next Steps

1. **Run test**: `./scripts/run_v5_test.sh 1`
2. **Review outputs**: Check `research/experiments/v5_test_runs/q1_*/`
3. **Analyze workers**: Compare prompts, responses, and SQL
4. **Identify patterns**: See which workers perform best
5. **Scale up**: Run full benchmark on all 97 queries

---

## Full Benchmark

Once single-query test works:

```bash
./scripts/run_v5_benchmark.sh
```

This runs all 97 queries with the same incremental saving strategy.

---

**Ready to test?** Just run: `./scripts/run_v5_test.sh 1`
