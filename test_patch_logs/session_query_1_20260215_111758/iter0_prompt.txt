## Role

You are a SQL optimization specialist. Your task is to propose **exactly 4 independent patch plans** for this query, each targeting a different optimization family.

Each patch plan must:
- Be atomic (steps applied sequentially: s1 → s2 → s3 → ...)
- Transform the original query using patch operations
- Preserve semantic equivalence (same rows, columns, ordering)
- Follow the patterns shown in reference examples below

You will **choose 4 of the 5 families** based on relevance to THIS SPECIFIC QUERY.


## Query: query_1

**Dialect**: SNOWFLAKE

```sql
-- start query 1 in stream 0 using template query1.tpl
with customer_total_return as
(select sr_customer_sk as ctr_customer_sk
,sr_store_sk as ctr_store_sk
,sum(SR_FEE) as ctr_total_return
from store_returns
,date_dim
where sr_returned_date_sk = d_date_sk
and d_year =2000
group by sr_customer_sk
,sr_store_sk)
 select c_customer_id
from customer_total_return ctr1
,store
,customer
where ctr1.ctr_total_return > (select avg(ctr_total_return)*1.2
from customer_total_return ctr2
where ctr1.ctr_store_sk = ctr2.ctr_store_sk)
and s_store_sk = ctr1.ctr_store_sk
and s_state = 'SD'
and ctr1.ctr_customer_sk = c_customer_sk
order by c_customer_id
 LIMIT 100;

-- end query 1 in stream 0 using template query1.tpl

```


## Current Execution Plan

```
GlobalStats | 7333 | 7333 | 127094259200
1 | 0 | Result | CUSTOMER.C_CUSTOMER_ID
1 | 1 | [0] | SortWithLimit | sortKey: [CUSTOMER.C_CUSTOMER_ID ASC NULLS LAST], rowCount: 100
1 | 2 | [1] | InnerJoin | joinKey: (CTR1.CTR_CUSTOMER_SK = CUSTOMER.C_CUSTOMER_SK)
1 | 3 | [2] | InnerJoin | joinKey: (STORE.S_STORE_SK = CTR1.CTR_STORE_SK)
1 | 4 | [3] | Filter | STORE.S_STATE = 'SD'
1 | 5 | [4] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.STORE | S_STORE_SK, S_STATE | 1 | 1 | 135680
1 | 6 | [3] | InnerJoin | joinKey: (CTR2.CTR_STORE_SK = CTR1.CTR_STORE_SK), joinFilter: (CTR1.CTR_TOTAL_RETURN) > (((SUM(CTR2.CTR_TOTAL_RETURN)) / (NVL(COUNT(CTR2.CTR_TOTAL_RETURN), 0))) * 1.2)
1 | 7 | [6] | Filter | (SUM(CTR2.CTR_TOTAL_RETURN) IS NOT NULL) AND (COUNT(CTR2.CTR_TOTAL_RETURN) IS NOT NULL)
1 | 8 | [7] | Aggregate | aggExprs: [SUM(CTR2.CTR_TOTAL_RETURN), COUNT(CTR2.CTR_TOTAL_RETURN)], groupKeys: [CTR2.CTR_STORE_SK]
1 | 9 | [8] | JoinFilter | joinKey: (STORE.S_STORE_SK = CTR1.CTR_STORE_SK)
1 | 10 | [9] | WithReference | CTR2
1 | 11 | [10] | Filter | STORE_RETURNS.SR_STORE_SK IS NOT NULL
1 | 12 | [11, 24] | WithClause | CUSTOMER_TOTAL_RETURN
1 | 13 | [12] | Aggregate | aggExprs: [SUM(SUM(SUM(STORE_RETURNS.SR_FEE)))], groupKeys: [STORE_RETURNS.SR_CUSTOMER_SK, STORE_RETURNS.SR_STORE_SK]
1 | 14 | [13] | Aggregate | aggExprs: [SUM(SUM(STORE_RETURNS.SR_FEE))], groupKeys: [STORE_RETURNS.SR_CUSTOMER_SK, STORE_RETURNS.SR_STORE_SK]
1 | 15 | [14] | InnerJoin | joinKey: (DATE_DIM.D_DATE_SK = STORE_RETURNS.SR_RETURNED_DATE_SK)
1 | 16 | [15] | Filter | DATE_DIM.D_YEAR = 2000
1 | 17 | [16] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.DATE_DIM | D_DATE_SK, D_YEAR | 1 | 1 | 2138624
1 | 18 | [15] | Aggregate | aggExprs: [SUM(STORE_RETURNS.SR_FEE)], groupKeys: [STORE_RETURNS.SR_CUSTOMER_SK, STORE_RETURNS.SR_STORE_SK, STORE_RETURNS.SR_RETURNED_DATE_SK]
1 | 19 | [18] | Filter | STORE_RETURNS.SR_RETURNED_DATE_SK IS NOT NULL
1 | 20 | [19] | JoinFilter | joinKey: (STORE.S_STORE_SK = CTR1.CTR_STORE_SK) OR (STORE.S_STORE_SK = CTR1.CTR_STORE_SK)
1 | 21 | [20] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.STORE_RETURNS | SR_RETURNED_DATE_SK, SR_CUSTOMER_SK, SR_STORE_SK, SR_FEE | 7070 | 7070 | 124763446272
1 | 22 | [6] | JoinFilter | joinKey: (STORE.S_STORE_SK = CTR1.CTR_STORE_SK)
1 | 23 | [22] | WithReference | CTR1
1 | 24 | [23] | Filter | (STORE_RETURNS.SR_STORE_SK IS NOT NULL) AND (STORE_RETURNS.SR_CUSTOMER_SK IS NOT NULL)
1 | 25 | [2] | JoinFilter | joinKey: (CTR1.CTR_CUSTOMER_SK = CUSTOMER.C_CUSTOMER_SK)
1 | 26 | [25] | TableScan | SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.CUSTOMER | C_CUSTOMER_SK, C_CUSTOMER_ID | 261 | 261 | 2328538624
```


## IR Structure (for patch targeting)

```
S0 [SELECT]
  CTE: customer_total_return  (via CTE_Q_S0_customer_total_return)
    FROM: store_returns, date_dim
    WHERE [eb0f6bc97f7168d4]: sr_returned_date_sk = d_date_sk AND d_year = 2000
    GROUP BY: sr_customer_sk, sr_store_sk
  MAIN QUERY (via Q_S0)
    FROM: customer_total_return ctr1, store, customer
    WHERE [e5b7485395ff5a80]: ctr1.ctr_total_return > (SELECT AVG(ctr_total_return) * 1.2 FROM customer_total_return AS ctr2 WH...
    ORDER BY: c_customer_id
S1 [OTHER_DDL]

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

**Note**: Use `by_node_id` (e.g., "S0") and `by_anchor_hash` (16-char hex) from map above to target patch operations.


## Optimization Families

Review the 5 families below. Each shows a pattern with a gold example patch plan.

Choose up to **4 most relevant families** for this query based on:
- Query structure (CTEs, subqueries, joins, aggregations, set operations)
- Execution plan signals (WHERE placement, repeated scans, correlated subqueries, materializations)
- Problem signature (cardinality estimation errors, loops vs sets, filter ordering)



### Family A: Early Filtering (Predicate Pushback)
**Description**: Push small filters into CTEs early, reduce row count before expensive operations
**Speedup Range**: 1.3–4.0x (~35% of all wins)
**Use When**:
  1. Late WHERE filters on dimension tables
  2. Cascading CTEs with filters applied downstream
  3. Expensive joins after filters could be pushed earlier

**Gold Example**: `sf_inline_decorrelate` (23.17x)

**BEFORE (slow):**
```sql
select  sum(cs_ext_discount_amt)  as "excess discount amount"
from
   catalog_sales
   ,item
   ,date_dim
where
(i_manufact_id in (1, 78, 97, 516, 521)
or i_manager_id BETWEEN 25 and 54)
and i_item_sk = cs_item_sk
and d_date between '1999-03-07' and
...
```

**AFTER (fast):**
```sql
WITH filtered_items AS (
    SELECT i_item_sk
    FROM item
    WHERE i_manufact_id IN (1, 78, 97, 516, 521)
       OR i_manager_id BETWEEN 25 AND 54
),
date_filtered_sales AS (
    SELECT cs.cs_item_sk, cs.cs_ext_discount_amt,
           cs.cs_list_price, cs.cs_sales_price
    FROM catalog_sales cs
...
```

**PATCH PLAN:**
```json
{
  "plan_id": "gold_sf_inline_decorrelate",
  "dialect": "snowflake",
  "description": "Decompose correlated scalar subquery into 3 CTEs (dimension filter, date-filtered fact, per-key threshold) and JOIN. Converts O(N*M) correlated scans to single hash join.",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_items",
        "cte_query_sql": "SELECT i_item_sk FROM item WHERE i_manufact_id IN (1, 78, 97, 516, 521) OR i_manager_id BETWEEN 25 AND 54"
      },
      "description": "Extract item dimension filter into CTE"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "date_filtered_sales",
        "cte_query_sql": "SELECT cs.cs_item_sk, cs.cs_ext_discount_amt, cs.cs_list_price, cs.cs_sales_price FROM catalog_sales cs JOIN date_dim d ON d.d_date_sk = cs.cs_sold_date_sk WHERE d.d_date BETWEEN '1999-03-07' AND CAST('1999-03-07' AS DATE) + INTERVAL '90 DAY'"
      },
      "description": "Extract date-filtered fact scan into CTE"
    },
    {
      "step_id": "s3",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "item_avg_discount",
        "cte_query_sql": "SELECT dfs.cs_item_sk, 1.3 * AVG(dfs.cs_ext_discount_amt) AS threshold FROM date_filtered_sales dfs JOIN filtered_items fi ON fi.i_item_sk = dfs.cs_item_sk WHERE dfs.cs_list_price BETWEEN 16 AND 45 AND dfs.cs_sales_price / dfs.cs_list_price BETWEEN 63 * 0.01 AND 83 * 0.01 GROUP BY dfs.cs_item_sk"
      },
      "description": "Decorrelate scalar subquery into per-key GROUP BY threshold CTE"
    },
    {
      "step_id": "s4",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "date_filtered_sales dfs JOIN item_avg_discount iad ON iad.cs_item_sk = dfs.cs_item_sk"
      },
      "description": "Replace comma-join FROM with CTE-based explicit JOINs"
    },
    {
      "step_id": "s5",
      "op": "replace_where_predicate",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "09dc78125155e528"
      },
      "payload": {
        "expr_sql": "dfs.cs_ext_discount_amt > iad.threshold"
      },
      "description": "Replace complex WHERE (with correlated subquery) with simple threshold comparison"
    }
  ]
}
```



### Family B: Decorrelation (Sets Over Loops)
**Description**: Convert correlated subqueries to standalone CTEs with GROUP BY, eliminate per-row re-execution
**Speedup Range**: 2.4–2.9x (~15% of all wins)
**Use When**:
  1. Correlated subqueries in WHERE clause
  2. Scalar aggregates computed per outer row
  3. DELIM_SCAN in execution plan (indicates correlation)

**Gold Example**: `sf_shared_scan_decorrelate` (7.82x)

**BEFORE (slow):**
```sql
select 
   sum(ws_ext_discount_amt)  as "Excess Discount Amount"
from
    web_sales
   ,item
   ,date_dim
where
(i_manufact_id BETWEEN 341 and 540
or i_category IN ('Home', 'Men', 'Music'))
and i_item_sk = ws_item_sk
...
```

**AFTER (fast):**
```sql
WITH common_scan AS (
  SELECT ws_item_sk, ws_ext_discount_amt, ws_sales_price, ws_list_price
  FROM web_sales
  INNER JOIN date_dim ON d_date_sk = ws_sold_date_sk
  WHERE d_date BETWEEN '1998-03-13' AND CAST('1998-03-13' AS DATE) + INTERVAL '90 DAY'
    AND ws_wholesale_cost BETWEEN 26 AND 46
),
threshold_computation AS (
  SELECT ws_item_sk, 1.3 * AVG(ws_ext_discount_amt) AS threshold
  FROM common_scan
...
```

**PATCH PLAN:**
```json
{
  "plan_id": "gold_sf_shared_scan_decorrelate",
  "dialect": "snowflake",
  "description": "Extract shared fact table scan into CTE, derive threshold and filtered rows from it, then JOIN. Converts O(N*M) correlated execution to O(N+M) hash join.",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "common_scan",
        "cte_query_sql": "SELECT ws_item_sk, ws_ext_discount_amt, ws_sales_price, ws_list_price FROM web_sales INNER JOIN date_dim ON d_date_sk = ws_sold_date_sk WHERE d_date BETWEEN '1998-03-13' AND CAST('1998-03-13' AS DATE) + INTERVAL '90 DAY' AND ws_wholesale_cost BETWEEN 26 AND 46"
      },
      "description": "Extract shared fact+date scan with common filters into CTE"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "threshold_computation",
        "cte_query_sql": "SELECT ws_item_sk, 1.3 * AVG(ws_ext_discount_amt) AS threshold FROM common_scan WHERE ws_sales_price / ws_list_price BETWEEN 34 * 0.01 AND 49 * 0.01 GROUP BY ws_item_sk"
      },
      "description": "Compute per-item discount threshold from shared scan"
    },
    {
      "step_id": "s3",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "outer_rows",
        "cte_query_sql": "SELECT cs.ws_item_sk, cs.ws_ext_discount_amt FROM common_scan cs INNER JOIN item ON i_item_sk = cs.ws_item_sk WHERE i_manufact_id BETWEEN 341 AND 540 OR i_category IN ('Home', 'Men', 'Music')"
      },
      "description": "Filter to item-matching rows from shared scan"
    },
    {
      "step_id": "s4",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "join_filter",
        "cte_query_sql": "SELECT o.ws_ext_discount_amt FROM outer_rows o INNER JOIN threshold_computation t ON o.ws_item_sk = t.ws_item_sk WHERE o.ws_ext_discount_amt > t.threshold"
      },
      "description": "Join outer rows with threshold, apply discount filter"
    },
    {
      "step_id": "s5",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "join_filter"
      },
      "description": "Replace original 3-table comma-join with single CTE reference"
    },
    {
      "step_id": "s6",
      "op": "delete_expr_subtree",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "0ef6ffe2461512ae"
      },
      "description": "Remove original WHERE clause (all conditions now in CTEs)"
    }
  ]
}
```



### Family C: Aggregation Pushdown (Minimize Rows Touched)
**Description**: Aggregate before expensive joins when GROUP BY keys ⊇ join keys, reduce intermediate sizes
**Speedup Range**: 1.3–15.3x (~5% of all wins (high variance))
**Use When**:
  1. GROUP BY happens after large joins
  2. GROUP BY keys are subset of join keys
  3. Intermediate result size >> final result size

**Gold Example**: `aggregate_pushdown` (42.90x)

**BEFORE (slow):**
```sql
select i_product_name
             ,i_brand
             ,i_class
             ,i_category
             ,avg(inv_quantity_on_hand) qoh
       from inventory
           ,date_dim
           ,item
       where inv_date_sk=d_date_sk
              and inv_item_sk=i_item_sk
...
```

**AFTER (fast):**
```sql
WITH date_filtered AS (SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1188 AND 1188 + 11), inventory_date AS (SELECT inv_item_sk, inv_quantity_on_hand FROM inventory JOIN date_filtered ON inv_date_sk = d_date_sk), inventory_agg AS (SELECT inv_item_sk, SUM(inv_quantity_on_hand) AS sum_qty, COUNT(inv_quantity_on_hand) AS cnt FROM inventory_date GROUP BY inv_item_sk), join_item AS (SELECT i_product_name, i_brand, i_class, i_category, sum_qty, cnt FROM inventory_agg JOIN item ON inv_item_sk = i_item_sk), rollup_aggregate AS (SELECT i_product_name, i_brand, i_class, i_category, CASE WHEN SUM(cnt) > 0 THEN SUM(sum_qty) / SUM(cnt) END AS qoh FROM join_item GROUP BY ROLLUP(i_product_name, i_brand, i_class, i_category)) SELECT i_product_name, i_brand, i_class, i_category, qoh FROM rollup_aggregate ORDER BY qoh ASC, i_product_name ASC, i_brand ASC, i_class ASC, i_category ASC LIMIT 100
```

**PATCH PLAN:**
```json
{
  "plan_id": "gold_duckdb_aggregate_pushdown",
  "dialect": "duckdb",
  "description": "Pre-aggregate fact table by join key before dimension joins to reduce rows entering the join from millions to thousands",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "date_filtered",
        "cte_query_sql": "SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1188 AND 1188 + 11"
      },
      "description": "Insert CTE 'date_filtered' for date dimension filtering"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "inventory_date",
        "cte_query_sql": "SELECT inv_item_sk, inv_quantity_on_hand FROM inventory JOIN date_filtered ON inv_date_sk = d_date_sk"
      },
      "description": "Insert CTE 'inventory_date' for date dimension filtering"
    },
    {
      "step_id": "s3",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "inventory_agg",
        "cte_query_sql": "SELECT inv_item_sk, SUM(inv_quantity_on_hand) AS sum_qty, COUNT(inv_quantity_on_hand) AS cnt FROM inventory_date GROUP BY inv_item_sk"
      },
      "description": "Insert CTE 'inventory_agg' for pre-aggregated computation"
    },
    {
      "step_id": "s4",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "join_item",
        "cte_query_sql": "SELECT i_product_name, i_brand, i_class, i_category, sum_qty, cnt FROM inventory_agg JOIN item ON inv_item_sk = i_item_sk"
      },
      "description": "Insert CTE 'join_item' for pre-filtered join"
    },
    {
      "step_id": "s5",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "rollup_aggregate",
        "cte_query_sql": "SELECT i_product_name, i_brand, i_class, i_category, CASE WHEN SUM(cnt) > 0 THEN SUM(sum_qty) / SUM(cnt) END AS qoh FROM join_item GROUP BY ROLLUP (i_product_name, i_brand, i_class, i_category)"
      },
      "description": "Insert CTE 'rollup_aggregate' for pre-aggregated computation"
    },
    {
      "step_id": "s6",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "rollup_aggregate"
      },
      "description": "Replace FROM clause with optimized version"
    },
    {
      "step_id": "s7",
      "op": "delete_expr_subtree",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "cb0b927b3e0ad199"
      },
      "description": "Remove WHERE clause (conditions moved to CTEs)"
    }
  ]
}
```



### Family D: Set Operation Optimization (Sets Over Loops)
**Description**: Replace INTERSECT/UNION-based patterns with EXISTS/NOT EXISTS, avoid full materialization
**Speedup Range**: 1.7–2.7x (~8% of all wins)
**Use When**:
  1. INTERSECT patterns between large sets
  2. UNION ALL with duplicate elimination
  3. Set operations materializing full intermediate results

**Gold Example**: `intersect_to_exists` (1.83x)

**BEFORE (slow):**
```sql
with  cross_items as
 (select i_item_sk ss_item_sk
 from item,
 (select iss.i_brand_id brand_id
     ,iss.i_class_id class_id
     ,iss.i_category_id category_id
 from store_sales
     ,item iss
     ,date_dim d1
 where ss_item_sk = iss.i_item_sk
...
```

**AFTER (fast):**
```sql
WITH cross_items AS (SELECT i.i_item_sk AS ss_item_sk FROM item AS i WHERE EXISTS(SELECT 1 FROM store_sales, item AS iss, date_dim AS d1 WHERE ss_item_sk = iss.i_item_sk AND ss_sold_date_sk = d1.d_date_sk AND d1.d_year BETWEEN 2000 AND 2000 + 2 AND iss.i_brand_id = i.i_brand_id AND iss.i_class_id = i.i_class_id AND iss.i_category_id = i.i_category_id) AND EXISTS(SELECT 1 FROM catalog_sales, item AS ics, date_dim AS d2 WHERE cs_item_sk = ics.i_item_sk AND cs_sold_date_sk = d2.d_date_sk AND d2.d_year BETWEEN 2000 AND 2000 + 2 AND ics.i_brand_id = i.i_brand_id AND ics.i_class_id = i.i_class_id AND ics.i_category_id = i.i_category_id) AND EXISTS(SELECT 1 FROM web_sales, item AS iws, date_dim AS d3 WHERE ws_item_sk = iws.i_item_sk AND ws_sold_date_sk = d3.d_date_sk AND d3.d_year BETWEEN 2000 AND 2000 + 2 AND iws.i_brand_id = i.i_brand_id AND iws.i_class_id = i.i_class_id AND iws.i_category_id = i.i_category_id)), avg_sales AS (SELECT AVG(quantity * list_price) AS average_sales FROM (SELECT ss_quantity AS quantity, ss_list_price AS list_price FROM store_sales, date_dim WHERE ss_sold_date_sk = d_date_sk AND d_year BETWEEN 2000 AND 2000 + 2 UNION ALL SELECT cs_quantity AS quantity, cs_list_price AS list_price FROM catalog_sales, date_dim WHERE cs_sold_date_sk = d_date_sk AND d_year BETWEEN 2000 AND 2000 + 2 UNION ALL SELECT ws_quantity AS quantity, ws_list_price AS list_price FROM web_sales, date_dim WHERE ws_sold_date_sk = d_date_sk AND d_year BETWEEN 2000 AND 2000 + 2) AS x)
SELECT channel, i_brand_id, i_class_id, i_category_id, SUM(sales), SUM(number_sales) FROM (SELECT 'store' AS channel, i_brand_id, i_class_id, i_category_id, SUM(ss_quantity * ss_list_price) AS sales, COUNT(*) AS number_sales FROM store_sales, item, date_dim WHERE ss_item_sk IN (SELECT ss_item_sk FROM cross_items) AND ss_item_sk = i_item_sk AND ss_sold_date_sk = d_date_sk AND d_year = 2000 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING SUM(ss_quantity * ss_list_price) > (SELECT average_sales FROM avg_sales) UNION ALL SELECT 'catalog' AS channel, i_brand_id, i_class_id, i_category_id, SUM(cs_quantity * cs_list_price) AS sales, COUNT(*) AS number_sales FROM catalog_sales, item, date_dim WHERE cs_item_sk IN (SELECT ss_item_sk FROM cross_items) AND cs_item_sk = i_item_sk AND cs_sold_date_sk = d_date_sk AND d_year = 2000 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING SUM(cs_quantity * cs_list_price) > (SELECT average_sales FROM avg_sales) UNION ALL SELECT 'web' AS channel, i_brand_id, i_class_id, i_category_id, SUM(ws_quantity * ws_list_price) AS sales, COUNT(*) AS number_sales FROM web_sales, item, date_dim WHERE ws_item_sk IN (SELECT ss_item_sk FROM cross_items) AND ws_item_sk = i_item_sk AND ws_sold_date_sk = d_date_sk AND d_year = 2000 + 2 AND d_moy = 11 GROUP BY i_brand_id, i_class_id, i_category_id HAVING SUM(ws_quantity * ws_list_price) > (SELECT average_sales FROM avg_sales)) AS y GROUP BY ROLLUP (channel, i_brand_id, i_class_id, i_category_id) ORDER BY channel, i_brand_id, i_class_id, i_category_id LIMIT 100;
```

**PATCH PLAN:**
```json
{
  "plan_id": "gold_duckdb_intersect_to_exists",
  "dialect": "duckdb",
  "description": "Convert INTERSECT subquery pattern to multiple EXISTS clauses for better join planning",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "replace_block_with_cte_pair",
      "target": {
        "by_node_id": "S0",
        "by_label": "cross_items"
      },
      "payload": {
        "sql_fragment": "cross_items AS (SELECT i.i_item_sk AS ss_item_sk FROM item AS i WHERE EXISTS(SELECT 1 FROM store_sales, item AS iss, date_dim AS d1 WHERE ss_item_sk = iss.i_item_sk AND ss_sold_date_sk = d1.d_date_sk AND d1.d_year BETWEEN 2000 AND 2000 + 2 AND iss.i_brand_id = i.i_brand_id AND iss.i_class_id = i.i_class_id AND iss.i_category_id = i.i_category_id) AND EXISTS(SELECT 1 FROM catalog_sales, item AS ics, date_dim AS d2 WHERE cs_item_sk = ics.i_item_sk AND cs_sold_date_sk = d2.d_date_sk AND d2.d_year BETWEEN 2000 AND 2000 + 2 AND ics.i_brand_id = i.i_brand_id AND ics.i_class_id = i.i_class_id AND ics.i_category_id = i.i_category_id) AND EXISTS(SELECT 1 FROM web_sales, item AS iws, date_dim AS d3 WHERE ws_item_sk = iws.i_item_sk AND ws_sold_date_sk = d3.d_date_sk AND d3.d_year BETWEEN 2000 AND 2000 + 2 AND iws.i_brand_id = i.i_brand_id AND iws.i_class_id = i.i_class_id AND iws.i_category_id = i.i_category_id))"
      },
      "description": "Replace CTE 'cross_items' body with optimized version"
    }
  ]
}
```



### Family E: Materialization / Prefetch (Don't Repeat Work)
**Description**: Extract repeated scans or pre-compute intermediate results for reuse across multiple consumers
**Speedup Range**: 1.3–6.2x (~18% of all wins)
**Use When**:
  1. Repeated scans of same table with different filters
  2. Dimension filters applied independently multiple times
  3. CTE referenced multiple times with implicit re-evaluation

**Gold Example**: `multi_dimension_prefetch` (2.71x)

**BEFORE (slow):**
```sql
select s_store_name, s_store_id,
        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,
        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,
        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,
        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,
        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,
        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,
        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales
 from date_dim, store_sales, store
 where d_date_sk = ss_sold_date_sk and
...
```

**AFTER (fast):**
```sql
WITH filtered_dates AS (SELECT d_date_sk, d_day_name FROM date_dim WHERE d_year = 2000), filtered_stores AS (SELECT s_store_sk, s_store_id, s_store_name FROM store WHERE s_gmt_offset = -5), filtered_sales AS (SELECT ss_sales_price, d_day_name, s_store_id, s_store_name FROM store_sales JOIN filtered_dates ON d_date_sk = ss_sold_date_sk JOIN filtered_stores ON s_store_sk = ss_store_sk)
SELECT s_store_name, s_store_id, SUM(CASE WHEN (d_day_name = 'Sunday') THEN ss_sales_price ELSE NULL END) AS sun_sales, SUM(CASE WHEN (d_day_name = 'Monday') THEN ss_sales_price ELSE NULL END) AS mon_sales, SUM(CASE WHEN (d_day_name = 'Tuesday') THEN ss_sales_price ELSE NULL END) AS tue_sales, SUM(CASE WHEN (d_day_name = 'Wednesday') THEN ss_sales_price ELSE NULL END) AS wed_sales, SUM(CASE WHEN (d_day_name = 'Thursday') THEN ss_sales_price ELSE NULL END) AS thu_sales, SUM(CASE WHEN (d_day_name = 'Friday') THEN ss_sales_price ELSE NULL END) AS fri_sales, SUM(CASE WHEN (d_day_name = 'Saturday') THEN ss_sales_price ELSE NULL END) AS sat_sales FROM filtered_sales GROUP BY s_store_name, s_store_id ORDER BY s_store_name, s_store_id, sun_sales, mon_sales, tue_sales, wed_sales, thu_sales, fri_sales, sat_sales LIMIT 100;
```

**PATCH PLAN:**
```json
{
  "plan_id": "gold_duckdb_multi_dimension_prefetch",
  "dialect": "duckdb",
  "description": "Pre-filter multiple dimension tables (date + store) into separate CTEs before joining with fact table",
  "preconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "postconditions": [
    {
      "kind": "parse_ok"
    }
  ],
  "steps": [
    {
      "step_id": "s1",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_dates",
        "cte_query_sql": "SELECT d_date_sk, d_day_name FROM date_dim WHERE d_year = 2000"
      },
      "description": "Insert CTE 'filtered_dates' for date dimension filtering"
    },
    {
      "step_id": "s2",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_stores",
        "cte_query_sql": "SELECT s_store_sk, s_store_id, s_store_name FROM store WHERE s_gmt_offset = -5"
      },
      "description": "Insert CTE 'filtered_stores'"
    },
    {
      "step_id": "s3",
      "op": "insert_cte",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "cte_name": "filtered_sales",
        "cte_query_sql": "SELECT ss_sales_price, d_day_name, s_store_id, s_store_name FROM store_sales JOIN filtered_dates ON d_date_sk = ss_sold_date_sk JOIN filtered_stores ON s_store_sk = ss_store_sk"
      },
      "description": "Insert CTE 'filtered_sales' for date dimension filtering"
    },
    {
      "step_id": "s4",
      "op": "replace_from",
      "target": {
        "by_node_id": "S0"
      },
      "payload": {
        "from_sql": "filtered_sales"
      },
      "description": "Replace FROM clause with optimized version"
    },
    {
      "step_id": "s5",
      "op": "delete_expr_subtree",
      "target": {
        "by_node_id": "S0",
        "by_anchor_hash": "834e9c75d01a8fa3"
      },
      "description": "Remove WHERE clause (conditions moved to CTEs)"
    }
  ]
}
```



## Your Task

Analyze this query against the 5 families above.

**Choose up to 4 families** that are most relevant. For each chosen family:
1. Create a patch plan with atomic steps
2. Score relevance (0.0–1.0) based on how well it matches this query
3. Provide reasoning for your choice


**Output format**:

```json
[
  {
    "family": "A",
    "transform": "date_cte_isolate",
    "plan_id": "t1_family_a",
    "relevance_score": 0.95,
    "reasoning": "Query has late calendar_date filter on large fact table, CTE cascade structure → early pushdown = high ROI",
    "steps": [
      {
        "step_id": "s1",
        "op": "insert_cte",
        "target": {"by_node_id": "S0"},
        "payload": {"cte_name": "date_filter", "cte_query_sql": "SELECT ... WHERE calendar_date > ..."},
        "description": "Extract date filter into separate CTE"
      },
      {
        "step_id": "s2",
        "op": "replace_from",
        "target": {"by_node_id": "S0"},
        "payload": {"from_sql": "fact_table JOIN date_filter ON ..."},
        "description": "Join via filtered CTE instead of raw table"
      }
    ]
  },
  {
    "family": "B",
    "transform": "decorrelate_subquery",
    "plan_id": "t2_family_b",
    "relevance_score": 0.88,
    "reasoning": "Correlated subquery in WHERE with DELIM_SCAN in plan → decorrelation = medium ROI",
    "steps": [...]
  },
  {
    "family": "E",
    "transform": "materialized_prefetch",
    "plan_id": "t3_family_e",
    "relevance_score": 0.72,
    "reasoning": "Multiple independent dimension filters applied → materialization saves repeated scans",
    "steps": [...]
  },
  {
    "family": "D",
    "transform": "intersect_to_exists",
    "plan_id": "t4_family_d",
    "relevance_score": 0.61,
    "reasoning": "Set operation subquery pattern detected → EXISTS conversion feasible",
    "steps": [...]
  }
]
```

**Rules**:
- Output up to 4 patch plans
- Each plan has its own `plan_id`, `family`, `transform` name
- Each plan includes `relevance_score` (0.0–1.0) and brief `reasoning`
- Each step in `steps` array is complete, executable SQL (no ellipsis)
- Preserve all WHERE filters (removing filters = semantic bug)
- Order patches by relevance_score (highest first)

After JSON, provide analysis:
```
## Analysis

For each available family, explain relevance (HIGH / MEDIUM / LOW) in 1-2 sentences.

**Chosen families**: [list]
**Expected speedups**: t1: Nx, t2: Nx, ...
**Confidence**: High/Medium/Low (brief justification)
```

Now output your JSON array of patch plans:
