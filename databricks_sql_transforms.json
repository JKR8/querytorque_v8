[
  {
    "id": "broadcast_hint_small_table_join",
    "name": "Broadcast Hint for Small-Table Joins",
    "description": "Add BROADCAST hint to force broadcasting small dimension tables instead of shuffle-based joins",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Databricks defaults to sort-merge join when CBO stats are stale or missing. Broadcasting a small table (<2GB) eliminates the shuffle of both sides, replacing it with a local hash join on every executor. Photon further accelerates broadcast hash joins over sort-merge.",
    "example": {
      "opportunity": "BROADCAST_HINT_JOIN",
      "input_slice": "SELECT o.order_id, c.customer_name\nFROM orders o\nINNER JOIN customers c ON o.customer_id = c.customer_id\nWHERE o.order_date >= '2024-01-01'",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "broadcast_hint_join",
            "nodes": {
              "main_query": "SELECT /*+ BROADCAST(c) */ o.order_id, c.customer_name\nFROM orders o\nINNER JOIN customers c ON o.customer_id = c.customer_id\nWHERE o.order_date >= '2024-01-01'"
            },
            "invariants_kept": ["same result rows", "same ordering"],
            "expected_speedup": "2-5x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "When the CBO does not have accurate stats (common when ANALYZE TABLE has not been run), Databricks may choose a sort-merge join requiring a full shuffle of both tables across the cluster. Adding /*+ BROADCAST(c) */ forces the smaller customers table to be broadcast to every executor, eliminating the expensive shuffle of the large orders table. Photon replaces sort-merge with hash joins natively, and broadcast hash join is the fastest join strategy when one side fits in memory.",
      "when_not_to_use": "When the 'small' table exceeds available executor memory (typically >2GB per executor, or >10GB with spark.sql.autoBroadcastJoinThreshold tuned). Also avoid for FULL OUTER joins where broadcast is not supported."
    },
    "original_sql": "SELECT o.order_id, c.customer_name\nFROM orders o\nINNER JOIN customers c ON o.customer_id = c.customer_id\nWHERE o.order_date >= '2024-01-01'",
    "optimized_sql": "SELECT /*+ BROADCAST(c) */ o.order_id, c.customer_name\nFROM orders o\nINNER JOIN customers c ON o.customer_id = c.customer_id\nWHERE o.order_date >= '2024-01-01'",
    "optimized_source": "databricks_docs_hints",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "predicate_pushdown_past_join",
    "name": "Push Filter Predicates Before Join",
    "description": "Move WHERE filters into subqueries or CTEs so they apply before the join, reducing shuffle volume",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Databricks Catalyst optimizer often pushes predicates down automatically, but complex queries with multiple joins or non-trivial expressions can prevent pushdown. Explicit early filtering drastically reduces the data shuffled across executors.",
    "example": {
      "opportunity": "PREDICATE_PUSHDOWN",
      "input_slice": "SELECT o.order_id, li.quantity, p.product_name\nFROM orders o\nJOIN line_items li ON o.order_id = li.order_id\nJOIN products p ON li.product_id = p.product_id\nWHERE o.order_date >= '2024-01-01'\n  AND o.order_date < '2024-02-01'\n  AND p.category = 'Electronics'",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "predicate_pushdown_explicit",
            "nodes": {
              "cte_filtered_orders": "SELECT order_id, order_date\nFROM orders\nWHERE order_date >= '2024-01-01'\n  AND order_date < '2024-02-01'",
              "cte_filtered_products": "SELECT product_id, product_name\nFROM products\nWHERE category = 'Electronics'",
              "main_query": "SELECT fo.order_id, li.quantity, fp.product_name\nFROM cte_filtered_orders fo\nJOIN line_items li ON fo.order_id = li.order_id\nJOIN cte_filtered_products fp ON li.product_id = fp.product_id"
            },
            "invariants_kept": ["same result rows", "same ordering"],
            "expected_speedup": "2-10x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "By filtering orders and products into CTEs before the joins, the shuffle exchange moves only the qualifying rows. In a distributed Spark environment, shuffle is the dominant cost—reducing the rows entering a shuffle stage from millions to thousands yields massive speedups. Dynamic File Pruning (DFP) on Delta tables further benefits from explicit predicates as it prunes Parquet files at the scan stage.",
      "when_not_to_use": "When Catalyst already successfully pushes predicates (check EXPLAIN output). Over-decomposing into CTEs can sometimes prevent Catalyst from finding global optimization opportunities."
    },
    "original_sql": "SELECT o.order_id, li.quantity, p.product_name\nFROM orders o\nJOIN line_items li ON o.order_id = li.order_id\nJOIN products p ON li.product_id = p.product_id\nWHERE o.order_date >= '2024-01-01'\n  AND o.order_date < '2024-02-01'\n  AND p.category = 'Electronics'",
    "optimized_sql": "WITH filtered_orders AS (\n  SELECT order_id\n  FROM orders\n  WHERE order_date >= '2024-01-01'\n    AND order_date < '2024-02-01'\n),\nfiltered_products AS (\n  SELECT product_id, product_name\n  FROM products\n  WHERE category = 'Electronics'\n)\nSELECT fo.order_id, li.quantity, fp.product_name\nFROM filtered_orders fo\nJOIN line_items li ON fo.order_id = li.order_id\nJOIN filtered_products fp ON li.product_id = fp.product_id",
    "optimized_source": "databricks_community_best_practices",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "replace_not_in_with_anti_join",
    "name": "Replace NOT IN with LEFT ANTI JOIN",
    "description": "Convert NOT IN subquery to LEFT ANTI JOIN to avoid broadcast of full subquery result and handle NULLs correctly",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "NOT IN with a subquery in Spark SQL can produce a BroadcastNestedLoopJoin (cartesian product) when NULLs are possible. LEFT ANTI JOIN uses the standard hash-based join path and avoids the NULL-safety cartesian fallback.",
    "example": {
      "opportunity": "NOT_IN_TO_ANTI_JOIN",
      "input_slice": "SELECT customer_id, customer_name\nFROM customers\nWHERE customer_id NOT IN (\n  SELECT customer_id FROM orders WHERE order_date >= '2024-01-01'\n)",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "not_in_to_left_anti_join",
            "nodes": {
              "main_query": "SELECT c.customer_id, c.customer_name\nFROM customers c\nLEFT ANTI JOIN orders o\n  ON c.customer_id = o.customer_id\n  AND o.order_date >= '2024-01-01'"
            },
            "invariants_kept": ["same result rows assuming customer_id NOT NULL"],
            "expected_speedup": "3-20x",
            "risk": "medium — NOT IN treats NULLs differently from ANTI JOIN; verify column is NOT NULL"
          }
        ]
      },
      "key_insight": "Spark's NOT IN semantics require checking every row for NULL values, which can force a BroadcastNestedLoopJoin (essentially a cartesian product). LEFT ANTI JOIN uses hash-based join infrastructure, which is vastly more efficient. On Databricks with Photon, anti joins are vectorized and can leverage Dynamic File Pruning on Delta tables.",
      "when_not_to_use": "When the subquery column can contain NULLs and the NOT IN NULL semantics (return no rows if any NULL exists) are intentionally desired. In that case NOT EXISTS is the semantically equivalent safe rewrite."
    },
    "original_sql": "SELECT customer_id, customer_name\nFROM customers\nWHERE customer_id NOT IN (\n  SELECT customer_id FROM orders WHERE order_date >= '2024-01-01'\n)",
    "optimized_sql": "SELECT c.customer_id, c.customer_name\nFROM customers c\nLEFT ANTI JOIN orders o\n  ON c.customer_id = o.customer_id\n  AND o.order_date >= '2024-01-01'",
    "optimized_source": "spark_sql_anti_pattern_guides",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "correlated_subquery_to_join",
    "name": "Decorrelate Scalar Subquery to JOIN + Aggregation",
    "description": "Replace correlated scalar subqueries in SELECT with a pre-aggregated JOIN to eliminate per-row re-execution",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Spark can decorrelate some subqueries automatically, but complex or nested correlated subqueries often remain as BroadcastNestedLoopJoin. Rewriting as explicit JOIN + GROUP BY lets the optimizer choose an efficient hash or merge join.",
    "example": {
      "opportunity": "DECORRELATE_SCALAR_SUBQUERY",
      "input_slice": "SELECT c.customer_id, c.customer_name,\n  (SELECT SUM(o.amount) FROM orders o WHERE o.customer_id = c.customer_id) AS total_spent\nFROM customers c",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "scalar_subquery_to_join_agg",
            "nodes": {
              "cte_order_totals": "SELECT customer_id, SUM(amount) AS total_spent\nFROM orders\nGROUP BY customer_id",
              "main_query": "SELECT c.customer_id, c.customer_name, COALESCE(ot.total_spent, 0) AS total_spent\nFROM customers c\nLEFT JOIN cte_order_totals ot ON c.customer_id = ot.customer_id"
            },
            "invariants_kept": ["same result rows", "NULL becomes 0 via COALESCE"],
            "expected_speedup": "5-50x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "A correlated scalar subquery is logically executed once per outer row. While Catalyst can sometimes decorrelate these into joins, complex expressions or nested correlations prevent this. The explicit rewrite performs a single GROUP BY + JOIN, which Spark can execute as two stages (aggregate, then hash join) instead of a nested loop. On large tables, this eliminates O(N*M) behavior.",
      "when_not_to_use": "When Catalyst already decorrelates the subquery (check EXPLAIN for LeftOuterJoin instead of BroadcastNestedLoopJoin). Also not needed for small inner tables where the broadcast nested loop is fast enough."
    },
    "original_sql": "SELECT c.customer_id, c.customer_name,\n  (SELECT SUM(o.amount) FROM orders o WHERE o.customer_id = c.customer_id) AS total_spent\nFROM customers c",
    "optimized_sql": "WITH order_totals AS (\n  SELECT customer_id, SUM(amount) AS total_spent\n  FROM orders\n  GROUP BY customer_id\n)\nSELECT c.customer_id, c.customer_name, COALESCE(ot.total_spent, 0) AS total_spent\nFROM customers c\nLEFT JOIN order_totals ot ON c.customer_id = ot.customer_id",
    "optimized_source": "spark_catalyst_decorrelation",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "union_all_instead_of_union",
    "name": "UNION ALL Instead of UNION",
    "description": "Replace UNION (DISTINCT) with UNION ALL when duplicates are impossible or acceptable",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "UNION forces a shuffle + sort or hash aggregate across all executors to deduplicate. UNION ALL simply appends partitions with zero shuffle cost.",
    "example": {
      "opportunity": "UNION_TO_UNION_ALL",
      "input_slice": "SELECT order_id, 'online' AS channel FROM online_orders\nUNION\nSELECT order_id, 'store' AS channel FROM store_orders",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "union_to_union_all",
            "nodes": {
              "main_query": "SELECT order_id, 'online' AS channel FROM online_orders\nUNION ALL\nSELECT order_id, 'store' AS channel FROM store_orders"
            },
            "invariants_kept": ["same result rows when source tables have no overlap"],
            "expected_speedup": "2-5x",
            "risk": "medium — must verify no cross-table duplicates exist or duplicates are acceptable"
          }
        ]
      },
      "key_insight": "UNION triggers a HashAggregate or Sort across the entire result set from both branches, requiring a full shuffle exchange. When source tables are known to be disjoint (different channels, date ranges, or IDs), UNION ALL skips deduplication entirely. In Spark's distributed execution model, eliminating one shuffle stage often halves wall-clock time.",
      "when_not_to_use": "When actual deduplication across the two branches is required for correctness."
    },
    "original_sql": "SELECT order_id, 'online' AS channel FROM online_orders\nUNION\nSELECT order_id, 'store' AS channel FROM store_orders",
    "optimized_sql": "SELECT order_id, 'online' AS channel FROM online_orders\nUNION ALL\nSELECT order_id, 'store' AS channel FROM store_orders",
    "optimized_source": "general_sql_optimization",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "exists_instead_of_in_large_list",
    "name": "EXISTS Instead of IN for Large Subqueries",
    "description": "Replace IN (subquery) with EXISTS for semi-join semantics on large correlated subqueries",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "IN materializes the full subquery result and broadcasts it. EXISTS can short-circuit per row and allows Spark to use a LeftSemi hash join, which is more efficient for large subqueries.",
    "example": {
      "opportunity": "IN_TO_EXISTS",
      "input_slice": "SELECT p.product_id, p.product_name\nFROM products p\nWHERE p.product_id IN (\n  SELECT li.product_id\n  FROM line_items li\n  JOIN orders o ON li.order_id = o.order_id\n  WHERE o.order_date >= '2024-01-01'\n)",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "in_to_exists",
            "nodes": {
              "main_query": "SELECT p.product_id, p.product_name\nFROM products p\nWHERE EXISTS (\n  SELECT 1\n  FROM line_items li\n  JOIN orders o ON li.order_id = o.order_id\n  WHERE o.order_date >= '2024-01-01'\n    AND li.product_id = p.product_id\n)"
            },
            "invariants_kept": ["same result rows", "same ordering"],
            "expected_speedup": "1.5-3x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Spark transforms both IN and EXISTS to LeftSemi joins in most cases, but complex IN subqueries with multiple joins can cause the optimizer to materialize the subquery as a broadcast or build a BroadcastExchangeExec. EXISTS with correlation gives Catalyst a clearer signal to use a LeftSemi join strategy, which is naturally optimized for early termination.",
      "when_not_to_use": "When Catalyst already transforms the IN to an optimal LeftSemi join (check EXPLAIN). For small literal IN-lists (e.g., IN (1,2,3)), IN is faster than EXISTS."
    },
    "original_sql": "SELECT p.product_id, p.product_name\nFROM products p\nWHERE p.product_id IN (\n  SELECT li.product_id\n  FROM line_items li\n  JOIN orders o ON li.order_id = o.order_id\n  WHERE o.order_date >= '2024-01-01'\n)",
    "optimized_sql": "SELECT p.product_id, p.product_name\nFROM products p\nWHERE EXISTS (\n  SELECT 1\n  FROM line_items li\n  JOIN orders o ON li.order_id = o.order_id\n  WHERE o.order_date >= '2024-01-01'\n    AND li.product_id = p.product_id\n)",
    "optimized_source": "spark_sql_semi_join_optimization",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "self_join_to_window_function",
    "name": "Replace Self-Join with Window Function",
    "description": "Convert self-joins for LAG/LEAD/running calculations to window functions to eliminate a full shuffle",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "A self-join requires a shuffle of the entire table on both sides. Window functions (LAG, LEAD, ROW_NUMBER, running SUM) require only a single sort-shuffle on the PARTITION BY key, processing data in a streaming fashion within each partition.",
    "example": {
      "opportunity": "SELF_JOIN_TO_WINDOW",
      "input_slice": "SELECT t1.id, t1.month_date, t1.revenue,\n  t2.revenue AS prev_month_revenue\nFROM monthly_metrics t1\nLEFT JOIN monthly_metrics t2\n  ON t1.id = t2.id\n  AND t2.month_date = ADD_MONTHS(t1.month_date, -1)",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "self_join_to_lag",
            "nodes": {
              "main_query": "SELECT id, month_date, revenue,\n  LAG(revenue) OVER (PARTITION BY id ORDER BY month_date) AS prev_month_revenue\nFROM monthly_metrics"
            },
            "invariants_kept": ["same result rows", "same ordering"],
            "expected_speedup": "2-8x",
            "risk": "low — verify that month gaps don't change semantics (LAG is ordinal, not calendar-aware)"
          }
        ]
      },
      "key_insight": "The self-join reads the table twice and shuffles both copies on the join key, doubling I/O and network traffic. A window function reads the table once, shuffles once on the PARTITION BY key, and then streams through each partition computing LAG/LEAD in O(1) per row. Photon has optimized vectorized window function support.",
      "when_not_to_use": "When the join condition involves complex calendar logic (e.g., 'previous business day') that doesn't map cleanly to ordinal LAG. Also not applicable when the self-join involves different filter conditions on each alias."
    },
    "original_sql": "SELECT t1.id, t1.month_date, t1.revenue,\n  t2.revenue AS prev_month_revenue\nFROM monthly_metrics t1\nLEFT JOIN monthly_metrics t2\n  ON t1.id = t2.id\n  AND t2.month_date = ADD_MONTHS(t1.month_date, -1)",
    "optimized_sql": "SELECT id, month_date, revenue,\n  LAG(revenue) OVER (PARTITION BY id ORDER BY month_date) AS prev_month_revenue\nFROM monthly_metrics",
    "optimized_source": "databricks_community_window_functions",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "sargable_date_predicates",
    "name": "Make Date Predicates SARGable",
    "description": "Replace function-wrapped column filters with range predicates to enable partition pruning and data skipping",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Wrapping a column in a function (YEAR(), DATE_TRUNC(), CAST()) prevents Databricks from using partition pruning, Z-order data skipping, and Delta file-level min/max statistics. Range predicates enable all three.",
    "example": {
      "opportunity": "SARGABLE_DATE_FILTER",
      "input_slice": "SELECT *\nFROM orders\nWHERE YEAR(order_date) = 2024\n  AND MONTH(order_date) = 6",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "function_to_range_predicate",
            "nodes": {
              "main_query": "SELECT *\nFROM orders\nWHERE order_date >= '2024-06-01'\n  AND order_date < '2024-07-01'"
            },
            "invariants_kept": ["same result rows", "same ordering"],
            "expected_speedup": "5-100x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Delta Lake stores per-file min/max statistics for each column. A range predicate like order_date >= '2024-06-01' AND order_date < '2024-07-01' allows the engine to skip entire Parquet files whose min/max range doesn't overlap. YEAR(order_date) = 2024 forces a full table scan because the function must be evaluated on every row. This also blocks partition pruning on partitioned tables.",
      "when_not_to_use": "When the filter is already on a computed/generated column that is itself the partition key (e.g., a pre-materialized year_month column)."
    },
    "original_sql": "SELECT *\nFROM orders\nWHERE YEAR(order_date) = 2024\n  AND MONTH(order_date) = 6",
    "optimized_sql": "SELECT *\nFROM orders\nWHERE order_date >= '2024-06-01'\n  AND order_date < '2024-07-01'",
    "optimized_source": "delta_lake_data_skipping",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "select_specific_columns",
    "name": "Select Specific Columns Instead of SELECT *",
    "description": "Replace SELECT * with explicit column list to leverage Parquet columnar pruning",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Delta/Parquet is columnar. SELECT * reads all column groups from storage. Specifying only needed columns allows the Parquet reader to skip entire column chunks, reducing I/O by orders of magnitude on wide tables.",
    "example": {
      "opportunity": "COLUMN_PRUNING",
      "input_slice": "SELECT *\nFROM wide_event_table\nWHERE event_date = '2024-06-15'",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "select_star_to_explicit_columns",
            "nodes": {
              "main_query": "SELECT event_id, user_id, event_type, event_timestamp\nFROM wide_event_table\nWHERE event_date = '2024-06-15'"
            },
            "invariants_kept": ["same result rows for selected columns"],
            "expected_speedup": "2-10x",
            "risk": "low — requires knowing which columns are needed"
          }
        ]
      },
      "key_insight": "Parquet and Delta store data in column groups. When you SELECT *, every column group in every qualifying file must be read from cloud storage (S3/ADLS/GCS). For a table with 200 columns where you need 4, you're reading 50x more data than necessary. Column pruning is one of the highest-impact optimizations on wide Delta tables because it reduces both I/O and memory pressure on executors.",
      "when_not_to_use": "When genuinely all columns are needed (e.g., a full table export or CTAS), or for narrow tables where the overhead is negligible."
    },
    "original_sql": "SELECT * FROM wide_event_table WHERE event_date = '2024-06-15'",
    "optimized_sql": "SELECT event_id, user_id, event_type, event_timestamp\nFROM wide_event_table\nWHERE event_date = '2024-06-15'",
    "optimized_source": "databricks_best_practices",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "aggregate_before_join",
    "name": "Pre-Aggregate Before Joining",
    "description": "Push GROUP BY aggregation into a CTE before joining to reduce the row count entering the join",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Joining a large fact table to another large table and then aggregating shuffles all rows through the join. Pre-aggregating the fact table first dramatically reduces rows entering the expensive shuffle join stage.",
    "example": {
      "opportunity": "AGGREGATE_PUSHDOWN",
      "input_slice": "SELECT c.region, c.segment,\n  SUM(o.amount) AS total_amount,\n  COUNT(*) AS order_count\nFROM orders o\nJOIN customers c ON o.customer_id = c.customer_id\nWHERE o.order_date >= '2024-01-01'\nGROUP BY c.region, c.segment",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "pre_aggregate_before_join",
            "nodes": {
              "cte_order_agg": "SELECT customer_id,\n  SUM(amount) AS total_amount,\n  COUNT(*) AS order_count\nFROM orders\nWHERE order_date >= '2024-01-01'\nGROUP BY customer_id",
              "main_query": "SELECT c.region, c.segment,\n  SUM(oa.total_amount) AS total_amount,\n  SUM(oa.order_count) AS order_count\nFROM cte_order_agg oa\nJOIN customers c ON oa.customer_id = c.customer_id\nGROUP BY c.region, c.segment"
            },
            "invariants_kept": ["same result rows", "same aggregation values"],
            "expected_speedup": "3-10x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "If orders has 100M rows but only 1M distinct customers, pre-aggregating by customer_id reduces the join input from 100M to 1M rows — a 100x reduction in shuffle volume. The two-phase aggregation (pre-agg by customer_id, then post-agg by region/segment) is mathematically equivalent for SUM and COUNT. Spark's partial aggregation can do this automatically for simple queries, but multi-join queries often prevent it.",
      "when_not_to_use": "When the aggregation function is not decomposable (e.g., MEDIAN, percentile). Also avoid when the GROUP BY doesn't reduce cardinality (e.g., grouping by a unique key)."
    },
    "original_sql": "SELECT c.region, c.segment,\n  SUM(o.amount) AS total_amount,\n  COUNT(*) AS order_count\nFROM orders o\nJOIN customers c ON o.customer_id = c.customer_id\nWHERE o.order_date >= '2024-01-01'\nGROUP BY c.region, c.segment",
    "optimized_sql": "WITH order_agg AS (\n  SELECT customer_id,\n    SUM(amount) AS total_amount,\n    COUNT(*) AS order_count\n  FROM orders\n  WHERE order_date >= '2024-01-01'\n  GROUP BY customer_id\n)\nSELECT c.region, c.segment,\n  SUM(oa.total_amount) AS total_amount,\n  SUM(oa.order_count) AS order_count\nFROM order_agg oa\nJOIN customers c ON oa.customer_id = c.customer_id\nGROUP BY c.region, c.segment",
    "optimized_source": "spark_aggregate_optimization",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "distinct_to_group_by",
    "name": "Replace DISTINCT with GROUP BY",
    "description": "Use GROUP BY instead of SELECT DISTINCT for better Spark optimization and partial aggregation",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "SELECT DISTINCT is implemented as a HashAggregate in Spark but may not benefit from partial (map-side) aggregation as reliably as an explicit GROUP BY. GROUP BY also gives the optimizer more flexibility to reorder and push down.",
    "example": {
      "opportunity": "DISTINCT_TO_GROUP_BY",
      "input_slice": "SELECT DISTINCT customer_id, product_category\nFROM order_details\nWHERE order_date >= '2024-01-01'",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "distinct_to_group_by",
            "nodes": {
              "main_query": "SELECT customer_id, product_category\nFROM order_details\nWHERE order_date >= '2024-01-01'\nGROUP BY customer_id, product_category"
            },
            "invariants_kept": ["same result rows"],
            "expected_speedup": "1.2-2x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "While Spark internally converts DISTINCT to an Aggregate node, explicit GROUP BY more reliably triggers partial (map-side) aggregation, where each executor deduplicates locally before the shuffle. This can dramatically reduce shuffle volume when there are many duplicates per partition. Photon's vectorized aggregation is also optimized for GROUP BY paths.",
      "when_not_to_use": "Functionally equivalent in most cases. The benefit is marginal for low-duplication datasets. Some Databricks SQL versions now optimize both identically."
    },
    "original_sql": "SELECT DISTINCT customer_id, product_category\nFROM order_details\nWHERE order_date >= '2024-01-01'",
    "optimized_sql": "SELECT customer_id, product_category\nFROM order_details\nWHERE order_date >= '2024-01-01'\nGROUP BY customer_id, product_category",
    "optimized_source": "spark_sql_optimization_guides",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "range_join_hint",
    "name": "Range Join Hint for Inequality Joins",
    "description": "Add RANGE_JOIN hint with bin size for BETWEEN/inequality join conditions to avoid nested loop join",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Inequality joins (BETWEEN, <, >) cannot use hash join and default to BroadcastNestedLoopJoin or SortMergeJoin with post-filter. Databricks' RANGE_JOIN hint uses bin-based partitioning to convert this into an efficient equi-join-like operation.",
    "example": {
      "opportunity": "RANGE_JOIN_HINT",
      "input_slice": "SELECT e.event_id, s.session_id\nFROM events e\nJOIN sessions s\n  ON e.user_id = s.user_id\n  AND e.event_time BETWEEN s.start_time AND s.end_time",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "add_range_join_hint",
            "nodes": {
              "main_query": "SELECT /*+ RANGE_JOIN(s, 60) */ e.event_id, s.session_id\nFROM events e\nJOIN sessions s\n  ON e.user_id = s.user_id\n  AND e.event_time BETWEEN s.start_time AND s.end_time"
            },
            "invariants_kept": ["same result rows", "same ordering"],
            "expected_speedup": "5-50x",
            "risk": "medium — bin size must be tuned to data distribution (seconds for timestamps, appropriate units for numeric ranges)"
          }
        ]
      },
      "key_insight": "Without the hint, Spark handles the BETWEEN condition as a post-join filter on a sort-merge or nested loop join, which can be extremely expensive. The RANGE_JOIN hint tells the Databricks optimizer to partition the range dimension into bins of the specified size (60 seconds in this case), converting the inequality into an equi-join on bin ID. This enables hash-based join strategies and dramatically reduces comparisons.",
      "when_not_to_use": "When one side is small enough for broadcast (broadcast join handles range conditions efficiently). Also requires tuning the bin size — too small creates too many bins, too large reduces selectivity."
    },
    "original_sql": "SELECT e.event_id, s.session_id\nFROM events e\nJOIN sessions s\n  ON e.user_id = s.user_id\n  AND e.event_time BETWEEN s.start_time AND s.end_time",
    "optimized_sql": "SELECT /*+ RANGE_JOIN(s, 60) */ e.event_id, s.session_id\nFROM events e\nJOIN sessions s\n  ON e.user_id = s.user_id\n  AND e.event_time BETWEEN s.start_time AND s.end_time",
    "optimized_source": "databricks_docs_range_join",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "count_distinct_to_approx",
    "name": "Approximate COUNT DISTINCT with approx_count_distinct",
    "description": "Replace exact COUNT(DISTINCT) with approx_count_distinct() for dashboards/analytics where ~2% error is acceptable",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "COUNT(DISTINCT) requires a full shuffle to collect all unique values globally. approx_count_distinct() uses HyperLogLog sketches that can be combined partition-locally, eliminating the heavy shuffle and reducing memory from O(distinct_count) to O(1).",
    "example": {
      "opportunity": "EXACT_TO_APPROX_COUNT",
      "input_slice": "SELECT region,\n  COUNT(DISTINCT user_id) AS unique_users\nFROM page_views\nWHERE view_date >= '2024-01-01'\nGROUP BY region",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "count_distinct_to_approx",
            "nodes": {
              "main_query": "SELECT region,\n  approx_count_distinct(user_id) AS unique_users\nFROM page_views\nWHERE view_date >= '2024-01-01'\nGROUP BY region"
            },
            "invariants_kept": ["approximate result within ~2% standard error"],
            "expected_speedup": "3-10x",
            "risk": "medium — results are approximate; not suitable for exact billing or compliance"
          }
        ]
      },
      "key_insight": "HyperLogLog sketches are mergeable across partitions, so each executor can compute a local sketch and then combine them. This avoids the global shuffle of all distinct values. For high-cardinality columns (millions of unique users), the memory and network savings are enormous. Photon's native HLL implementation is particularly fast.",
      "when_not_to_use": "When exact counts are required (financial reporting, regulatory compliance, SLA metrics). Also unnecessary when the column has low cardinality (e.g., <1000 distinct values) where exact COUNT DISTINCT is already fast."
    },
    "original_sql": "SELECT region,\n  COUNT(DISTINCT user_id) AS unique_users\nFROM page_views\nWHERE view_date >= '2024-01-01'\nGROUP BY region",
    "optimized_sql": "SELECT region,\n  approx_count_distinct(user_id) AS unique_users\nFROM page_views\nWHERE view_date >= '2024-01-01'\nGROUP BY region",
    "optimized_source": "databricks_builtin_functions",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "partition_filter_enforcement",
    "name": "Add Partition Column to WHERE Clause",
    "description": "Ensure partitioned tables always have the partition key in the WHERE clause for partition pruning",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Delta tables partitioned by a column (e.g., event_date) store data in separate directories per partition value. Without a filter on the partition key, Spark must list and scan all partition directories.",
    "example": {
      "opportunity": "PARTITION_PRUNING",
      "input_slice": "-- Table is PARTITIONED BY (event_month)\nSELECT user_id, event_type, COUNT(*)\nFROM events\nWHERE event_timestamp >= '2024-06-01'\n  AND event_timestamp < '2024-07-01'\nGROUP BY user_id, event_type",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "add_partition_filter",
            "nodes": {
              "main_query": "SELECT user_id, event_type, COUNT(*)\nFROM events\nWHERE event_month = '2024-06'\n  AND event_timestamp >= '2024-06-01'\n  AND event_timestamp < '2024-07-01'\nGROUP BY user_id, event_type"
            },
            "invariants_kept": ["same result rows"],
            "expected_speedup": "10-100x",
            "risk": "low — redundant filter is always safe"
          }
        ]
      },
      "key_insight": "The filter on event_timestamp alone does not help the partition pruner if the table is partitioned on event_month (a derived string column). Adding the explicit partition key filter event_month = '2024-06' allows Spark to skip listing/scanning all other partition directories entirely. This is critical for tables with years of history where you may be scanning 1/120th of the data instead of all of it.",
      "when_not_to_use": "When the table uses Liquid Clustering instead of traditional partitioning (Liquid Clustering uses data skipping rather than partition directories). Also not needed if Databricks' Dynamic Partition Pruning already handles it from a join context."
    },
    "original_sql": "SELECT user_id, event_type, COUNT(*)\nFROM events\nWHERE event_timestamp >= '2024-06-01'\n  AND event_timestamp < '2024-07-01'\nGROUP BY user_id, event_type",
    "optimized_sql": "SELECT user_id, event_type, COUNT(*)\nFROM events\nWHERE event_month = '2024-06'\n  AND event_timestamp >= '2024-06-01'\n  AND event_timestamp < '2024-07-01'\nGROUP BY user_id, event_type",
    "optimized_source": "delta_lake_partition_pruning",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "coalesce_repeated_case_when",
    "name": "Consolidate Multiple CASE WHEN on Same Column",
    "description": "Merge multiple CASE WHEN expressions evaluating the same column into a single pivoted expression or JOIN",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Multiple CASE WHEN on the same column creates redundant expression evaluation trees. Consolidating into a single scan with conditional aggregation reduces both CPU and memory overhead.",
    "example": {
      "opportunity": "CONSOLIDATE_CASE_WHEN",
      "input_slice": "SELECT customer_id,\n  SUM(CASE WHEN status = 'completed' THEN amount ELSE 0 END) AS completed_amount,\n  SUM(CASE WHEN status = 'pending' THEN amount ELSE 0 END) AS pending_amount,\n  SUM(CASE WHEN status = 'cancelled' THEN amount ELSE 0 END) AS cancelled_amount,\n  COUNT(CASE WHEN status = 'completed' THEN 1 END) AS completed_count,\n  COUNT(CASE WHEN status = 'pending' THEN 1 END) AS pending_count,\n  COUNT(CASE WHEN status = 'cancelled' THEN 1 END) AS cancelled_count\nFROM orders\nGROUP BY customer_id",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "case_when_to_filter_aggregate",
            "nodes": {
              "main_query": "SELECT customer_id,\n  SUM(amount) FILTER (WHERE status = 'completed') AS completed_amount,\n  SUM(amount) FILTER (WHERE status = 'pending') AS pending_amount,\n  SUM(amount) FILTER (WHERE status = 'cancelled') AS cancelled_amount,\n  COUNT(*) FILTER (WHERE status = 'completed') AS completed_count,\n  COUNT(*) FILTER (WHERE status = 'pending') AS pending_count,\n  COUNT(*) FILTER (WHERE status = 'cancelled') AS cancelled_count\nFROM orders\nGROUP BY customer_id"
            },
            "invariants_kept": ["same result rows", "same values"],
            "expected_speedup": "1.1-1.5x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Databricks SQL supports the FILTER (WHERE ...) clause on aggregate functions, which is ANSI SQL standard. While functionally equivalent to CASE WHEN, FILTER clauses can be optimized more aggressively by Photon's vectorized execution engine because the filter predicate is evaluated in batch before the aggregation, rather than as a per-row branching expression.",
      "when_not_to_use": "Marginal improvement on small datasets. Some older Databricks runtime versions may not fully optimize FILTER clauses. CASE WHEN is more portable across engines."
    },
    "original_sql": "SELECT customer_id,\n  SUM(CASE WHEN status = 'completed' THEN amount ELSE 0 END) AS completed_amount,\n  SUM(CASE WHEN status = 'pending' THEN amount ELSE 0 END) AS pending_amount,\n  SUM(CASE WHEN status = 'cancelled' THEN amount ELSE 0 END) AS cancelled_amount,\n  COUNT(CASE WHEN status = 'completed' THEN 1 END) AS completed_count,\n  COUNT(CASE WHEN status = 'pending' THEN 1 END) AS pending_count,\n  COUNT(CASE WHEN status = 'cancelled' THEN 1 END) AS cancelled_count\nFROM orders\nGROUP BY customer_id",
    "optimized_sql": "SELECT customer_id,\n  SUM(amount) FILTER (WHERE status = 'completed') AS completed_amount,\n  SUM(amount) FILTER (WHERE status = 'pending') AS pending_amount,\n  SUM(amount) FILTER (WHERE status = 'cancelled') AS cancelled_amount,\n  COUNT(*) FILTER (WHERE status = 'completed') AS completed_count,\n  COUNT(*) FILTER (WHERE status = 'pending') AS pending_count,\n  COUNT(*) FILTER (WHERE status = 'cancelled') AS cancelled_count\nFROM orders\nGROUP BY customer_id",
    "optimized_source": "databricks_sql_ansi_features",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "avoid_order_by_in_subquery",
    "name": "Remove ORDER BY from Subqueries/CTEs",
    "description": "Remove ORDER BY in subqueries or CTEs where the sort is discarded by the outer query",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "ORDER BY inside a CTE or subquery forces a global sort (shuffle + sort) but the ordering is not guaranteed to survive a subsequent JOIN, GROUP BY, or UNION ALL. Spark often cannot eliminate the unnecessary sort.",
    "example": {
      "opportunity": "REMOVE_SUBQUERY_ORDER_BY",
      "input_slice": "WITH recent_orders AS (\n  SELECT customer_id, order_id, amount\n  FROM orders\n  WHERE order_date >= '2024-01-01'\n  ORDER BY order_date DESC\n)\nSELECT customer_id, SUM(amount) AS total\nFROM recent_orders\nGROUP BY customer_id",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "remove_subquery_order_by",
            "nodes": {
              "cte_recent_orders": "SELECT customer_id, order_id, amount\nFROM orders\nWHERE order_date >= '2024-01-01'",
              "main_query": "SELECT customer_id, SUM(amount) AS total\nFROM cte_recent_orders\nGROUP BY customer_id"
            },
            "invariants_kept": ["same result rows", "same values"],
            "expected_speedup": "1.5-3x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "ORDER BY requires a global sort — all data must be shuffled to a single partition and sorted. In a distributed system this is one of the most expensive operations. When the outer query does GROUP BY, JOIN, or UNION ALL, the sort order is destroyed anyway. Removing the inner ORDER BY eliminates a full shuffle+sort stage. Catalyst sometimes optimizes this away, but not reliably in CTEs.",
      "when_not_to_use": "When the CTE uses ORDER BY with LIMIT (top-N pattern) — the ORDER BY is meaningful there. Also when the CTE is the final output and ordering matters."
    },
    "original_sql": "WITH recent_orders AS (\n  SELECT customer_id, order_id, amount\n  FROM orders\n  WHERE order_date >= '2024-01-01'\n  ORDER BY order_date DESC\n)\nSELECT customer_id, SUM(amount) AS total\nFROM recent_orders\nGROUP BY customer_id",
    "optimized_sql": "WITH recent_orders AS (\n  SELECT customer_id, order_id, amount\n  FROM orders\n  WHERE order_date >= '2024-01-01'\n)\nSELECT customer_id, SUM(amount) AS total\nFROM recent_orders\nGROUP BY customer_id",
    "optimized_source": "spark_catalyst_sort_elimination",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "avoid_cross_join_implicit",
    "name": "Eliminate Implicit Cross Joins",
    "description": "Convert comma-separated FROM clause with WHERE join conditions to explicit JOIN syntax to avoid accidental cartesian products",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Implicit join syntax (FROM a, b WHERE a.id = b.id) can produce a cartesian product if the WHERE condition is accidentally omitted or misspelled. Explicit JOIN makes the optimizer's job easier and prevents accidental SHUFFLE_REPLICATE_NL joins.",
    "example": {
      "opportunity": "IMPLICIT_TO_EXPLICIT_JOIN",
      "input_slice": "SELECT o.order_id, c.customer_name, p.product_name\nFROM orders o, customers c, products p\nWHERE o.customer_id = c.customer_id\n  AND o.product_id = p.product_id\n  AND o.order_date >= '2024-01-01'",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "implicit_to_explicit_join",
            "nodes": {
              "main_query": "SELECT o.order_id, c.customer_name, p.product_name\nFROM orders o\nINNER JOIN customers c ON o.customer_id = c.customer_id\nINNER JOIN products p ON o.product_id = p.product_id\nWHERE o.order_date >= '2024-01-01'"
            },
            "invariants_kept": ["same result rows", "same ordering"],
            "expected_speedup": "1-2x (prevents catastrophic degeneration)",
            "risk": "low"
          }
        ]
      },
      "key_insight": "While Catalyst usually resolves comma-join to the same plan as explicit JOIN, edge cases exist where the optimizer cannot push a WHERE predicate into the join condition, resulting in a cartesian product followed by a filter. Explicit JOIN syntax guarantees the predicate is part of the join condition. This is a defensive optimization that prevents worst-case O(N*M) behavior.",
      "when_not_to_use": "When the comma-join produces the correct plan (check EXPLAIN). The main value is defensive — preventing future regressions when queries are modified."
    },
    "original_sql": "SELECT o.order_id, c.customer_name, p.product_name\nFROM orders o, customers c, products p\nWHERE o.customer_id = c.customer_id\n  AND o.product_id = p.product_id\n  AND o.order_date >= '2024-01-01'",
    "optimized_sql": "SELECT o.order_id, c.customer_name, p.product_name\nFROM orders o\nINNER JOIN customers c ON o.customer_id = c.customer_id\nINNER JOIN products p ON o.product_id = p.product_id\nWHERE o.order_date >= '2024-01-01'",
    "optimized_source": "sql_best_practices",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "merge_to_insert_anti_join",
    "name": "Rewrite MERGE INSERT-only to INSERT + ANTI JOIN",
    "description": "Replace MERGE ... WHEN NOT MATCHED INSERT with INSERT ... LEFT ANTI JOIN to avoid expensive merge scan",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "MERGE with only a WHEN NOT MATCHED clause still performs a full anti-join against the target table. Rewriting as INSERT + explicit ANTI JOIN allows broadcasting the matching keys and avoids the MERGE scan overhead.",
    "example": {
      "opportunity": "MERGE_TO_INSERT_ANTI_JOIN",
      "input_slice": "MERGE INTO target_data t\nUSING source_data s\nON t.user_id = s.user_id\nWHEN NOT MATCHED THEN INSERT *",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "merge_to_insert_anti_join",
            "nodes": {
              "cte_matching": "SELECT s.user_id\nFROM target_data t\nINNER JOIN source_data s ON t.user_id = s.user_id",
              "main_query": "INSERT INTO target_data\nSELECT s.*\nFROM source_data s\nLEFT ANTI JOIN cte_matching m ON s.user_id = m.user_id"
            },
            "invariants_kept": ["same inserted rows"],
            "expected_speedup": "3-7x",
            "risk": "medium — bypasses MERGE ACID guarantees; ensure no concurrent writes"
          }
        ]
      },
      "key_insight": "MERGE internally performs a left anti join of source against target, but the MERGE command also scans the full target for rewrite purposes. When you only need INSERT (no UPDATE/DELETE), the explicit INSERT + ANTI JOIN pattern avoids the target rewrite phase entirely. This pattern was documented in the Databricks MERGE deep-dive blog as achieving 3-7x improvement, especially when the source is small enough to broadcast the matching keys.",
      "when_not_to_use": "When the MERGE also has WHEN MATCHED clauses (UPDATE/DELETE). When concurrent writers exist and you need MERGE's ACID conflict resolution. When the source-target overlap is very high (INNER JOIN becomes large)."
    },
    "original_sql": "MERGE INTO target_data t\nUSING source_data s\nON t.user_id = s.user_id\nWHEN NOT MATCHED THEN INSERT *",
    "optimized_sql": "WITH matching AS (\n  SELECT s.user_id\n  FROM target_data t\n  INNER JOIN source_data s ON t.user_id = s.user_id\n)\nINSERT INTO target_data\nSELECT s.*\nFROM source_data s\nLEFT ANTI JOIN matching m ON s.user_id = m.user_id",
    "optimized_source": "databricks_community_merge_deep_dive",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "avoid_udf_use_builtin",
    "name": "Replace UDF with Built-in Function",
    "description": "Replace Python/Scala UDFs with native Spark SQL built-in functions to stay in Photon's vectorized execution",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Python UDFs require serialization of every row from JVM to Python and back (via Arrow for Pandas UDFs). This serialization overhead can be 10-100x slower than a native built-in function. Photon cannot accelerate UDF execution at all.",
    "example": {
      "opportunity": "UDF_TO_BUILTIN",
      "input_slice": "-- Python UDF registered as 'extract_domain'\n-- def extract_domain(email): return email.split('@')[1]\nSELECT user_id, extract_domain(email) AS domain\nFROM users",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "udf_to_builtin_string_function",
            "nodes": {
              "main_query": "SELECT user_id,\n  SUBSTRING(email, INSTR(email, '@') + 1) AS domain\nFROM users"
            },
            "invariants_kept": ["same result rows", "same values"],
            "expected_speedup": "10-100x",
            "risk": "low — verify edge cases (NULL emails, missing @)"
          }
        ]
      },
      "key_insight": "Python UDFs force a row-by-row serialization roundtrip between JVM and Python worker processes. Even Pandas UDFs (vectorized) still cross the JVM-Python boundary per batch. Native SQL functions like SUBSTRING, INSTR, SPLIT, REGEXP_EXTRACT run entirely within the JVM/Photon vectorized engine, processing millions of values per second without serialization. Databricks explicitly recommends avoiding UDFs when built-in alternatives exist.",
      "when_not_to_use": "When no built-in function equivalent exists (complex ML inference, custom business logic). In those cases, prefer Pandas UDFs over scalar Python UDFs for better batch performance."
    },
    "original_sql": "SELECT user_id, extract_domain(email) AS domain\nFROM users",
    "optimized_sql": "SELECT user_id,\n  SUBSTRING(email, INSTR(email, '@') + 1) AS domain\nFROM users",
    "optimized_source": "databricks_docs_udf_avoidance",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "window_dedup_instead_of_group_by_subquery",
    "name": "ROW_NUMBER Dedup Instead of GROUP BY + Self-Join",
    "description": "Replace GROUP BY to find max/min + self-join to get full row with ROW_NUMBER() window function",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "The 'get the latest row per group' pattern using GROUP BY MAX + self-join reads the table twice and shuffles twice. ROW_NUMBER() reads and shuffles once.",
    "example": {
      "opportunity": "GROUP_BY_SELFJOIN_TO_ROW_NUMBER",
      "input_slice": "SELECT o.*\nFROM orders o\nINNER JOIN (\n  SELECT customer_id, MAX(order_date) AS max_date\n  FROM orders\n  GROUP BY customer_id\n) latest ON o.customer_id = latest.customer_id\n  AND o.order_date = latest.max_date",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "group_selfjoin_to_row_number",
            "nodes": {
              "cte_ranked": "SELECT *,\n  ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) AS rn\nFROM orders",
              "main_query": "SELECT * EXCEPT(rn)\nFROM cte_ranked\nWHERE rn = 1"
            },
            "invariants_kept": ["same result rows — returns one row per customer with latest order"],
            "expected_speedup": "2-4x",
            "risk": "low — ROW_NUMBER breaks ties arbitrarily; original could return multiple rows on ties"
          }
        ]
      },
      "key_insight": "The GROUP BY + self-join pattern scans the table twice: once for the aggregate, once for the full row fetch. It also requires two shuffle stages (one for GROUP BY, one for the JOIN). ROW_NUMBER() scans once, shuffles once (on PARTITION BY), and the rn = 1 filter is a cheap local filter. Databricks SQL also supports the QUALIFY clause for even cleaner syntax.",
      "when_not_to_use": "When ties should return all matching rows (use RANK() or DENSE_RANK() instead). When the GROUP BY subquery applies additional filters not on the main table."
    },
    "original_sql": "SELECT o.*\nFROM orders o\nINNER JOIN (\n  SELECT customer_id, MAX(order_date) AS max_date\n  FROM orders\n  GROUP BY customer_id\n) latest ON o.customer_id = latest.customer_id\n  AND o.order_date = latest.max_date",
    "optimized_sql": "WITH ranked AS (\n  SELECT *,\n    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) AS rn\n  FROM orders\n)\nSELECT * EXCEPT(rn)\nFROM ranked\nWHERE rn = 1",
    "optimized_source": "spark_window_optimization",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "exists_instead_of_count_check",
    "name": "EXISTS Instead of COUNT(*) > 0 Check",
    "description": "Replace COUNT(*) > 0 existence checks with EXISTS for early termination",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "COUNT(*) > 0 must scan and count all matching rows. EXISTS can short-circuit after finding the first match, potentially skipping millions of rows.",
    "example": {
      "opportunity": "COUNT_TO_EXISTS",
      "input_slice": "SELECT customer_id\nFROM customers c\nWHERE (\n  SELECT COUNT(*)\n  FROM orders o\n  WHERE o.customer_id = c.customer_id\n    AND o.order_date >= '2024-01-01'\n) > 0",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "count_check_to_exists",
            "nodes": {
              "main_query": "SELECT customer_id\nFROM customers c\nWHERE EXISTS (\n  SELECT 1\n  FROM orders o\n  WHERE o.customer_id = c.customer_id\n    AND o.order_date >= '2024-01-01'\n)"
            },
            "invariants_kept": ["same result rows"],
            "expected_speedup": "2-10x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "EXISTS is converted to a LeftSemi join in Spark, which stops processing a partition key as soon as it finds one match. COUNT(*) > 0 forces full aggregation of all matches before the comparison. For customers with thousands of orders, EXISTS skips counting beyond the first match. This is especially impactful in Databricks where the LeftSemi join can leverage Dynamic File Pruning.",
      "when_not_to_use": "When you actually need the count value (e.g., COUNT(*) > 5). Spark may already optimize simple COUNT > 0 patterns internally in newer runtimes."
    },
    "original_sql": "SELECT customer_id\nFROM customers c\nWHERE (\n  SELECT COUNT(*)\n  FROM orders o\n  WHERE o.customer_id = c.customer_id\n    AND o.order_date >= '2024-01-01'\n) > 0",
    "optimized_sql": "SELECT customer_id\nFROM customers c\nWHERE EXISTS (\n  SELECT 1\n  FROM orders o\n  WHERE o.customer_id = c.customer_id\n    AND o.order_date >= '2024-01-01'\n)",
    "optimized_source": "spark_semi_join_optimization",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "avoid_repeated_expensive_expression",
    "name": "Factor Out Repeated Expensive Expressions into CTE",
    "description": "Extract repeated complex expressions (subqueries, aggregations) that appear multiple times into a single CTE",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Spark does not always recognize and eliminate common subexpressions across different branches of a query. CTEs allow explicit materialization of expensive computations, reducing redundant shuffle/scan stages.",
    "example": {
      "opportunity": "FACTOR_REPEATED_EXPRESSION",
      "input_slice": "SELECT\n  (SELECT AVG(amount) FROM orders WHERE order_date >= '2024-01-01') AS avg_amount,\n  o.order_id,\n  o.amount,\n  o.amount - (SELECT AVG(amount) FROM orders WHERE order_date >= '2024-01-01') AS diff_from_avg\nFROM orders o\nWHERE o.order_date >= '2024-01-01'",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "extract_common_subexpression",
            "nodes": {
              "cte_avg": "SELECT AVG(amount) AS avg_amount\nFROM orders\nWHERE order_date >= '2024-01-01'",
              "main_query": "SELECT a.avg_amount,\n  o.order_id,\n  o.amount,\n  o.amount - a.avg_amount AS diff_from_avg\nFROM orders o\nCROSS JOIN cte_avg a\nWHERE o.order_date >= '2024-01-01'"
            },
            "invariants_kept": ["same result rows", "same values"],
            "expected_speedup": "2x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "Each scalar subquery may be executed independently, causing duplicate table scans and aggregations. By extracting the common expression into a CTE and cross-joining the single-row result, the expensive aggregation runs once. Spark may cache the subquery result, but this is not guaranteed across all optimization paths.",
      "when_not_to_use": "When the repeated expression is trivially cheap (column reference, constant). Also when Spark's subquery deduplication already eliminates the redundancy (check EXPLAIN for ReusedSubquery)."
    },
    "original_sql": "SELECT\n  (SELECT AVG(amount) FROM orders WHERE order_date >= '2024-01-01') AS avg_amount,\n  o.order_id,\n  o.amount,\n  o.amount - (SELECT AVG(amount) FROM orders WHERE order_date >= '2024-01-01') AS diff_from_avg\nFROM orders o\nWHERE o.order_date >= '2024-01-01'",
    "optimized_sql": "WITH avg_calc AS (\n  SELECT AVG(amount) AS avg_amount\n  FROM orders\n  WHERE order_date >= '2024-01-01'\n)\nSELECT a.avg_amount,\n  o.order_id,\n  o.amount,\n  o.amount - a.avg_amount AS diff_from_avg\nFROM orders o\nCROSS JOIN avg_calc a\nWHERE o.order_date >= '2024-01-01'",
    "optimized_source": "spark_common_subexpression_elimination",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "full_outer_join_to_targeted_joins",
    "name": "Decompose FULL OUTER JOIN into UNION of Targeted Joins",
    "description": "Replace FULL OUTER JOIN with LEFT JOIN UNION ALL LEFT ANTI JOIN when one side is much smaller or broadcast hints don't work",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "FULL OUTER JOIN cannot use broadcast join in Spark — it always requires a sort-merge or shuffle hash join. Decomposing into targeted joins enables broadcast on each component.",
    "example": {
      "opportunity": "FULL_OUTER_TO_UNION",
      "input_slice": "SELECT\n  COALESCE(a.key, b.key) AS key,\n  a.value_a,\n  b.value_b\nFROM table_a a\nFULL OUTER JOIN table_b b ON a.key = b.key",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "full_outer_to_left_union_anti",
            "nodes": {
              "cte_left": "SELECT a.key, a.value_a, b.value_b\nFROM table_a a\nLEFT JOIN table_b b ON a.key = b.key",
              "cte_right_only": "SELECT b.key, NULL AS value_a, b.value_b\nFROM table_b b\nLEFT ANTI JOIN table_a a ON b.key = a.key",
              "main_query": "SELECT * FROM cte_left\nUNION ALL\nSELECT * FROM cte_right_only"
            },
            "invariants_kept": ["same result rows"],
            "expected_speedup": "2-5x",
            "risk": "medium — slightly more complex query; must handle NULL typing correctly"
          }
        ]
      },
      "key_insight": "FULL OUTER JOIN prevents Databricks from using broadcast join because both sides need full preservation. By decomposing into a LEFT JOIN (matching + left-only rows) and a LEFT ANTI JOIN (right-only rows), each component can independently use broadcast if one side is small. The UNION ALL combines results without a shuffle.",
      "when_not_to_use": "When both tables are very large (broadcast won't help either way). When the optimizer already produces an efficient SortMergeJoin plan. The decomposed version is harder to maintain."
    },
    "original_sql": "SELECT\n  COALESCE(a.key, b.key) AS key,\n  a.value_a,\n  b.value_b\nFROM table_a a\nFULL OUTER JOIN table_b b ON a.key = b.key",
    "optimized_sql": "WITH left_matched AS (\n  SELECT a.key, a.value_a, b.value_b\n  FROM table_a a\n  LEFT JOIN table_b b ON a.key = b.key\n),\nright_only AS (\n  SELECT b.key, CAST(NULL AS STRING) AS value_a, b.value_b\n  FROM table_b b\n  LEFT ANTI JOIN table_a a ON b.key = a.key\n)\nSELECT * FROM left_matched\nUNION ALL\nSELECT * FROM right_only",
    "optimized_source": "spark_join_strategy_optimization",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "string_cast_to_native_comparison",
    "name": "Avoid Implicit String Casting in Comparisons",
    "description": "Replace string comparisons on numeric/date columns with native type comparisons to enable predicate pushdown",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Comparing a numeric column to a string literal can force implicit CAST, preventing data skipping and partition pruning. Using the correct literal type allows Parquet/Delta predicate pushdown.",
    "example": {
      "opportunity": "TYPE_CAST_PUSHDOWN",
      "input_slice": "SELECT *\nFROM transactions\nWHERE amount > '100'\n  AND transaction_date > '2024-01-01'",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "native_type_comparison",
            "nodes": {
              "main_query": "SELECT *\nFROM transactions\nWHERE amount > 100\n  AND transaction_date > DATE '2024-01-01'"
            },
            "invariants_kept": ["same result rows"],
            "expected_speedup": "1.5-5x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "When comparing a DECIMAL column to a STRING literal '100', Spark may cast the column to STRING for comparison, which disables Parquet predicate pushdown (min/max data skipping) and any Delta data skipping on that column. Using the native literal type (integer 100, DATE '2024-01-01') allows the predicate to be pushed down to the Parquet reader, skipping entire row groups and files.",
      "when_not_to_use": "When the column is actually a STRING type. Modern Databricks runtimes handle some implicit casts better, but explicit typing is always safer."
    },
    "original_sql": "SELECT *\nFROM transactions\nWHERE amount > '100'\n  AND transaction_date > '2024-01-01'",
    "optimized_sql": "SELECT *\nFROM transactions\nWHERE amount > 100\n  AND transaction_date > DATE '2024-01-01'",
    "optimized_source": "delta_data_skipping_requirements",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "reduce_join_explosion_with_pre_dedup",
    "name": "Pre-Deduplicate Before Many-to-Many Join",
    "description": "Add deduplication before joins that produce data explosion due to many-to-many key relationships",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "A many-to-many join on a non-unique key can explode row counts (N*M per key), causing massive shuffle spills. Pre-deduplicating or pre-aggregating the smaller side limits the explosion factor.",
    "example": {
      "opportunity": "PRE_DEDUP_BEFORE_JOIN",
      "input_slice": "SELECT t.tag_name, e.event_id, e.event_type\nFROM events e\nJOIN event_tags t ON e.event_id = t.event_id",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "pre_aggregate_tags",
            "nodes": {
              "cte_tags_agg": "SELECT event_id,\n  COLLECT_SET(tag_name) AS tags\nFROM event_tags\nGROUP BY event_id",
              "main_query": "SELECT EXPLODE(ta.tags) AS tag_name, e.event_id, e.event_type\nFROM events e\nJOIN cte_tags_agg ta ON e.event_id = ta.event_id"
            },
            "invariants_kept": ["same result rows"],
            "expected_speedup": "2-5x",
            "risk": "medium — COLLECT_SET has memory overhead; may need spark.sql.objectHashAggregate.sortBased.fallbackThreshold tuning"
          }
        ]
      },
      "key_insight": "When event_tags has multiple rows per event_id and events also has many rows, the join produces a cartesian product per key. Pre-aggregating tags into an array (COLLECT_SET) converts the many-to-many into a many-to-one join. The EXPLODE after the join recreates the original cardinality but the shuffle only moves the compact aggregated form. This is critical when data spills to disk during the join shuffle.",
      "when_not_to_use": "When the join is truly one-to-many and there's no explosion. When COLLECT_SET exceeds memory limits (very high-cardinality groups). When additional columns from the many-side are needed in the join."
    },
    "original_sql": "SELECT t.tag_name, e.event_id, e.event_type\nFROM events e\nJOIN event_tags t ON e.event_id = t.event_id",
    "optimized_sql": "WITH tags_agg AS (\n  SELECT event_id,\n    COLLECT_SET(tag_name) AS tags\n  FROM event_tags\n  GROUP BY event_id\n)\nSELECT EXPLODE(ta.tags) AS tag_name, e.event_id, e.event_type\nFROM events e\nJOIN tags_agg ta ON e.event_id = ta.event_id",
    "optimized_source": "databricks_data_explosion_guide",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "qualify_instead_of_subquery_filter",
    "name": "Use QUALIFY Clause Instead of Subquery Wrapper",
    "description": "Replace the common pattern of wrapping a window function in a subquery to filter by it with QUALIFY",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "QUALIFY filters window function results in-place without requiring a subquery layer. This can simplify the plan and reduce an extra projection stage.",
    "example": {
      "opportunity": "SUBQUERY_TO_QUALIFY",
      "input_slice": "SELECT *\nFROM (\n  SELECT *,\n    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) AS rn\n  FROM orders\n)\nWHERE rn = 1",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "subquery_filter_to_qualify",
            "nodes": {
              "main_query": "SELECT *\nFROM orders\nQUALIFY ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) = 1"
            },
            "invariants_kept": ["same result rows"],
            "expected_speedup": "1.1-1.5x",
            "risk": "low — QUALIFY is Databricks-specific SQL extension, not ANSI standard"
          }
        ]
      },
      "key_insight": "QUALIFY eliminates the need for a subquery wrapper, which can prevent an unnecessary extra projection and potentially an extra exchange in the physical plan. While Spark often optimizes the subquery away, QUALIFY is semantically cleaner and guaranteed to be handled in a single plan stage. Databricks SQL supports QUALIFY natively.",
      "when_not_to_use": "When portability to other engines (Postgres, MySQL) is needed — QUALIFY is not ANSI SQL. When the window function result is needed in the output (QUALIFY implicitly discards it)."
    },
    "original_sql": "SELECT *\nFROM (\n  SELECT *,\n    ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) AS rn\n  FROM orders\n)\nWHERE rn = 1",
    "optimized_sql": "SELECT *\nFROM orders\nQUALIFY ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date DESC) = 1",
    "optimized_source": "databricks_sql_qualify_clause",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "higher_order_functions_over_explode",
    "name": "Higher-Order Functions Instead of EXPLODE + Aggregate",
    "description": "Replace EXPLODE array + GROUP BY re-aggregation with TRANSFORM/FILTER/AGGREGATE higher-order functions",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "EXPLODE creates new rows requiring shuffle for subsequent aggregation. Higher-order functions process arrays in-place without row multiplication, eliminating shuffle entirely.",
    "example": {
      "opportunity": "EXPLODE_TO_HIGHER_ORDER",
      "input_slice": "SELECT order_id,\n  SUM(item_price) AS total_price\nFROM (\n  SELECT order_id, EXPLODE(items.price) AS item_price\n  FROM orders_nested\n)\nGROUP BY order_id",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "explode_agg_to_aggregate_function",
            "nodes": {
              "main_query": "SELECT order_id,\n  AGGREGATE(TRANSFORM(items, x -> x.price), CAST(0 AS DOUBLE), (acc, x) -> acc + x) AS total_price\nFROM orders_nested"
            },
            "invariants_kept": ["same result rows", "same values"],
            "expected_speedup": "3-10x",
            "risk": "medium — higher-order function syntax is more complex; must handle NULL arrays"
          }
        ]
      },
      "key_insight": "EXPLODE turns each array element into a separate row, potentially increasing row count by 10-100x, then requires a GROUP BY shuffle to re-aggregate. Higher-order functions (TRANSFORM, FILTER, AGGREGATE) process the array within each row, keeping the row count constant. No shuffle is needed because the computation is purely local. Databricks has optimized built-in support for these functions.",
      "when_not_to_use": "When you need to join the exploded elements with another table (the elements must exist as rows for a join). When the array processing logic is too complex for higher-order function syntax."
    },
    "original_sql": "SELECT order_id,\n  SUM(item_price) AS total_price\nFROM (\n  SELECT order_id, EXPLODE(items.price) AS item_price\n  FROM orders_nested\n)\nGROUP BY order_id",
    "optimized_sql": "SELECT order_id,\n  AGGREGATE(TRANSFORM(items, x -> x.price), CAST(0 AS DOUBLE), (acc, x) -> acc + x) AS total_price\nFROM orders_nested",
    "optimized_source": "databricks_docs_higher_order_functions",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "json_path_over_parse_json",
    "name": "Direct JSON Path Extraction Over Full JSON Parsing",
    "description": "Use colon notation or GET_JSON_OBJECT instead of parsing entire JSON strings into structs",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Databricks supports native semi-structured data access with colon (dot) notation and VARIANT types. Parsing full JSON into a struct processes every field; path extraction reads only the needed fields.",
    "example": {
      "opportunity": "JSON_PATH_EXTRACTION",
      "input_slice": "SELECT\n  FROM_JSON(payload, 'struct<user_id:STRING, event:STRING, metadata:struct<source:STRING>>').user_id,\n  FROM_JSON(payload, 'struct<user_id:STRING, event:STRING, metadata:struct<source:STRING>>').event\nFROM raw_events",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "from_json_to_path_extraction",
            "nodes": {
              "main_query": "SELECT\n  payload:user_id::STRING AS user_id,\n  payload:event::STRING AS event\nFROM raw_events"
            },
            "invariants_kept": ["same result values"],
            "expected_speedup": "2-5x",
            "risk": "low — colon notation requires STRING column or VARIANT type"
          }
        ]
      },
      "key_insight": "FROM_JSON parses the entire JSON string into a struct, materializing all fields even if only two are needed. Databricks' colon notation (payload:user_id) uses optimized path extraction that reads only the requested JSON keys. For large JSON payloads with dozens of fields, this reduces CPU and memory by an order of magnitude. With VARIANT columns (Databricks native semi-structured type), this is even more efficient.",
      "when_not_to_use": "When you need many fields from the same JSON (FROM_JSON once + multiple field accesses may be comparable). When the JSON is stored as VARIANT type and you're already using native access."
    },
    "original_sql": "SELECT\n  FROM_JSON(payload, 'struct<user_id:STRING, event:STRING, metadata:struct<source:STRING>>').user_id,\n  FROM_JSON(payload, 'struct<user_id:STRING, event:STRING, metadata:struct<source:STRING>>').event\nFROM raw_events",
    "optimized_sql": "SELECT\n  payload:user_id::STRING AS user_id,\n  payload:event::STRING AS event\nFROM raw_events",
    "optimized_source": "databricks_semi_structured_data",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  },

  {
    "id": "limit_pushdown_with_order",
    "name": "Combine ORDER BY + LIMIT for Top-N Pushdown",
    "description": "Ensure ORDER BY and LIMIT are together at the final query level to enable Spark's TakeOrderedAndProject optimization",
    "benchmark_queries": [],
    "verified_speedup": null,
    "engine": "databricks",
    "principle": "Spark has a special TakeOrderedAndProject physical operator that combines sort + limit efficiently by maintaining a bounded heap per partition. This only activates when ORDER BY and LIMIT appear together at the final stage.",
    "example": {
      "opportunity": "TOP_N_PUSHDOWN",
      "input_slice": "WITH all_orders AS (\n  SELECT customer_id, amount, order_date\n  FROM orders\n  WHERE order_date >= '2024-01-01'\n  ORDER BY amount DESC\n)\nSELECT *\nFROM all_orders\nLIMIT 100",
      "output": {
        "rewrite_sets": [
          {
            "id": "rs_01",
            "transform": "merge_order_and_limit",
            "nodes": {
              "main_query": "SELECT customer_id, amount, order_date\nFROM orders\nWHERE order_date >= '2024-01-01'\nORDER BY amount DESC\nLIMIT 100"
            },
            "invariants_kept": ["same result rows", "same ordering"],
            "expected_speedup": "2-10x",
            "risk": "low"
          }
        ]
      },
      "key_insight": "When ORDER BY is in a CTE and LIMIT is in the outer query, Spark may perform a full global sort in the CTE and then take 100 rows. When they're together, Spark uses TakeOrderedAndProject which maintains a top-100 heap per partition, then merges only the top-100 from each partition — never fully sorting the data. For a table with 100M rows, this reduces sort from O(N log N) to O(N log K) where K=100.",
      "when_not_to_use": "When the CTE result is used by multiple consumers (the ORDER BY in the CTE serves multiple outer queries)."
    },
    "original_sql": "WITH all_orders AS (\n  SELECT customer_id, amount, order_date\n  FROM orders\n  WHERE order_date >= '2024-01-01'\n  ORDER BY amount DESC\n)\nSELECT *\nFROM all_orders\nLIMIT 100",
    "optimized_sql": "SELECT customer_id, amount, order_date\nFROM orders\nWHERE order_date >= '2024-01-01'\nORDER BY amount DESC\nLIMIT 100",
    "optimized_source": "spark_top_n_optimization",
    "benchmark_query_num": null,
    "sf10_baseline_ms": null,
    "sf10_speedup": null,
    "sf10_rows_match": null
  }
]
