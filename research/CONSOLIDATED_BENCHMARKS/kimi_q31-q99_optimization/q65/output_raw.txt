 ```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "early_filter",
      "nodes": {
        "filtered_sales": "SELECT ss.ss_store_sk, ss.ss_item_sk, ss.ss_sales_price FROM store_sales ss JOIN date_dim d ON ss.ss_sold_date_sk = d.d_date_sk WHERE d.d_month_seq BETWEEN 1221 AND 1221 + 11",
        "item_revenue": "SELECT ss_store_sk, ss_item_sk, SUM(ss_sales_price) AS revenue FROM filtered_sales GROUP BY ss_store_sk, ss_item_sk",
        "store_avg": "SELECT ss_store_sk, AVG(revenue) AS ave FROM item_revenue GROUP BY ss_store_sk",
        "main_query": "SELECT s.s_store_name, i.i_item_desc, ir.revenue, i.i_current_price, i.i_wholesale_cost, i.i_brand FROM item_revenue ir JOIN store_avg sb ON ir.ss_store_sk = sb.ss_store_sk JOIN store s ON s.s_store_sk = ir.ss_store_sk JOIN item i ON i.i_item_sk = ir.ss_item_sk WHERE ir.revenue <= 0.1 * sb.ave ORDER BY s.s_store_name, i.i_item_desc LIMIT 100"
      },
      "invariants_kept": [
        "output columns unchanged",
        "grain preserved (store-item level)",
        "same filter predicate d_month_seq applied",
        "same ordering and limit"
      ],
      "expected_speedup": "2.00x",
      "risk": "low"
    }
  ],
  "explanation": "Eliminated redundant scan of store_sales by extracting common date filter into CTE 'filtered_sales'. The original query scanned store_sales twice (once for sb via sa, once for sc). Now we filter once, then compute item_revenue (replacing both sa and sc), compute store_avg from it (replacing sb), and join. This cuts I/O on the largest table in half."
}
```