{
  "query_num": 43,
  "status": "success",
  "original_sql": "-- start query 43 in stream 0 using template query43.tpl\nselect s_store_name, s_store_id,\n        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,\n        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,\n        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,\n        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,\n        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,\n        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,\n        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales\n from date_dim, store_sales, store\n where d_date_sk = ss_sold_date_sk and\n       s_store_sk = ss_store_sk and\n       s_gmt_offset = -5 and\n       d_year = 2000 \n group by s_store_name, s_store_id\n order by s_store_name, s_store_id,sun_sales,mon_sales,tue_sales,wed_sales,thu_sales,fri_sales,sat_sales\n LIMIT 100;\n\n-- end query 43 in stream 0 using template query43.tpl\n",
  "optimized_sql": "WITH filtered_dates AS (SELECT d_date_sk, d_day_name FROM date_dim WHERE d_year = 2000), filtered_stores AS (SELECT s_store_sk, s_store_name, s_store_id FROM store WHERE s_gmt_offset = -5)\nSELECT s.s_store_name, s.s_store_id, SUM(CASE WHEN d.d_day_name = 'Sunday' THEN ss.ss_sales_price END) AS sun_sales, SUM(CASE WHEN d.d_day_name = 'Monday' THEN ss.ss_sales_price END) AS mon_sales, SUM(CASE WHEN d.d_day_name = 'Tuesday' THEN ss.ss_sales_price END) AS tue_sales, SUM(CASE WHEN d.d_day_name = 'Wednesday' THEN ss.ss_sales_price END) AS wed_sales, SUM(CASE WHEN d.d_day_name = 'Thursday' THEN ss.ss_sales_price END) AS thu_sales, SUM(CASE WHEN d.d_day_name = 'Friday' THEN ss.ss_sales_price END) AS fri_sales, SUM(CASE WHEN d.d_day_name = 'Saturday' THEN ss.ss_sales_price END) AS sat_sales FROM filtered_dates AS d JOIN store_sales AS ss ON d.d_date_sk = ss.ss_sold_date_sk JOIN filtered_stores AS s ON s.s_store_sk = ss.ss_store_sk GROUP BY s.s_store_name, s.s_store_id ORDER BY s.s_store_name, s.s_store_id, sun_sales, mon_sales, tue_sales, wed_sales, thu_sales, fri_sales, sat_sales LIMIT 100",
  "raw_response": " ```json\n{\n  \"rewrite_sets\": [\n    {\n      \"id\": \"rs_01\",\n      \"transform\": \"early_filter\",\n      \"nodes\": {\n        \"filtered_dates\": \"SELECT d_date_sk, d_day_name FROM date_dim WHERE d_year = 2000\",\n        \"filtered_stores\": \"SELECT s_store_sk, s_store_name, s_store_id FROM store WHERE s_gmt_offset = -5\",\n        \"main_query\": \"SELECT s.s_store_name, s.s_store_id, SUM(CASE WHEN d.d_day_name = 'Sunday' THEN ss.ss_sales_price END) AS sun_sales, SUM(CASE WHEN d.d_day_name = 'Monday' THEN ss.ss_sales_price END) AS mon_sales, SUM(CASE WHEN d.d_day_name = 'Tuesday' THEN ss.ss_sales_price END) AS tue_sales, SUM(CASE WHEN d.d_day_name = 'Wednesday' THEN ss.ss_sales_price END) AS wed_sales, SUM(CASE WHEN d.d_day_name = 'Thursday' THEN ss.ss_sales_price END) AS thu_sales, SUM(CASE WHEN d.d_day_name = 'Friday' THEN ss.ss_sales_price END) AS fri_sales, SUM(CASE WHEN d.d_day_name = 'Saturday' THEN ss.ss_sales_price END) AS sat_sales FROM filtered_dates d JOIN store_sales ss ON d.d_date_sk = ss.ss_sold_date_sk JOIN filtered_stores s ON s.s_store_sk = ss.ss_store_sk GROUP BY s.s_store_name, s.s_store_id ORDER BY s.s_store_name, s.s_store_id, sun_sales, mon_sales, tue_sales, wed_sales, thu_sales, fri_sales, sat_sales LIMIT 100\"\n      },\n      \"invariants_kept\": [\n        \"same result rows\",\n        \"same ordering\",\n        \"same column output\",\n        \"same aggregation semantics\"\n      ],\n      \"expected_speedup\": \"3.50x\",\n      \"risk\": \"low\"\n    }\n  ],\n  \"explanation\": \"Applied early_filter to push d_year=2000 predicate into date_dim and s_gmt_offset=-5 predicate into store table before joining. This reduces the cardinality of both dimension tables significantly (date_dim filtered from ~10 years to 1 year, store filtered to specific timezone) before the expensive join with the large store_sales fact table. Also projects only necessary columns in the filtered CTEs to reduce I/O.\"\n}\n```",
  "error": null,
  "latency_ms": 45209.012002000236,
  "tokens_in": 1690,
  "tokens_out": 2654
}