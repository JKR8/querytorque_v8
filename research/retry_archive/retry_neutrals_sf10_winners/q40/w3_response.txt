```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "date_cte_isolate",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk, d_date FROM date_dim WHERE d_date BETWEEN CAST('2000-02-10' AS DATE) AND CAST('2000-04-10' AS DATE)",
        "main_query": "SELECT w_state, i_item_id, SUM(CASE WHEN (CAST(d_date AS DATE) < CAST('2000-03-11' AS DATE)) THEN cs_sales_price - COALESCE(cr_refunded_cash, 0) ELSE 0 END) AS sales_before, SUM(CASE WHEN (CAST(d_date AS DATE) >= CAST('2000-03-11' AS DATE)) THEN cs_sales_price - COALESCE(cr_refunded_cash, 0) ELSE 0 END) AS sales_after FROM catalog_sales LEFT OUTER JOIN catalog_returns ON (cs_order_number = cr_order_number AND cs_item_sk = cr_item_sk) INNER JOIN warehouse ON cs_warehouse_sk = w_warehouse_sk INNER JOIN item ON i_item_sk = cs_item_sk INNER JOIN filtered_dates ON cs_sold_date_sk = d_date_sk WHERE i_current_price BETWEEN 0.99 AND 1.49 GROUP BY w_state, i_item_id ORDER BY w_state, i_item_id LIMIT 100"
      },
      "invariants_kept": [
        "same result rows", 
        "same ordering",
        "same column output"
      ],
      "expected_speedup": "3.2x",
      "risk": "low"
    }
  ],
  "explanation": "Isolated the date_dim filter into a CTE (filtered_dates) to create a small pre-filtered dimension table (73,049 â†’ 61 rows). This allows the optimizer to join this small CTE early with catalog_sales, dramatically reducing the intermediate join size before other operations. The main query joins with this CTE instead of the full date_dim table, preserving all semantics while reducing the data processed in subsequent joins."
}
```