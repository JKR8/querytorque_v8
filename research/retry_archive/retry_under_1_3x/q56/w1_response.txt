Looking at this query, I can see three main CTEs (ss, cs, ws) that have identical structure but operate on different sales tables. Each one:
1. Filters items by color
2. Joins with date_dim with year/month filters
3. Joins with customer_address with offset filter
4. Aggregates sales by item

The main opportunity is to extract common filtering patterns into reusable CTEs.

```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "date_cte_isolate",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_year = 2001 AND d_moy = 2",
        "filtered_items": "SELECT i_item_sk, i_item_id FROM item WHERE i_color IN ('slate', 'blanched', 'burnished')",
        "filtered_addresses": "SELECT ca_address_sk FROM customer_address WHERE ca_gmt_offset = -5",
        "ss": "SELECT fi.i_item_id, SUM(ss_ext_sales_price) AS total_sales FROM store_sales ss JOIN filtered_dates fd ON ss.ss_sold_date_sk = fd.d_date_sk JOIN filtered_addresses fa ON ss.ss_addr_sk = fa.ca_address_sk JOIN filtered_items fi ON ss.ss_item_sk = fi.i_item_sk GROUP BY fi.i_item_id",
        "ws": "SELECT fi.i_item_id, SUM(ws_ext_sales_price) AS total_sales FROM web_sales ws JOIN filtered_dates fd ON ws.ws_sold_date_sk = fd.d_date_sk JOIN filtered_addresses fa ON ws.ws_bill_addr_sk = fa.ca_address_sk JOIN filtered_items fi ON ws.ws_item_sk = fi.i_item_sk GROUP BY fi.i_item_id"
      },
      "invariants_kept": [
        "output columns unchanged",
        "grain preserved",
        "same result rows"
      ],
      "expected_speedup": "3.5x",
      "risk": "low"
    }
  ],
  "explanation": "Extracted common date, item, and address filters into reusable CTEs. This reduces redundant scanning of dimension tables from 9 scans (3 CTEs Ã— 3 dim tables) to just 3 total scans. The filtered dimension CTEs are small (~28 rows for dates, ~102k for items, ~90k for addresses) and can be hash-joined efficiently with large fact tables. This eliminates repeated predicate evaluation on the same dimension rows across CTEs."
}
```