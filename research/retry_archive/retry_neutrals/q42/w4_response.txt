```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "early_filter",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk, d_year FROM date_dim WHERE d_moy = 11 AND d_year = 2000",
        "filtered_items": "SELECT i_item_sk, i_category_id, i_category FROM item WHERE i_manager_id = 1",
        "main_query": "SELECT fd.d_year, fi.i_category_id, fi.i_category, SUM(ss_ext_sales_price) FROM store_sales ss JOIN filtered_dates fd ON ss.ss_sold_date_sk = fd.d_date_sk JOIN filtered_items fi ON ss.ss_item_sk = fi.i_item_sk GROUP BY fd.d_year, fi.i_category_id, fi.i_category ORDER BY SUM(ss_ext_sales_price) DESC, fd.d_year, fi.i_category_id, fi.i_category LIMIT 100"
      },
      "invariants_kept": [
        "same output columns",
        "same grouping grain",
        "same result rows",
        "same ordering"
      ],
      "expected_speedup": "3x",
      "risk": "low"
    }
  ],
  "explanation": "Created early-filtering CTEs for date_dim and item to push predicates before the join with store_sales. This prevents a full sequential scan of store_sales by filtering rows early via the join conditions. The filtered_dates CTE returns only 30 rows (d_moy=11, d_year=2000), and filtered_items returns only 1,847 rows (i_manager_id=1), dramatically reducing the hash join input size for store_sales from 345M rows to only those matching both dimension filters."
}
```