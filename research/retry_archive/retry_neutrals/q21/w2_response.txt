```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "date_cte_isolate",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk, d_date FROM date_dim WHERE d_date BETWEEN CAST('2000-02-10' AS DATE) AND CAST('2000-04-10' AS DATE)",
        "filtered_items": "SELECT i_item_sk, i_item_id FROM item WHERE i_current_price BETWEEN 0.99 AND 1.49",
        "joined_facts": "SELECT w_warehouse_name, i_item_id, d_date, inv_quantity_on_hand FROM inventory JOIN filtered_dates ON inv_date_sk = d_date_sk JOIN filtered_items ON inv_item_sk = i_item_sk JOIN warehouse ON inv_warehouse_sk = w_warehouse_sk",
        "main_query": "SELECT w_warehouse_name, i_item_id, SUM(CASE WHEN (CAST(d_date AS DATE) < CAST('2000-03-11' AS DATE)) THEN inv_quantity_on_hand ELSE 0 END) AS inv_before, SUM(CASE WHEN (CAST(d_date AS DATE) >= CAST('2000-03-11' AS DATE)) THEN inv_quantity_on_hand ELSE 0 END) AS inv_after FROM joined_facts GROUP BY w_warehouse_name, i_item_id HAVING (CASE WHEN SUM(CASE WHEN (CAST(d_date AS DATE) < CAST('2000-03-11' AS DATE)) THEN inv_quantity_on_hand ELSE 0 END) > 0 THEN (SUM(CASE WHEN (CAST(d_date AS DATE) >= CAST('2000-03-11' AS DATE)) THEN inv_quantity_on_hand ELSE 0 END) * 1.000) / SUM(CASE WHEN (CAST(d_date AS DATE) < CAST('2000-03-11' AS DATE)) THEN inv_quantity_on_hand ELSE 0 END) ELSE NULL END) BETWEEN 2.000 / 3.000 AND 3.000 / 2.000 ORDER BY w_warehouse_name NULLS FIRST, i_item_id NULLS FIRST LIMIT 100"
      },
      "invariants_kept": [
        "same result rows",
        "same ordering",
        "same column output",
        "same grouping and aggregation"
      ],
      "expected_speedup": "5.0x",
      "risk": "low"
    }
  ],
  "explanation": "Isolated date_dim and item filters into separate CTEs before joining with the large inventory fact table. This reduces the cardinality of the primary join from 1.5B rows (full inventory scan) to only rows matching the date and price filters. The date CTE selects 61 rows (vs 73K), item CTE selects 6,464 rows (vs 102K), which dramatically reduces the intermediate join size from 4.5M rows to a much smaller set."
}
```