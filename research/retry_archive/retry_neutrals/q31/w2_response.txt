Looking at the query structure, I can see the main optimization opportunity: the CTEs `ss` and `ws` are computing aggregated sales data for ALL quarters and years, but the main query only needs Q1, Q2, and Q3 of year 2000. This causes unnecessary computation. I'll use pushdown to filter early.

```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "pushdown",
      "nodes": {
        "ss_q1_2000": "SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND d_year = 2000 AND d_qoy = 1 GROUP BY ca_county, d_qoy, d_year",
        "ss_q2_2000": "SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND d_year = 2000 AND d_qoy = 2 GROUP BY ca_county, d_qoy, d_year",
        "ss_q3_2000": "SELECT ca_county, d_qoy, d_year, SUM(ss_ext_sales_price) AS store_sales FROM store_sales, date_dim, customer_address WHERE ss_sold_date_sk = d_date_sk AND ss_addr_sk = ca_address_sk AND d_year = 2000 AND d_qoy = 3 GROUP BY ca_county, d_qoy, d_year",
        "ws_q1_2000": "SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND d_year = 2000 AND d_qoy = 1 GROUP BY ca_county, d_qoy, d_year",
        "ws_q2_2000": "SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND d_year = 2000 AND d_qoy = 2 GROUP BY ca_county, d_qoy, d_year",
        "ws_q3_2000": "SELECT ca_county, d_qoy, d_year, SUM(ws_ext_sales_price) AS web_sales FROM web_sales, date_dim, customer_address WHERE ws_sold_date_sk = d_date_sk AND ws_bill_addr_sk = ca_address_sk AND d_year = 2000 AND d_qoy = 3 GROUP BY ca_county, d_qoy, d_year",
        "main_query": "SELECT ss1.ca_county, ss1.d_year, (ws2.web_sales * 1.0000) / ws1.web_sales AS web_q1_q2_increase, (ss2.store_sales * 1.0000) / ss1.store_sales AS store_q1_q2_increase, (ws3.web_sales * 1.0000) / ws2.web_sales AS web_q2_q3_increase, (ss3.store_sales * 1.0000) / ss2.store_sales AS store_q2_q3_increase FROM ss_q1_2000 AS ss1, ss_q2_2000 AS ss2, ss_q3_2000 AS ss3, ws_q1_2000 AS ws1, ws_q2_2000 AS ws2, ws_q3_2000 AS ws3 WHERE ss1.ca_county = ss2.ca_county AND ss2.ca_county = ss3.ca_county AND ss1.ca_county = ws1.ca_county AND ws1.ca_county = ws2.ca_county AND ws1.ca_county = ws3.ca_county AND CASE WHEN ws1.web_sales > 0 THEN (ws2.web_sales * 1.0000) / ws1.web_sales ELSE NULL END > CASE WHEN ss1.store_sales > 0 THEN (ss2.store_sales * 1.0000) / ss1.store_sales ELSE NULL END AND CASE WHEN ws2.web_sales > 0 THEN (ws3.web_sales * 1.0000) / ws2.web_sales ELSE NULL END > CASE WHEN ss2.store_sales > 0 THEN (ss3.store_sales * 1.0000) / ss2.store_sales ELSE NULL END ORDER BY ss1.ca_county"
      },
      "invariants_kept": [
        "same result rows",
        "same ordering",
        "same column output",
        "same aggregation logic"
      ],
      "expected_speedup": "3.0x",
      "risk": "low"
    }
  ],
  "explanation": "Pushed d_year=2000 and d_qoy filters into each CTE before aggregation, creating specialized CTEs for each quarter. This reduces the amount of data processed in store_sales and web_sales scans from scanning entire tables to only scanning rows for specific quarters. The main query joins are simplified since the filtering is already done. This follows the verified pattern from Q93 with similar speedup."
}
```