## Example: Star Schema Dimension Filter First (STAR_SCHEMA_DIMENSION_FILTER_FIRST)
Verified speedup: unknown

### Input:
[main_query]:
-- May scan fact table first
      SELECT f.*, d1.name, d2.category
      FROM fact_sales f
      JOIN dim_date d1 ON f.date_id = d1.id
      JOIN dim_product d2 ON f.product_id = d2.id
      WHERE d1.year = 2025
        AND d2.category = 'Electronics';


**Key insight:** Star schema queries with selective dimension filters where optimizer
      scans fact table first instead of filtering dimensions.

---

## Example: Cte Optimization Fence Materialized (CTE_OPTIMIZATION_FENCE_MATERIALIZED)
Verified speedup: unknown

### Input:
[main_query]:
-- May be inlined and computed multiple times in PG12+
      WITH expensive_calc AS (
          SELECT id, complex_function(data) AS result 
          FROM big_table
      )
      SELECT * FROM expensive_calc e1
      JOIN expensive_calc e2 ON e1.result = e2.result;


**Key insight:** - CTE contains expensive computation that should run once
      - Need to isolate subquery planning to prevent bad plan choices
      - Force specific join ordering

---

## Example: Filter Subquery to Join (FILTER_SUB_QUERY_TO_JOIN)
Verified speedup: unknown

### Input:
[main_query]:
SELECT t1.id, t1.name FROM t1 WHERE t1.x IN (SELECT t2.y FROM t2 WHERE t2.active = true)

### Output:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "filter_sub_query_to_join",
      "nodes": {
        "main_query": "SELECT ... FROM t1 JOIN t2 ON t1.x = t2.y WHERE ..."
      },
      "invariants_kept": [
        "same result rows",
        "same output columns"
      ],
      "expected_speedup": "2x",
      "risk": "medium"
    }
  ]
}
```

**Key insight:** Rewrite scalar/IN/EXISTS subqueries into joins to enable predicate pushdown and better join planning.

---

## CONSTRAINTS (Learned from Benchmark Failures)

The following constraints are MANDATORY based on observed failures:

### LITERAL_PRESERVATION [CRITICAL]
CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

### OR_TO_UNION_LIMIT [HIGH]
CAUTION with OR→UNION: Only split OR conditions into UNION ALL when there are ≤3 simple branches AND they have different access patterns. If you have nested ORs (e.g., 3 conditions × 3 values = 9 combinations), DO NOT expand them - keep the original OR structure. DuckDB handles OR predicates efficiently. Over-splitting causes multiple scans of fact tables and severe regressions (0.23x-0.41x observed). When in doubt, preserve the original OR structure.


---

You are an autonomous Query Rewrite Engine. Your goal is to maximize execution speed while strictly preserving semantic invariants.

Output atomic rewrite sets in JSON.

RULES:
- Primary Goal: Maximize execution speed while strictly preserving semantic invariants.
- Allowed Transforms: Use the provided list. If a standard SQL optimization applies that is not listed, label it "semantic_rewrite".
- Atomic Sets: Group dependent changes (e.g., creating a CTE and joining it) into a single rewrite_set.
- Contracts: Output columns, grain, and total result rows must remain invariant.
- Naming: Use descriptive CTE names (e.g., `filtered_returns` vs `cte1`).
- Column Aliasing: Permitted only for aggregations or disambiguation.

ALLOWED TRANSFORMS: pushdown, decorrelate, or_to_union, early_filter, date_cte_isolate, materialize_cte, flatten_subquery, reorder_join, multi_push_predicate, inline_cte, remove_redundant, semantic_rewrite

OUTPUT FORMAT:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "transform_name",
      "nodes": {
        "node_id": "new SQL..."
      },
      "invariants_kept": ["list of preserved semantics"],
      "expected_speedup": "2x",
      "risk": "low"
    }
  ],
  "explanation": "what was changed and why"
}
```

## Target Nodes
  [customer_total_return] GROUP_BY
  [main_query] GROUP_BY CORRELATED

## Subgraph Slice
[customer_total_return] type=cte
```sql
SELECT sr_customer_sk AS ctr_customer_sk, sr_store_sk AS ctr_store_sk, sr_reason_sk AS ctr_reason_sk, SUM(SR_REFUNDED_CASH) AS ctr_total_return FROM store_returns, date_dim WHERE sr_returned_date_sk = d_date_sk AND d_year = 2000 AND sr_return_amt / sr_return_quantity BETWEEN 16 AND 75 GROUP BY sr_customer_sk, sr_store_sk, sr_reason_sk
```

[main_query] type=main
```sql
SELECT c_customer_id FROM customer_total_return AS ctr1, store, customer, customer_demographics WHERE ctr1.ctr_total_return > (SELECT AVG(ctr_total_return) * 1.2 FROM customer_total_return AS ctr2 WHERE ctr1.ctr_store_sk = ctr2.ctr_store_sk) AND ctr1.ctr_reason_sk BETWEEN 25 AND 28 AND s_store_sk = ctr1.ctr_store_sk AND s_state IN ('MI', 'ND', 'TX') AND ctr1.ctr_customer_sk = c_customer_sk AND c_current_cdemo_sk = cd_demo_sk AND cd_marital_status IN ('M', 'M') AND cd_education_status IN ('College', 'College') AND cd_gender = 'M' AND c_birth_month = 9 AND c_birth_year BETWEEN 1979 AND 1985 ORDER BY c_customer_id LIMIT 100
```


## Node Contracts
[customer_total_return]:
  output_columns: ['ctr_customer_sk', 'ctr_store_sk', 'ctr_reason_sk', 'ctr_total_return']
  grain: ['sr_customer_sk', 'sr_store_sk', 'sr_reason_sk']
  required_predicates: ['sr_returned_date_sk = d_date_sk', 'd_year = 2000']
[main_query]:
  output_columns: ['c_customer_id']
  required_predicates: ['c_birth_month = 9', "cd_gender = 'M'", 'c_current_cdemo_sk = cd_demo_sk']

## Downstream Usage
[customer_total_return]: downstream_refs=['ctr_total_return']

## Cost Attribution
No cost data.

## Detected Opportunities
## Knowledge Base Patterns (verified on TPC-DS)
## Detected Optimization Opportunities

1. **QT-OPT-002** - Correlated Subquery to Pre-computed CTE
  Trigger: WHERE col > (SELECT AVG/SUM/COUNT FROM ... WHERE correlated)
  Rewrite: Create CTE with GROUP BY on correlation key, then JOIN instead of correlated lookup
   Matched: Correlated subquery with aggregate comparison

2. **QT-OPT-003** - Date CTE Isolation
  Trigger: date_dim joined with d_year/d_qoy/d_month filter, fact table present
  Rewrite: Create CTE: SELECT d_date_sk FROM date_dim WHERE filter, join fact to CTE early
   Matched: date_dim filter with fact table


## Node-Specific Opportunities
DECORRELATE: [main_query] has correlated subquery
  Fix: Move aggregate to CTE, join instead of correlated lookup
  Expected: 2-3x speedup (verified Q1: 2.81x)

PUSHDOWN: [main_query] filters on [customer_total_return] after GROUP BY
  Fix: Push filter into CTE before aggregation
  Expected: 2x speedup (verified Q93: 2.71x)

PUSHDOWN: [main_query] filters on [customer_total_return] after GROUP BY
  Fix: Push filter into CTE before aggregation
  Expected: 2x speedup (verified Q93: 2.71x)

Now output your rewrite_sets: