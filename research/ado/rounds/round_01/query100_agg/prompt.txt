## Example: Dsb Self Join Decomposition (DSB_SELF_JOIN_DECOMPOSITION)
Verified speedup: unknown

### Input:
[main_query]:
-- DSB Query 100: items sold together
      SELECT i1.i_item_id, i2.i_item_id, COUNT(*)
      FROM store_sales ss1
      JOIN store_sales ss2 ON ss1.ss_ticket_number = ss2.ss_ticket_number 
                           AND ss1.ss_item_sk < ss2.ss_item_sk
      JOIN item i1 ON ss1.ss_item_sk = i1.i_item_sk
      JOIN item i2 ON ss2.ss_item_sk = i2.i_item_sk
      GROUP BY i1.i_item_id, i2.i_item_id;


**Key insight:** DSB Query 100 pattern: items frequently sold together.

---

## Example: Subquery Offset Zero Barrier (SUBQUERY_OFFSET_ZERO_BARRIER)
Verified speedup: unknown

### Input:
[main_query]:
-- Subquery may be "pulled up" and reordered
      SELECT * FROM fact_table f
      JOIN (
          SELECT * FROM dim_table WHERE active = true
      ) d ON f.dim_id = d.id;


**Key insight:** - Force specific join order without global setting changes
      - Subquery results should compute before joining
      - Debug plans by isolating subquery execution

---

## Example: Star Schema Dimension Filter First (STAR_SCHEMA_DIMENSION_FILTER_FIRST)
Verified speedup: unknown

### Input:
[main_query]:
-- May scan fact table first
      SELECT f.*, d1.name, d2.category
      FROM fact_sales f
      JOIN dim_date d1 ON f.date_id = d1.id
      JOIN dim_product d2 ON f.product_id = d2.id
      WHERE d1.year = 2025
        AND d2.category = 'Electronics';


**Key insight:** Star schema queries with selective dimension filters where optimizer
      scans fact table first instead of filtering dimensions.

---

## CONSTRAINTS (Learned from Benchmark Failures)

The following constraints are MANDATORY based on observed failures:

### LITERAL_PRESERVATION [CRITICAL]
CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

### OR_TO_UNION_LIMIT [HIGH]
CAUTION with OR→UNION: Only split OR conditions into UNION ALL when there are ≤3 simple branches AND they have different access patterns. If you have nested ORs (e.g., 3 conditions × 3 values = 9 combinations), DO NOT expand them - keep the original OR structure. DuckDB handles OR predicates efficiently. Over-splitting causes multiple scans of fact tables and severe regressions (0.23x-0.41x observed). When in doubt, preserve the original OR structure.


---

You are an autonomous Query Rewrite Engine. Your goal is to maximize execution speed while strictly preserving semantic invariants.

Output atomic rewrite sets in JSON.

RULES:
- Primary Goal: Maximize execution speed while strictly preserving semantic invariants.
- Allowed Transforms: Use the provided list. If a standard SQL optimization applies that is not listed, label it "semantic_rewrite".
- Atomic Sets: Group dependent changes (e.g., creating a CTE and joining it) into a single rewrite_set.
- Contracts: Output columns, grain, and total result rows must remain invariant.
- Naming: Use descriptive CTE names (e.g., `filtered_returns` vs `cte1`).
- Column Aliasing: Permitted only for aggregations or disambiguation.

ALLOWED TRANSFORMS: pushdown, decorrelate, or_to_union, early_filter, date_cte_isolate, materialize_cte, flatten_subquery, reorder_join, multi_push_predicate, inline_cte, remove_redundant, semantic_rewrite

OUTPUT FORMAT:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "transform_name",
      "nodes": {
        "node_id": "new SQL..."
      },
      "invariants_kept": ["list of preserved semantics"],
      "expected_speedup": "2x",
      "risk": "low"
    }
  ],
  "explanation": "what was changed and why"
}
```

## Target Nodes
  [main_query] GROUP_BY

## Subgraph Slice
[main_query] type=main
```sql
SELECT item1.i_item_sk, item2.i_item_sk, COUNT(*) AS cnt FROM item AS item1, item AS item2, store_sales AS s1, store_sales AS s2, date_dim, customer, customer_address, customer_demographics WHERE item1.i_item_sk < item2.i_item_sk AND s1.ss_ticket_number = s2.ss_ticket_number AND s1.ss_item_sk = item1.i_item_sk AND s2.ss_item_sk = item2.i_item_sk AND s1.ss_customer_sk = c_customer_sk AND c_current_addr_sk = ca_address_sk AND c_current_cdemo_sk = cd_demo_sk AND d_year BETWEEN 2000 AND 2000 + 1 AND d_date_sk = s1.ss_sold_date_sk AND item1.i_category IN ('Electronics', 'Men') AND item2.i_manager_id BETWEEN 81 AND 100 AND cd_marital_status = 'S' AND cd_education_status = 'Secondary' AND s1.ss_list_price BETWEEN 16 AND 30 AND s2.ss_list_price BETWEEN 16 AND 30 GROUP BY item1.i_item_sk, item2.i_item_sk ORDER BY cnt
```


## Node Contracts
[main_query]:
  output_columns: ['i_item_sk', 'i_item_sk', 'cnt']
  grain: ['i_item_sk', 'i_item_sk']
  required_predicates: ["cd_education_status = 'Secondary'", "cd_marital_status = 'S'", 'd_date_sk = s1.ss_sold_date_sk']

## Downstream Usage
No usage data.

## Cost Attribution
No cost data.

## Detected Opportunities
## Knowledge Base Patterns (verified on TPC-DS)
## Detected Optimization Opportunities

1. **QT-OPT-003** - Date CTE Isolation
  Trigger: date_dim joined with d_year/d_qoy/d_month filter, fact table present
  Rewrite: Create CTE: SELECT d_date_sk FROM date_dim WHERE filter, join fact to CTE early
   Matched: date_dim filter with fact table


Now output your rewrite_sets: