Optimize this SQL query.

## Execution Plan

**Operators by cost:**
- SEQ_SCAN (store_sales): 59.7% cost, 940,428 rows
- SEQ_SCAN (customer): 35.0% cost, 1,999,569 rows
- HASH_JOIN: 2.5% cost, 5,399 rows
- HASH_JOIN: 0.7% cost, 215,413 rows
- HASH_GROUP_BY: 0.6% cost, 5,431 rows

**Table scans:**
- customer: 1,999,569 rows ← FILTERED by c_customer_sk<=1999999
- store_sales: 940,428 rows (NO FILTER)
- household_demographics: 4,800 rows ← FILTERED by ["optional: hd_buy_potential='501-1000' OR hd_buy_potential='Unknown'", 'hd_vehicle_count>0']
- store: 402 rows ← FILTERED by optional: s_county IN ('Fairfield County', 'Walker
- date_dim: 72 rows ← FILTERED by ['d_dom>=1 AND d_dom<=2', 'd_year>=2000 AND d_year<=2002']

---

## Block Map
```
┌─────────────────────────────────────────────────────────────────────────────────┐
│ BLOCK                  │ CLAUSE   │ CONTENT SUMMARY                               │
├─────────────────────────────────────────────────────────────────────────────────┤
│ main_query             │ .select  │ c_last_name, c_first_name, c_salutation, c... │
│                        │ .from    │ (subquery: store_sales, date_dim, store) +1   │
│                        │ .where   │ ss_customer_sk = c_customer_sk AND cnt BET... │
│                        │ .group_by │ ss_ticket_number, ss_customer_sk              │
└─────────────────────────────────────────────────────────────────────────────────┘

```

---

## Optimization Patterns

These patterns have produced >2x speedups:

1. **Dimension filter hoisting**: If a filtered dimension is in main_query but the CTE aggregates fact data that COULD be filtered by it (via FK), move the dimension join+filter INTO the CTE to filter early.

2. **Correlated subquery to window function**: A correlated subquery computes an aggregate per group. Fix: Replace with a window function in the CTE (e.g., `AVG(...) OVER (PARTITION BY group_col)`).

3. **Join elimination**: A table is joined only to validate a foreign key exists, but no columns from it are used. Fix: Remove the join, add `WHERE fk_column IS NOT NULL`.

4. **UNION ALL decomposition**: Complex OR conditions cause full scans. Fix: Split into separate queries with simple filters, UNION ALL results.

5. **Scan consolidation**: Same table scanned multiple times with different filters. Fix: Single scan with CASE WHEN expressions to compute multiple aggregates conditionally.

**Verify**: Optimized query must return identical results.

---

## SQL
```sql
-- start query 73 in stream 0 using template query73.tpl
select c_last_name
       ,c_first_name
       ,c_salutation
       ,c_preferred_cust_flag 
       ,ss_ticket_number
       ,cnt from
   (select ss_ticket_number
          ,ss_customer_sk
          ,count(*) cnt
    from store_sales,date_dim,store,household_demographics
    where store_sales.ss_sold_date_sk = date_dim.d_date_sk
    and store_sales.ss_store_sk = store.s_store_sk  
    and store_sales.ss_hdemo_sk = household_demographics.hd_demo_sk
    and date_dim.d_dom between 1 and 2 
    and (household_demographics.hd_buy_potential = '501-1000' or
         household_demographics.hd_buy_potential = 'Unknown')
    and household_demographics.hd_vehicle_count > 0
    and case when household_demographics.hd_vehicle_count > 0 then 
             household_demographics.hd_dep_count/ household_demographics.hd_vehicle_count else null end > 1
    and date_dim.d_year in (2000,2000+1,2000+2)
    and store.s_county in ('Fairfield County','Walker County','Daviess County','Barrow County')
    group by ss_ticket_number,ss_customer_sk) dj,customer
    where ss_customer_sk = c_customer_sk
      and cnt between 1 and 5
    order by cnt desc, c_last_name asc;

-- end query 73 in stream 0 using template query73.tpl
```

---

## Output

Return JSON:
```json
{
  "operations": [...],
  "semantic_warnings": [],
  "explanation": "..."
}
```

### Operations

| Op | Fields | Description |
|----|--------|-------------|
| `add_cte` | `after`, `name`, `sql` | Insert new CTE |
| `delete_cte` | `name` | Remove CTE |
| `replace_cte` | `name`, `sql` | Replace entire CTE body |
| `replace_clause` | `target`, `sql` | Replace clause (`""` to remove) |
| `patch` | `target`, `patches[]` | Snippet search/replace |

### Example
```json
{
  "operations": [
    {"op": "replace_cte", "name": "my_cte", "sql": "SELECT sk, SUM(val) FROM t WHERE sk IS NOT NULL GROUP BY sk"}
  ],
  "semantic_warnings": ["Removed join - added IS NOT NULL to preserve filtering"],
  "explanation": "Removed unnecessary dimension join, using FK directly"
}
```

### Block ID Syntax
```
{cte}.select    {cte}.from    {cte}.where    {cte}.group_by    {cte}.having
main_query.union[N].select    main_query.union[N].from    ...
```

### Rules
1. **Return 1-5 operations maximum** - focus on highest-impact changes first
2. Operations apply sequentially
3. `patch.search` must be unique within target clause
4. `add_cte.sql` = query body only (no CTE name)
5. All CTE refs must resolve after ops
6. When removing a join, update column references (e.g., `c_customer_sk` → `ss_customer_sk AS c_customer_sk`)

The system will iterate if more optimization is possible. You don't need to fix everything at once.