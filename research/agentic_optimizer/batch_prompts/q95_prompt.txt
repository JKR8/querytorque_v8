Optimize this SQL query.

## Execution Plan

**Operators by cost:**
- SEQ_SCAN (web_sales): 28.9% cost, 60,193 rows
- SEQ_SCAN (customer_address): 24.6% cost, 31,331 rows
- SEQ_SCAN (web_sales): 15.8% cost, 719,845 rows
- HASH_JOIN: 12.1% cost, 77,632 rows
- HASH_JOIN: 11.9% cost, 77,632 rows

**Table scans:**
- web_sales: 719,831 rows ← FILTERED by ws_order_number>=90 AND ws_order_number<=5999975
- web_sales: 719,831 rows ← FILTERED by ws_order_number>=90 AND ws_order_number<=5999975
- web_returns: 71,681 rows (NO FILTER)
- web_sales: 719,845 rows (NO FILTER)
- web_sales: 719,845 rows (NO FILTER)
- date_dim: 61 rows ← FILTERED by (CAST(d_date AS TIMESTAMP) BETWEEN '1999-02-01 00:
- web_sales: 60,193 rows (NO FILTER)
- customer_address: 31,331 rows ← FILTERED by ca_state='NC'
- web_site: 2 rows ← FILTERED by web_company_name='pri'

---

## Block Map
```
┌─────────────────────────────────────────────────────────────────────────────────┐
│ BLOCK                  │ CLAUSE   │ CONTENT SUMMARY                               │
├─────────────────────────────────────────────────────────────────────────────────┤
│ ws_wh                  │ .select  │ ws1.ws_order_number, wh1, wh2                 │
│                        │ .from    │ web_sales                                     │
│                        │ .where   │ ws1.ws_order_number = ws2.ws_order_number ... │
├─────────────────────────────────────────────────────────────────────────────────┤
│ main_query             │ .select  │ order count, total shipping cost, total ne... │
│                        │ .from    │ web_sales                                     │
│                        │ .where   │ d_date BETWEEN '1999-2-01' AND (CAST('1999... │
└─────────────────────────────────────────────────────────────────────────────────┘

Refs:
  main_query.where → ws_wh
  main_query.where → ws_wh

Repeated Scans:
  web_sales: 2× (ws_wh.from, main_query.from)

```

---

## Optimization Patterns

These patterns have produced >2x speedups:

1. **Dimension filter hoisting**: If a filtered dimension is in main_query but the CTE aggregates fact data that COULD be filtered by it (via FK), move the dimension join+filter INTO the CTE to filter early.

2. **Correlated subquery to window function**: A correlated subquery computes an aggregate per group. Fix: Replace with a window function in the CTE (e.g., `AVG(...) OVER (PARTITION BY group_col)`).

3. **Join elimination**: A table is joined only to validate a foreign key exists, but no columns from it are used. Fix: Remove the join, add `WHERE fk_column IS NOT NULL`.

4. **UNION ALL decomposition**: Complex OR conditions cause full scans. Fix: Split into separate queries with simple filters, UNION ALL results.

5. **Scan consolidation**: Same table scanned multiple times with different filters. Fix: Single scan with CASE WHEN expressions to compute multiple aggregates conditionally.

**Verify**: Optimized query must return identical results.

---

## SQL
```sql
-- start query 95 in stream 0 using template query95.tpl
with ws_wh as
(select ws1.ws_order_number,ws1.ws_warehouse_sk wh1,ws2.ws_warehouse_sk wh2
 from web_sales ws1,web_sales ws2
 where ws1.ws_order_number = ws2.ws_order_number
   and ws1.ws_warehouse_sk <> ws2.ws_warehouse_sk)
 select 
   count(distinct ws_order_number) as "order count"
  ,sum(ws_ext_ship_cost) as "total shipping cost"
  ,sum(ws_net_profit) as "total net profit"
from
   web_sales ws1
  ,date_dim
  ,customer_address
  ,web_site
where
    d_date between '1999-2-01' and 
           (cast('1999-2-01' as date) + INTERVAL 60 DAY)
and ws1.ws_ship_date_sk = d_date_sk
and ws1.ws_ship_addr_sk = ca_address_sk
and ca_state = 'NC'
and ws1.ws_web_site_sk = web_site_sk
and web_company_name = 'pri'
and ws1.ws_order_number in (select ws_order_number
                            from ws_wh)
and ws1.ws_order_number in (select wr_order_number
                            from web_returns,ws_wh
                            where wr_order_number = ws_wh.ws_order_number)
order by count(distinct ws_order_number)
 LIMIT 100;

-- end query 95 in stream 0 using template query95.tpl
```

---

## Output

Return JSON:
```json
{
  "operations": [...],
  "semantic_warnings": [],
  "explanation": "..."
}
```

### Operations

| Op | Fields | Description |
|----|--------|-------------|
| `add_cte` | `after`, `name`, `sql` | Insert new CTE |
| `delete_cte` | `name` | Remove CTE |
| `replace_cte` | `name`, `sql` | Replace entire CTE body |
| `replace_clause` | `target`, `sql` | Replace clause (`""` to remove) |
| `patch` | `target`, `patches[]` | Snippet search/replace |

### Example
```json
{
  "operations": [
    {"op": "replace_cte", "name": "my_cte", "sql": "SELECT sk, SUM(val) FROM t WHERE sk IS NOT NULL GROUP BY sk"}
  ],
  "semantic_warnings": ["Removed join - added IS NOT NULL to preserve filtering"],
  "explanation": "Removed unnecessary dimension join, using FK directly"
}
```

### Block ID Syntax
```
{cte}.select    {cte}.from    {cte}.where    {cte}.group_by    {cte}.having
main_query.union[N].select    main_query.union[N].from    ...
```

### Rules
1. **Return 1-5 operations maximum** - focus on highest-impact changes first
2. Operations apply sequentially
3. `patch.search` must be unique within target clause
4. `add_cte.sql` = query body only (no CTE name)
5. All CTE refs must resolve after ops
6. When removing a join, update column references (e.g., `c_customer_sk` → `ss_customer_sk AS c_customer_sk`)

The system will iterate if more optimization is possible. You don't need to fix everything at once.