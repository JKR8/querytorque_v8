Optimize this SQL query.

## Execution Plan

**Operators by cost:**
- SEQ_SCAN (inventory): 56.6% cost, 3,995,147 rows
- SEQ_SCAN (customer_demographics): 12.1% cost, 384,142 rows
- HASH_JOIN: 10.0% cost, 8,692 rows
- SEQ_SCAN (item): 9.1% cost, 203,978 rows
- SEQ_SCAN (catalog_sales): 6.1% cost, 279,870 rows

**Table scans:**
- catalog_returns: 26,576 rows (NO FILTER)
- date_dim: 360 rows ← FILTERED by d_date_sk>=2450815 AND d_date_sk<=2452635
- inventory: 3,995,147 rows ← FILTERED by inv_item_sk<=203999
- item: 203,978 rows ← FILTERED by i_item_sk<=203999
- date_dim: 448 rows ← FILTERED by d_date_sk>=2450817 AND d_date_sk<=2452744
- customer_demographics: 384,142 rows ← FILTERED by cd_marital_status='W'
- catalog_sales: 279,870 rows (NO FILTER)
- date_dim: 365 rows ← FILTERED by d_year=2002
- household_demographics: 1,200 rows ← FILTERED by hd_buy_potential='501-1000'
- warehouse: 15 rows (NO FILTER)
- promotion: 1,000 rows (NO FILTER)

---

## Block Map
```
┌─────────────────────────────────────────────────────────────────────────────────┐
│ BLOCK                  │ CLAUSE   │ CONTENT SUMMARY                               │
├─────────────────────────────────────────────────────────────────────────────────┤
│ main_query             │ .select  │ i_item_desc, w_warehouse_name, d1.d_week_s... │
│                        │ .from    │ catalog_sales                                 │
│                        │ .where   │ d1.d_week_seq = d2.d_week_seq AND inv_quan... │
│                        │ .group_by │ i_item_desc, w_warehouse_name, d_week_seq     │
└─────────────────────────────────────────────────────────────────────────────────┘

```

---

## Optimization Patterns

These patterns have produced >2x speedups:

1. **Dimension filter hoisting**: If a filtered dimension is in main_query but the CTE aggregates fact data that COULD be filtered by it (via FK), move the dimension join+filter INTO the CTE to filter early.

2. **Correlated subquery to window function**: A correlated subquery computes an aggregate per group. Fix: Replace with a window function in the CTE (e.g., `AVG(...) OVER (PARTITION BY group_col)`).

3. **Join elimination**: A table is joined only to validate a foreign key exists, but no columns from it are used. Fix: Remove the join, add `WHERE fk_column IS NOT NULL`.

4. **UNION ALL decomposition**: Complex OR conditions cause full scans. Fix: Split into separate queries with simple filters, UNION ALL results.

5. **Scan consolidation**: Same table scanned multiple times with different filters. Fix: Single scan with CASE WHEN expressions to compute multiple aggregates conditionally.

**Verify**: Optimized query must return identical results.

---

## SQL
```sql
-- start query 72 in stream 0 using template query72.tpl
select i_item_desc
      ,w_warehouse_name
      ,d1.d_week_seq
      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo
      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo
      ,count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity 
  and d3.d_date > d1.d_date + 5
  and hd_buy_potential = '501-1000'
  and d1.d_year = 2002
  and cd_marital_status = 'W'
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d1.d_week_seq
 LIMIT 100;

-- end query 72 in stream 0 using template query72.tpl
```

---

## Output

Return JSON:
```json
{
  "operations": [...],
  "semantic_warnings": [],
  "explanation": "..."
}
```

### Operations

| Op | Fields | Description |
|----|--------|-------------|
| `add_cte` | `after`, `name`, `sql` | Insert new CTE |
| `delete_cte` | `name` | Remove CTE |
| `replace_cte` | `name`, `sql` | Replace entire CTE body |
| `replace_clause` | `target`, `sql` | Replace clause (`""` to remove) |
| `patch` | `target`, `patches[]` | Snippet search/replace |

### Example
```json
{
  "operations": [
    {"op": "replace_cte", "name": "my_cte", "sql": "SELECT sk, SUM(val) FROM t WHERE sk IS NOT NULL GROUP BY sk"}
  ],
  "semantic_warnings": ["Removed join - added IS NOT NULL to preserve filtering"],
  "explanation": "Removed unnecessary dimension join, using FK directly"
}
```

### Block ID Syntax
```
{cte}.select    {cte}.from    {cte}.where    {cte}.group_by    {cte}.having
main_query.union[N].select    main_query.union[N].from    ...
```

### Rules
1. **Return 1-5 operations maximum** - focus on highest-impact changes first
2. Operations apply sequentially
3. `patch.search` must be unique within target clause
4. `add_cte.sql` = query body only (no CTE name)
5. All CTE refs must resolve after ops
6. When removing a join, update column references (e.g., `c_customer_sk` → `ss_customer_sk AS c_customer_sk`)

The system will iterate if more optimization is possible. You don't need to fix everything at once.