Optimize this SQL query.

## Execution Plan

**Operators by cost:**
- SEQ_SCAN (customer): 20.2% cost, 1,999,926 rows
- SEQ_SCAN (store_sales): 14.1% cost, 552,090 rows
- HASH_GROUP_BY: 8.4% cost, 451,412 rows
- HASH_GROUP_BY: 7.3% cost, 449,874 rows
- HASH_JOIN: 7.1% cost, 537,338 rows

**Table scans:**
- customer: 1,999,995 rows ← FILTERED by optional: Dynamic Filter (c_first_name)
- store_sales: 552,090 rows (NO FILTER)
- date_dim: 366 rows ← FILTERED by d_year=2000 AND d_year>=1999 AND d_year<=2000
- customer: 1,999,926 rows ← FILTERED by c_customer_sk>=7 AND c_customer_sk<=1999999
- web_sales: 144,610 rows (NO FILTER)
- date_dim: 366 rows ← FILTERED by d_year=2000 AND d_year>=1999 AND d_year<=2000
- customer: 1,999,427 rows ← FILTERED by c_customer_sk<=1999999
- store_sales: 550,426 rows (NO FILTER)
- date_dim: 365 rows ← FILTERED by d_year=1999 AND d_year>=1999 AND d_year<=2000
- customer: 1,999,965 rows ← FILTERED by c_customer_sk>=7 AND c_customer_sk<=1999999
- web_sales: 143,552 rows (NO FILTER)
- date_dim: 365 rows ← FILTERED by d_year=1999 AND d_year>=1999 AND d_year<=2000

---

## Block Map
```
┌─────────────────────────────────────────────────────────────────────────────────┐
│ BLOCK                  │ CLAUSE   │ CONTENT SUMMARY                               │
├─────────────────────────────────────────────────────────────────────────────────┤
│ year_total             │ .select  │ customer_id, customer_first_name, customer... │
│                        │ .from    │ customer                                      │
│                        │ .where   │ c_customer_sk = ss_customer_sk AND ss_sold... │
│                        │ .group_by │ c_customer_id, c_first_name, c_last_name      │
├─────────────────────────────────────────────────────────────────────────────────┤
│ main_query             │ .select  │ t_s_secyear.customer, t_s_secyear.customer... │
│                        │ .from    │                                               │
│                        │ .where   │ t_s_secyear.customer_id = t_s_firstyear.cu... │
│                        │ .group_by │ c_customer_id, c_first_name, c_last_name      │
└─────────────────────────────────────────────────────────────────────────────────┘

Refs:
  main_query.from → year_total

Repeated Scans:
  store_sales: 2× (year_total.from, main_query.from)
  date_dim: 2× (year_total.from, main_query.from)

```

---

## Optimization Patterns

These patterns have produced >2x speedups:

1. **Dimension filter hoisting**: If a filtered dimension is in main_query but the CTE aggregates fact data that COULD be filtered by it (via FK), move the dimension join+filter INTO the CTE to filter early.

2. **Correlated subquery to window function**: A correlated subquery computes an aggregate per group. Fix: Replace with a window function in the CTE (e.g., `AVG(...) OVER (PARTITION BY group_col)`).

3. **Join elimination**: A table is joined only to validate a foreign key exists, but no columns from it are used. Fix: Remove the join, add `WHERE fk_column IS NOT NULL`.

4. **UNION ALL decomposition**: Complex OR conditions cause full scans. Fix: Split into separate queries with simple filters, UNION ALL results.

5. **Scan consolidation**: Same table scanned multiple times with different filters. Fix: Single scan with CASE WHEN expressions to compute multiple aggregates conditionally.

**Verify**: Optimized query must return identical results.

---

## SQL
```sql
-- start query 74 in stream 0 using template query74.tpl
with year_total as (
 select c_customer_id customer_id
       ,c_first_name customer_first_name
       ,c_last_name customer_last_name
       ,d_year as year
       ,stddev_samp(ss_net_paid) year_total
       ,'s' sale_type
 from customer
     ,store_sales
     ,date_dim
 where c_customer_sk = ss_customer_sk
   and ss_sold_date_sk = d_date_sk
   and d_year in (1999,1999+1)
 group by c_customer_id
         ,c_first_name
         ,c_last_name
         ,d_year
 union all
 select c_customer_id customer_id
       ,c_first_name customer_first_name
       ,c_last_name customer_last_name
       ,d_year as year
       ,stddev_samp(ws_net_paid) year_total
       ,'w' sale_type
 from customer
     ,web_sales
     ,date_dim
 where c_customer_sk = ws_bill_customer_sk
   and ws_sold_date_sk = d_date_sk
   and d_year in (1999,1999+1)
 group by c_customer_id
         ,c_first_name
         ,c_last_name
         ,d_year
         )
  select
        t_s_secyear.customer_id, t_s_secyear.customer_first_name, t_s_secyear.customer_last_name
 from year_total t_s_firstyear
     ,year_total t_s_secyear
     ,year_total t_w_firstyear
     ,year_total t_w_secyear
 where t_s_secyear.customer_id = t_s_firstyear.customer_id
         and t_s_firstyear.customer_id = t_w_secyear.customer_id
         and t_s_firstyear.customer_id = t_w_firstyear.customer_id
         and t_s_firstyear.sale_type = 's'
         and t_w_firstyear.sale_type = 'w'
         and t_s_secyear.sale_type = 's'
         and t_w_secyear.sale_type = 'w'
         and t_s_firstyear.year = 1999
         and t_s_secyear.year = 1999+1
         and t_w_firstyear.year = 1999
         and t_w_secyear.year = 1999+1
         and t_s_firstyear.year_total > 0
         and t_w_firstyear.year_total > 0
         and case when t_w_firstyear.year_total > 0 then t_w_secyear.year_total / t_w_firstyear.year_total else null end
           > case when t_s_firstyear.year_total > 0 then t_s_secyear.year_total / t_s_firstyear.year_total else null end
 order by 2,1,3
 LIMIT 100;

-- end query 74 in stream 0 using template query74.tpl
```

---

## Output

Return JSON:
```json
{
  "operations": [...],
  "semantic_warnings": [],
  "explanation": "..."
}
```

### Operations

| Op | Fields | Description |
|----|--------|-------------|
| `add_cte` | `after`, `name`, `sql` | Insert new CTE |
| `delete_cte` | `name` | Remove CTE |
| `replace_cte` | `name`, `sql` | Replace entire CTE body |
| `replace_clause` | `target`, `sql` | Replace clause (`""` to remove) |
| `patch` | `target`, `patches[]` | Snippet search/replace |

### Example
```json
{
  "operations": [
    {"op": "replace_cte", "name": "my_cte", "sql": "SELECT sk, SUM(val) FROM t WHERE sk IS NOT NULL GROUP BY sk"}
  ],
  "semantic_warnings": ["Removed join - added IS NOT NULL to preserve filtering"],
  "explanation": "Removed unnecessary dimension join, using FK directly"
}
```

### Block ID Syntax
```
{cte}.select    {cte}.from    {cte}.where    {cte}.group_by    {cte}.having
main_query.union[N].select    main_query.union[N].from    ...
```

### Rules
1. **Return 1-5 operations maximum** - focus on highest-impact changes first
2. Operations apply sequentially
3. `patch.search` must be unique within target clause
4. `add_cte.sql` = query body only (no CTE name)
5. All CTE refs must resolve after ops
6. When removing a join, update column references (e.g., `c_customer_sk` → `ss_customer_sk AS c_customer_sk`)

The system will iterate if more optimization is possible. You don't need to fix everything at once.