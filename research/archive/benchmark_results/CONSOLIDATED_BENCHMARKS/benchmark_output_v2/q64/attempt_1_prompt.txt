## Example: Date CTE Isolation (DATE_CTE_ISOLATE)
Verified speedup: 4.00x

### Input:
[main_query]:
SELECT a.ca_state state, count(*) cnt
FROM customer_address a, customer c, store_sales s, date_dim d, item i
WHERE a.ca_address_sk = c.c_current_addr_sk
  AND c.c_customer_sk = s.ss_customer_sk
  AND s.ss_sold_date_sk = d.d_date_sk
  AND s.ss_item_sk = i.i_item_sk
  AND d.d_month_seq = (SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1)
  AND i.i_current_price > 1.2 * (SELECT avg(j.i_current_price) FROM item j WHERE j.i_category = i.i_category)
GROUP BY a.ca_state HAVING count(*) >= 10
ORDER BY cnt, a.ca_state LIMIT 100

### Output:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "date_cte_isolate",
      "nodes": {
        "target_month": "SELECT DISTINCT d_month_seq FROM date_dim WHERE d_year = 2000 AND d_moy = 1",
        "category_avg_price": "SELECT i_category, AVG(i_current_price) * 1.2 AS avg_threshold FROM item GROUP BY i_category",
        "filtered_dates": "SELECT d_date_sk FROM date_dim JOIN target_month ON d_month_seq = target_month.d_month_seq",
        "filtered_sales": "SELECT ss_customer_sk, ss_item_sk FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk",
        "main_query": "SELECT a.ca_state AS state, COUNT(*) AS cnt FROM customer_address a JOIN customer c ON a.ca_address_sk = c.c_current_addr_sk JOIN filtered_sales s ON c.c_customer_sk = s.ss_customer_sk JOIN item i ON s.ss_item_sk = i.i_item_sk JOIN category_avg_price cap ON i.i_category = cap.i_category WHERE i.i_current_price > cap.avg_threshold GROUP BY a.ca_state HAVING COUNT(*) >= 10 ORDER BY cnt, a.ca_state LIMIT 100"
      },
      "invariants_kept": [
        "same result rows",
        "same ordering",
        "same column output",
        "same grouping and aggregation"
      ],
      "expected_speedup": "2.0x",
      "risk": "low"
    }
  ]
}
```

**Key insight:** Extract date month_seq subquery into CTE. Extract category average into separate CTE with GROUP BY. Join instead of correlated subquery. This allows each CTE to be scanned once.


---

## Example: OR to UNION ALL (OR_TO_UNION)
Verified speedup: 3.17x

### Input:
[main_query]:
SELECT ca_zip, sum(cs_sales_price)
FROM catalog_sales, customer, customer_address, date_dim
WHERE cs_bill_customer_sk = c_customer_sk
  AND c_current_addr_sk = ca_address_sk
  AND (substr(ca_zip,1,5) IN ('85669', '86197', ...)
       OR ca_state IN ('CA','WA','GA')
       OR cs_sales_price > 500)
  AND cs_sold_date_sk = d_date_sk
  AND d_qoy = 1 AND d_year = 2001
GROUP BY ca_zip ORDER BY ca_zip LIMIT 100

### Output:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "or_to_union",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_qoy = 1 AND d_year = 2001",
        "filtered_sales": "SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE substr(ca_zip,1,5) IN ('85669', '86197', '88274', '83405', '86475', '85392', '85460', '80348', '81792') UNION ALL SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE ca_state IN ('CA','WA','GA') UNION ALL SELECT cs_sales_price, ca_zip FROM catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk JOIN customer ON cs_bill_customer_sk = c_customer_sk JOIN customer_address ON c_current_addr_sk = ca_address_sk WHERE cs_sales_price > 500",
        "main_query": "SELECT ca_zip, SUM(cs_sales_price) FROM filtered_sales GROUP BY ca_zip ORDER BY ca_zip LIMIT 100"
      },
      "invariants_kept": [
        "output columns unchanged",
        "same rows after aggregation"
      ],
      "expected_speedup": "2.98x",
      "risk": "low"
    }
  ]
}
```

**Key insight:** Each OR branch becomes a separate query with focused predicates. Date filter is extracted as CTE and joined into each branch.


---

## Example: Filter Pushdown (PUSHDOWN)
Verified speedup: 2.11x

### Input:
[main_query]:
SELECT CASE WHEN (SELECT COUNT(*) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20) > 2972190 
  THEN (SELECT AVG(ss_ext_sales_price) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20)
  ELSE (SELECT AVG(ss_net_profit) FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20) END AS bucket1,
  ...
FROM reason WHERE r_reason_sk = 1

### Output:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "pushdown",
      "nodes": {
        "quantity_1_20_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 1 AND 20",
        "quantity_21_40_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 21 AND 40",
        "quantity_41_60_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 41 AND 60",
        "quantity_61_80_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 61 AND 80",
        "quantity_81_100_stats": "SELECT COUNT(*) AS cnt, AVG(ss_ext_sales_price) AS avg_ext_price, AVG(ss_net_profit) AS avg_net_profit FROM store_sales WHERE ss_quantity BETWEEN 81 AND 100",
        "main_query": "SELECT CASE WHEN q1.cnt > 2972190 THEN q1.avg_ext_price ELSE q1.avg_net_profit END AS bucket1, CASE WHEN q2.cnt > 4505785 THEN q2.avg_ext_price ELSE q2.avg_net_profit END AS bucket2, CASE WHEN q3.cnt > 1575726 THEN q3.avg_ext_price ELSE q3.avg_net_profit END AS bucket3, CASE WHEN q4.cnt > 3188917 THEN q4.avg_ext_price ELSE q4.avg_net_profit END AS bucket4, CASE WHEN q5.cnt > 3525216 THEN q5.avg_ext_price ELSE q5.avg_net_profit END AS bucket5 FROM reason CROSS JOIN quantity_1_20_stats AS q1 CROSS JOIN quantity_21_40_stats AS q2 CROSS JOIN quantity_41_60_stats AS q3 CROSS JOIN quantity_61_80_stats AS q4 CROSS JOIN quantity_81_100_stats AS q5 WHERE r_reason_sk = 1"
      },
      "invariants_kept": [
        "same result rows",
        "same aggregation results",
        "same output columns"
      ],
      "expected_speedup": "2.11x",
      "risk": "low"
    }
  ]
}
```

**Key insight:** Extract repeated quantity-range subqueries into CTEs. Each CTE computes count, avg_ext_price, avg_net_profit in ONE pass instead of scanning store_sales 15+ times.


---

You are an autonomous Query Rewrite Engine. Your goal is to maximize execution speed while strictly preserving semantic invariants.

Output atomic rewrite sets in JSON.

RULES:
- Primary Goal: Maximize execution speed while strictly preserving semantic invariants.
- Allowed Transforms: Use the provided list. If a standard SQL optimization applies that is not listed, label it "semantic_rewrite".
- Atomic Sets: Group dependent changes (e.g., creating a CTE and joining it) into a single rewrite_set.
- Contracts: Output columns, grain, and total result rows must remain invariant.
- Naming: Use descriptive CTE names (e.g., `filtered_returns` vs `cte1`).
- Column Aliasing: Permitted only for aggregations or disambiguation.

ALLOWED TRANSFORMS: pushdown, decorrelate, or_to_union, early_filter, date_cte_isolate, materialize_cte, flatten_subquery, reorder_join, multi_push_predicate, inline_cte, remove_redundant, semantic_rewrite

OUTPUT FORMAT:
```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "transform_name",
      "nodes": {
        "node_id": "new SQL..."
      },
      "invariants_kept": ["list of preserved semantics"],
      "expected_speedup": "2x",
      "risk": "low"
    }
  ],
  "explanation": "what was changed and why"
}
```

## Target Nodes
  [cross_sales] GROUP_BY
  [cs_ui] GROUP_BY

## Subgraph Slice
[cross_sales] type=cte
```sql
SELECT i_product_name AS product_name, i_item_sk AS item_sk, s_store_name AS store_name, s_zip AS store_zip, ad1.ca_street_number AS b_street_number, ad1.ca_street_name AS b_street_name, ad1.ca_city AS b_city, ad1.ca_zip AS b_zip, ad2.ca_street_number AS c_street_number, ad2.ca_street_name AS c_street_name, ad2.ca_city AS c_city, ad2.ca_zip AS c_zip, d1.d_year AS syear, d2.d_year AS fsyear, d3.d_year AS s2year, COUNT(*) AS cnt, SUM(ss_wholesale_cost) AS s1, SUM(ss_list_price) AS s2, SUM(ss_coupon_amt) AS s3 FROM store_sales, store_returns, cs_ui, date_dim AS d1, date_dim AS d2, date_dim AS d3, store, customer, customer_demographics AS cd1, customer_demographics AS cd2, promotion, household_demographics AS hd1, household_demographics AS hd2, customer_address AS ad1, customer_address AS ad2, income_band AS ib1, income_band AS ib2, item WHERE ss_store_sk = s_store_sk AND ss_sold_date_sk = d1.d_date_sk AND ss_customer_sk = c_customer_sk AND ss_cdemo_sk = cd1.cd_demo_sk AND ss_hdemo_sk = hd1.hd_demo_sk AND ss_addr_sk = ad1.ca_address_sk AND ss_item_sk = i_item_sk AND ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number AND ss_item_sk = cs_ui.cs_item_sk AND c_current_cdemo_sk = cd2.cd_demo_sk AND c_current_hdemo_sk = hd2.hd_demo_sk AND c_current_addr_sk = ad2.ca_address_sk AND c_first_sales_date_sk = d2.d_date_sk AND c_first_shipto_date_sk = d3.d_date_sk AND ss_promo_sk = p_promo_sk AND hd1.hd_income_band_sk = ib1.ib_income_band_sk AND hd2.hd_income_band_sk = ib2.ib_income_band_sk AND cd1.cd_marital_status <> cd2.cd_marital_status AND i_color IN ('blanched', 'medium', 'brown', 'chocolate', 'burlywood', 'drab') AND i_current_price BETWEEN 23 AND 23 + 10 AND i_current_price BETWEEN 23 + 1 AND 23 + 15 GROUP BY i_product_name, i_item_sk, s_store_name, s_zip, ad1.ca_street_number, ad1.ca_street_name, ad1.ca_city, ad1.ca_zip, ad2.ca_street_number, ad2.ca_street_name, ad2.ca_city, ad2.ca_zip, d1.d_year, d2.d_year, d3.d_year
```

[cs_ui] type=cte
```sql
SELECT cs_item_sk, SUM(cs_ext_list_price) AS sale, SUM(cr_refunded_cash + cr_reversed_charge + cr_store_credit) AS refund FROM catalog_sales, catalog_returns WHERE cs_item_sk = cr_item_sk AND cs_order_number = cr_order_number GROUP BY cs_item_sk HAVING SUM(cs_ext_list_price) > 2 * SUM(cr_refunded_cash + cr_reversed_charge + cr_store_credit)
```

[main_query] type=main
```sql
SELECT cs1.product_name, cs1.store_name, cs1.store_zip, cs1.b_street_number, cs1.b_street_name, cs1.b_city, cs1.b_zip, cs1.c_street_number, cs1.c_street_name, cs1.c_city, cs1.c_zip, cs1.syear, cs1.cnt, cs1.s1 AS s11, cs1.s2 AS s21, cs1.s3 AS s31, cs2.s1 AS s12, cs2.s2 AS s22, cs2.s3 AS s32, cs2.syear, cs2.cnt FROM cross_sales AS cs1, cross_sales AS cs2 WHERE cs1.item_sk = cs2.item_sk AND cs1.syear = 2001 AND cs2.syear = 2001 + 1 AND cs2.cnt <= cs1.cnt AND cs1.store_name = cs2.store_name AND cs1.store_zip = cs2.store_zip ORDER BY cs1.product_name, cs1.store_name, cs2.cnt, cs1.s1, cs2.s1
```


## Node Contracts
[cross_sales]:
  output_columns: ['product_name', 'item_sk', 'store_name', 'store_zip', 'b_street_number', 'b_street_name', 'b_city', 'b_zip', 'c_street_number', 'c_street_name']
  grain: ['i_product_name', 'i_item_sk', 's_store_name', 's_zip', 'ca_street_number', 'ca_street_name', 'ca_city', 'ca_zip', 'ca_street_number', 'ca_street_name', 'ca_city', 'ca_zip', 'd_year', 'd_year', 'd_year']
  required_predicates: ['hd2.hd_income_band_sk = ib2.ib_income_band_sk', 'hd1.hd_income_band_sk = ib1.ib_income_band_sk', 'ss_promo_sk = p_promo_sk']
[cs_ui]:
  output_columns: ['cs_item_sk', 'sale', 'refund']
  grain: ['cs_item_sk']
  required_predicates: ['cs_item_sk = cr_item_sk', 'cs_order_number = cr_order_number']
[main_query]:
  output_columns: ['product_name', 'store_name', 'store_zip', 'b_street_number', 'b_street_name', 'b_city', 'b_zip', 'c_street_number', 'c_street_name', 'c_city']
  required_predicates: ['cs1.store_zip = cs2.store_zip', 'cs1.store_name = cs2.store_name', 'cs2.cnt <= cs1.cnt']

## Downstream Usage
[cs_ui]: downstream_refs=['cs_item_sk']

## Cost Attribution
[cross_sales]: 80.9% cost, ~38912 rows, ops=[SEQ_SCAN[household_demographics], SEQ_SCAN[income_band], SEQ_SCAN[household_demographics]]
[cs_ui]: 18.7% cost, ~1439500 rows, ops=[SEQ_SCAN[catalog_sales], SEQ_SCAN[catalog_returns], HASH_GROUP_BY]
[main_query]: 0.0% cost, ~6 rows, ops=[SEQ_SCAN[COLUMN_DATA_SCAN], SEQ_SCAN[CTE_SCAN], SEQ_SCAN[CTE_SCAN]]

## Detected Opportunities
## Knowledge Base Patterns (verified on TPC-DS)
## Detected Optimization Opportunities

1. **QT-OPT-003** - Date CTE Isolation
  Trigger: date_dim joined with d_year/d_qoy/d_month filter, fact table present
  Rewrite: Create CTE: SELECT d_date_sk FROM date_dim WHERE filter, join fact to CTE early
   Matched: date_dim filter with fact table


## Node-Specific Opportunities
PUSHDOWN: [main_query] filters on [cross_sales] after GROUP BY
  Fix: Push filter into CTE before aggregation
  Expected: 2x speedup (verified Q93: 2.71x)

PUSHDOWN: [main_query] filters on [cross_sales] after GROUP BY
  Fix: Push filter into CTE before aggregation
  Expected: 2x speedup (verified Q93: 2.71x)

Now output your rewrite_sets:

## Execution Plan
```
Operators by cost:
- SEQ_SCAN(store_sales): 41.5% cost, 24,575 rows
- SEQ_SCAN(store_sales): 21.8% cost, 24,576 rows
- SEQ_SCAN(store_sales): 16.7% cost, 1,439,500 rows
- SEQ_SCAN(store_sales): 7.7% cost, 18,432 rows
- SEQ_SCAN(store_sales): 3.9% cost, 24,576 rows

Scans:
- store_sales x1: 34,537,284 → 24,575 rows (filtered)
- customer x1: 24,000,000 → 24,576 rows (filtered)
- customer_demographics x2: 23,049,600 → 24,576 rows (filtered)
- catalog_sales x1: 17,274,156 → 1,439,500 rows (filtered)
- customer_address x2: 9,000,000 rows (no filter)
- store_returns x1: 865,743 → 6,144 rows (filtered)
- item x1: 408,000 → 2,112 rows (filtered)
- catalog_returns x1: 288,002 → 143,999 rows (filtered)

Misestimates:
- SEQ_SCAN: est 1,000,000 vs actual 18,432 (54.3x)
- SEQ_SCAN: est 1,920,800 vs actual 24,576 (78.2x)
- SEQ_SCAN: est 1,920,800 vs actual 24,576 (78.2x)
- SEQ_SCAN: est 73,049 vs actual 810 (90.2x)
- SEQ_SCAN: est 73,049 vs actual 840 (87.0x)
- SEQ_SCAN: est 1,000,000 vs actual 18,432 (54.3x)
- SEQ_SCAN: est 2,000,000 vs actual 24,576 (81.4x)
- FILTER: est 73,049 vs actual 730 (100.1x)
- HASH_JOIN: est 2,258 vs actual 0 (2258.0x)
- FILTER: est 2,878,107 vs actual 24,552 (117.2x)
- SEQ_SCAN: est 2,878,107 vs actual 24,575 (117.1x)
- HASH_JOIN: est 1,892 vs actual 0 (1892.0x)
- SEQ_SCAN: est 288,581 vs actual 6,144 (47.0x)
- HASH_JOIN: est 2,536 vs actual 0 (2536.0x)
- PROJECTION: est 60,116 vs actual 1,132 (53.1x)
- FILTER: est 60,116 vs actual 1,132 (53.1x)
- PROJECTION: est 60,116 vs actual 1,430 (42.0x)
- HASH_GROUP_BY: est 60,116 vs actual 1,430 (42.0x)
- PROJECTION: est 72,000 vs actual 1,433 (50.2x)
- PROJECTION: est 72,000 vs actual 1,433 (50.2x)
- HASH_JOIN: est 72,000 vs actual 1,433 (50.2x)
- FILTER: est 8,160 vs actual 39 (209.2x)
- PROJECTION: est 8,160 vs actual 39 (209.2x)
- FILTER: est 8,160 vs actual 39 (209.2x)
- HASH_JOIN: est 40,800 vs actual 2,112 (19.3x)
- SEQ_SCAN: est 40,800 vs actual 2,112 (19.3x)

Joins:
- HASH_JOIN: ? x ? -> 0 rows
- HASH_JOIN: household_demographics x income_band -> 2,048 rows
- HASH_JOIN: ? x ? -> 0 rows
- HASH_JOIN: household_demographics x income_band -> 2,048 rows
- HASH_JOIN: customer_address x ? -> 0 rows
```
