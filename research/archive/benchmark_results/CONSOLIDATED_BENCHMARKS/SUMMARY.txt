================================================================================
DuckDB TPC-DS CONSOLIDATED BENCHMARK KNOWLEDGE BASE - SUMMARY
================================================================================

BUILD DATE: 2026-02-05
VERSION: v1
STATUS: COMPLETE

================================================================================
WHAT WAS BUILT
================================================================================

A comprehensive consolidated knowledge base integrating:
  ✓ Kimi K2.5 (99 queries, Feb 2, 2026)
  ✓ V2 Standard Mode (88 queries, Feb 5, 2026)  
  ✓ V2 Evolutionary Mode (15 queries, Feb 5, 2026)
  ✓ ML Pattern Classifier (6 gold patterns)
  ✓ Full SQL Source Code (88 queries)

================================================================================
FILES CREATED
================================================================================

DATA FILES (336 KB total):
  1. DuckDB_TPC-DS_Master_v1_20260205.csv (11 KB)
     - 99 rows (all TPC-DS queries)
     - 21 columns (metrics + classifications)
     - Ready for pandas analysis
     
  2. DuckDB_TPC-DS_SQL_v1_20260205.csv (286 KB)
     - 99 rows with full SQL
     - Original + Optimized SQL side-by-side
     - Complete source artifacts for study
     
  3. DuckDB_TPC-DS_Master_v1_METADATA.json (1.8 KB)
     - Data lineage and versioning
     - Source attribution
     - Gold example mappings

ANALYSIS DOCUMENTS:
  4. README.md (8.8 KB)
     - Quick start guide
     - Usage examples
     - Pattern mining guide
     
  5. SCHEMA.md (5.5 KB)
     - Column definitions
     - Data quality notes
     - Coverage statistics
     
  6. PATTERNS.md (1.5 KB)
     - Transform effectiveness
     - Risk distribution
     - Speedup ranges
     
  7. GOLD_EXAMPLES.md (1.8 KB)
     - 6 verified high-value optimizations
     - Usage in few-shot prompts
     - Pattern combination analysis
     
  8. FAILURES.md (1.6 KB)
     - Failure distribution
     - Regression analysis
     - Validation failure details

================================================================================
KEY FINDINGS
================================================================================

OVERALL PERFORMANCE:
  ✓ 13 queries improved (13.1% success rate)
  ✓ 39 queries neutral (39.4% - no regression, no improvement)
  ✗ 35 queries regressed (35.4% - made slower)
  ✗ 9 queries failed validation (9.1% - wrong results)
  ✗ 3 queries had errors (3.0% - generation failed)

GOLD EXAMPLES (6 verified):
  • Q1: decorrelate → 2.92x speedup
  • Q93: early_filter → 2.73x speedup
  • Q15: or_to_union → 2.78x speedup
  • Q39: pushdown → 2.44x speedup
  • Q90: early_filter → 1.84x speedup
  • Q74: pushdown → 1.42x speedup

TOP INSIGHTS:
  1. Decorrelation works best on correlated subqueries
  2. OR-to-UNION dangerous if >3 branches (causes 9x scans)
  3. Early filtering consistently useful
  4. ~47% of optimizations either fail or regress
  5. Only 6 patterns reliably improve performance

================================================================================
HOW TO USE THIS
================================================================================

1. QUICK ANALYSIS (Python):
   import pandas as pd
   df = pd.read_csv('DuckDB_TPC-DS_Master_v1_20260205.csv')
   gold = df[df['Classification'] == 'GOLD_EXAMPLE']
   print(gold)

2. GET FULL SQL:
   sql_df = pd.read_csv('DuckDB_TPC-DS_SQL_v1_20260205.csv')
   q1 = sql_df[sql_df['Query_Num'] == 1]
   print(q1['SQL_Original'].values[0])
   print(q1['SQL_Optimized'].values[0])

3. ANALYZE PATTERNS:
   See PATTERNS.md for transform effectiveness
   See GOLD_EXAMPLES.md for few-shot examples
   See FAILURES.md for what doesn't work

4. FIND SPECIFIC QUERY:
   # Get all data for Q1
   q1_data = df[df['Query_Num'] == 1]
   
   # See Kimi validation
   print(q1_data['Kimi_Status'], q1_data['Kimi_Speedup'])
   
   # See V2 optimization
   print(q1_data['V2_Status'], q1_data['Transform_Recommended'])

5. COMPARE MODES:
   # Queries with both standard and evolutionary
   overlap = df[(df['V2_Status'].notna()) & (df['Evo_Status'].notna())]
   print(f"Overlap queries: Q{overlap['Query_Num'].tolist()}")

================================================================================
DATA SOURCES & LINEAGE
================================================================================

KIMI K2.5 (Feb 2, 2026):
  Source: /research/experiments/benchmarks/kimi_benchmark_20260202_221828/
  Queries: 99 (Q1-Q99, complete)
  Validation: Full SF100 dataset
  Coverage: 100%

V2 STANDARD (Feb 5, 2026):
  Source: /research/benchmarks/qt-sql/runs/benchmark_output_v2/
  Queries: 88 (missing Q3,4,5,6,8,9,11,12,14,15,17)
  Time: 12:24-12:52 UTC
  Coverage: 89% (SQL artifacts present)

V2 EVOLUTIONARY (Feb 5, 2026):
  Source: /research/benchmarks/qt-sql/results/benchmark_99_evo_20260205_030536.csv
  Queries: 15 (Q2-Q16, MCTS search)
  Time: 03:05-05:57 UTC
  Coverage: 5 overlaps with standard (Q2,Q7,Q10,Q13,Q16)

ML PATTERNS:
  Source: /research/ml_pipeline/models/pattern_weights.json
  Patterns: 6 gold patterns (GLD-001 through GLD-006)
  Confidence: Single patterns up to 1.0, combinations averaged

================================================================================
NEXT STEPS
================================================================================

FOR RESEARCHERS:
  1. Mine patterns to identify what predicts success
  2. Study the 6 gold examples for prompt injection
  3. Analyze the 47 failures to find constraints
  4. Compare V2 Standard vs Evolutionary for Q2-Q16

FOR PRACTITIONERS:
  1. Use GOLD_EXAMPLES for few-shot prompt templates
  2. Avoid patterns in FAILURES.md
  3. Check similar queries for patterns
  4. Update master CSV when new benchmarks run

FOR FUTURE VERSIONS:
  1. Add PostgreSQL TPC-DS benchmark
  2. Add alternative LLM models (Deepseek, etc.)
  3. Add different scale factors (SF1, SF10, SF100)
  4. Add execution plan analysis
  5. Add cost model predictions

================================================================================
VERSION TRACKING
================================================================================

This is VERSION 1 (v1):
  • 99 queries consolidated
  • 88 with SQL artifacts  
  • 3 data sources merged
  • 4 analysis documents
  • Full data lineage

Future versions should:
  • Update METADATA.json
  • Create new v2/v3 files with YYYYMMDD
  • Document what changed
  • Compare against v1 baseline
  • Maintain this versioning scheme

Example: DuckDB_TPC-DS_Master_v2_20260210.csv

================================================================================
FILES ORGANIZATION
================================================================================

/CONSOLIDATED_BENCHMARKS/
  ├── README.md                          # START HERE
  ├── SCHEMA.md                          # Column definitions
  ├── PATTERNS.md                        # Pattern analysis
  ├── GOLD_EXAMPLES.md                   # High-value examples
  ├── FAILURES.md                        # Failure analysis
  ├── SUMMARY.txt                        # This file
  │
  ├── DuckDB_TPC-DS_Master_v1_20260205.csv        # Core metrics
  ├── DuckDB_TPC-DS_SQL_v1_20260205.csv           # Full SQL
  └── DuckDB_TPC-DS_Master_v1_METADATA.json       # Version info

================================================================================
CONTACT & DOCUMENTATION
================================================================================

For questions about:
  - Columns: See SCHEMA.md
  - Gold examples: See GOLD_EXAMPLES.md
  - Patterns: See PATTERNS.md
  - Failures: See FAILURES.md
  - Usage: See README.md

For reproducibility:
  - See METADATA.json for data lineage
  - All source paths documented
  - Date/time stamps on all data

================================================================================
END OF SUMMARY
================================================================================

Status: READY FOR USE
Created: 2026-02-05
Size: 336 KB
Format: CSV + Markdown (portable, no dependencies)

This knowledge base is complete and ready for pattern mining and analysis.
