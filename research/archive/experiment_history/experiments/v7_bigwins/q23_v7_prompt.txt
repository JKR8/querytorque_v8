Optimize this SQL query for performance.

## Algorithm

1. **FIND BOTTLENECK**: Look at the largest row sources below
2. **REDUCE EARLY**: For each bottleneck, ask "can we filter this earlier?"
   - Push dimension filters INTO CTEs/subqueries before GROUP BY
   - Convert correlated subqueries to window functions or CTEs
   - Join small filtered tables early to reduce rows before aggregation
3. **VERIFY**: Result must return identical data

Principle: The earlier you reduce rows, the faster everything downstream runs.

## Example

WRONG - filters 1M rows AFTER aggregating all 100M:
```sql
WITH sales_agg AS (
    SELECT store_id, SUM(amount) as total
    FROM sales
    GROUP BY store_id  -- aggregates ALL 100M rows
)
SELECT * FROM sales_agg
WHERE store_id IN (SELECT store_id FROM stores WHERE region = 'West')  -- filters AFTER
```

RIGHT - filters to 1M rows BEFORE aggregating:
```sql
WITH sales_agg AS (
    SELECT s.store_id, SUM(amount) as total
    FROM sales
    JOIN stores s ON sales.store_id = s.store_id
    WHERE s.region = 'West'  -- filter BEFORE GROUP BY
    GROUP BY s.store_id  -- aggregates only 1M West rows
)
SELECT * FROM sales_agg
```

The RIGHT version is 100x faster because it aggregates 100x fewer rows.

## Bottlenecks

- HASH_GROUP_BY: 22.9% cost, 1,638,079 rows <-- BOTTLENECK
- HASH_GROUP_BY: 13.9% cost, 1,456,609 rows
- SEQ_SCAN (store_sales): 1,653,986 rows (3 scans!) <-- REPEATED SCANS
- SEQ_SCAN (customer): 1,999,997 rows (3 scans!)

## Table Scans (with selectivity)

- store_sales: scanned 3x (NO FILTER in best_ss_customer) <-- SCAN CONSOLIDATION OPPORTUNITY
- customer: scanned 3x (NO FILTER in best_ss_customer)
- date_dim: 73K -> 1,461 rows (FILTERED by d_year 2000-2003) <-- HIGH SELECTIVITY
- date_dim: 73K -> 31 rows (FILTERED by d_year=2000, d_moy=5) <-- VERY HIGH SELECTIVITY

Filter Gap: best_ss_customer scans ALL store_sales without year filter, but max_store_sales has year filter

## SQL

```sql
with frequent_ss_items as
 (select substr(i_item_desc,1,30) itemdesc,i_item_sk item_sk,d_date solddate,count(*) cnt
  from store_sales
      ,date_dim
      ,item
  where ss_sold_date_sk = d_date_sk
    and ss_item_sk = i_item_sk
    and d_year in (2000,2000+1,2000+2,2000+3)
  group by substr(i_item_desc,1,30),i_item_sk,d_date
  having count(*) >4),
 max_store_sales as
 (select max(csales) tpcds_cmax
  from (select c_customer_sk,sum(ss_quantity*ss_sales_price) csales
        from store_sales
            ,customer
            ,date_dim
        where ss_customer_sk = c_customer_sk
         and ss_sold_date_sk = d_date_sk
         and d_year in (2000,2000+1,2000+2,2000+3)
        group by c_customer_sk)),
 best_ss_customer as
 (select c_customer_sk,sum(ss_quantity*ss_sales_price) ssales
  from store_sales
      ,customer
  where ss_customer_sk = c_customer_sk
  group by c_customer_sk
  having sum(ss_quantity*ss_sales_price) > (95/100.0) * (select * from max_store_sales))
  select sum(sales)
 from (select cs_quantity*cs_list_price sales
       from catalog_sales
           ,date_dim
       where d_year = 2000
         and d_moy = 5
         and cs_sold_date_sk = d_date_sk
         and cs_item_sk in (select item_sk from frequent_ss_items)
         and cs_bill_customer_sk in (select c_customer_sk from best_ss_customer)
      union all
      select ws_quantity*ws_list_price sales
       from web_sales
           ,date_dim
       where d_year = 2000
         and d_moy = 5
         and ws_sold_date_sk = d_date_sk
         and ws_item_sk in (select item_sk from frequent_ss_items)
         and ws_bill_customer_sk in (select c_customer_sk from best_ss_customer))
 LIMIT 100;
```

## Output

Return:
1. The optimized SQL query
2. One sentence explaining what you changed and why
