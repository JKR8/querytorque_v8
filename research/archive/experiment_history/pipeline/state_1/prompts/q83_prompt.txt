You are an autonomous Query Rewrite Engine. Your goal is to maximize execution speed while strictly preserving semantic invariants.

RULES:
- Maximize execution speed while preserving semantic invariants (output columns, grain, total result rows).
- Group dependent changes into a single rewrite_set.
- Use descriptive CTE names (e.g., `filtered_returns` not `cte1`).
- If a standard SQL optimization applies that is not in the allowed list, label it "semantic_rewrite".

ALLOWED TRANSFORMS: pushdown, decorrelate, or_to_union, early_filter, date_cte_isolate, materialize_cte, flatten_subquery, reorder_join, multi_push_predicate, inline_cte, remove_redundant, semantic_rewrite

---
## Query Structure

### DAG Topology
```
  [sr_items] type=cte tables=[store_returns, item, date_dim, date_dim, date_dim] GROUP_BY
  [cr_items] type=cte tables=[catalog_returns, item, date_dim, date_dim, date_dim] GROUP_BY
  [wr_items] type=cte tables=[web_returns, item, date_dim, date_dim, date_dim] GROUP_BY
  [main_query] type=main tables=[sr_items, cr_items, wr_items] GROUP_BY

  Edges:
    sr_items -> main_query
    cr_items -> main_query
    wr_items -> main_query
```

### Target Nodes
[sr_items] GROUP_BY
  [wr_items] GROUP_BY

### SQL
[sr_items] type=cte
```sql
SELECT
  i_item_id AS item_id,
  SUM(sr_return_quantity) AS sr_item_qty
FROM store_returns, item, date_dim
WHERE
  sr_item_sk = i_item_sk
  AND d_date IN (
    SELECT
      d_date
    FROM date_dim
    WHERE
      d_week_seq IN (
        SELECT
          d_week_seq
        FROM date_dim
        WHERE
          d_date IN ('2001-06-06', '2001-09-02', '2001-11-11')
      )
  )
  AND sr_returned_date_sk = d_date_sk
GROUP BY
  i_item_id
```

[cr_items] type=cte
```sql
SELECT
  i_item_id AS item_id,
  SUM(cr_return_quantity) AS cr_item_qty
FROM catalog_returns, item, date_dim
WHERE
  cr_item_sk = i_item_sk
  AND d_date IN (
    SELECT
      d_date
    FROM date_dim
    WHERE
      d_week_seq IN (
        SELECT
          d_week_seq
        FROM date_dim
        WHERE
          d_date IN ('2001-06-06', '2001-09-02', '2001-11-11')
      )
  )
  AND cr_returned_date_sk = d_date_sk
GROUP BY
  i_item_id
```

[wr_items] type=cte
```sql
SELECT
  i_item_id AS item_id,
  SUM(wr_return_quantity) AS wr_item_qty
FROM web_returns, item, date_dim
WHERE
  wr_item_sk = i_item_sk
  AND d_date IN (
    SELECT
      d_date
    FROM date_dim
    WHERE
      d_week_seq IN (
        SELECT
          d_week_seq
        FROM date_dim
        WHERE
          d_date IN ('2001-06-06', '2001-09-02', '2001-11-11')
      )
  )
  AND wr_returned_date_sk = d_date_sk
GROUP BY
  i_item_id
```

[main_query] type=main
```sql
SELECT
  sr_items.item_id,
  sr_item_qty,
  sr_item_qty / (
    sr_item_qty + cr_item_qty + wr_item_qty
  ) / 3.0 * 100 AS sr_dev,
  cr_item_qty,
  cr_item_qty / (
    sr_item_qty + cr_item_qty + wr_item_qty
  ) / 3.0 * 100 AS cr_dev,
  wr_item_qty,
  wr_item_qty / (
    sr_item_qty + cr_item_qty + wr_item_qty
  ) / 3.0 * 100 AS wr_dev,
  (
    sr_item_qty + cr_item_qty + wr_item_qty
  ) / 3.0 AS average
FROM sr_items, cr_items, wr_items
WHERE
  sr_items.item_id = cr_items.item_id AND sr_items.item_id = wr_items.item_id
ORDER BY
  sr_items.item_id,
  sr_item_qty
LIMIT 100
```

### Contracts
[sr_items]:
  output_columns: ['item_id', 'sr_item_qty']
  grain: ['i_item_id']
  required_predicates: ['sr_returned_date_sk = d_date_sk', 'sr_item_sk = i_item_sk']
[main_query]:
  output_columns: ['item_id', 'sr_item_qty', 'sr_dev', 'cr_item_qty', 'cr_dev', 'wr_item_qty', 'wr_dev', 'average']
  required_predicates: ['sr_items.item_id = cr_items.item_id', 'sr_items.item_id = wr_items.item_id']
[wr_items]:
  output_columns: ['item_id', 'wr_item_qty']
  grain: ['i_item_id']
  required_predicates: ['wr_returned_date_sk = d_date_sk', 'wr_item_sk = i_item_sk']

### Downstream Usage
[sr_items]: downstream_refs=['item_id', 'sr_item_qty']
[wr_items]: downstream_refs=['item_id', 'wr_item_qty']

---
## Performance Profile

### Cost Attribution
[sr_items]: 76.1% cost, ~176390 rows, ops=[SEQ_SCAN[store_returns], HASH_GROUP_BY]
[main_query]: 2.1% cost, ~1000 rows, ops=[HASH_JOIN]
[wr_items]: 13.7% cost, ~102000 rows, ops=[SEQ_SCAN[item], SEQ_SCAN[web_returns], SEQ_SCAN[date_dim]]

### Execution Plan
```
Operators by cost:
- SEQ_SCAN(store_returns): 72.8% cost, 176,390 rows
- SEQ_SCAN(store_returns): 10.3% cost, 56,840 rows
- SEQ_SCAN(store_returns): 5.2% cost, 96,661 rows
- HASH_GROUP_BY: 2.2% cost, 20,047 rows
- SEQ_SCAN(store_returns): 1.2% cost, 102,000 rows

Scans:
- store_returns x1: 34,530,384 rows (no filter)
- catalog_returns x1: 17,294,688 rows (no filter)
- web_returns x1: 4,315,332 rows (no filter)
- item x3: 102,000 rows (no filter)
- date_dim x9: 73,049 → 73,049 rows (filtered)

Misestimates:
- PROJECTION: est 131,087 vs actual 7,319 (17.9x)
- HASH_JOIN: est 131,087 vs actual 7,319 (17.9x)
- HASH_JOIN: est 143,844 vs actual 7,319 (19.7x)
- SEQ_SCAN: est 719,222 vs actual 56,840 (12.7x)
- HASH_JOIN: est 14,609 vs actual 21 (695.7x)
- SEQ_SCAN: est 73,049 vs actual 161 (453.7x)
- HASH_JOIN: est 14,609 vs actual 21 (695.7x)
- SEQ_SCAN: est 73,049 vs actual 161 (453.7x)
- PROJECTION: est 14,609 vs actual 3 (4869.7x)
- FILTER: est 14,609 vs actual 3 (4869.7x)
- HASH_JOIN: est 43 vs actual 4,679 (108.8x)
- HASH_GROUP_BY: est 2,221 vs actual 12,023 (5.4x)
- PROJECTION: est 286,360 vs actual 13,736 (20.8x)
- HASH_JOIN: est 286,360 vs actual 13,736 (20.8x)
- HASH_JOIN: est 288,244 vs actual 13,736 (21.0x)
- SEQ_SCAN: est 1,441,224 vs actual 96,661 (14.9x)
- HASH_JOIN: est 14,609 vs actual 21 (695.7x)
- SEQ_SCAN: est 73,049 vs actual 161 (453.7x)
- HASH_JOIN: est 14,609 vs actual 21 (695.7x)
- SEQ_SCAN: est 73,049 vs actual 161 (453.7x)
- PROJECTION: est 14,609 vs actual 3 (4869.7x)
- FILTER: est 14,609 vs actual 3 (4869.7x)
- HASH_GROUP_BY: est 2,202 vs actual 20,047 (9.1x)
- PROJECTION: est 594,134 vs actual 25,492 (23.3x)
- HASH_JOIN: est 594,134 vs actual 25,492 (23.3x)
- HASH_JOIN: est 575,506 vs actual 25,492 (22.6x)
- SEQ_SCAN: est 2,877,532 vs actual 176,390 (16.3x)
- HASH_JOIN: est 14,609 vs actual 21 (695.7x)
- SEQ_SCAN: est 73,049 vs actual 161 (453.7x)
- HASH_JOIN: est 14,609 vs actual 21 (695.7x)
- SEQ_SCAN: est 73,049 vs actual 161 (453.7x)
- PROJECTION: est 14,609 vs actual 3 (4869.7x)
- FILTER: est 14,609 vs actual 3 (4869.7x)

Joins:
- HASH_JOIN: ? x ? -> 633 rows
- HASH_JOIN: item x ? -> 7,319 rows
- HASH_JOIN: web_returns x ? -> 7,319 rows
- HASH_JOIN: date_dim x ? -> 21 rows
- HASH_JOIN: date_dim x ? -> 21 rows
```

### Optimization Opportunities
1. **QT-OPT-007** - Materialize Repeated Subquery
  Trigger: Same subquery pattern appears multiple times in query
  Rewrite: Extract to CTE with MATERIALIZED hint, reference by name
   Matched: Repeated subquery pattern

PUSHDOWN: [main_query] filters on [sr_items] after GROUP BY
  Fix: Push filter into CTE before aggregation
  Expected: 2x speedup (verified Q93: 2.71x)

PUSHDOWN: [main_query] filters on [cr_items] after GROUP BY
  Fix: Push filter into CTE before aggregation
  Expected: 2x speedup (verified Q93: 2.71x)

PUSHDOWN: [main_query] filters on [wr_items] after GROUP BY
  Fix: Push filter into CTE before aggregation
  Expected: 2x speedup (verified Q93: 2.71x)

---
## Previous Attempts

- baseline: 1.00x [none] NEUTRAL
- kimi: 1.24x [none] WIN
- v2_standard: 1.00x [materialize_cte] NEUTRAL
- dsr1: 1.16x [semantic_rewrite] WIN

**Worked**: semantic_rewrite
**No effect**: materialize_cte

**Recommended patterns** (details in Examples section below):
- **dimension_cte_isolate** (1.93x) — Pre-filter ALL dimension tables into CTEs before joining with fact table, not just date_dim.
- **multi_dimension_prefetch** (2.71x) — Pre-filter multiple dimension tables (date + store) into separate CTEs before joining with fact table.
- **early_filter** (4.00x) — Filter dimension tables FIRST, then join to fact tables to reduce expensive joins.

---
## Examples (Verified Patterns)

## Example: Dimension CTE Isolation (DIMENSION_CTE_ISOLATE)
Verified speedup: 1.93x
Benchmark: Q26

### Original SQL:
```sql
select i_item_id, 
        avg(cs_quantity) agg1,
        avg(cs_list_price) agg2,
        avg(cs_coupon_amt) agg3,
        avg(cs_sales_price) agg4 
 from catalog_sales, customer_demographics, date_dim, item, promotion
 where cs_sold_date_sk = d_date_sk and
       cs_item_sk = i_item_sk and
       cs_bill_cdemo_sk = cd_demo_sk and
       cs_promo_sk = p_promo_sk and
       cd_gender = 'M' and 
       cd_marital_status = 'S' and
       cd_education_status = 'Unknown' and
       (p_channel_email = 'N' or p_channel_event = 'N') and
       d_year = 2001 
 group by i_item_id
 order by i_item_id
 LIMIT 100;
```

### Optimized SQL:
```sql
WITH filtered_dates AS (SELECT d_date_sk FROM date_dim WHERE d_year = 2000), filtered_customer_demographics AS (SELECT cd_demo_sk FROM customer_demographics WHERE cd_gender = 'M' AND cd_marital_status = 'S' AND cd_education_status = 'College'), prejoined_sales AS (SELECT cs.cs_quantity, cs.cs_list_price, cs.cs_coupon_amt, cs.cs_sales_price, i.i_item_id, p.p_channel_email, p.p_channel_event FROM catalog_sales AS cs JOIN filtered_dates AS fd ON cs.cs_sold_date_sk = fd.d_date_sk JOIN filtered_customer_demographics AS fcd ON cs.cs_bill_cdemo_sk = fcd.cd_demo_sk JOIN item AS i ON cs.cs_item_sk = i.i_item_sk JOIN promotion AS p ON cs.cs_promo_sk = p.p_promo_sk), branch_both AS (SELECT cs_quantity, cs_list_price, cs_coupon_amt, cs_sales_price, i_item_id FROM prejoined_sales WHERE p_channel_email = 'N' AND p_channel_event = 'N'), branch_email AS (SELECT cs_quantity, cs_list_price, cs_coupon_amt, cs_sales_price, i_item_id FROM prejoined_sales WHERE p_channel_email = 'N' AND p_channel_event <> 'N'), branch_event AS (SELECT cs_quantity, cs_list_price, cs_coupon_amt, cs_sales_price, i_item_id FROM prejoined_sales WHERE p_channel_email <> 'N' AND p_channel_event = 'N'), combined_sales AS (SELECT * FROM branch_email UNION ALL SELECT * FROM branch_event UNION ALL SELECT * FROM branch_both)
SELECT i_item_id, AVG(cs_quantity) AS agg1, AVG(cs_list_price) AS agg2, AVG(cs_coupon_amt) AS agg3, AVG(cs_sales_price) AS agg4 FROM combined_sales GROUP BY i_item_id ORDER BY i_item_id LIMIT 100;
```

**Key insight:** Pre-filter EACH dimension table into its own CTE returning only the surrogate key. This reduces the cardinality of subsequent joins. Works best when dimension filters are highly selective.


## Example: Multi Dimension Prefetch (MULTI_DIMENSION_PREFETCH)
Verified speedup: 2.71x
Benchmark: Q43

### Original SQL:
```sql
select s_store_name, s_store_id,
        sum(case when (d_day_name='Sunday') then ss_sales_price else null end) sun_sales,
        sum(case when (d_day_name='Monday') then ss_sales_price else null end) mon_sales,
        sum(case when (d_day_name='Tuesday') then ss_sales_price else  null end) tue_sales,
        sum(case when (d_day_name='Wednesday') then ss_sales_price else null end) wed_sales,
        sum(case when (d_day_name='Thursday') then ss_sales_price else null end) thu_sales,
        sum(case when (d_day_name='Friday') then ss_sales_price else null end) fri_sales,
        sum(case when (d_day_name='Saturday') then ss_sales_price else null end) sat_sales
 from date_dim, store_sales, store
 where d_date_sk = ss_sold_date_sk and
       s_store_sk = ss_store_sk and
       s_gmt_offset = -5 and
       d_year = 2000 
 group by s_store_name, s_store_id
 order by s_store_name, s_store_id,sun_sales,mon_sales,tue_sales,wed_sales,thu_sales,fri_sales,sat_sales
 LIMIT 100;
```

### Optimized SQL:
```sql
WITH filtered_dates AS (SELECT d_date_sk, d_day_name FROM date_dim WHERE d_year = 2000), filtered_stores AS (SELECT s_store_sk, s_store_id, s_store_name FROM store WHERE s_gmt_offset = -5), filtered_sales AS (SELECT ss_sales_price, d_day_name, s_store_id, s_store_name FROM store_sales JOIN filtered_dates ON d_date_sk = ss_sold_date_sk JOIN filtered_stores ON s_store_sk = ss_store_sk)
SELECT s_store_name, s_store_id, SUM(CASE WHEN (d_day_name = 'Sunday') THEN ss_sales_price ELSE NULL END) AS sun_sales, SUM(CASE WHEN (d_day_name = 'Monday') THEN ss_sales_price ELSE NULL END) AS mon_sales, SUM(CASE WHEN (d_day_name = 'Tuesday') THEN ss_sales_price ELSE NULL END) AS tue_sales, SUM(CASE WHEN (d_day_name = 'Wednesday') THEN ss_sales_price ELSE NULL END) AS wed_sales, SUM(CASE WHEN (d_day_name = 'Thursday') THEN ss_sales_price ELSE NULL END) AS thu_sales, SUM(CASE WHEN (d_day_name = 'Friday') THEN ss_sales_price ELSE NULL END) AS fri_sales, SUM(CASE WHEN (d_day_name = 'Saturday') THEN ss_sales_price ELSE NULL END) AS sat_sales FROM filtered_sales GROUP BY s_store_name, s_store_id ORDER BY s_store_name, s_store_id, sun_sales, mon_sales, tue_sales, wed_sales, thu_sales, fri_sales, sat_sales LIMIT 100;
```

**Key insight:** Pre-filter BOTH date_dim AND store into separate CTEs. Include only the columns needed for the join and grouping. The optimizer can then use these smaller CTEs efficiently when joining with the fact table.

**When NOT to use:** Do not create dimension CTEs without a WHERE clause that actually reduces rows — an unfiltered dimension CTE is pure overhead (full scan + materialization for zero selectivity benefit). Avoid on queries with 5+ tables and complex inter-table predicates where forcing join order via CTEs prevents the optimizer from choosing a better plan. Caused 0.85x on Q67 (unfiltered dimension CTEs added overhead) and 0.77x on Q72 (forced suboptimal join ordering on complex multi-table query).


## Example: Early Dimension Filter (EARLY_FILTER)
Verified speedup: 4.00x
Benchmark: Q93, Q11

### Original SQL:
```sql
select ss_customer_sk
            ,sum(act_sales) sumsales
      from (select ss_item_sk
                  ,ss_ticket_number
                  ,ss_customer_sk
                  ,case when sr_return_quantity is not null then (ss_quantity-sr_return_quantity)*ss_sales_price
                                                            else (ss_quantity*ss_sales_price) end act_sales
            from store_sales left outer join store_returns on (sr_item_sk = ss_item_sk
                                                               and sr_ticket_number = ss_ticket_number)
                ,reason
            where sr_reason_sk = r_reason_sk
              and r_reason_desc = 'duplicate purchase') t
      group by ss_customer_sk
      order by sumsales, ss_customer_sk
 LIMIT 100;
```

### Optimized SQL:
```sql
WITH filtered_reason AS (SELECT r_reason_sk FROM reason WHERE r_reason_desc = 'duplicate purchase'), filtered_returns AS (SELECT sr_item_sk, sr_ticket_number, sr_return_quantity FROM store_returns JOIN filtered_reason ON sr_reason_sk = r_reason_sk)
SELECT ss_customer_sk, SUM(act_sales) AS sumsales FROM (SELECT ss.ss_customer_sk, CASE WHEN NOT fr.sr_return_quantity IS NULL THEN (ss.ss_quantity - fr.sr_return_quantity) * ss.ss_sales_price ELSE (ss.ss_quantity * ss.ss_sales_price) END AS act_sales FROM store_sales AS ss JOIN filtered_returns AS fr ON (fr.sr_item_sk = ss.ss_item_sk AND fr.sr_ticket_number = ss.ss_ticket_number)) AS t GROUP BY ss_customer_sk ORDER BY sumsales, ss_customer_sk LIMIT 100;
```

**Key insight:** Filter dimension table (reason) FIRST, then join to fact. Reduces returns to only 'duplicate purchase' before expensive store_sales join.


---
## Constraints

**CTE_COLUMN_COMPLETENESS** [CRITICAL]: CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.

**LITERAL_PRESERVATION** [CRITICAL]: CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

**MIN_BASELINE_THRESHOLD** [HIGH]: If the query execution plan shows very fast runtime (under 100ms), be conservative with CTE-based transforms. Each CTE adds materialization overhead (hash table creation, intermediate result storage). On fast queries, this overhead can exceed the filtering benefit. Prefer minimal changes or no change over adding multiple CTEs to an already-fast query.

**NO_UNFILTERED_DIMENSION_CTE** [HIGH]: Every CTE you create must include a WHERE clause that actually reduces row count. Selecting fewer columns is not filtering — the CTE still materializes every row. If a dimension table has no predicate to push down, leave it as a direct join in the main query instead of wrapping it in a CTE.

**OR_TO_UNION_GUARD** [HIGH]: Only apply or_to_union when (a) the OR branches involve different tables or fundamentally different access paths — never when all branches filter the same column (e.g., t_hour ranges), since the optimizer already handles same-column ORs efficiently in a single scan — and (b) the result is 3 or fewer UNION ALL branches. Nested ORs that would expand into 4+ branches (e.g., 3 conditions x 3 values = 9 combinations) must be left as-is. Violating these rules causes 0.23x–0.59x regressions from multiplied fact table scans.

**REMOVE_REPLACED_CTES** [HIGH]: When creating replacement CTEs, overwrite the original by using the same node_id in your rewrite_sets, or ensure the original is removed from the WITH clause. Every CTE in the final query should be actively used — dead CTEs still get materialized and waste resources (caused 0.49x on Q31, 0.68x on Q74).

**NO_MATERIALIZE_EXISTS** [CRITICAL]: Keep EXISTS and NOT EXISTS as-is — they use semi-join short-circuiting that stops scanning after the first match. Converting them to materialized CTEs (e.g., WITH cte AS (SELECT DISTINCT ... FROM large_table)) forces a full table scan, which is catastrophically slower (0.14x observed on Q16). When you see EXISTS, preserve it.


---
## Output Format

Respond with a JSON object containing your rewrite_sets:

```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "transform_name",
      "nodes": {
        "node_id": "new SQL..."
      },
      "invariants_kept": ["same result rows", "same ordering"],
      "expected_speedup": "2x",
      "risk": "low"
    }
  ],
  "explanation": "what was changed and why"
}
```

Now output your rewrite_sets: