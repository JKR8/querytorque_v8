You are an autonomous Query Rewrite Engine. Your goal is to maximize execution speed while strictly preserving semantic invariants.

RULES:
- Maximize execution speed while preserving semantic invariants (output columns, grain, total result rows).
- Group dependent changes into a single rewrite_set.
- Use descriptive CTE names (e.g., `filtered_returns` not `cte1`).
- If a standard SQL optimization applies that is not in the allowed list, label it "semantic_rewrite".

ALLOWED TRANSFORMS: pushdown, decorrelate, or_to_union, early_filter, date_cte_isolate, materialize_cte, flatten_subquery, reorder_join, multi_push_predicate, inline_cte, remove_redundant, semantic_rewrite

---
## Query Structure

### DAG Topology
```
  [main_query] type=main tables=[item, item, store_sales, store_sales, store_sales] GROUP_BY
```

### Target Nodes
[main_query] GROUP_BY

### SQL
[main_query] type=main
```sql
SELECT
  asceding.rnk,
  i1.i_product_name AS best_performing,
  i2.i_product_name AS worst_performing
FROM (
  SELECT
    *
  FROM (
    SELECT
      item_sk,
      RANK() OVER (ORDER BY rank_col ASC) AS rnk
    FROM (
      SELECT
        ss_item_sk AS item_sk,
        AVG(ss_net_profit) AS rank_col
      FROM store_sales AS ss1
      WHERE
        ss_store_sk = 146
      GROUP BY
        ss_item_sk
      HAVING
        AVG(ss_net_profit) > 0.9 * (
          SELECT
            AVG(ss_net_profit) AS rank_col
          FROM store_sales
          WHERE
            ss_store_sk = 146 AND ss_addr_sk IS NULL
          GROUP BY
            ss_store_sk
        )
    ) AS V1
  ) AS V11
  WHERE
    rnk < 11
) AS asceding, (
  SELECT
    *
  FROM (
    SELECT
      item_sk,
      RANK() OVER (ORDER BY rank_col DESC) AS rnk
    FROM (
      SELECT
        ss_item_sk AS item_sk,
        AVG(ss_net_profit) AS rank_col
      FROM store_sales AS ss1
      WHERE
        ss_store_sk = 146
      GROUP BY
        ss_item_sk
      HAVING
        AVG(ss_net_profit) > 0.9 * (
          SELECT
            AVG(ss_net_profit) AS rank_col
          FROM store_sales
          WHERE
            ss_store_sk = 146 AND ss_addr_sk IS NULL
          GROUP BY
            ss_store_sk
        )
    ) AS V2
  ) AS V21
  WHERE
    rnk < 11
) AS descending, item AS i1, item AS i2
WHERE
  asceding.rnk = descending.rnk
  AND i1.i_item_sk = asceding.item_sk
  AND i2.i_item_sk = descending.item_sk
ORDER BY
  asceding.rnk
LIMIT 100
```

### Contracts
[main_query]:
  output_columns: ['rnk', 'best_performing', 'worst_performing']
  grain: ['ss_item_sk']
  required_predicates: ['i2.i_item_sk = descending.item_sk', 'asceding.rnk = descending.rnk', 'i1.i_item_sk = asceding.item_sk']

### Downstream Usage
No usage data.

---
## Performance Profile

### Cost Attribution
[main_query]: 97.0% cost, ~2048 rows, ops=[SEQ_SCAN[item], SEQ_SCAN[item]]

### Execution Plan
```
Operators by cost:
- SEQ_SCAN(item): 92.8% cost, 2,048 rows
- SEQ_SCAN(item): 3.4% cost, 2,048 rows
- TOP_N: 0.0% cost, 0 rows
- PROJECTION: 0.0% cost, 0 rows
- HASH_JOIN: 0.0% cost, 0 rows

Scans:
- item x2: 102,000 rows (no filter)

Misestimates:
- PROJECTION: est 62,464 vs actual 0 (62464.0x)
- HASH_JOIN: est 62,464 vs actual 0 (62464.0x)
- HASH_JOIN: est 1,870 vs actual 0 (1870.0x)
- SEQ_SCAN: est 102,000 vs actual 2,048 (49.8x)
- PROJECTION: est 1,306 vs actual 0 (1306.0x)
- FILTER: est 1,306 vs actual 0 (1306.0x)
- PROJECTION: est 6,531 vs actual 0 (6531.0x)
- PROJECTION: est 6,531 vs actual 0 (6531.0x)
- NESTED_LOOP_JOIN: est 6,531 vs actual 0 (6531.0x)
- HASH_GROUP_BY: est 95,597 vs actual 0 (95597.0x)
- HASH_JOIN: est 1,870 vs actual 0 (1870.0x)
- SEQ_SCAN: est 102,000 vs actual 2,048 (49.8x)
- PROJECTION: est 1,306 vs actual 0 (1306.0x)
- FILTER: est 1,306 vs actual 0 (1306.0x)
- PROJECTION: est 6,531 vs actual 0 (6531.0x)
- PROJECTION: est 6,531 vs actual 0 (6531.0x)
- NESTED_LOOP_JOIN: est 6,531 vs actual 0 (6531.0x)
- HASH_GROUP_BY: est 95,597 vs actual 0 (95597.0x)

Joins:
- HASH_JOIN: ? x ? -> 0 rows
- HASH_JOIN: item x ? -> 0 rows
- NESTED_LOOP_JOIN: ? x ? -> 0 rows
- HASH_JOIN: item x ? -> 0 rows
- NESTED_LOOP_JOIN: ? x ? -> 0 rows
```

### Optimization Opportunities
1. **QT-OPT-007** - Materialize Repeated Subquery
  Trigger: Same subquery pattern appears multiple times in query
  Rewrite: Extract to CTE with MATERIALIZED hint, reference by name
   Matched: Repeated subquery pattern

---
## Previous Attempts

- baseline: 1.00x [none] NEUTRAL
- v2_standard: 1.00x [materialize_cte] NEUTRAL
- dsr1: 1.37x [materialize_cte] WIN

**Worked**: materialize_cte

**Recommended patterns** (details in Examples section below):
- **single_pass_aggregation** (4.47x) — Consolidate multiple subqueries scanning the same table into a single CTE with conditional aggregates.
- **pushdown** (2.11x) — Push filters from outer query into CTEs/subqueries to reduce intermediate result sizes.
- **deferred_window_aggregation** (1.36x) — When multiple CTEs each perform GROUP BY + WINDOW (cumulative sum), then are joined with FULL OUTER JOIN followed by another WINDOW pass for NULL carry-forward: defer the WINDOW out of the CTEs, join daily totals, then compute cumulative sums once on the joined result.

---
## Examples (Verified Patterns)

## Example: Single Pass Aggregation (SINGLE_PASS_AGGREGATION)
Verified speedup: 4.47x
Benchmark: Q9

### Original SQL:
```sql
select case when (select count(*) 
                  from store_sales 
                  where ss_quantity between 1 and 20) > 2972190
            then (select avg(ss_ext_sales_price) 
                  from store_sales 
                  where ss_quantity between 1 and 20) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 1 and 20) end bucket1 ,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 21 and 40) > 4505785
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 21 and 40) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 21 and 40) end bucket2,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 41 and 60) > 1575726
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 41 and 60)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 41 and 60) end bucket3,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 61 and 80) > 3188917
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 61 and 80)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 61 and 80) end bucket4,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 81 and 100) > 3525216
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 81 and 100)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 81 and 100) end bucket5
from reason
where r_reason_sk = 1;
```

### Optimized SQL:
```sql
WITH sales_stats AS (SELECT COUNT(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 END) AS cnt1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_ext_sales_price END) AS avg_price1, AVG(CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN ss_net_profit END) AS avg_profit1, COUNT(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN 1 END) AS cnt2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_ext_sales_price END) AS avg_price2, AVG(CASE WHEN ss_quantity BETWEEN 21 AND 40 THEN ss_net_profit END) AS avg_profit2, COUNT(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN 1 END) AS cnt3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_ext_sales_price END) AS avg_price3, AVG(CASE WHEN ss_quantity BETWEEN 41 AND 60 THEN ss_net_profit END) AS avg_profit3, COUNT(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN 1 END) AS cnt4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_ext_sales_price END) AS avg_price4, AVG(CASE WHEN ss_quantity BETWEEN 61 AND 80 THEN ss_net_profit END) AS avg_profit4, COUNT(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN 1 END) AS cnt5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_ext_sales_price END) AS avg_price5, AVG(CASE WHEN ss_quantity BETWEEN 81 AND 100 THEN ss_net_profit END) AS avg_profit5 FROM store_sales)
SELECT CASE WHEN s.cnt1 > 2972190 THEN s.avg_price1 ELSE s.avg_profit1 END AS bucket1, CASE WHEN s.cnt2 > 4505785 THEN s.avg_price2 ELSE s.avg_profit2 END AS bucket2, CASE WHEN s.cnt3 > 1575726 THEN s.avg_price3 ELSE s.avg_profit3 END AS bucket3, CASE WHEN s.cnt4 > 3188917 THEN s.avg_price4 ELSE s.avg_profit4 END AS bucket4, CASE WHEN s.cnt5 > 3525216 THEN s.avg_price5 ELSE s.avg_profit5 END AS bucket5 FROM reason AS r, sales_stats AS s WHERE r.r_reason_sk = 1;
```

**Key insight:** Multiple scalar subqueries with different filter conditions on the same table can be consolidated into a single CTE using conditional CASE expressions inside aggregates. Reduces N scans to 1 scan.


## Example: Filter Pushdown (PUSHDOWN)
Verified speedup: 2.11x
Benchmark: Q9

### Original SQL:
```sql
select case when (select count(*) 
                  from store_sales 
                  where ss_quantity between 1 and 20) > 2972190
            then (select avg(ss_ext_sales_price) 
                  from store_sales 
                  where ss_quantity between 1 and 20) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 1 and 20) end bucket1 ,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 21 and 40) > 4505785
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 21 and 40) 
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 21 and 40) end bucket2,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 41 and 60) > 1575726
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 41 and 60)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 41 and 60) end bucket3,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 61 and 80) > 3188917
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 61 and 80)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 61 and 80) end bucket4,
       case when (select count(*)
                  from store_sales
                  where ss_quantity between 81 and 100) > 3525216
            then (select avg(ss_ext_sales_price)
                  from store_sales
                  where ss_quantity between 81 and 100)
            else (select avg(ss_net_profit)
                  from store_sales
                  where ss_quantity between 81 and 100) end bucket5
from reason
where r_reason_sk = 1;
```

### Optimized SQL:
```sql
WITH quantity_aggregations AS (SELECT CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 WHEN ss_quantity BETWEEN 21 AND 40 THEN 2 WHEN ss_quantity BETWEEN 41 AND 60 THEN 3 WHEN ss_quantity BETWEEN 61 AND 80 THEN 4 WHEN ss_quantity BETWEEN 81 AND 100 THEN 5 END AS bucket, COUNT(*) AS cnt, AVG(ss_ext_discount_amt) AS avg_disc, AVG(ss_net_paid) AS avg_net FROM store_sales WHERE ss_quantity BETWEEN 1 AND 100 GROUP BY CASE WHEN ss_quantity BETWEEN 1 AND 20 THEN 1 WHEN ss_quantity BETWEEN 21 AND 40 THEN 2 WHEN ss_quantity BETWEEN 41 AND 60 THEN 3 WHEN ss_quantity BETWEEN 61 AND 80 THEN 4 WHEN ss_quantity BETWEEN 81 AND 100 THEN 5 END)
SELECT CASE WHEN q1.cnt > 74129 THEN q1.avg_disc ELSE q1.avg_net END AS bucket1, CASE WHEN q2.cnt > 122840 THEN q2.avg_disc ELSE q2.avg_net END AS bucket2, CASE WHEN q3.cnt > 56580 THEN q3.avg_disc ELSE q3.avg_net END AS bucket3, CASE WHEN q4.cnt > 10097 THEN q4.avg_disc ELSE q4.avg_net END AS bucket4, CASE WHEN q5.cnt > 165306 THEN q5.avg_disc ELSE q5.avg_net END AS bucket5 FROM reason CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 1) AS q1 CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 2) AS q2 CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 3) AS q3 CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 4) AS q4 CROSS JOIN (SELECT cnt, avg_disc, avg_net FROM quantity_aggregations WHERE bucket = 5) AS q5 WHERE r_reason_sk = 1;
```

**Key insight:** Extract repeated quantity-range subqueries into CTEs. Each CTE computes count, avg_ext_price, avg_net_profit in ONE pass instead of scanning store_sales 15+ times.


## Example: Deferred Window Aggregation (DEFERRED_WINDOW_AGGREGATION)
Verified speedup: 1.36x
Benchmark: Q51

### Original SQL:
```sql
WITH web_v1 as (
select
  ws_item_sk item_sk, d_date,
  sum(sum(ws_sales_price))
      over (partition by ws_item_sk order by d_date rows between unbounded preceding and current row) cume_sales
from web_sales
    ,date_dim
where ws_sold_date_sk=d_date_sk
  and d_month_seq between 1216 and 1216+11
  and ws_item_sk is not NULL
group by ws_item_sk, d_date),
store_v1 as (
select
  ss_item_sk item_sk, d_date,
  sum(sum(ss_sales_price))
      over (partition by ss_item_sk order by d_date rows between unbounded preceding and current row) cume_sales
from store_sales
    ,date_dim
where ss_sold_date_sk=d_date_sk
  and d_month_seq between 1216 and 1216+11
  and ss_item_sk is not NULL
group by ss_item_sk, d_date)
 select *
from (select item_sk
     ,d_date
     ,web_sales
     ,store_sales
     ,max(web_sales)
         over (partition by item_sk order by d_date rows between unbounded preceding and current row) web_cumulative
     ,max(store_sales)
         over (partition by item_sk order by d_date rows between unbounded preceding and current row) store_cumulative
     from (select case when web.item_sk is not null then web.item_sk else store.item_sk end item_sk
                 ,case when web.d_date is not null then web.d_date else store.d_date end d_date
                 ,web.cume_sales web_sales
                 ,store.cume_sales store_sales
           from web_v1 web full outer join store_v1 store on (web.item_sk = store.item_sk
                                                          and web.d_date = store.d_date)
          )x )y
where web_cumulative > store_cumulative
order by item_sk
        ,d_date
 LIMIT 100;
```

### Optimized SQL:
```sql
WITH filtered_dates AS (SELECT d_date_sk, d_date FROM date_dim WHERE d_month_seq BETWEEN 1216 AND 1216 + 11), filtered_web_sales AS (SELECT ws_item_sk AS item_sk, d_date, ws_sales_price FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk WHERE NOT ws_item_sk IS NULL), filtered_store_sales AS (SELECT ss_item_sk AS item_sk, d_date, ss_sales_price FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk WHERE NOT ss_item_sk IS NULL), web_v1 AS (SELECT item_sk, d_date, SUM(SUM(ws_sales_price)) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS cume_sales FROM filtered_web_sales GROUP BY item_sk, d_date), store_v1 AS (SELECT item_sk, d_date, SUM(SUM(ss_sales_price)) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS cume_sales FROM filtered_store_sales GROUP BY item_sk, d_date)
SELECT * FROM (SELECT item_sk, d_date, web_sales, store_sales, MAX(web_sales) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS web_cumulative, MAX(store_sales) OVER (PARTITION BY item_sk ORDER BY d_date rows BETWEEN UNBOUNDED preceding AND CURRENT ROW) AS store_cumulative FROM (SELECT CASE WHEN NOT web.item_sk IS NULL THEN web.item_sk ELSE store.item_sk END AS item_sk, CASE WHEN NOT web.d_date IS NULL THEN web.d_date ELSE store.d_date END AS d_date, web.cume_sales AS web_sales, store.cume_sales AS store_sales FROM web_v1 AS web FULL OUTER JOIN store_v1 AS store ON (web.item_sk = store.item_sk AND web.d_date = store.d_date)) AS x) AS y WHERE web_cumulative > store_cumulative ORDER BY item_sk, d_date LIMIT 100;
```

**Key insight:** When CTEs compute GROUP BY + WINDOW (running sum), then FULL OUTER JOIN introduces NULLs requiring a MAX() OVER() carry-forward pass: remove WINDOW from the CTEs (keep only GROUP BY for daily totals), join the daily totals, then compute SUM() OVER() once on the joined result. SUM() naturally skips NULLs, so the carry-forward is free. Reduces 3 WINDOW passes (2 in CTEs + 1 MAX carry-forward) to 1.

**When NOT to use:** Do not use when the CTE window function is referenced by other consumers besides the final join (the cumulative value is needed elsewhere). Do not use when the window function is not a monotonically accumulating SUM - e.g., AVG, COUNT, or non-monotonic window functions require separate computation. Only applies when the join is FULL OUTER and the carry-forward window is MAX/LAST_VALUE over a cumulative sum.


---
## Constraints

**CTE_COLUMN_COMPLETENESS** [CRITICAL]: CRITICAL: When creating or modifying a CTE, its SELECT list MUST include ALL columns referenced by downstream queries. Check the Node Contracts section: every column in downstream_refs MUST appear in the CTE output. Also ensure: (1) JOIN columns used by consumers are included in SELECT, (2) every table referenced in WHERE is present in FROM/JOIN, (3) no ambiguous column names between the CTE and re-joined tables. Dropping a column that a downstream node needs will cause an execution error.

**LITERAL_PRESERVATION** [CRITICAL]: CRITICAL: When rewriting SQL, you MUST copy ALL literal values (strings, numbers, dates) EXACTLY from the original query. Do NOT invent, substitute, or 'improve' any filter values. If the original says d_year = 2000, your rewrite MUST say d_year = 2000. If the original says ca_state = 'GA', your rewrite MUST say ca_state = 'GA'. Changing these values will produce WRONG RESULTS and the rewrite will be REJECTED.

**MIN_BASELINE_THRESHOLD** [HIGH]: If the query execution plan shows very fast runtime (under 100ms), be conservative with CTE-based transforms. Each CTE adds materialization overhead (hash table creation, intermediate result storage). On fast queries, this overhead can exceed the filtering benefit. Prefer minimal changes or no change over adding multiple CTEs to an already-fast query.

**NO_UNFILTERED_DIMENSION_CTE** [HIGH]: Every CTE you create must include a WHERE clause that actually reduces row count. Selecting fewer columns is not filtering — the CTE still materializes every row. If a dimension table has no predicate to push down, leave it as a direct join in the main query instead of wrapping it in a CTE.

**OR_TO_UNION_GUARD** [HIGH]: Only apply or_to_union when (a) the OR branches involve different tables or fundamentally different access paths — never when all branches filter the same column (e.g., t_hour ranges), since the optimizer already handles same-column ORs efficiently in a single scan — and (b) the result is 3 or fewer UNION ALL branches. Nested ORs that would expand into 4+ branches (e.g., 3 conditions x 3 values = 9 combinations) must be left as-is. Violating these rules causes 0.23x–0.59x regressions from multiplied fact table scans.

**REMOVE_REPLACED_CTES** [HIGH]: When creating replacement CTEs, overwrite the original by using the same node_id in your rewrite_sets, or ensure the original is removed from the WITH clause. Every CTE in the final query should be actively used — dead CTEs still get materialized and waste resources (caused 0.49x on Q31, 0.68x on Q74).

**NO_MATERIALIZE_EXISTS** [CRITICAL]: Keep EXISTS and NOT EXISTS as-is — they use semi-join short-circuiting that stops scanning after the first match. Converting them to materialized CTEs (e.g., WITH cte AS (SELECT DISTINCT ... FROM large_table)) forces a full table scan, which is catastrophically slower (0.14x observed on Q16). When you see EXISTS, preserve it.


---
## Output Format

Respond with a JSON object containing your rewrite_sets:

```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "transform_name",
      "nodes": {
        "node_id": "new SQL..."
      },
      "invariants_kept": ["same result rows", "same ordering"],
      "expected_speedup": "2x",
      "risk": "low"
    }
  ],
  "explanation": "what was changed and why"
}
```

Now output your rewrite_sets: