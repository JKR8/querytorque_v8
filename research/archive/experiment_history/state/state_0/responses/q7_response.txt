Looking at this query and the execution plan, I can see the main issue: the store_sales fact table (345M rows) is being scanned unfiltered. The query joins with 4 dimension tables, but only applies filters on date_dim, customer_demographics, and promotion. The current plan does late filtering.

Based on the provided patterns and constraints, I'll use a **multi-dimension prefetch approach** to filter all applicable dimension tables first, then join with the fact table. This should significantly reduce the fact table join size.

```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "multi_dimension_prefetch",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_year = 2001",
        "filtered_customer_demographics": "SELECT cd_demo_sk FROM customer_demographics WHERE cd_gender = 'F' AND cd_marital_status = 'W' AND cd_education_status = 'College'",
        "filtered_promotions": "SELECT p_promo_sk FROM promotion WHERE p_channel_email = 'N' OR p_channel_event = 'N'",
        "joined_facts": "SELECT ss_item_sk, ss_quantity, ss_list_price, ss_coupon_amt, ss_sales_price FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk JOIN filtered_customer_demographics ON ss_cdemo_sk = cd_demo_sk JOIN filtered_promotions ON ss_promo_sk = p_promo_sk",
        "main_query": "SELECT i_item_id, AVG(ss_quantity) AS agg1, AVG(ss_list_price) AS agg2, AVG(ss_coupon_amt) AS agg3, AVG(ss_sales_price) AS agg4 FROM joined_facts JOIN item ON ss_item_sk = i_item_sk GROUP BY i_item_id ORDER BY i_item_id LIMIT 100"
      },
      "invariants_kept": [
        "same result rows",
        "same ordering",
        "same column output"
      ],
      "expected_speedup": "2.8x",
      "risk": "low"
    }
  ],
  "explanation": "Created CTEs for filtered date_dim (d_year=2001), customer_demographics (gender=F, marital_status=W, education=College), and promotion (channel_email=N OR channel_event=N). These CTEs return only surrogate keys. Then created a joined_facts CTE that pre-joins store_sales with all three filtered dimension CTEs, creating a much smaller intermediate fact set. Finally, the main query joins this filtered fact set with the item table and computes aggregates. This reduces the 345M row store_sales scan to only rows matching all three dimension filters, which should be dramatically fewer based on the execution plan showing date_dim filters to 365 rows and customer_demographics to 27,440 rows."
}
```

**Key insights:**
1. The execution plan shows store_sales is scanned unfiltered (345M rows) despite joins with 3 filtered dimension tables
2. Date_dim filter reduces to 365 rows, customer_demographics to 27,440 rows
3. By pre-filtering all 3 dimension tables and pre-joining with store_sales, we create a much smaller intermediate result
4. This follows the MULTI_DIMENSION_PREFETCH pattern from the examples
5. We preserve OR condition structure in promotion filter as per OR_TO_UNION_LIMIT constraint
6. All literal values are preserved exactly as in original query per LITERAL_PRESERVATION constraint