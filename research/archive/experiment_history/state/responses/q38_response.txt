Looking at this query, I can see a significant opportunity to apply a **prefetch_fact_join** pattern similar to the example. The current query performs three separate large fact table scans (web_sales, store_sales, catalog_sales) and repeats the same date filter multiple times. The key insight is to pre-join each fact table with the date filter first to create smaller filtered fact sets before doing the customer joins and EXISTS checks.

```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "prefetch_fact_join",
      "nodes": {
        "date_filter": "SELECT d_date_sk, d_date FROM date_dim WHERE d_month_seq BETWEEN 1200 AND 1200 + 11",
        "web_sales_filtered": "SELECT ws_bill_customer_sk, d_date FROM web_sales JOIN date_filter ON ws_sold_date_sk = d_date_sk",
        "store_sales_filtered": "SELECT ss_customer_sk, d_date FROM store_sales JOIN date_filter sf ON ss_sold_date_sk = sf.d_date_sk",
        "catalog_sales_filtered": "SELECT cs_bill_customer_sk, d_date FROM catalog_sales JOIN date_filter cf ON cs_sold_date_sk = cf.d_date_sk",
        "main_query": "SELECT COUNT(*) FROM (SELECT DISTINCT c_last_name, c_first_name, wsf.d_date FROM web_sales_filtered wsf JOIN customer ON wsf.ws_bill_customer_sk = customer.c_customer_sk WHERE EXISTS(SELECT 1 FROM store_sales_filtered ssf JOIN customer sc ON ssf.ss_customer_sk = sc.c_customer_sk WHERE sc.c_last_name = customer.c_last_name AND sc.c_first_name = customer.c_first_name AND ssf.d_date = wsf.d_date) AND EXISTS(SELECT 1 FROM catalog_sales_filtered csf JOIN customer cc ON csf.cs_bill_customer_sk = cc.c_customer_sk WHERE cc.c_last_name = customer.c_last_name AND cc.c_first_name = customer.c_first_name AND csf.d_date = wsf.d_date)) AS hot_cust LIMIT 100"
      },
      "invariants_kept": [
        "same result rows",
        "same column output",
        "same DISTINCT semantics",
        "same EXISTS logic"
      ],
      "expected_speedup": "2.5x",
      "risk": "low"
    }
  ],
  "explanation": "Applied prefetch_fact_join transform: First CTE filters dates. Then three CTEs pre-join each fact table (web_sales, store_sales, catalog_sales) with the filtered dates to create smaller intermediate results. This reduces the large fact table scans before joining with customer tables. The date filter is computed once and reused, avoiding repeated scans of date_dim. Each filtered fact table contains only the rows within the target date range, making subsequent customer joins and EXISTS checks much faster."
}
```

**Key changes:**
1. **Preserved the date_filter CTE** as-is (literal preservation constraint)
2. **Created three filtered fact tables** by pre-joining each sales table with the date filter
3. **Each filtered CTE only contains relevant columns** needed for subsequent joins (customer keys and dates)
4. **Main query now joins with filtered CTEs** instead of raw fact tables, dramatically reducing the data volume for customer joins
5. **Same logic preserved** - EXISTS subqueries still check for matching customer names and dates

This approach addresses the core performance issue: the original query scans massive fact tables (345M+ rows for store_sales) before applying date filters. By pre-joining with the date filter (which reduces to only 366 rows), each filtered fact table becomes much smaller, making the subsequent customer joins and EXISTS checks much more efficient.