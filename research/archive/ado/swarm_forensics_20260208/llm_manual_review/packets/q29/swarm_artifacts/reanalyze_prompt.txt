You are analyzing 5 failed optimization attempts to design a refined approach that reaches 2.0x speedup.

Your job: understand WHY each attempt fell short, identify unexplored optimization angles, and synthesize a NEW strategy that combines the best insights while avoiding repeated mistakes.

## Query: query_29
## Target: 2.0x speedup
## Dialect: duckdb

```sql
-- start query 29 in stream 0 using template query29.tpl
select  
     i_item_id
    ,i_item_desc
    ,s_store_id
    ,s_store_name
    ,avg(ss_quantity)        as store_sales_quantity
    ,avg(sr_return_quantity) as store_returns_quantity
    ,avg(cs_quantity)        as catalog_sales_quantity
 from
    store_sales
   ,store_returns
   ,catalog_sales
   ,date_dim             d1
   ,date_dim             d2
   ,date_dim             d3
   ,store
   ,item
 where
     d1.d_moy               = 4 
 and d1.d_year              = 1999
 and d1.d_date_sk           = ss_sold_date_sk
 and i_item_sk              = ss_item_sk
 and s_store_sk             = ss_store_sk
 and ss_customer_sk         = sr_customer_sk
 and ss_item_sk             = sr_item_sk
 and ss_ticket_number       = sr_ticket_number
 and sr_returned_date_sk    = d2.d_date_sk
 and d2.d_moy               between 4 and  4 + 3 
 and d2.d_year              = 1999
 and sr_customer_sk         = cs_bill_customer_sk
 and sr_item_sk             = cs_item_sk
 and cs_sold_date_sk        = d3.d_date_sk     
 and d3.d_year              in (1999,1999+1,1999+2)
 group by
    i_item_id
   ,i_item_desc
   ,s_store_id
   ,s_store_name
 order by
    i_item_id 
   ,i_item_desc
   ,s_store_id
   ,s_store_name
 LIMIT 100;

-- end query 29 in stream 0 using template query29.tpl
```

## Previous Attempts

### Worker 1: conservative_pushdown_filter
- **Status**: error (0.00x)
- **Error**: Binder Error: Referenced column "d_moy" not found in FROM clause!
Candidate bindings: "ss_cdemo_sk", "ss_hdemo_sk", "d_date_sk", "ss_item_sk", "ss_store_sk"

LINE 17: ...old_date_sk IN (SELECT d_date_sk FROM filtered_dates WHERE d_moy = 4 AND d_year = 1999)
                                                                       ^
- **Transforms**: none
- **Examples used**: early_filter, pushdown, materialize_cte
- **Strategy hint**: Apply early filtering on dimension tables (date_dim, store, item), push predicates into CTEs, and materialize repeated subquery patterns to reduce join sizes.

```sql
WITH filtered_dates AS (
  SELECT d_date_sk
  FROM date_dim
  WHERE (d_moy = 4 AND d_year = 1999)
     OR (d_moy BETWEEN 4 AND 7 AND d_year = 1999)
     OR (d_year IN (1999, 2000, 2001))
),
store_sales_filtered AS (
  SELECT
    ss_quantity,
    ss_item_sk,
    ss_store_sk,
    ss_customer_sk,
    ss_ticket_number,
    ss_sold_date_sk
  FROM store_sales
  WHERE ss_sold_date_sk IN (SELECT d_date_sk FROM filtered_dates WHERE d_moy = 4 AND d_year = 1999)
),
store_returns_filtered AS (
  SELECT
    sr_return_quantity,
    sr_item_sk,
    sr_customer_sk,
    sr_ticket_number,
    sr_returned_date_sk
  FROM store_returns
  WHERE sr_returned_date_sk IN (SELECT d_date_sk FROM filtered_dates WHERE d_moy BETWEEN 4 AND 7 AND d_year = 1999)
),
catalog_sales_filtered AS (
  SELECT
-- ... (truncated)
```

### Worker 2: moderate_date_dimension_isolation
- **Status**: pass (1.03x)
- **Transforms**: none
- **Examples used**: date_cte_isolate, dimension_cte_isolate, multi_date_range_cte
- **Strategy hint**: Pre-filter each date_dim alias (d1, d2, d3) and other dimension tables into separate CTEs before joining with fact tables to leverage predicate pushdown.

```sql
WITH d1_dates AS (
  SELECT d_date_sk
  FROM date_dim
  WHERE d_moy = 4
    AND d_year = 1999
),
d2_dates AS (
  SELECT d_date_sk
  FROM date_dim
  WHERE d_moy BETWEEN 4 AND 7
    AND d_year = 1999
),
d3_dates AS (
  SELECT d_date_sk
  FROM date_dim
  WHERE d_year IN (1999, 2000, 2001)
),
filtered_store_sales AS (
  SELECT
    ss_item_sk,
    ss_customer_sk,
    ss_ticket_number,
    ss_store_sk,
    ss_quantity
  FROM store_sales
  JOIN d1_dates ON ss_sold_date_sk = d1_dates.d_date_sk
),
filtered_store_returns AS (
  SELECT
    sr_item_sk,
-- ... (truncated)
```

### Worker 3: aggressive_multi_stage_prefetch
- **Status**: pass (0.87x)
- **Transforms**: none
- **Examples used**: prefetch_fact_join, multi_dimension_prefetch, shared_dimension_multi_channel
- **Strategy hint**: Pre-join filtered dimensions (date/store/item) with their respective fact tables in staged CTEs, then combine pre-aggregated results to minimize large intermediate joins.

```sql
-- start query 29 in stream 0 using template query29.tpl
select  
     i_item_id
    ,i_item_desc
    ,s_store_id
    ,s_store_name
    ,avg(ss_quantity)        as store_sales_quantity
    ,avg(sr_return_quantity) as store_returns_quantity
    ,avg(cs_quantity)        as catalog_sales_quantity
 from
    store_sales
   ,store_returns
   ,catalog_sales
   ,date_dim             d1
   ,date_dim             d2
   ,date_dim             d3
   ,store
   ,item
 where
     d1.d_moy               = 4 
 and d1.d_year              = 1999
 and d1.d_date_sk           = ss_sold_date_sk
 and i_item_sk              = ss_item_sk
 and s_store_sk             = ss_store_sk
 and ss_customer_sk         = sr_customer_sk
 and ss_item_sk             = sr_item_sk
 and ss_ticket_number       = sr_ticket_number
 and sr_returned_date_sk    = d2.d_date_sk
 and d2.d_moy               between 4 and  4 + 3 
 and d2.d_year              = 1999
-- ... (truncated)
```

### Worker 4: novel_structural_transform
- **Status**: pass (1.01x)
- **Transforms**: none
- **Examples used**: or_to_union, intersect_to_exists, composite_decorrelate_union
- **Strategy hint**: Explore converting the d3.d_year IN clause to UNION ALL branches, apply EXISTS-style join transformations, and decorrelate multi-fact joins via distinct customer/item CTEs.

```sql
WITH filtered_d1 AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_moy = 4
      AND d_year = 1999
),
filtered_d2 AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_moy BETWEEN 4 AND 7
      AND d_year = 1999
),
filtered_d3_1999 AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year = 1999
),
filtered_d3_2000 AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year = 2000
),
filtered_d3_2001 AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year = 2001
),
store_sales_filtered AS (
    SELECT
        ss_item_sk,
-- ... (truncated)
```

### Worker 5: refined_snipe
- **Status**: pass (1.00x)
- **Transforms**: none
- **Examples used**: 
- **Strategy hint**: Snipe from iter 1

```sql
WITH d1_dates AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_moy = 4
      AND d_year = 1999
),
d2_dates AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_moy BETWEEN 4 AND 7
      AND d_year = 1999
),
d3_dates AS (
    SELECT d_date_sk
    FROM date_dim
    WHERE d_year IN (1999, 2000, 2001)
),
filtered_store_sales AS (
    SELECT
        ss_item_sk,
        ss_customer_sk,
        ss_ticket_number,
        ss_store_sk,
        ss_quantity
    FROM store_sales
    JOIN d1_dates ON store_sales.ss_sold_date_sk = d1_dates.d_date_sk
),
filtered_store_returns AS (
    SELECT
        sr_item_sk,
-- ... (truncated)
```

## DAG Structure & Bottlenecks

| Node | Role | Cost % |
|------|------|-------:|
| main_query |  | 0.0% |

## Available Examples (Full Catalog)

- **composite_decorrelate_union** (2.42xx) — Decorrelate multiple correlated EXISTS subqueries into pre-materialized DISTINCT
- **date_cte_isolate** (4.00xx) — Extract date filtering into a separate CTE to enable predicate pushdown and redu
- **decorrelate** (2.92xx) — Convert correlated subquery to separate CTE with GROUP BY, then JOIN
- **deferred_window_aggregation** (1.36xx) — When multiple CTEs each perform GROUP BY + WINDOW (cumulative sum), then are joi
- **dimension_cte_isolate** (1.93xx) — Pre-filter ALL dimension tables into CTEs before joining with fact table, not ju
- **early_filter** (4.00xx) — Filter dimension tables FIRST, then join to fact tables to reduce expensive join
- **intersect_to_exists** (1.83xx) — Convert INTERSECT subquery pattern to multiple EXISTS clauses for better join pl
- **materialize_cte** (1.37xx) — Extract repeated subquery patterns into a CTE to avoid recomputation
- **multi_date_range_cte** (2.35xx) — When query uses multiple date_dim aliases with different filters (d1, d2, d3), c
- **multi_dimension_prefetch** (2.71xx) — Pre-filter multiple dimension tables (date + store) into separate CTEs before jo
- **or_to_union** (3.17xx) — Split OR conditions on different columns into UNION ALL branches for better inde
- **prefetch_fact_join** (3.77xx) — Pre-filter dimension table into CTE, then pre-join with fact table in second CTE
- **pushdown** (2.11xx) — Push filters from outer query into CTEs/subqueries to reduce intermediate result
- **shared_dimension_multi_channel** (1.30xx) — Extract shared dimension filters (date, item, promotion) into CTEs when multiple
- **single_pass_aggregation** (4.47xx) — Consolidate multiple subqueries scanning the same table into a single CTE with c
- **union_cte_split** (1.36xx) — Split a generic UNION ALL CTE into specialized CTEs when the main query filters 

## Your Task

Analyze the failed attempts and design a refined approach:

1. **Failure Analysis**: Why did all attempts fall short? Be specific about mechanisms.
2. **Common Patterns**: What did multiple workers try unsuccessfully?
3. **Unexplored Space**: What optimization angles were missed entirely?
4. **Refined Strategy**: Synthesize a NEW approach combining best insights.

### Output Format (follow EXACTLY)

```
FAILURE_ANALYSIS:
<Why all workers fell short — be specific about mechanisms>

UNEXPLORED_OPPORTUNITIES:
<What optimization approaches haven't been tried>

REFINED_STRATEGY:
<Concrete optimization approach for next attempt>

EXAMPLES: <ex1>, <ex2>, <ex3>
HINT: <specific guidance for the refined attempt>
```