You are a SQL rewrite engine for PostgreSQL v14.3. Follow the Target DAG structure below. Your job is to write correct, executable SQL for each node — not to decide whether to restructure. Preserve exact semantic equivalence (same rows, same columns, same ordering). Preserve defensive guards: if the original uses CASE WHEN x > 0 THEN y/x END around a division, keep it — even when a WHERE clause makes the zero case unreachable. Guards prevent silent breakage if filters change upstream. Strip benchmark comments (-- start query, -- end query) from your output.

## Semantic Contract (MUST preserve)

Query finds (item, warehouse, week) triples where catalog_sales inventory was insufficient (inv_quantity_on_hand < cs_quantity), filtered by demographic criteria (unmarried, dep_count 9-11, buy_potential >10000), item category, wholesale cost range, and shipping delay (d3.d_date > d1.d_date + 3 days) for year 1998. JOIN types: 8 INNER + 1 LEFT (promotion) + 1 LEFT (catalog_returns). The LEFT JOINs preserve all matching catalog_sales rows. Aggregation: COUNT and conditional SUM on promotion NULL status — safe for restructuring.

## Target DAG + Node Contracts

Build your rewrite following this CTE structure. Each node's OUTPUT list is exhaustive — your SQL must produce exactly those columns.

TARGET_DAG:
  filtered_dates -> filtered_cs -> cs_inv_join -> dim_lookups -> final_agg

NODE_CONTRACTS:
  filtered_dates:
    FROM: date_dim d1
    WHERE: d1.d_year = 1998
    OUTPUT: d_date_sk, d_week_seq, d_date
    EXPECTED_ROWS: ~365
    CONSUMERS: filtered_cs

  filtered_cs:
    FROM: catalog_sales JOIN filtered_dates ON cs_sold_date_sk = d_date_sk
    WHERE: cs_wholesale_cost BETWEEN 35 AND 55
    OUTPUT: cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_ship_date_sk, cs_promo_sk, cs_order_number, cs_quantity, d_week_seq, d_date
    EXPECTED_ROWS: ~170K (pre-filtered from 14M)
    CONSUMERS: cs_inv_join

  cs_inv_join:
    FROM: filtered_cs JOIN date_dim d2 ON d2.d_week_seq = filtered_cs.d_week_seq
          JOIN inventory ON inv_date_sk = d2.d_date_sk AND inv_item_sk = cs_item_sk
    WHERE: inv_quantity_on_hand < cs_quantity
    OUTPUT: cs_item_sk, cs_bill_cdemo_sk, cs_bill_hdemo_sk, cs_ship_date_sk, cs_promo_sk, cs_order_number, cs_quantity, d_week_seq, d_date, inv_warehouse_sk
    EXPECTED_ROWS: ~5K
    CONSUMERS: dim_lookups

  dim_lookups:
    FROM: cs_inv_join JOIN warehouse ON inv_warehouse_sk = w_warehouse_sk
          JOIN item ON cs_item_sk = i_item_sk
          JOIN customer_demographics ON cs_bill_cdemo_sk = cd_demo_sk
          JOIN household_demographics ON cs_bill_hdemo_sk = hd_demo_sk
          JOIN date_dim d3 ON cs_ship_date_sk = d3.d_date_sk
          LEFT JOIN promotion ON cs_promo_sk = p_promo_sk
          LEFT JOIN catalog_returns ON cr_item_sk = cs_item_sk AND cr_order_number = cs_order_number
    WHERE: d3.d_date > d_date + interval '3 day' AND hd_buy_potential = '>10000' AND cd_marital_status = 'U' AND cd_dep_count BETWEEN 9 AND 11 AND i_category IN ('Children', 'Jewelry', 'Men')
    OUTPUT: i_item_desc, w_warehouse_name, d_week_seq, p_promo_sk
    EXPECTED_ROWS: ~2K
    CONSUMERS: final_agg

  final_agg:
    FROM: dim_lookups
    GROUP BY: i_item_desc, w_warehouse_name, d_week_seq
    AGGREGATE: SUM(CASE WHEN p_promo_sk IS NULL THEN 1 ELSE 0 END) AS no_promo, SUM(CASE WHEN p_promo_sk IS NOT NULL THEN 1 ELSE 0 END) AS promo, COUNT(*) AS total_cnt
    OUTPUT: i_item_desc, w_warehouse_name, d_week_seq, no_promo, promo, total_cnt
    EXPECTED_ROWS: ~100
    CONSUMERS: result

## Hazard Flags (avoid these specific risks)

- CTE materialization fence: filtered_cs CTE must carry ALL columns needed downstream (cs_promo_sk for LEFT JOIN promotion, cs_order_number for LEFT JOIN catalog_returns).
- Non-equi join (inv_quantity_on_hand < cs_quantity) MUST remain as nested-loop — do not attempt to convert to hash join.
- LEFT JOIN to catalog_returns is in the original query — preserve it even though cr_* columns are not in the output (may affect row count via duplication).

## Regression Warnings (observed failures on similar queries)

None applicable.

## Constraints (analyst-filtered for this query)

- LITERAL_PRESERVATION: All numeric literals (1998, 9, 11, 35, 55, '>10000', 3 days) must be preserved exactly.
- SEMANTIC_EQUIVALENCE: The non-equi condition inv_quantity_on_hand < cs_quantity must remain row-level, not aggregated.
- COMPLETE_OUTPUT: 6 output columns (i_item_desc, w_warehouse_name, d_week_seq, no_promo, promo, total_cnt).
- CTE_COLUMN_COMPLETENESS: Any intermediate CTEs must carry all columns needed downstream.
- NON_EQUI_JOIN_INPUT_BLINDNESS: Active — nested-loop on inventory×catalog_sales is the bottleneck.

## Example Adaptation Notes

For each example: what to apply to your rewrite, and what to ignore.

pg_date_cte_explicit_join: Q072 has d1.d_year=1998 filter on date_dim — isolating this into a CTE reduces the catalog_sales join input. Same pattern as Q099 (2.28x).
pg_dimension_prefetch_star: Q072 has 8 dimension joins — pre-filtering date+cost before the expensive inventory non-equi join reduces nested-loop input.

## Reference Examples

Pattern reference only — do not copy table/column names or literals.

### 1. pg_date_cte_explicit_join (2.28x)

**Principle:** Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.

**BEFORE (slow):**
```sql
select 
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk <= 30 ) then 1 else 0 end)  as "30 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 30) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 60) then 1 else 0 end )  as "31-60 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 60) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 90) then 1 else 0 end)  as "61-90 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk > 90) and
                 (cs_ship_date_sk - cs_sold_date_sk <= 120) then 1 else 0 end)  as "91-120 days"
  ,sum(case when (cs_ship_date_sk - cs_sold_date_sk  > 120) then 1 else 0 end)  as ">120 days"
from
   catalog_sales
  ,warehouse
  ,ship_mode
  ,call_center
  ,date_dim
where
d_month_seq between 1193 and 1193 + 23
and cs_ship_date_sk   = d_date_sk
and cs_warehouse_sk   = w_warehouse_sk
and cs_ship_mode_sk   = sm_ship_mode_sk
and cs_call_center_sk = cc_call_center_sk
and cs_list_price between 271 and 300
and sm_type = 'REGULAR'
and cc_class = 'small'
and w_gmt_offset = -5
group by
   substring(w_warehouse_name,1,20)
  ,sm_type
  ,cc_name
order by substring(w_warehouse_name,1,20)
        ,sm_type
        ,cc_name
limit 100;
```

**AFTER (fast):**
[filtered_dates]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_month_seq BETWEEN 1193 AND 1216
```
[main_query]:
```sql
SELECT SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name, SUM(CASE WHEN (cs_ship_date_sk - cs_sold_date_sk <= 30) THEN 1 ELSE 0 END) AS "30 days", ... FROM catalog_sales JOIN filtered_dates ON cs_ship_date_sk = d_date_sk JOIN warehouse ON cs_warehouse_sk = w_warehouse_sk JOIN ship_mode ON cs_ship_mode_sk = sm_ship_mode_sk JOIN call_center ON cs_call_center_sk = cc_call_center_sk WHERE cs_list_price BETWEEN 271 AND 300 AND sm_type = 'REGULAR' AND cc_class = 'small' AND w_gmt_offset = -5 GROUP BY SUBSTRING(w_warehouse_name FROM 1 FOR 20), sm_type, cc_name ORDER BY 1, 2, 3 LIMIT 100
```

### 2. pg_dimension_prefetch_star (3.32x)

**Principle:** Multi-Dimension Prefetch (PG): pre-filter all selective dimensions into CTEs to create tiny hash tables, combined with explicit JOIN syntax. PostgreSQL's optimizer gets better cardinality estimates from pre-materialized small dimension results.

**BEFORE (slow):**
```sql
with ssr as
 (select  s_store_id as store_id,
          sum(ss_ext_sales_price) as sales,
          sum(coalesce(sr_return_amt, 0)) as returns,
          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit
  from store_sales left outer join store_returns on
         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),
     date_dim,
     store,
     item,
     promotion
 where ss_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
       and ss_store_sk = s_store_sk
       and ss_item_sk = i_item_sk
       and i_current_price > 50
       and ss_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ss_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
 group by s_store_id)
 ,
 csr as
 (select  cp_catalog_page_id as catalog_page_id,
          sum(cs_ext_sales_price) as sales,
          sum(coalesce(cr_return_amount, 0)) as returns,
          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit
  from catalog_sales left outer join catalog_returns on
         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),
     date_dim,
     catalog_page,
     item,
     promotion
 where cs_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and cs_catalog_page_sk = cp_catalog_page_sk
       and cs_item_sk = i_item_sk
       and i_current_price > 50
       and cs_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and cs_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by cp_catalog_page_id)
 ,
 wsr as
 (select  web_site_id,
          sum(ws_ext_sales_price) as sales,
          sum(coalesce(wr_return_amt, 0)) as returns,
          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit
  from web_sales left outer join web_returns on
         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),
     date_dim,
     web_site,
     item,
     promotion
 where ws_sold_date_sk = d_date_sk
       and d_date between cast('1998-08-23' as date)
                  and cast('1998-08-23' as date) + interval '30 day'
        and ws_web_site_sk = web_site_sk
       and ws_item_sk = i_item_sk
       and i_current_price > 50
       and ws_promo_sk = p_promo_sk
       and p_channel_email = 'Y'
       and p_channel_tv = 'Y'
       and p_channel_radio = 'N'
       and p_channel_press = 'N'
       and p_channel_event = 'Y'
       and ws_wholesale_cost BETWEEN 63 AND 78
       and i_category IN ('Jewelry', 'Music')
group by web_site_id)
  select  channel
        , id
        , sum(sales) as sales
        , sum(returns) as returns
        , sum(profit) as profit
 from
 (select 'store channel' as channel
        , 'store' || store_id as id
        , sales
        , returns
        , profit
 from   ssr
 union all
 select 'catalog channel' as channel
        , 'catalog_page' || catalog_page_id as id
        , sales
        , returns
        , profit
 from  csr
 union all
 select 'web channel' as channel
        , 'web_site' || web_site_id as id
        , sales
        , returns
        , profit
 from   wsr
 ) x
 group by rollup (channel, id)
 order by channel
         ,id
 limit 100;
```

**AFTER (fast):**
[filtered_date]:
```sql
SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1998-08-23' AS DATE) AND CAST('1998-08-23' AS DATE) + INTERVAL '30 DAY'
```
[filtered_item]:
```sql
SELECT i_item_sk FROM item WHERE i_current_price > 50 AND i_category IN ('Jewelry', 'Music')
```
[filtered_promotion]:
```sql
SELECT p_promo_sk FROM promotion WHERE p_channel_email = 'Y' AND p_channel_tv = 'Y' AND p_channel_radio = 'N' AND p_channel_press = 'N' AND p_channel_event = 'Y'
```
[ssr]:
```sql
SELECT s_store_id AS store_id, SUM(ss_ext_sales_price) AS sales, SUM(COALESCE(sr_return_amt, 0)) AS returns, SUM(ss_net_profit - COALESCE(sr_net_loss, 0)) AS profit FROM store_sales LEFT OUTER JOIN store_returns ON (ss_item_sk = sr_item_sk AND ss_ticket_number = sr_ticket_number) INNER JOIN filtered_date ON ss_sold_date_sk = filtered_date.d_date_sk INNER JOIN store ON ss_store_sk = s_store_sk INNER JOIN filtered_item ON ss_item_sk = filtered_item.i_item_sk INNER JOIN filtered_promotion ON ss_promo_sk = filtered_promotion.p_promo_sk WHERE ss_wholesale_cost BETWEEN 63 AND 78 GROUP BY s_store_id
```

## Original SQL

```sql
select  i_item_desc
      ,w_warehouse_name
      ,d1.d_week_seq
      ,sum(case when p_promo_sk is null then 1 else 0 end) no_promo
      ,sum(case when p_promo_sk is not null then 1 else 0 end) promo
      ,count(*) total_cnt
from catalog_sales
join inventory on (cs_item_sk = inv_item_sk)
join warehouse on (w_warehouse_sk=inv_warehouse_sk)
join item on (i_item_sk = cs_item_sk)
join customer_demographics on (cs_bill_cdemo_sk = cd_demo_sk)
join household_demographics on (cs_bill_hdemo_sk = hd_demo_sk)
join date_dim d1 on (cs_sold_date_sk = d1.d_date_sk)
join date_dim d2 on (inv_date_sk = d2.d_date_sk)
join date_dim d3 on (cs_ship_date_sk = d3.d_date_sk)
left outer join promotion on (cs_promo_sk=p_promo_sk)
left outer join catalog_returns on (cr_item_sk = cs_item_sk and cr_order_number = cs_order_number)
where d1.d_week_seq = d2.d_week_seq
  and inv_quantity_on_hand < cs_quantity
  and d3.d_date > d1.d_date + interval '3 day'
  and hd_buy_potential = '>10000'
  and d1.d_year = 1998
  and cd_marital_status = 'U'
  and cd_dep_count between 9 and 11
  and i_category IN ('Children', 'Jewelry', 'Men')
  and cs_wholesale_cost BETWEEN 35 AND 55
group by i_item_desc,w_warehouse_name,d1.d_week_seq
order by total_cnt desc, i_item_desc, w_warehouse_name, d_week_seq
limit 100;
```

## Per-Rewrite Configuration (SET LOCAL)

You have two optimization levers: SQL rewrite AND per-query configuration.
After writing your rewrite, analyze its execution profile and emit SET LOCAL
commands that fix planner-level bottlenecks specific to YOUR rewrite.

## System Resource Envelope

Memory budget: shared_buffers=4GB, effective_cache_size=12GB
Global work_mem: 128MB (per-operation)
Active connections: ~10 (work_mem headroom: safe up to 512MB per-op)
Storage: SSD (random_page_cost=1.1)
Parallel capacity: max_parallel_workers=8, per_gather=4

SET LOCAL permissions:
  user-level (always available): effective_cache_size, enable_hashjoin, enable_mergejoin, enable_nestloop, enable_seqscan, from_collapse_limit, geqo_threshold, hash_mem_multiplier, jit, jit_above_cost, join_collapse_limit, max_parallel_workers_per_gather, parallel_setup_cost, parallel_tuple_cost, random_page_cost, work_mem

### Tunable Parameters (whitelist — only these are allowed)

- **effective_cache_size** (1024MB–65536MB): Advisory: how much OS cache to expect (MB). Safe to set aggressively.
- **enable_hashjoin** (on | off): Enable hash join plan type.
- **enable_mergejoin** (on | off): Enable merge join plan type.
- **enable_nestloop** (on | off): Enable nested-loop join plan type.
- **enable_seqscan** (on | off): Enable sequential scan plan type.
- **from_collapse_limit** (1–20): Max FROM items before subqueries stop being flattened.
- **geqo_threshold** (2–20): Number of FROM items that triggers genetic query optimizer.
- **hash_mem_multiplier** (1.0–10.0): Multiplier applied to work_mem for hash-based operations.
- **jit** (on | off): Enable JIT compilation.
- **jit_above_cost** (0.0–1000000.0): Query cost above which JIT is activated.
- **join_collapse_limit** (1–20): Max FROM items before planner stops trying all join orders.
- **max_parallel_workers_per_gather** (0–8): Max parallel workers per Gather node.
- **parallel_setup_cost** (0.0–10000.0): Planner estimate of cost to launch parallel workers.
- **parallel_tuple_cost** (0.0–1.0): Planner estimate of cost to transfer a tuple to parallel worker.
- **random_page_cost** (1.0–10.0): Planner estimate of cost of a random page fetch (1.0 = SSD, 4.0 = HDD).
- **work_mem** (64MB–2048MB): Memory for sorts/hashes per operation (MB). Allocated PER-OPERATION, not per-query. Count hash/sort ops in EXPLAIN before sizing.

### Rules
- Every SET LOCAL MUST cite a specific EXPLAIN node your rewrite creates/changes
- work_mem is PER-OPERATION: count hash/sort ops in your rewrite before sizing
- random_page_cost: ONLY change if your rewrite creates index-favorable access patterns
- Empty is valid: if your rewrite has no planner bottleneck, emit no SET LOCAL
- Stay within the resource envelope bounds above

### Output Format
If you recommend SET LOCAL, prefix your SQL block with the commands:

```sql
SET LOCAL work_mem = '512MB';
SET LOCAL jit = 'off';
-- rewritten query follows
WITH ...
SELECT ...
```

If no config changes help, just output the rewritten SQL directly.

## Rewrite Checklist (must pass before final SQL)

- Follow every node in `TARGET_DAG` and produce each `NODE_CONTRACT` output column exactly.
- Keep all semantic invariants from `Semantic Contract` and `Constraints` (including join/null behavior).
- Preserve all literals and the exact final output schema/order.
- Apply `Hazard Flags` and `Regression Warnings` as hard guards against known failure modes.

## Output

Return the complete rewritten SQL query. The query must be syntactically
valid and ready to execute.

### Column Completeness Contract

Your rewritten query MUST produce **exactly** these output columns (same names, same order):

  1. `i_item_desc`
  2. `w_warehouse_name`
  3. `d_week_seq`
  4. `no_promo`
  5. `promo`
  6. `total_cnt`

Do NOT add, remove, or rename any columns. The result set schema must be identical to the original query.

```sql
-- Your rewritten query here
```

After the SQL, explain the mechanism:

```
Changes: <1-2 sentences: what structural change + the expected mechanism>
  e.g., 'Consolidated 4 store_sales scans into 1 with CASE branches — reduces I/O by 3x'
  e.g., 'Deferred customer join to resolve_names — joins 4K rows instead of 5.4M'
Expected speedup: <estimate>
```

Now output your rewritten SQL: