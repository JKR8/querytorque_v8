1. **Eliminated duplicate table scans**: The original query scanned `web_sales` twice (once for each subquery), totaling ~1.15M rows scanned. The optimized version scans it once, reducing I/O and processing time by approximately half for this table.
2. **Used conditional aggregation**: By computing both counts (amc and pmc) in a single pass with CASE statements, we avoid redundant joins and filtering operations, leveraging the filtered results from smaller tables more efficiently.
3. **Simplified predicate logic**: Changed `t_hour BETWEEN X AND X+1` to `t_hour IN (10, 11, 16, 17)` for clarity and potential index utilization, though the execution plan shows sequential scans on `time_dim` are already low-cost.
4. **Maintained semantics**: The result is mathematically identicalâ€”counting rows where `t_hour` is 10-11 for the numerator and 16-17 for the denominator, with all other filters unchanged.
5. **Reduced join overhead**: Instead of performing two separate sets of joins (each with hash joins costing ~1-1.4%), we perform one set of joins, which should cut the hash join overhead roughly in half.