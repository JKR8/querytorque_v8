Generate minimal witness data so this SQL query returns at least 2 rows.
Output ONLY valid JSON â€” no markdown fences, no extra text.

## Query analysis (pre-computed)
TABLES:
  call_center
  catalog_returns
  customer
  customer_address
  customer_demographics
  date_dim
  household_demographics

JOINS:
  customer_address.ca_address_sk = customer.c_current_addr_sk
  household_demographics.hd_demo_sk = customer.c_current_hdemo_sk
  customer_demographics.cd_demo_sk = customer.c_current_cdemo_sk
  catalog_returns.cr_returning_customer_sk = customer.c_customer_sk
  catalog_returns.cr_call_center_sk = call_center.cc_call_center_sk
  catalog_returns.cr_returned_date_sk = date_dim.d_date_sk

FILTERS:
  customer_address.ca_gmt_offset = -7
  date_dim.d_moy = 2
  date_dim.d_year = 1998
  customer_demographics.cd_marital_status = 'M'
  customer_demographics.cd_education_status = 'Unknown'
  customer_demographics.cd_marital_status = 'W'
  customer_demographics.cd_education_status = 'Advanced Degree'

AGGREGATES:
  GROUP BY: call_center.cc_call_center_id, call_center.cc_name, call_center.cc_manager, customer_demographics.cd_marital_status, customer_demographics.cd_education_status

COLUMNS NEEDED (table.column : type):
  call_center: cc_call_center_id (VARCHAR), cc_call_center_sk (INTEGER), cc_manager (VARCHAR), cc_name (VARCHAR)
  catalog_returns: cr_call_center_sk (INTEGER), cr_net_loss (DECIMAL(7), cr_returned_date_sk (INTEGER), cr_returning_customer_sk (INTEGER)
  customer: c_current_addr_sk (INTEGER), c_current_cdemo_sk (INTEGER), c_current_hdemo_sk (INTEGER), c_customer_sk (INTEGER)
  customer_address: ca_address_sk (INTEGER), ca_gmt_offset (DECIMAL(5)
  customer_demographics: cd_demo_sk (INTEGER), cd_education_status (VARCHAR), cd_marital_status (VARCHAR)
  date_dim: d_date_sk (INTEGER), d_moy (INTEGER), d_year (INTEGER)
  household_demographics: hd_demo_sk (INTEGER)

## SQL (for reference)
select  
        cc_call_center_id Call_Center,
        cc_name Call_Center_Name,
        cc_manager Manager,
        sum(cr_net_loss) Returns_Loss
from
        call_center,
        catalog_returns,
        date_dim,
        customer,
        customer_address,
        customer_demographics,
        household_demographics
where
        cr_call_center_sk       = cc_call_center_sk
and     cr_returned_date_sk     = d_date_sk
and     cr_returning_customer_sk= c_customer_sk
and     cd_demo_sk              = c_current_cdemo_sk
and     hd_demo_sk              = c_current_hdemo_sk
and     ca_address_sk           = c_current_addr_sk
and     d_year                  = 1998 
and     d_moy                   = 2
and     ( (cd_marital_status       = 'M' and cd_education_status     = 'Unknown')
        or(cd_marital_status       = 'W' and cd_education_status     = 'Advanced Degree'))
and     hd_buy_potential like '1001-5000%'
and     ca_gmt_offset           = -7
group by cc_call_center_id,cc_name,cc_manager,cd_marital_status,cd_education_status
order by sum(cr_net_loss) desc;


## Example (different query, shows the format)
For a query: "SELECT c_name FROM customer, store WHERE c_store_sk = s_store_sk AND s_state = 'TX' AND c_age > (SELECT avg(c_age)*1.2 FROM customer c2 WHERE c2.c_store_sk = c.c_store_sk)"

{"reasoning": "Need 2+ customers at same store. avg age = (50+20)/2=35, 1.2*35=42. Customer with age 50>42 qualifies. Second store: avg=(60+25)/2=42.5, 1.2*42.5=51. Customer 60>51 qualifies.", "tables": {"store": {"columns": ["s_store_sk", "s_state"], "rows": [[1000, "TX"], [1001, "TX"]]}, "customer": {"columns": ["c_customer_sk", "c_name", "c_store_sk", "c_age"], "rows": [[2000, "Alice", 1000, 50], [2001, "Bob", 1000, 20], [2002, "Carol", 1001, 60], [2003, "Dan", 1001, 25]]}}}

## Rules
1. Include ONLY the columns listed in COLUMNS NEEDED above.
2. Every _sk join must have matching rows on both sides.
3. For correlated aggregate comparisons (value > avg*1.2): you need 2+ rows per group.
   The "winner" row's value must exceed 1.2x the group average (which includes that row).
   SHOW THE MATH in reasoning.
4. Denominators in division must be > 0.
5. String values are case-sensitive: use exact values from FILTERS.
6. Use integer keys starting at 1000.
7. Dates as strings: "2002-06-15".
8. null for columns you don't care about.
