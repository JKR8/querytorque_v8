## Role

You are a SQL optimization analyst for PostgreSQL. Your mission: diagnose this query's bottleneck from the EXPLAIN plan and design 8-16 independent transform PROBES.

A team of workers will execute each probe independently — one transform per worker. Each worker outputs a PatchPlan JSON that transforms the query's IR structure. You design the strike package, they execute it.

You have the full engine playbook, gold examples, and AST-detected transform matches below. Use them to design probes that exploit KNOWN engine weaknesses, not generic rewrites.

## Query: query069_multi_i1

**Dialect**: POSTGRES

```sql
select 
  cd_gender,
  cd_marital_status,
  cd_education_status,
  count(*) cnt1,
  cd_purchase_estimate,
  count(*) cnt2,
  cd_credit_rating,
  count(*) cnt3
 from
  customer c,customer_address ca,customer_demographics
 where
  c.c_current_addr_sk = ca.ca_address_sk and
  ca_state in ('CO','NC','TX') and
  cd_demo_sk = c.c_current_cdemo_sk
  and cd_marital_status in ('S', 'M', 'U')
  and cd_education_status in ('Primary', 'College') and
  exists (select *
          from store_sales,date_dim
          where c.c_customer_sk = ss_customer_sk and
                ss_sold_date_sk = d_date_sk and
                d_year = 2002 and
                d_moy between 10 and 10+2
                and ss_list_price between 80 and 169
          ) and
   (not exists (select *
            from web_sales,date_dim
            where c.c_customer_sk = ws_bill_customer_sk and
                  ws_sold_date_sk = d_date_sk and
                  d_year = 2002 and
                  d_moy between 10 and 10+2
                  and ws_list_price between 80 and 169
            ) and
    not exists (select *
            from catalog_sales,date_dim
            where c.c_customer_sk = cs_ship_customer_sk and
                  cs_sold_date_sk = d_date_sk and
                  d_year = 2002 and
                  d_moy between 10 and 10+2
                  and cs_list_price between 80 and 169)
            )
 group by cd_gender,
          cd_marital_status,
          cd_education_status,
          cd_purchase_estimate,
          cd_credit_rating
 order by cd_gender,
          cd_marital_status,
          cd_education_status,
          cd_purchase_estimate,
          cd_credit_rating
 limit 100;
```


## Current Execution Plan

```
Total execution time: 33245.8ms
Planning time: 1.6ms

-> Limit  (rows=80 loops=1 time=33245.8ms)
  -> Aggregate  (rows=80 loops=1 time=33245.8ms)
    -> Nested Loop Anti  (rows=964 loops=1 time=33241.7ms)
       Join Filter: (c.c_customer_sk = catalog_sales.cs_ship_customer_sk)
      -> Nested Loop Anti  (rows=1,105 loops=1 time=7671.7ms)
         Join Filter: (c.c_customer_sk = web_sales.ws_bill_customer_sk)
        -> Gather Merge  (rows=1,128 loops=1 time=604.1ms)
           Workers: 2/2 launched
          -> Sort  (rows=376 loops=3 time=592.0ms)
             Sort Method: quicksort  Space: 56kB (Memory)
            -> Nested Loop Inner  (rows=376 loops=3 time=591.3ms)
              -> Hash Join Semi  (rows=1,691 loops=3 time=573.6ms)
                 Hash Cond: (c.c_customer_sk = store_sales.ss_customer_sk)
                -> Hash Join Inner  (rows=22K loops=3 time=48.2ms)
                   Hash Cond: (c.c_current_addr_sk = ca.ca_address_sk)
                  -> Seq Scan on customer c  (rows=167K loops=3 time=15.9ms)
                  -> Hash  (rows=11K loops=3 time=14.1ms)
                    -> Seq Scan on customer_address ca  (rows=11K loops=3 time=12.7ms)
                       Filter: (ca_state = ANY ('{CO,NC,TX}'::bpchar[]))
                       Rows Removed by Filter: 72K
                -> Hash  (rows=151K loops=3 time=507.3ms)
                   Batches: 8  Memory: 3264kB
                  -> Nested Loop Inner  (rows=151K loops=3 time=217.2ms)
                    -> Index Only Scan on date_dim  (rows=31 loops=3 time=0.6ms)
                       Index Cond: ((d_year = 2002) AND (d_moy >= 10) AND (d_moy <= 12))
                    -> Index Only Scan on store_sales  (rows=4,912 loops=92 time=6.8ms)
                       Filter: ((ss_list_price >= '80'::numeric) AND (ss_list_price <= '169'::numeric))
                       Index Cond: (ss_sold_date_sk = date_dim.d_date_sk)
                       Rows Removed by Filter: 7,334
              -> Index Scan on customer_demographics  (rows=0 loops=5074 time=0.0ms)
                 Filter: ((cd_education_status = ANY ('{Primary,College}'::bpchar[])) AND (cd_marital_status = ANY ('{S,M,...
                 Index Cond: (cd_demo_sk = c.c_current_cdemo_sk)
                 Rows Removed by Filter: 1
        -> Materialize  (rows=84K loops=1128 time=3.4ms)
          -> Gather  (rows=84K loops=1 time=77.3ms)
             Workers: 2/2 launched
            -> Nested Loop Inner  (rows=28K loops=3 time=35.5ms)
              -> Index Only Scan on date_dim date_dim_1  (rows=31 loops=3 time=0.5ms)
                 Index Cond: ((d_year = 2002) AND (d_moy >= 10) AND (d_moy <= 12))
              -> Index Scan on web_sales  (rows=917 loops=92 time=1.1ms)
                 Filter: ((ws_list_price >= '80'::numeric) AND (ws_list_price <= '169'::numeric))
                 Index Cond: (ws_sold_date_sk = date_dim_1.d_date_sk)
                 Rows Removed by Filter: 1,827
      -> Materialize  (rows=311K loops=1105 time=12.5ms)
        -> Nested Loop Inner  (rows=332K loops=1 time=246.2ms)
          -> Index Scan on date_dim date_dim_2  (rows=92 loops=1 time=0.1ms)
             Index Cond: ((d_year = 2002) AND (d_moy >= 10) AND (d_moy <= 12))
          -> Index Scan on catalog_sales  (rows=3,614 loops=92 time=2.5ms)
             Filter: ((cs_list_price >= '80'::numeric) AND (cs_list_price <= '169'::numeric))
             Index Cond: (cs_sold_date_sk = date_dim_2.d_date_sk)
             Rows Removed by Filter: 7,612
```


## IR Structure (for patch targeting)

```
S0 [SELECT]
  MAIN QUERY (via Q_S0)
    FROM: customer c, customer_address ca, customer_demographics
    WHERE [dae945277e160f9b]: c.c_current_addr_sk = ca.ca_address_sk AND ca_state IN ('CO', 'NC', 'TX') AND cd_demo_sk = c.c_cu...
    GROUP BY: cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating
    ORDER BY: cd_gender, cd_marital_status, cd_education_status, cd_purchase_estimate, cd_credit_rating

Patch operations: insert_cte, replace_expr_subtree, replace_where_predicate, replace_from, delete_expr_subtree
Target: by_node_id (statement, e.g. "S0") + by_anchor_hash (expression)
```

**Note**: Use `by_node_id` (e.g., "S0") and `by_anchor_hash` (16-char hex) from map above to target patch operations.


## Optimization Families

This is a briefing of what we know, not a set of hard rules. Use your judgement about what's worth trying based on the EXPLAIN plan above.

**3 families have proven gold examples** on this engine. All 6 families are listed — those without gold examples are still valid strategies if the EXPLAIN plan warrants them.

Choose the most relevant families for this query based on:
- Query structure (CTEs, subqueries, joins, aggregations, set operations)
- Execution plan signals (WHERE placement, repeated scans, correlated subqueries)
- Problem signature (cardinality estimation errors, loops vs sets, filter ordering)



### Family A: Early Filtering (Predicate Pushback)
**Description**: Push small filters into CTEs early, reduce row count before expensive operations
**Speedup Range**: 1.3–4.0x (~35% of all wins)
**Use When**:
  1. Late WHERE filters on dimension tables
  2. Cascading CTEs with filters applied downstream
  3. Expensive joins after filters could be pushed earlier

**Gold Example**: None yet observed on PostgreSQL. Strategy is valid if EXPLAIN evidence supports it.



### Family B: Decorrelation (Sets Over Loops)
**Description**: Convert correlated subqueries to standalone CTEs with GROUP BY, eliminate per-row re-execution
**Speedup Range**: 2.4–2.9x (~15% of all wins)
**Use When**:
  1. Correlated subqueries in WHERE clause
  2. Scalar aggregates computed per outer row
  3. DELIM_SCAN in execution plan (indicates correlation)

**Gold Example**: `early_filter_decorrelate` (27.80x (V2 DSB SF10, was 1.13x in V1))



### Family C: Aggregation Pushdown (Minimize Rows Touched)
**Description**: Aggregate before expensive joins when GROUP BY keys ⊇ join keys, reduce intermediate sizes
**Speedup Range**: 1.3–15.3x (~5% of all wins (high variance))
**Use When**:
  1. GROUP BY happens after large joins
  2. GROUP BY keys are subset of join keys
  3. Intermediate result size >> final result size

**Gold Example**: None yet observed on PostgreSQL. Strategy is valid if EXPLAIN evidence supports it.



### Family D: Set Operation Optimization (Sets Over Loops)
**Description**: Replace INTERSECT/UNION-based patterns with EXISTS/NOT EXISTS, avoid full materialization
**Speedup Range**: 1.7–2.7x (~8% of all wins)
**Use When**:
  1. INTERSECT patterns between large sets
  2. UNION ALL with duplicate elimination
  3. Set operations materializing full intermediate results

**Gold Example**: None yet observed on PostgreSQL. Strategy is valid if EXPLAIN evidence supports it.



### Family E: Materialization / Prefetch (Don't Repeat Work)
**Description**: Extract repeated scans or pre-compute intermediate results for reuse across multiple consumers
**Speedup Range**: 1.3–6.2x (~18% of all wins)
**Use When**:
  1. Repeated scans of same table with different filters
  2. Dimension filters applied independently multiple times
  3. CTE referenced multiple times with implicit re-evaluation

**Gold Example**: `pg_date_consolidation` (3.10x)



### Family F: Join Transform (Right Shape First)
**Description**: Restructure join topology: convert comma joins to explicit INNER JOIN, optimize join order, eliminate self-joins via single-pass aggregation
**Speedup Range**: 1.8–8.6x (~19% of all wins)
**Use When**:
  1. Comma-separated joins (implicit cross joins) in FROM clause
  2. Self-joins scanning same table multiple times
  3. Dimension-fact join order suboptimal for predicate pushdown

**Gold Example**: `pg_date_cte_explicit_join` (2.28x)



## Engine Playbook (POSTGRES)

# PostgreSQL Rewrite Playbook
# DSB SF10 field intelligence

## ENGINE STRENGTHS — do NOT rewrite these patterns

1. **BITMAP_OR_SCAN**: Multi-branch ORs on indexed columns handled via bitmap combination in one scan. Splitting ORs to UNION ALL is lethal (0.21x observed).
2. **EXISTS semi-join**: Uses early termination. Converting a single EXISTS to a materializing CTE caused 0.50x, 0.75x — semi-join destroyed. **Exception**: When 3+ correlated NOT EXISTS channels scan different fact tables (e.g., Q069 17.48x), pre-materializing each channel into DISTINCT CTEs with LEFT JOIN IS NULL anti-pattern eliminates repeated Materialize node re-scans.
3. **INNER JOIN reordering**: Freely reorders INNER JOINs by selectivity estimates. Do NOT manually restructure INNER JOIN order.
4. **Index-only scan**: Reads only index when covering all requested columns. Small dimension lookups may not need CTEs.
5. **Parallel query execution**: Large scans and aggregations parallelized across workers. CTEs block parallelism (materialization is single-threaded).
6. **JIT compilation**: JIT-compiles complex expressions for long-running queries (>100ms).

## GLOBAL GUARDS

1. OR conditions on indexed columns → never split to UNION ALL (0.21x observed)
2. Single EXISTS → never materialize into CTE (0.50x, 0.75x — semi-join destroyed). Exception: 3+ NOT EXISTS channels → pre-materialize each into DISTINCT CTE + LEFT JOIN IS NULL (17.48x observed)
3. INNER JOIN order → never restructure (optimizer handles reordering)
4. Small dimensions (< 10K rows) → index-only scan may be faster than CTE
5. Baseline < 100ms → skip CTE-based rewrites (overhead exceeds savings)
6. CTEs block parallel execution — only use when benefit outweighs parallelism loss
7. Use AS MATERIALIZED when CTE must not be inlined (decorrelation, shared scans)
8. Preserve efficient existing CTEs — don't decompose working patterns
9. Verify NULL semantics in NOT IN conversions
10. ROLLUP/window in same query → CTE may prevent pushdown optimizations
11. Never inline a large UNION CTE — re-execution multiplied per reference (0.16x — 6 fact scans re-executed)
12. Max 2 cascading fact-table CTE chains — deeper chains block parallelism
13. EXPLAIN cost gaps ≠ runtime gains for config tuning — 6 false positives caught (up to 84% EXPLAIN gap → 0% runtime). Always 3-race validate config changes.

---

## DOCUMENTED CASES

Cases ordered by safety (zero-regression cases first, then by decreasing risk).

**P6: Multiple Date_dim Aliases with Overlapping Filters** (SMALLEST SET FIRST) — ZERO REGRESSIONS

| Aspect | Detail |
|---|---|
| Detect | 2+ date_dim aliases in FROM with similar year/month_seq/moy predicates. |
| Gates | 2+ date_dim instances with overlapping date predicates. Selectivity < 1% of date_dim (always true for year+month). Combine with explicit JOIN conversion when comma joins present. |
| Treatments | date_consolidation (1 win, 3.10x), date_cte_isolate (3 wins + 7 improved). Apply first — date CTE is smallest, most reliable transform. |
| Failures | None observed. |

**P3: Same Fact+Dimension Scan Repeated Across Subquery Boundaries** (DON'T REPEAT WORK) — ZERO REGRESSIONS

| Aspect | Detail |
|---|---|
| Detect | Identical scan subtrees appearing 2+ times in EXPLAIN with similar costs. Same fact table joined to same dimensions in multiple subqueries, or self-join with different GROUP BY granularity. |
| Gates | 2+ subqueries scanning same fact table with identical filters. COUNT/SUM/AVG/MIN/MAX only (not STDDEV/PERCENTILE). Self-join → consolidate into single CTE. 3 channel scans → single_pass_aggregation. |
| Treatments | single_pass_aggregation (1 win, 1.98x), self_join_pivot (1 win, 1.79x) |
| Failures | None observed. |

**P4: Non-Equi Join Without Prefiltering** (MINIMIZE ROWS TOUCHED) — ZERO REGRESSIONS

| Aspect | Detail |
|---|---|
| Detect | Expensive non-equi join (BETWEEN, <, >) in EXPLAIN with large inputs. Neither side filtered. |
| Gates | Non-equi join predicate exists. Both join inputs > 10K rows. At least one side has selective dimension filter available. |
| Treatments | pg_materialized_dimension_fact_prefilter (1 win, 12.07x). Apply after P1 and P6. |
| Failures | None observed. |

**P1: Comma Join Confusing Cardinality Estimation** (ARM THE OPTIMIZER)

| Aspect | Detail |
|---|---|
| Detect | FROM t1, t2, t3 WHERE t1.key = t2.key (comma joins, no explicit JOIN). Hash/nested-loop join with poor row estimates in EXPLAIN. |
| Gates | Multiple tables in comma-separated FROM with equi-join predicates. Dimension filters available. 1-2 fact tables only (3+ → join order lock). Max 3-4 dimension CTEs. Stop if all JOINs already explicit → skip to P6/P7. |
| Treatments | pg_date_cte_explicit_join (4 wins, 2.1x avg), pg_dimension_prefetch_star (3 wins, 2.8x avg), explicit_join_materialized (2 wins, 5.9x avg) |
| Failures | 0.88x (explicit join overhead on simple query) |

**P5: Set Operation Materializing Full Result Sets** (SETS OVER LOOPS)

| Aspect | Detail |
|---|---|
| Detect | INTERSECT/EXCEPT between large result sets. Correlated EXISTS on 3+ channels (store, web, catalog). |
| Gates | INTERSECT with 10K+ rows → convert to EXISTS. Correlated NOT EXISTS on 3+ channels → materialize channel sets. Simple EXISTS (single channel) → KEEP EXISTS. NOT EXISTS already hash anti-join in EXPLAIN → STOP. |
| Treatments | intersect_to_exists (1 win, 1.78x), set_operation_materialization (1 win, 17.48x) |
| Failures | 0.75x (over-materialized date CTE in EXISTS path) |

**P2: Correlated Subquery Executing Per Outer Row** (SETS OVER LOOPS) — HIGHEST IMPACT

| Aspect | Detail |
|---|---|
| Detect | Nested loop in EXPLAIN, inner side re-executes aggregate per outer row. SQL: WHERE col > (SELECT AGG(...) FROM ... WHERE outer.key = inner.key). If EXPLAIN shows hash join on correlation key → already decorrelated → STOP. |
| Gates | Correlated scalar subquery with aggregate (AVG, SUM, COUNT). NOT EXISTS: NEVER decorrelate (destroys semi-join, 0.50x). Inner = outer table → extract common scan to shared CTE. ALWAYS use AS MATERIALIZED. 1-2 fact tables safe, 3+ → STOP. |
| Treatments | inline_decorrelate_materialized (3 wins, avg 500x), decorrelate (8 wins, avg 3.2x), shared_scan + decorrelate (2 wins, avg 7000x) |
| Failures | 0.51x (multi-fact join lock), 0.75x (EXISTS materialized) |

**P7: Multi-Dimension Prefetch for Star-Schema Aggregation** (SMALLEST SET FIRST) — CAUTION

| Aspect | Detail |
|---|---|
| Detect | Large fact table scan followed by late dimension filter in EXPLAIN. Star schema with 3+ dimension filters in WHERE. |
| Gates | 3+ selective dimension filters, each < 10% of dimension table. Single fact table, NOT self-join or multi-fact. Stop if self-join → use P3 (0.25x). Stop if multi-fact → join order lock (0.51x). |
| Treatments | pg_dimension_prefetch_star (2 wins, 2.5x avg), multi_dimension_prefetch (1 win, 2.50x) |
| Failures | 0.25x (self-join), 0.51x (multi-fact) |

---

## CONFIG TUNING PATTERNS

Config tuning is ADDITIVE to SQL rewrite — not a substitute. Apply after SQL rewrite.
Evidence: 52 queries benchmarked, 25 config wins, 3-race validated (PG 14.3, SF10).
CRITICAL: EXPLAIN ANALYZE cost gaps do NOT predict runtime gains. 6 false positives
caught where EXPLAIN showed 38-84% improvement but runtime showed 0% or regression.
Always 3-race validate config changes.

**C1: Merge Join Forcing Suboptimal Plan** — HIGHEST IMPACT hint

| Aspect | Detail |
|---|---|
| Detect | EXPLAIN shows Merge Join with Sort node below it on large unsorted inputs (both > 10K rows). |
| Config | `/*+ Set(enable_mergejoin off) */` |
| Evidence | 6 wins (+8.6%–+82.5%, avg +50.6%). |
| Risk | LOW when Sort+MJ visible. Do NOT disable on pre-sorted data. |

**C2: Cost Model Undervaluing Index Scans on SSD** — HIGHEST RECOVERY

| Aspect | Detail |
|---|---|
| Detect | Seq Scan on fact tables despite btree indexes on join/filter columns. |
| Config | `SET LOCAL random_page_cost = '1.1'; SET LOCAL effective_cache_size = '48GB'` |
| Evidence | 6 wins (+46.0%–+89.0%, avg +71.1%). Rescued 3 rewrite regressions. Nonlinear interaction — neither alone sufficient. |
| Risk | LOW on SSD. Zero regressions observed. |

**C3: Parallelism Underutilized on Large Scans** — MOST VERSATILE

| Aspect | Detail |
|---|---|
| Detect | Large Seq Scan (>100K rows) without Gather/Parallel node, query > 500ms. |
| Config | `SET LOCAL max_parallel_workers_per_gather = '4'; SET LOCAL parallel_setup_cost = '100'; SET LOCAL parallel_tuple_cost = '0.001'` |
| Evidence | 5 standalone wins (+6.2%–+28.2%, avg +14.3%). Also in 10+ combo wins. |
| Risk | MEDIUM. 7.34x REGRESSION on 244ms query. NEVER on queries < 500ms. par4-alone -15.3% — must include work_mem. |

**C4: Hash/Sort Spilling to Disk** — TARGETED

| Aspect | Detail |
|---|---|
| Detect | Hash Batches > 1 or Sort Space Type = 'Disk' in EXPLAIN ANALYZE. |
| Config | work_mem sized by op count: ≤2 ops → 512MB, 3-5 → 256MB, 6+ → 128MB |
| Evidence | 4 wins (+11.4%–+41.5%, avg +21.7%). Often needs par4. |
| Risk | LOW. work_mem is per-operation — count sort+hash ops before sizing. |

**C5: Nested Loop on Large Join Inputs** — HIGH IMPACT hint

| Aspect | Detail |
|---|---|
| Detect | Nested Loop in EXPLAIN with >10K rows on both sides, equi-join condition exists. |
| Config | `/*+ Set(enable_nestloop off) */` |
| Evidence | 3 wins (+42.5%–+81.3%, avg +60.4%). |
| Risk | HIGH. -1454% regression observed. NEVER on correlated subqueries (use P2 instead). |

**C6: Sort Overhead on Pre-Ordered Data** — RARE

| Aspect | Detail |
|---|---|
| Detect | Sort node on index-ordered data or where hash aggregation is viable. |
| Config | `SET LOCAL enable_sort = 'off'` |
| Evidence | 2 wins (+4.7%–+68.2%, avg +36.5%). High variance (3.2-7.7%). |
| Risk | MEDIUM. Forces hash-based execution. Validate carefully. |

---

## PRUNING GUIDE

| Plan shows | Skip |
|---|---|
| No comma joins (all explicit JOINs) | P1 (comma join fix) |
| No nested loops on large tables | P2 (decorrelation) |
| Each table appears once | P3 (repeated scans) |
| No non-equi joins (BETWEEN, <, >) | P4 (non-equi prefilter) |
| No INTERSECT/EXCEPT and no correlated multi-channel EXISTS | P5 (set operation) |
| Single date_dim reference | P6 (date consolidation) |
| No GROUP BY or only 1 dimension filter | P7 (multi-dim prefetch) |
| Baseline < 100ms | ALL CTE-based transforms |
| Bitmap OR scan present | OR→UNION rewrites |
| Parallel workers active + query fast | CTE-heavy transforms |

## REGRESSION REGISTRY

| Severity | Transform | Result | Root cause |
|----------|-----------|--------|------------|
| CATASTROPHIC | cte_inlining | 0.16x | Inlined large UNION CTE → 6 fact scans re-executed 2x each |
| SEVERE | multi_dim_prefetch | 0.15x | CTEs blocked date-predicate pushdown on 90-day interval join |
| SEVERE | dimension_prefetch | 0.25x | Applied star-schema pattern to 6-way self-join → parallelism destroyed |
| MAJOR | cte_materialization | 0.30x | Multi-scan CTE overhead similar to above cte_inlining pattern |
| MAJOR | early_fact_filtering | 0.51x | Disabled nestloop too aggressively + DISTINCT forced hash spill |
| MAJOR | date_cte_prefetch | 0.75x | Over-materialized date CTE in EXISTS path → destroyed semi-join |
| MODERATE | explicit_join | 0.88x | Explicit join conversion overhead exceeded benefit on simple query |
| CATASTROPHIC | forced_parallelism (C3) | 7.34x regr | Worker startup + coordination overhead on 244ms query. NEVER force par on < 500ms |
| CATASTROPHIC | enable_nestloop_off (C5) | -1454% | NL was correct plan. Disabling forced catastrophic merge/hash on unsuitable query |
| MAJOR | geqo_off | -254% | Exhaustive planner found "better" cost plan on 19 joins but cardinality errors made it catastrophic |
| MAJOR | par4_without_wm | -15.3% | Parallelism without sufficient work_mem causes hash spill under parallel execution |


## AST-Detected Transform Matches

These transforms matched this query's AST structure (precondition overlap). Use as additional suggestions — you are NOT limited to this list.

- **date_cte_explicit_join** (Family F, 60% overlap): Dimension Isolation + Explicit Joins: materialize selective dimension filters into CTEs to create tiny hash tables, AND convert comma-separated joins to explicit JOIN syntax. On PostgreSQL, the combination enables better hash join planning with a tiny probe table.
  Engine gap: COMMA_JOIN_WEAKNESS
- **pg_self_join_decomposition** (Family E, 60% overlap): Shared Materialization (PG): when the same fact+dimension scan appears multiple times in self-join patterns, materialize it once as a CTE and derive all needed aggregates from the same result. PostgreSQL materializes CTEs by default, making this extremely effective.
  Engine gap: CROSS_CTE_PREDICATE_BLINDNESS
- **materialized_dimension_fact_prefilter** (Family F, 57% overlap): Staged Reduction for Non-Equi Joins: when queries have expensive non-equi joins, reduce BOTH dimension and fact table sizes via MATERIALIZED CTEs before the join. Combined selectivity dramatically cuts the search space for inequality predicates.
  Engine gap: NON_EQUI_JOIN_INPUT_BLINDNESS
- **early_filter_decorrelate** (Family B, 50% overlap): Early Selection + Decorrelation: push dimension filters into CTE definitions before materialization, and decorrelate correlated subqueries by pre-computing thresholds in separate CTEs. Filters reduce rows early; decorrelation replaces per-row subquery execution with a single pre-computed JOIN.
  Engine gap: CORRELATED_SUBQUERY_PARALYSIS
- **inline_decorrelate_materialized** (Family B, 50% overlap): Inline Decorrelation with MATERIALIZED CTEs: When a WHERE clause contains a correlated scalar subquery (e.g., col > (SELECT 1.3 * avg(col) FROM ... WHERE correlated_key = outer.key)), PostgreSQL re-executes the subquery per outer row. Fix: decompose into 3 MATERIALIZED CTEs — (1) pre-filter dimension table, (2) pre-filter fact table by date range, (3) compute per-key aggregate threshold from filtered data — then JOIN the threshold CTE in the final query. MATERIALIZED keyword prevents PG from inlining the CTEs back into correlated form.
  Engine gap: CORRELATED_SUBQUERY_PARALYSIS

## Your Task

### Step 1: BOTTLENECK HYPOTHESIS (2-3 sentences)
Cite specific EXPLAIN operators, row counts, and cost. This hypothesis
gets passed to every worker as shared context.

### Step 2: DESIGN 8-16 PROBES
Each probe = ONE narrow transform applied to ONE specific part of the query.
Draw from the playbook pathologies, gold examples, AST matches, and your
own EXPLAIN-driven hypotheses.

Each probe's `target` field must tell the worker exactly WHERE and HOW to
apply the transform — the worker uses it to derive a target IR and build
a PatchPlan.

Good probes are specific:
- "Convert the 3 correlated NOT EXISTS subqueries (web_sales, catalog_sales) into MATERIALIZED CTEs with DISTINCT customer_sk, then use LEFT JOIN ... IS NULL anti-pattern"
- "Extract the shared date_dim filter (d_year=2002, d_moy BETWEEN 10 AND 12) into a single CTE, join all 3 fact tables through it"
- "Replace comma join customer,customer_address,customer_demographics with explicit INNER JOIN chain"

Bad probes are vague:
- "Optimize the subqueries" (which ones? how?)
- "Add indexes" (not a SQL rewrite)

### Step 3: OUTPUT

```json
{
  "hypothesis": "The bottleneck is ...",
  "probes": [
    {
      "probe_id": "p01",
      "transform_id": "decorrelate_not_exists_to_cte",
      "family": "B",
      "target": "Convert the NOT EXISTS (web_sales, date_dim) correlated subquery into a MATERIALIZED CTE: SELECT DISTINCT ws_bill_customer_sk FROM web_sales JOIN date_dim ON ws_sold_date_sk = d_date_sk WHERE d_year = 2002 AND d_moy BETWEEN 10 AND 12 AND ws_list_price BETWEEN 80 AND 169. Then replace NOT EXISTS with LEFT JOIN cte ON c_customer_sk = ws_bill_customer_sk WHERE ws_bill_customer_sk IS NULL",
      "confidence": 0.95,
      "recommended_examples": ["early_filter_decorrelate"]
    }
  ],
  "dropped": [
    {"transform_id": "materialize_cte", "reason": "No CTEs in original query to materialize"}
  ]
}
```

Rules:
- Design 8-16 probes (more is better — they're cheap)
- Each probe = ONE transform, not a compound strategy
- Rank by expected impact (highest confidence first)
- `target` is critical: specific enough that a worker can derive a target IR from it
- `recommended_examples`: list gold example IDs the worker should use as patch template
- Include `dropped` list for AST catalog suggestions you chose not to fire
- `transform_id` can be a catalog ID or a descriptive name you invent
- Family codes: A=Early Filter, B=Decorrelate, C=Aggregation, D=Set Ops, E=Materialization, F=Join Transform