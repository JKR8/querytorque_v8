```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "multi_dimension_prefetch",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('2002-05-20' AS DATE) AND (CAST('2002-05-20' AS DATE) + INTERVAL '30' DAY)",
        "filtered_items": "SELECT i_item_sk, i_item_id, i_item_desc, i_category, i_class, i_current_price FROM item WHERE i_category IN ('Sports', 'Music', 'Shoes')",
        "main_query": "SELECT i_item_id, i_item_desc, i_category, i_class, i_current_price, SUM(ss_ext_sales_price) AS itemrevenue, SUM(ss_ext_sales_price) * 100 / SUM(SUM(ss_ext_sales_price)) OVER (PARTITION BY i_class) AS revenueratio FROM store_sales JOIN filtered_dates ON ss_sold_date_sk = d_date_sk JOIN filtered_items ON ss_item_sk = i_item_sk GROUP BY i_item_id, i_item_desc, i_category, i_class, i_current_price ORDER BY i_category, i_class, i_item_id, i_item_desc, revenueratio"
      },
      "invariants_kept": [
        "same result rows",
        "same ordering",
        "same column output",
        "grain preserved"
      ],
      "expected_speedup": "3.0x",
      "risk": "low"
    }
  ],
  "explanation": "Prefiltered both dimension tables (date_dim and item) into CTEs with only needed columns before joining with the large fact table. This reduces the join cardinality early and allows the optimizer to use smaller dimension sets. date_dim filter reduces from 73,049 to 31 rows, item filter reduces from 102,000 to filtered subset. Store_sales joins occur with pre-filtered dimension keys, minimizing intermediate result size."
}
```