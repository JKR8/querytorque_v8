```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "date_cte_isolate",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN CAST('1999-02-22' AS DATE) AND CAST('1999-03-24' AS DATE)",
        "filtered_items": "SELECT i_item_sk, i_item_id, i_item_desc, i_category, i_class, i_current_price FROM item WHERE i_category IN ('Sports', 'Books', 'Home')",
        "main_query": "SELECT i_item_id, i_item_desc, i_category, i_class, i_current_price, SUM(ws_ext_sales_price) AS itemrevenue, SUM(ws_ext_sales_price) * 100.0000 / SUM(SUM(ws_ext_sales_price)) OVER (PARTITION BY i_class) AS revenueratio FROM web_sales JOIN filtered_dates ON ws_sold_date_sk = d_date_sk JOIN filtered_items ON ws_item_sk = i_item_sk GROUP BY i_item_id, i_item_desc, i_category, i_class, i_current_price ORDER BY i_category, i_class, i_item_id, i_item_desc, revenueratio LIMIT 100"
      },
      "invariants_kept": [
        "same result rows",
        "same output columns",
        "same ordering",
        "same aggregation semantics"
      ],
      "expected_speedup": "3.5x",
      "risk": "low"
    }
  ],
  "explanation": "Isolated date_dim filter into a CTE (31 rows vs 73K) and item filter into a CTE (102K rows vs full table). This transforms sequential scans with late filtering into early reduction, drastically shrinking the hash join inputs. The date_dim misestimate (471x) is addressed by materializing the filtered dates first. Joins now process only relevant rows early, reducing I/O and hash table sizes."
}
```