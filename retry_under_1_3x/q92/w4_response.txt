Looking at this query, I can see a correlated subquery that's computing an average for each item within a date range, then comparing it to the outer query's discount amount. The query scans web_sales twice (once in outer query, once in subquery) and date_dim twice.

The main opportunity is to decorrelate the subquery by precomputing the average discount per item for the date range once, then joining it with the outer query. This eliminates the repeated scanning and correlated execution.

```json
{
  "rewrite_sets": [
    {
      "id": "rs_01",
      "transform": "decorrelate",
      "nodes": {
        "filtered_dates": "SELECT d_date_sk FROM date_dim WHERE d_date BETWEEN '2000-01-27' AND CAST('2000-04-26' AS DATE)",
        "item_avg_discount": "SELECT ws_item_sk, AVG(ws_ext_discount_amt) AS avg_discount FROM web_sales JOIN filtered_dates ON d_date_sk = ws_sold_date_sk GROUP BY ws_item_sk",
        "main_query": "SELECT SUM(ws_ext_discount_amt) AS \"Excess Discount Amount\" FROM web_sales JOIN item ON i_item_sk = ws_item_sk JOIN filtered_dates ON d_date_sk = ws_sold_date_sk JOIN item_avg_discount ON web_sales.ws_item_sk = item_avg_discount.ws_item_sk WHERE i_manufact_id = 350 AND ws_ext_discount_amt > 1.3 * item_avg_discount.avg_discount ORDER BY SUM(ws_ext_discount_amt) LIMIT 100"
      },
      "invariants_kept": [
        "same result values",
        "same output columns",
        "same ordering",
        "same row count (single row aggregate)"
      ],
      "expected_speedup": "1.8x",
      "risk": "low"
    }
  ],
  "explanation": "Decorrelated the subquery by creating two CTEs: 1) filtered_dates isolates the date range filter, 2) item_avg_discount precomputes the average discount per item for that date range. The main query then joins with these CTEs instead of executing a correlated subquery. This reduces from 2 scans of web_sales and 2 scans of date_dim to 1 scan of each (plus one CTE scan), eliminates the correlated execution overhead, and allows better join optimization."
}
```